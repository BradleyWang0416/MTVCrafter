The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/accelerator.py:498: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-09-27 11:10:38,176 
python train_vqvae_new.py --batch_size 40 --config vqvae_experiment_configs/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/config.yaml --data_mode joint3d --num_frames 16 --sample_stride 1 --data_stride 16 --project_dir vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5 --not_find_unused_parameters --nb_code 4096 --codebook_dim 2048 --loss_type mpjpe --vqvae_type hybrid --hrnet_output_level 3 --vision_guidance_ratio 0.5 --downsample_time [1,2] --frame_upsample_rate [2.0,1.0] --fix_weights --resume_pth  --fix_weights_except stage4.0.branches.3
2025-09-27 11:10:38,177 
PID: 3272535
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/accelerator.py:498: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/accelerator.py:498: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/accelerator.py:498: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
vision backbone weights are fixed
vision backbone weights are fixed
vision backbone weights are fixed
2025-09-27 11:12:16,876 Data loaded with 97196 samples
vision backbone weights are fixed
2025-09-27 11:12:17,418 Trainable parameters: 56,011,523
2025-09-27 11:12:17,418 Non-trainable parameters: 23,812,864
Trainning Epoch:   0%|          | 0/823 [00:00<?, ?it/s]Trainning Epoch:   0%|          | 0/823 [00:00<?, ?it/s]Trainning Epoch:   0%|          | 0/823 [00:00<?, ?it/s]2025-09-27 11:12:19,264 Number of trainable parameters: 56.011523 M
2025-09-27 11:12:19,264 Args: {'num_frames': 16, 'sample_stride': 1, 'data_stride': 16, 'data_mode': 'joint3d', 'load_data_file': '/data2/wxs/DATASETS/Human3.6M_for_MotionBERT/h36m_sh_conf_cam_source_final_wImgPath_wJ3dCam_wJ2dCpn.pkl', 'load_image_source_file': '/data2/wxs/DATASETS/Human3.6M_for_MotionBERT/images_source.pkl', 'load_bbox_file': '/data2/wxs/DATASETS/Human3.6M_for_MotionBERT/bboxes_xyxy.pkl', 'load_text_source_file': '', 'return_extra': [['image']], 'normalize': 'anisotropic', 'filter_invalid_images': True, 'processed_image_shape': [192, 256], 'backbone': 'hrnet_32', 'get_item_list': ['factor_2_5d', 'video_rgb', 'joint3d_image_affined', 'joint3d_image_affined_normed', 'joint3d_image_affined_scale', 'joint3d_image_affined_transl', 'affine_trans', 'affine_trans_inv', 'joint_2_5d_image'], 'config': 'vqvae_experiment_configs/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/config.yaml', 'resume_pth': '', 'batch_size': 40, 'commit_ratio': 0.5, 'nb_code': 4096, 'codebook_dim': 2048, 'max_epoch': 1000000000.0, 'total_iter': 500000, 'world_size': 1, 'rank': 0, 'save_interval': 20000, 'warm_up_iter': 5000, 'print_iter': 200, 'learning_rate': 0.0002, 'lr_schedule': [300000], 'gamma': 0.05, 'weight_decay': 0.0001, 'device': 'cuda', 'project_config': '', 'allow_tf32': False, 'project_dir': 'vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5', 'seed': 6666, 'not_find_unused_parameters': True, 'loss_type': 'mpjpe', 'vqvae_type': 'hybrid', 'joint_data_type': 'joint3d_image_affined_normed', 'hrnet_output_level': 3, 'fix_weights': True, 'fix_weights_except': 'stage4.0.branches.3', 'vision_guidance_ratio': 0.5, 'downsample_time': [1, 2], 'frame_upsample_rate': [2.0, 1.0]}
Trainning Epoch:   0%|          | 0/823 [00:00<?, ?it/s]2025-09-27 11:15:45,186 current_lr 0.000008 at iteration 200
2025-09-27 11:15:46,017 Stage: Warm Up | Epoch: 0 | Iter: 200 | Total Loss: 0.171889 | Recon Loss: 0.163240 | Commit Loss: 0.017297 | Perplexity: 295.428929
2025-09-27 11:19:07,678 current_lr 0.000016 at iteration 400
2025-09-27 11:19:08,505 Stage: Warm Up | Epoch: 0 | Iter: 400 | Total Loss: 0.123295 | Recon Loss: 0.083479 | Commit Loss: 0.079632 | Perplexity: 278.471287
2025-09-27 11:22:29,615 current_lr 0.000024 at iteration 600
2025-09-27 11:22:30,447 Stage: Warm Up | Epoch: 0 | Iter: 600 | Total Loss: 0.119563 | Recon Loss: 0.059567 | Commit Loss: 0.119992 | Perplexity: 311.415567
Trainning Epoch:   0%|          | 1/823 [10:19<141:24:25, 619.30s/it]Trainning Epoch:   0%|          | 1/823 [10:19<141:24:26, 619.30s/it]Trainning Epoch:   0%|          | 1/823 [10:19<141:24:05, 619.28s/it]Trainning Epoch:   0%|          | 1/823 [10:19<141:24:30, 619.31s/it]2025-09-27 11:25:54,051 current_lr 0.000032 at iteration 800
2025-09-27 11:25:54,884 Stage: Warm Up | Epoch: 1 | Iter: 800 | Total Loss: 0.104051 | Recon Loss: 0.049605 | Commit Loss: 0.108891 | Perplexity: 344.753134
2025-09-27 11:29:15,392 current_lr 0.000040 at iteration 1000
2025-09-27 11:29:16,219 Stage: Warm Up | Epoch: 1 | Iter: 1000 | Total Loss: 0.089311 | Recon Loss: 0.043510 | Commit Loss: 0.091602 | Perplexity: 369.665878
2025-09-27 11:32:36,662 current_lr 0.000048 at iteration 1200
2025-09-27 11:32:37,494 Stage: Warm Up | Epoch: 1 | Iter: 1200 | Total Loss: 0.077842 | Recon Loss: 0.039822 | Commit Loss: 0.076039 | Perplexity: 382.129132
Trainning Epoch:   0%|          | 2/823 [20:34<140:41:30, 616.92s/it]Trainning Epoch:   0%|          | 2/823 [20:34<140:41:42, 616.93s/it]Trainning Epoch:   0%|          | 2/823 [20:34<140:41:43, 616.93s/it]Trainning Epoch:   0%|          | 2/823 [20:34<140:41:34, 616.92s/it]2025-09-27 11:36:01,571 current_lr 0.000056 at iteration 1400
2025-09-27 11:36:02,405 Stage: Warm Up | Epoch: 2 | Iter: 1400 | Total Loss: 0.066593 | Recon Loss: 0.036127 | Commit Loss: 0.060932 | Perplexity: 382.156308
2025-09-27 11:39:22,897 current_lr 0.000064 at iteration 1600
2025-09-27 11:39:23,723 Stage: Warm Up | Epoch: 2 | Iter: 1600 | Total Loss: 0.057597 | Recon Loss: 0.033598 | Commit Loss: 0.047997 | Perplexity: 371.718571
2025-09-27 11:42:44,534 current_lr 0.000072 at iteration 1800
2025-09-27 11:42:45,368 Stage: Warm Up | Epoch: 2 | Iter: 1800 | Total Loss: 0.051071 | Recon Loss: 0.031915 | Commit Loss: 0.038312 | Perplexity: 362.085800
Trainning Epoch:   0%|          | 3/823 [30:50<140:24:19, 616.41s/it]Trainning Epoch:   0%|          | 3/823 [30:50<140:24:27, 616.42s/it]Trainning Epoch:   0%|          | 3/823 [30:50<140:24:24, 616.42s/it]Trainning Epoch:   0%|          | 3/823 [30:50<140:24:25, 616.42s/it]2025-09-27 11:46:08,957 current_lr 0.000080 at iteration 2000
2025-09-27 11:46:09,794 Stage: Warm Up | Epoch: 3 | Iter: 2000 | Total Loss: 0.046661 | Recon Loss: 0.030501 | Commit Loss: 0.032320 | Perplexity: 358.503665
2025-09-27 11:49:29,912 current_lr 0.000088 at iteration 2200
2025-09-27 11:49:30,745 Stage: Warm Up | Epoch: 3 | Iter: 2200 | Total Loss: 0.042971 | Recon Loss: 0.029343 | Commit Loss: 0.027254 | Perplexity: 357.183920
2025-09-27 11:52:50,597 current_lr 0.000096 at iteration 2400
2025-09-27 11:52:51,427 Stage: Warm Up | Epoch: 3 | Iter: 2400 | Total Loss: 0.039511 | Recon Loss: 0.027837 | Commit Loss: 0.023349 | Perplexity: 357.249239
Trainning Epoch:   0%|          | 4/823 [41:04<140:00:27, 615.42s/it]Trainning Epoch:   0%|          | 4/823 [41:04<140:00:25, 615.42s/it]Trainning Epoch:   0%|          | 4/823 [41:04<140:00:23, 615.41s/it]Trainning Epoch:   0%|          | 4/823 [41:04<140:00:26, 615.42s/it]2025-09-27 11:56:16,759 current_lr 0.000104 at iteration 2600
2025-09-27 11:56:17,590 Stage: Warm Up | Epoch: 4 | Iter: 2600 | Total Loss: 0.037281 | Recon Loss: 0.026777 | Commit Loss: 0.021007 | Perplexity: 355.974865
2025-09-27 11:59:39,117 current_lr 0.000112 at iteration 2800
2025-09-27 11:59:39,954 Stage: Warm Up | Epoch: 4 | Iter: 2800 | Total Loss: 0.035029 | Recon Loss: 0.025806 | Commit Loss: 0.018447 | Perplexity: 356.728629
2025-09-27 12:03:01,709 current_lr 0.000120 at iteration 3000
2025-09-27 12:03:02,540 Stage: Warm Up | Epoch: 4 | Iter: 3000 | Total Loss: 0.033136 | Recon Loss: 0.024794 | Commit Loss: 0.016684 | Perplexity: 356.924435
Trainning Epoch:   1%|          | 5/823 [51:23<140:10:40, 616.92s/it]Trainning Epoch:   1%|          | 5/823 [51:23<140:10:39, 616.92s/it]Trainning Epoch:   1%|          | 5/823 [51:23<140:10:46, 616.93s/it]Trainning Epoch:   1%|          | 5/823 [51:23<140:10:46, 616.93s/it]2025-09-27 12:06:28,889 current_lr 0.000128 at iteration 3200
2025-09-27 12:06:29,716 Stage: Warm Up | Epoch: 5 | Iter: 3200 | Total Loss: 0.032213 | Recon Loss: 0.024744 | Commit Loss: 0.014939 | Perplexity: 355.555922
2025-09-27 12:09:51,652 current_lr 0.000136 at iteration 3400
2025-09-27 12:09:52,483 Stage: Warm Up | Epoch: 5 | Iter: 3400 | Total Loss: 0.030627 | Recon Loss: 0.023658 | Commit Loss: 0.013938 | Perplexity: 355.183741
2025-09-27 12:13:14,702 current_lr 0.000144 at iteration 3600
2025-09-27 12:13:15,536 Stage: Warm Up | Epoch: 5 | Iter: 3600 | Total Loss: 0.029841 | Recon Loss: 0.023391 | Commit Loss: 0.012900 | Perplexity: 352.509025
Trainning Epoch:   1%|          | 6/823 [1:01:44<140:19:37, 618.33s/it]Trainning Epoch:   1%|          | 6/823 [1:01:44<140:19:39, 618.33s/it]Trainning Epoch:   1%|          | 6/823 [1:01:44<140:19:43, 618.34s/it]Trainning Epoch:   1%|          | 6/823 [1:01:44<140:19:43, 618.34s/it]2025-09-27 12:16:40,698 current_lr 0.000152 at iteration 3800
2025-09-27 12:16:41,525 Stage: Warm Up | Epoch: 6 | Iter: 3800 | Total Loss: 0.029099 | Recon Loss: 0.022979 | Commit Loss: 0.012241 | Perplexity: 349.868167
2025-09-27 12:20:02,868 current_lr 0.000160 at iteration 4000
2025-09-27 12:20:03,706 Stage: Warm Up | Epoch: 6 | Iter: 4000 | Total Loss: 0.028082 | Recon Loss: 0.022415 | Commit Loss: 0.011335 | Perplexity: 346.643302
2025-09-27 12:23:25,392 current_lr 0.000168 at iteration 4200
2025-09-27 12:23:26,217 Stage: Warm Up | Epoch: 6 | Iter: 4200 | Total Loss: 0.026680 | Recon Loss: 0.021203 | Commit Loss: 0.010955 | Perplexity: 350.278875
Trainning Epoch:   1%|          | 7/823 [1:12:03<140:11:24, 618.49s/it]Trainning Epoch:   1%|          | 7/823 [1:12:03<140:11:25, 618.49s/it]Trainning Epoch:   1%|          | 7/823 [1:12:03<140:11:26, 618.49s/it]Trainning Epoch:   1%|          | 7/823 [1:12:03<140:11:24, 618.49s/it]2025-09-27 12:26:51,645 current_lr 0.000176 at iteration 4400
2025-09-27 12:26:52,475 Stage: Warm Up | Epoch: 7 | Iter: 4400 | Total Loss: 0.025956 | Recon Loss: 0.020780 | Commit Loss: 0.010352 | Perplexity: 350.509847
2025-09-27 12:30:13,785 current_lr 0.000184 at iteration 4600
2025-09-27 12:30:14,615 Stage: Warm Up | Epoch: 7 | Iter: 4600 | Total Loss: 0.025182 | Recon Loss: 0.020358 | Commit Loss: 0.009649 | Perplexity: 350.078130
2025-09-27 12:33:36,720 current_lr 0.000192 at iteration 4800
2025-09-27 12:33:37,551 Stage: Warm Up | Epoch: 7 | Iter: 4800 | Total Loss: 0.024286 | Recon Loss: 0.019637 | Commit Loss: 0.009297 | Perplexity: 353.392956
Trainning Epoch:   1%|          | 8/823 [1:22:23<140:07:26, 618.95s/it]Trainning Epoch:   1%|          | 8/823 [1:22:23<140:07:24, 618.95s/it]Trainning Epoch:   1%|          | 8/823 [1:22:23<140:07:30, 618.96s/it]Trainning Epoch:   1%|          | 8/823 [1:22:23<140:07:31, 618.96s/it]2025-09-27 12:37:03,219 current_lr 0.000200 at iteration 5000
2025-09-27 12:37:04,051 Stage: Warm Up | Epoch: 8 | Iter: 5000 | Total Loss: 0.023878 | Recon Loss: 0.019515 | Commit Loss: 0.008725 | Perplexity: 351.916269
2025-09-27 12:40:25,308 Stage: Train 0.5 | Epoch: 8 | Iter: 5200 | Total Loss: 0.023115 | Recon Loss: 0.018870 | Commit Loss: 0.008490 | Perplexity: 354.862663
2025-09-27 12:43:46,088 Stage: Train 0.5 | Epoch: 8 | Iter: 5400 | Total Loss: 0.021921 | Recon Loss: 0.017863 | Commit Loss: 0.008116 | Perplexity: 355.862192
Trainning Epoch:   1%|          | 9/823 [1:32:39<139:43:10, 617.92s/it]Trainning Epoch:   1%|          | 9/823 [1:32:39<139:43:09, 617.92s/it]Trainning Epoch:   1%|          | 9/823 [1:32:39<139:43:15, 617.93s/it]Trainning Epoch:   1%|          | 9/823 [1:32:39<139:43:16, 617.93s/it]2025-09-27 12:47:10,012 Stage: Train 0.5 | Epoch: 9 | Iter: 5600 | Total Loss: 0.021730 | Recon Loss: 0.017782 | Commit Loss: 0.007896 | Perplexity: 355.432838
2025-09-27 12:50:30,388 Stage: Train 0.5 | Epoch: 9 | Iter: 5800 | Total Loss: 0.020770 | Recon Loss: 0.016947 | Commit Loss: 0.007646 | Perplexity: 357.098921
2025-09-27 12:53:51,037 Stage: Train 0.5 | Epoch: 9 | Iter: 6000 | Total Loss: 0.020396 | Recon Loss: 0.016633 | Commit Loss: 0.007526 | Perplexity: 359.146836
Trainning Epoch:   1%|          | 10/823 [1:42:52<139:11:44, 616.36s/it]Trainning Epoch:   1%|          | 10/823 [1:42:52<139:11:48, 616.37s/it]Trainning Epoch:   1%|          | 10/823 [1:42:52<139:11:52, 616.37s/it]Trainning Epoch:   1%|          | 10/823 [1:42:52<139:11:51, 616.37s/it]2025-09-27 12:57:16,367 Stage: Train 0.5 | Epoch: 10 | Iter: 6200 | Total Loss: 0.019961 | Recon Loss: 0.016344 | Commit Loss: 0.007232 | Perplexity: 359.161833
2025-09-27 13:00:37,812 Stage: Train 0.5 | Epoch: 10 | Iter: 6400 | Total Loss: 0.019171 | Recon Loss: 0.015698 | Commit Loss: 0.006946 | Perplexity: 357.230157
2025-09-27 13:03:59,375 Stage: Train 0.5 | Epoch: 10 | Iter: 6600 | Total Loss: 0.018741 | Recon Loss: 0.015335 | Commit Loss: 0.006811 | Perplexity: 355.383219
Trainning Epoch:   1%|▏         | 11/823 [1:53:08<139:02:04, 616.41s/it]Trainning Epoch:   1%|▏         | 11/823 [1:53:08<139:02:10, 616.42s/it]Trainning Epoch:   1%|▏         | 11/823 [1:53:08<139:02:09, 616.42s/it]Trainning Epoch:   1%|▏         | 11/823 [1:53:08<139:02:11, 616.42s/it]2025-09-27 13:07:25,354 Stage: Train 0.5 | Epoch: 11 | Iter: 6800 | Total Loss: 0.018264 | Recon Loss: 0.014986 | Commit Loss: 0.006555 | Perplexity: 354.628118
2025-09-27 13:10:48,864 Stage: Train 0.5 | Epoch: 11 | Iter: 7000 | Total Loss: 0.017855 | Recon Loss: 0.014680 | Commit Loss: 0.006350 | Perplexity: 352.392989
2025-09-27 13:14:12,423 Stage: Train 0.5 | Epoch: 11 | Iter: 7200 | Total Loss: 0.017510 | Recon Loss: 0.014402 | Commit Loss: 0.006216 | Perplexity: 350.472428
Trainning Epoch:   1%|▏         | 12/823 [2:03:31<139:16:27, 618.23s/it]Trainning Epoch:   1%|▏         | 12/823 [2:03:31<139:16:30, 618.24s/it]Trainning Epoch:   1%|▏         | 12/823 [2:03:31<139:16:30, 618.24s/it]Trainning Epoch:   1%|▏         | 12/823 [2:03:31<139:16:31, 618.24s/it]2025-09-27 13:17:40,105 Stage: Train 0.5 | Epoch: 12 | Iter: 7400 | Total Loss: 0.017298 | Recon Loss: 0.014249 | Commit Loss: 0.006098 | Perplexity: 349.093916
2025-09-27 13:21:03,385 Stage: Train 0.5 | Epoch: 12 | Iter: 7600 | Total Loss: 0.016777 | Recon Loss: 0.013809 | Commit Loss: 0.005937 | Perplexity: 348.143053
2025-09-27 13:24:26,314 Stage: Train 0.5 | Epoch: 12 | Iter: 7800 | Total Loss: 0.016438 | Recon Loss: 0.013548 | Commit Loss: 0.005781 | Perplexity: 345.201532
Trainning Epoch:   2%|▏         | 13/823 [2:13:52<139:19:22, 619.21s/it]Trainning Epoch:   2%|▏         | 13/823 [2:13:52<139:19:18, 619.21s/it]Trainning Epoch:   2%|▏         | 13/823 [2:13:52<139:19:20, 619.21s/it]Trainning Epoch:   2%|▏         | 13/823 [2:13:52<139:19:21, 619.21s/it]2025-09-27 13:27:52,631 Stage: Train 0.5 | Epoch: 13 | Iter: 8000 | Total Loss: 0.016124 | Recon Loss: 0.013334 | Commit Loss: 0.005580 | Perplexity: 341.527300
2025-09-27 13:31:15,290 Stage: Train 0.5 | Epoch: 13 | Iter: 8200 | Total Loss: 0.015929 | Recon Loss: 0.013183 | Commit Loss: 0.005492 | Perplexity: 341.198237
2025-09-27 13:34:38,048 Stage: Train 0.5 | Epoch: 13 | Iter: 8400 | Total Loss: 0.015626 | Recon Loss: 0.012956 | Commit Loss: 0.005341 | Perplexity: 341.220136
Trainning Epoch:   2%|▏         | 14/823 [2:24:12<139:12:58, 619.50s/it]Trainning Epoch:   2%|▏         | 14/823 [2:24:12<139:13:00, 619.51s/it]Trainning Epoch:   2%|▏         | 14/823 [2:24:12<139:12:59, 619.51s/it]Trainning Epoch:   2%|▏         | 14/823 [2:24:12<139:13:01, 619.51s/it]2025-09-27 13:38:04,531 Stage: Train 0.5 | Epoch: 14 | Iter: 8600 | Total Loss: 0.015409 | Recon Loss: 0.012805 | Commit Loss: 0.005207 | Perplexity: 339.229435
2025-09-27 13:41:26,120 Stage: Train 0.5 | Epoch: 14 | Iter: 8800 | Total Loss: 0.014886 | Recon Loss: 0.012396 | Commit Loss: 0.004979 | Perplexity: 337.479530
2025-09-27 13:44:48,176 Stage: Train 0.5 | Epoch: 14 | Iter: 9000 | Total Loss: 0.014489 | Recon Loss: 0.012072 | Commit Loss: 0.004835 | Perplexity: 344.595995
Trainning Epoch:   2%|▏         | 15/823 [2:34:30<138:53:59, 618.86s/it]Trainning Epoch:   2%|▏         | 15/823 [2:34:30<138:53:55, 618.86s/it]Trainning Epoch:   2%|▏         | 15/823 [2:34:30<138:53:57, 618.86s/it]Trainning Epoch:   2%|▏         | 15/823 [2:34:30<138:53:57, 618.86s/it]2025-09-27 13:48:14,144 Stage: Train 0.5 | Epoch: 15 | Iter: 9200 | Total Loss: 0.014362 | Recon Loss: 0.012026 | Commit Loss: 0.004672 | Perplexity: 347.429945
2025-09-27 13:51:36,541 Stage: Train 0.5 | Epoch: 15 | Iter: 9400 | Total Loss: 0.013781 | Recon Loss: 0.011604 | Commit Loss: 0.004353 | Perplexity: 342.680050
2025-09-27 13:54:58,988 Stage: Train 0.5 | Epoch: 15 | Iter: 9600 | Total Loss: 0.013440 | Recon Loss: 0.011331 | Commit Loss: 0.004219 | Perplexity: 346.928736
Trainning Epoch:   2%|▏         | 16/823 [2:44:49<138:44:44, 618.94s/it]Trainning Epoch:   2%|▏         | 16/823 [2:44:49<138:44:47, 618.94s/it]Trainning Epoch:   2%|▏         | 16/823 [2:44:49<138:44:47, 618.94s/it]Trainning Epoch:   2%|▏         | 16/823 [2:44:49<138:44:50, 618.95s/it]2025-09-27 13:58:24,269 Stage: Train 0.5 | Epoch: 16 | Iter: 9800 | Total Loss: 0.013547 | Recon Loss: 0.011490 | Commit Loss: 0.004114 | Perplexity: 349.983008
2025-09-27 14:01:45,421 Stage: Train 0.5 | Epoch: 16 | Iter: 10000 | Total Loss: 0.013079 | Recon Loss: 0.011080 | Commit Loss: 0.004000 | Perplexity: 348.412198
2025-09-27 14:05:07,074 Stage: Train 0.5 | Epoch: 16 | Iter: 10200 | Total Loss: 0.012817 | Recon Loss: 0.010845 | Commit Loss: 0.003943 | Perplexity: 348.735265
Trainning Epoch:   2%|▏         | 17/823 [2:55:05<138:21:56, 618.01s/it]Trainning Epoch:   2%|▏         | 17/823 [2:55:05<138:21:53, 618.01s/it]Trainning Epoch:   2%|▏         | 17/823 [2:55:05<138:21:53, 618.01s/it]Trainning Epoch:   2%|▏         | 17/823 [2:55:05<138:21:55, 618.01s/it]2025-09-27 14:08:32,493 Stage: Train 0.5 | Epoch: 17 | Iter: 10400 | Total Loss: 0.012835 | Recon Loss: 0.010879 | Commit Loss: 0.003912 | Perplexity: 348.883285
2025-09-27 14:11:53,127 Stage: Train 0.5 | Epoch: 17 | Iter: 10600 | Total Loss: 0.012712 | Recon Loss: 0.010803 | Commit Loss: 0.003819 | Perplexity: 347.995476
2025-09-27 14:15:14,337 Stage: Train 0.5 | Epoch: 17 | Iter: 10800 | Total Loss: 0.012401 | Recon Loss: 0.010501 | Commit Loss: 0.003800 | Perplexity: 349.079683
Trainning Epoch:   2%|▏         | 18/823 [3:05:20<137:59:22, 617.10s/it]Trainning Epoch:   2%|▏         | 18/823 [3:05:20<137:59:18, 617.09s/it]Trainning Epoch:   2%|▏         | 18/823 [3:05:20<137:59:22, 617.10s/it]Trainning Epoch:   2%|▏         | 18/823 [3:05:20<137:59:23, 617.10s/it]2025-09-27 14:18:40,108 Stage: Train 0.5 | Epoch: 18 | Iter: 11000 | Total Loss: 0.012354 | Recon Loss: 0.010511 | Commit Loss: 0.003685 | Perplexity: 347.293887
2025-09-27 14:22:03,137 Stage: Train 0.5 | Epoch: 18 | Iter: 11200 | Total Loss: 0.012104 | Recon Loss: 0.010259 | Commit Loss: 0.003691 | Perplexity: 348.559505
2025-09-27 14:25:26,443 Stage: Train 0.5 | Epoch: 18 | Iter: 11400 | Total Loss: 0.012206 | Recon Loss: 0.010365 | Commit Loss: 0.003681 | Perplexity: 347.390937
Trainning Epoch:   2%|▏         | 19/823 [3:15:41<138:06:02, 618.36s/it]Trainning Epoch:   2%|▏         | 19/823 [3:15:41<138:06:08, 618.37s/it]Trainning Epoch:   2%|▏         | 19/823 [3:15:41<138:06:04, 618.36s/it]Trainning Epoch:   2%|▏         | 19/823 [3:15:41<138:06:05, 618.36s/it]2025-09-27 14:28:52,589 Stage: Train 0.5 | Epoch: 19 | Iter: 11600 | Total Loss: 0.011911 | Recon Loss: 0.010097 | Commit Loss: 0.003628 | Perplexity: 346.384464
2025-09-27 14:32:15,087 Stage: Train 0.5 | Epoch: 19 | Iter: 11800 | Total Loss: 0.011844 | Recon Loss: 0.010034 | Commit Loss: 0.003621 | Perplexity: 347.782636
2025-09-27 14:35:37,497 Stage: Train 0.5 | Epoch: 19 | Iter: 12000 | Total Loss: 0.011984 | Recon Loss: 0.010180 | Commit Loss: 0.003608 | Perplexity: 347.867802
Trainning Epoch:   2%|▏         | 20/823 [3:26:00<137:57:48, 618.52s/it]Trainning Epoch:   2%|▏         | 20/823 [3:26:00<137:57:52, 618.52s/it]Trainning Epoch:   2%|▏         | 20/823 [3:26:00<137:57:52, 618.52s/it]Trainning Epoch:   2%|▏         | 20/823 [3:26:00<137:57:52, 618.52s/it]2025-09-27 14:39:04,064 Stage: Train 0.5 | Epoch: 20 | Iter: 12200 | Total Loss: 0.011854 | Recon Loss: 0.010066 | Commit Loss: 0.003577 | Perplexity: 348.742571
2025-09-27 14:42:28,551 Stage: Train 0.5 | Epoch: 20 | Iter: 12400 | Total Loss: 0.011609 | Recon Loss: 0.009863 | Commit Loss: 0.003492 | Perplexity: 348.006885
2025-09-27 14:45:53,793 Stage: Train 0.5 | Epoch: 20 | Iter: 12600 | Total Loss: 0.011520 | Recon Loss: 0.009754 | Commit Loss: 0.003532 | Perplexity: 350.659648
Trainning Epoch:   3%|▎         | 21/823 [3:36:26<138:17:11, 620.74s/it]Trainning Epoch:   3%|▎         | 21/823 [3:36:26<138:17:11, 620.74s/it]Trainning Epoch:   3%|▎         | 21/823 [3:36:26<138:17:12, 620.74s/it]Trainning Epoch:   3%|▎         | 21/823 [3:36:26<138:17:17, 620.74s/it]2025-09-27 14:49:21,562 Stage: Train 0.5 | Epoch: 21 | Iter: 12800 | Total Loss: 0.011517 | Recon Loss: 0.009779 | Commit Loss: 0.003476 | Perplexity: 349.554769
2025-09-27 14:52:45,052 Stage: Train 0.5 | Epoch: 21 | Iter: 13000 | Total Loss: 0.011272 | Recon Loss: 0.009562 | Commit Loss: 0.003419 | Perplexity: 350.106136
2025-09-27 14:56:08,357 Stage: Train 0.5 | Epoch: 21 | Iter: 13200 | Total Loss: 0.011176 | Recon Loss: 0.009483 | Commit Loss: 0.003385 | Perplexity: 348.609906
Trainning Epoch:   3%|▎         | 22/823 [3:46:47<138:10:57, 621.04s/it]Trainning Epoch:   3%|▎         | 22/823 [3:46:48<138:11:02, 621.05s/it]Trainning Epoch:   3%|▎         | 22/823 [3:46:48<138:11:02, 621.05s/it]Trainning Epoch:   3%|▎         | 22/823 [3:46:47<138:11:03, 621.05s/it]2025-09-27 14:59:35,613 Stage: Train 0.5 | Epoch: 22 | Iter: 13400 | Total Loss: 0.011278 | Recon Loss: 0.009601 | Commit Loss: 0.003354 | Perplexity: 349.755885
2025-09-27 15:02:59,590 Stage: Train 0.5 | Epoch: 22 | Iter: 13600 | Total Loss: 0.011225 | Recon Loss: 0.009560 | Commit Loss: 0.003330 | Perplexity: 349.972133
2025-09-27 15:06:23,430 Stage: Train 0.5 | Epoch: 22 | Iter: 13800 | Total Loss: 0.011007 | Recon Loss: 0.009351 | Commit Loss: 0.003311 | Perplexity: 350.238886
Trainning Epoch:   3%|▎         | 23/823 [3:57:11<138:10:45, 621.81s/it]Trainning Epoch:   3%|▎         | 23/823 [3:57:11<138:10:49, 621.81s/it]Trainning Epoch:   3%|▎         | 23/823 [3:57:11<138:10:49, 621.81s/it]Trainning Epoch:   3%|▎         | 23/823 [3:57:11<138:10:50, 621.81s/it]2025-09-27 15:09:51,150 Stage: Train 0.5 | Epoch: 23 | Iter: 14000 | Total Loss: 0.010969 | Recon Loss: 0.009331 | Commit Loss: 0.003275 | Perplexity: 352.106897
2025-09-27 15:13:14,271 Stage: Train 0.5 | Epoch: 23 | Iter: 14200 | Total Loss: 0.010933 | Recon Loss: 0.009274 | Commit Loss: 0.003318 | Perplexity: 351.097756
2025-09-27 15:16:37,900 Stage: Train 0.5 | Epoch: 23 | Iter: 14400 | Total Loss: 0.010777 | Recon Loss: 0.009143 | Commit Loss: 0.003268 | Perplexity: 354.647470
Trainning Epoch:   3%|▎         | 24/823 [4:07:34<138:03:19, 622.03s/it]Trainning Epoch:   3%|▎         | 24/823 [4:07:34<138:03:20, 622.03s/it]Trainning Epoch:   3%|▎         | 24/823 [4:07:34<138:03:20, 622.03s/it]Trainning Epoch:   3%|▎         | 24/823 [4:07:34<138:03:20, 622.03s/it]2025-09-27 15:20:05,067 Stage: Train 0.5 | Epoch: 24 | Iter: 14600 | Total Loss: 0.010733 | Recon Loss: 0.009147 | Commit Loss: 0.003172 | Perplexity: 357.108340
2025-09-27 15:23:25,582 Stage: Train 0.5 | Epoch: 24 | Iter: 14800 | Total Loss: 0.010625 | Recon Loss: 0.009027 | Commit Loss: 0.003196 | Perplexity: 359.511873
2025-09-27 15:26:46,994 Stage: Train 0.5 | Epoch: 24 | Iter: 15000 | Total Loss: 0.010627 | Recon Loss: 0.009036 | Commit Loss: 0.003182 | Perplexity: 358.489459
2025-09-27 15:30:08,189 Stage: Train 0.5 | Epoch: 24 | Iter: 15200 | Total Loss: 0.010440 | Recon Loss: 0.008881 | Commit Loss: 0.003117 | Perplexity: 357.623791
Trainning Epoch:   3%|▎         | 25/823 [4:17:48<137:24:30, 619.89s/it]Trainning Epoch:   3%|▎         | 25/823 [4:17:49<137:24:33, 619.89s/it]Trainning Epoch:   3%|▎         | 25/823 [4:17:49<137:24:33, 619.89s/it]Trainning Epoch:   3%|▎         | 25/823 [4:17:49<137:24:34, 619.89s/it]2025-09-27 15:33:33,968 Stage: Train 0.5 | Epoch: 25 | Iter: 15400 | Total Loss: 0.010405 | Recon Loss: 0.008832 | Commit Loss: 0.003146 | Perplexity: 359.099452
2025-09-27 15:36:56,579 Stage: Train 0.5 | Epoch: 25 | Iter: 15600 | Total Loss: 0.010337 | Recon Loss: 0.008778 | Commit Loss: 0.003119 | Perplexity: 358.547287
2025-09-27 15:40:18,786 Stage: Train 0.5 | Epoch: 25 | Iter: 15800 | Total Loss: 0.010310 | Recon Loss: 0.008771 | Commit Loss: 0.003079 | Perplexity: 358.414251
Trainning Epoch:   3%|▎         | 26/823 [4:28:07<137:09:26, 619.53s/it]Trainning Epoch:   3%|▎         | 26/823 [4:28:07<137:09:27, 619.53s/it]Trainning Epoch:   3%|▎         | 26/823 [4:28:07<137:09:26, 619.53s/it]Trainning Epoch:   3%|▎         | 26/823 [4:28:07<137:09:26, 619.53s/it]2025-09-27 15:43:45,290 Stage: Train 0.5 | Epoch: 26 | Iter: 16000 | Total Loss: 0.010213 | Recon Loss: 0.008677 | Commit Loss: 0.003071 | Perplexity: 358.420899
2025-09-27 15:47:08,608 Stage: Train 0.5 | Epoch: 26 | Iter: 16200 | Total Loss: 0.010238 | Recon Loss: 0.008714 | Commit Loss: 0.003048 | Perplexity: 358.784957
2025-09-27 15:50:31,983 Stage: Train 0.5 | Epoch: 26 | Iter: 16400 | Total Loss: 0.010108 | Recon Loss: 0.008591 | Commit Loss: 0.003034 | Perplexity: 357.262880
Trainning Epoch:   3%|▎         | 27/823 [4:38:28<137:05:54, 620.04s/it]Trainning Epoch:   3%|▎         | 27/823 [4:38:28<137:05:55, 620.04s/it]Trainning Epoch:   3%|▎         | 27/823 [4:38:28<137:05:55, 620.04s/it]Trainning Epoch:   3%|▎         | 27/823 [4:38:28<137:05:55, 620.04s/it]2025-09-27 15:53:58,413 Stage: Train 0.5 | Epoch: 27 | Iter: 16600 | Total Loss: 0.010234 | Recon Loss: 0.008702 | Commit Loss: 0.003065 | Perplexity: 358.375949
2025-09-27 15:57:20,808 Stage: Train 0.5 | Epoch: 27 | Iter: 16800 | Total Loss: 0.010080 | Recon Loss: 0.008559 | Commit Loss: 0.003043 | Perplexity: 359.219848
2025-09-27 16:00:43,353 Stage: Train 0.5 | Epoch: 27 | Iter: 17000 | Total Loss: 0.010039 | Recon Loss: 0.008521 | Commit Loss: 0.003036 | Perplexity: 357.210805
Trainning Epoch:   3%|▎         | 28/823 [4:48:48<136:53:08, 619.86s/it]Trainning Epoch:   3%|▎         | 28/823 [4:48:48<136:53:09, 619.86s/it]Trainning Epoch:   3%|▎         | 28/823 [4:48:48<136:53:09, 619.86s/it]Trainning Epoch:   3%|▎         | 28/823 [4:48:48<136:53:09, 619.86s/it]2025-09-27 16:04:10,843 Stage: Train 0.5 | Epoch: 28 | Iter: 17200 | Total Loss: 0.009957 | Recon Loss: 0.008460 | Commit Loss: 0.002995 | Perplexity: 356.834605
2025-09-27 16:07:34,925 Stage: Train 0.5 | Epoch: 28 | Iter: 17400 | Total Loss: 0.009874 | Recon Loss: 0.008372 | Commit Loss: 0.003005 | Perplexity: 356.656241
2025-09-27 16:10:57,917 Stage: Train 0.5 | Epoch: 28 | Iter: 17600 | Total Loss: 0.009946 | Recon Loss: 0.008443 | Commit Loss: 0.003005 | Perplexity: 355.506038
Trainning Epoch:   4%|▎         | 29/823 [4:59:10<136:53:36, 620.68s/it]Trainning Epoch:   4%|▎         | 29/823 [4:59:10<136:53:35, 620.67s/it]Trainning Epoch:   4%|▎         | 29/823 [4:59:10<136:53:34, 620.67s/it]Trainning Epoch:   4%|▎         | 29/823 [4:59:10<136:53:35, 620.67s/it]2025-09-27 16:14:23,309 Stage: Train 0.5 | Epoch: 29 | Iter: 17800 | Total Loss: 0.009860 | Recon Loss: 0.008360 | Commit Loss: 0.003001 | Perplexity: 356.716855
2025-09-27 16:17:45,375 Stage: Train 0.5 | Epoch: 29 | Iter: 18000 | Total Loss: 0.009902 | Recon Loss: 0.008411 | Commit Loss: 0.002982 | Perplexity: 356.128078
2025-09-27 16:21:07,406 Stage: Train 0.5 | Epoch: 29 | Iter: 18200 | Total Loss: 0.009754 | Recon Loss: 0.008267 | Commit Loss: 0.002972 | Perplexity: 356.367152
Trainning Epoch:   4%|▎         | 30/823 [5:09:28<136:30:57, 619.74s/it]Trainning Epoch:   4%|▎         | 30/823 [5:09:28<136:30:58, 619.75s/it]Trainning Epoch:   4%|▎         | 30/823 [5:09:28<136:30:58, 619.75s/it]Trainning Epoch:   4%|▎         | 30/823 [5:09:28<136:30:58, 619.75s/it]2025-09-27 16:24:33,671 Stage: Train 0.5 | Epoch: 30 | Iter: 18400 | Total Loss: 0.009763 | Recon Loss: 0.008286 | Commit Loss: 0.002954 | Perplexity: 354.814493
2025-09-27 16:27:55,684 Stage: Train 0.5 | Epoch: 30 | Iter: 18600 | Total Loss: 0.009679 | Recon Loss: 0.008190 | Commit Loss: 0.002978 | Perplexity: 355.740316
2025-09-27 16:31:18,223 Stage: Train 0.5 | Epoch: 30 | Iter: 18800 | Total Loss: 0.009669 | Recon Loss: 0.008209 | Commit Loss: 0.002921 | Perplexity: 355.145412
Trainning Epoch:   4%|▍         | 31/823 [5:19:47<136:17:46, 619.53s/it]Trainning Epoch:   4%|▍         | 31/823 [5:19:47<136:17:47, 619.53s/it]Trainning Epoch:   4%|▍         | 31/823 [5:19:47<136:17:48, 619.53s/it]Trainning Epoch:   4%|▍         | 31/823 [5:19:47<136:17:55, 619.54s/it]2025-09-27 16:34:43,168 Stage: Train 0.5 | Epoch: 31 | Iter: 19000 | Total Loss: 0.009565 | Recon Loss: 0.008120 | Commit Loss: 0.002891 | Perplexity: 354.128495
2025-09-27 16:38:04,370 Stage: Train 0.5 | Epoch: 31 | Iter: 19200 | Total Loss: 0.009585 | Recon Loss: 0.008139 | Commit Loss: 0.002891 | Perplexity: 354.211977
2025-09-27 16:41:25,767 Stage: Train 0.5 | Epoch: 31 | Iter: 19400 | Total Loss: 0.009656 | Recon Loss: 0.008197 | Commit Loss: 0.002918 | Perplexity: 354.210528
Trainning Epoch:   4%|▍         | 32/823 [5:30:02<135:51:00, 618.28s/it]Trainning Epoch:   4%|▍         | 32/823 [5:30:02<135:51:03, 618.29s/it]Trainning Epoch:   4%|▍         | 32/823 [5:30:02<135:51:04, 618.29s/it]Trainning Epoch:   4%|▍         | 32/823 [5:30:02<135:51:06, 618.29s/it]2025-09-27 16:44:51,384 Stage: Train 0.5 | Epoch: 32 | Iter: 19600 | Total Loss: 0.009477 | Recon Loss: 0.008040 | Commit Loss: 0.002873 | Perplexity: 356.328072
2025-09-27 16:48:13,646 Stage: Train 0.5 | Epoch: 32 | Iter: 19800 | Total Loss: 0.009417 | Recon Loss: 0.007995 | Commit Loss: 0.002845 | Perplexity: 359.596848
2025-09-27 16:51:35,968 Stage: Train 0.5 | Epoch: 32 | Iter: 20000 | Total Loss: 0.009346 | Recon Loss: 0.007947 | Commit Loss: 0.002799 | Perplexity: 361.757028
2025-09-27 16:51:35,969 Saving model at iteration 20000
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
2025-09-27 16:51:36,648 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_33_step_20000
2025-09-27 16:51:37,261 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_33_step_20000/model.safetensors
2025-09-27 16:51:37,923 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_33_step_20000/optimizer.bin
2025-09-27 16:51:37,924 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_33_step_20000/scheduler.bin
2025-09-27 16:51:37,924 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_33_step_20000/sampler.bin
2025-09-27 16:51:37,925 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_33_step_20000/random_states_0.pkl
Trainning Epoch:   4%|▍         | 33/823 [5:40:23<135:49:11, 618.93s/it]Trainning Epoch:   4%|▍         | 33/823 [5:40:23<135:49:13, 618.93s/it]Trainning Epoch:   4%|▍         | 33/823 [5:40:23<135:49:13, 618.93s/it]Trainning Epoch:   4%|▍         | 33/823 [5:40:23<135:49:13, 618.93s/it]2025-09-27 16:55:03,894 Stage: Train 0.5 | Epoch: 33 | Iter: 20200 | Total Loss: 0.009288 | Recon Loss: 0.007902 | Commit Loss: 0.002772 | Perplexity: 363.789562
2025-09-27 16:58:26,767 Stage: Train 0.5 | Epoch: 33 | Iter: 20400 | Total Loss: 0.009217 | Recon Loss: 0.007844 | Commit Loss: 0.002746 | Perplexity: 362.504076
2025-09-27 17:01:50,391 Stage: Train 0.5 | Epoch: 33 | Iter: 20600 | Total Loss: 0.009218 | Recon Loss: 0.007851 | Commit Loss: 0.002735 | Perplexity: 362.657062
Trainning Epoch:   4%|▍         | 34/823 [5:50:44<135:47:31, 619.58s/it]Trainning Epoch:   4%|▍         | 34/823 [5:50:44<135:47:30, 619.58s/it]Trainning Epoch:   4%|▍         | 34/823 [5:50:44<135:47:31, 619.58s/it]Trainning Epoch:   4%|▍         | 34/823 [5:50:44<135:47:31, 619.58s/it]2025-09-27 17:05:16,007 Stage: Train 0.5 | Epoch: 34 | Iter: 20800 | Total Loss: 0.009080 | Recon Loss: 0.007730 | Commit Loss: 0.002701 | Perplexity: 362.840292
2025-09-27 17:08:36,663 Stage: Train 0.5 | Epoch: 34 | Iter: 21000 | Total Loss: 0.009087 | Recon Loss: 0.007747 | Commit Loss: 0.002680 | Perplexity: 364.112493
2025-09-27 17:11:59,170 Stage: Train 0.5 | Epoch: 34 | Iter: 21200 | Total Loss: 0.009033 | Recon Loss: 0.007703 | Commit Loss: 0.002659 | Perplexity: 362.992636
Trainning Epoch:   4%|▍         | 35/823 [6:01:01<135:27:40, 618.86s/it]Trainning Epoch:   4%|▍         | 35/823 [6:01:01<135:27:34, 618.85s/it]Trainning Epoch:   4%|▍         | 35/823 [6:01:01<135:27:36, 618.85s/it]Trainning Epoch:   4%|▍         | 35/823 [6:01:01<135:27:34, 618.85s/it]2025-09-27 17:15:27,177 Stage: Train 0.5 | Epoch: 35 | Iter: 21400 | Total Loss: 0.008955 | Recon Loss: 0.007606 | Commit Loss: 0.002698 | Perplexity: 365.258743
2025-09-27 17:18:51,911 Stage: Train 0.5 | Epoch: 35 | Iter: 21600 | Total Loss: 0.008968 | Recon Loss: 0.007627 | Commit Loss: 0.002682 | Perplexity: 363.653450
2025-09-27 17:22:16,357 Stage: Train 0.5 | Epoch: 35 | Iter: 21800 | Total Loss: 0.008941 | Recon Loss: 0.007596 | Commit Loss: 0.002690 | Perplexity: 364.870873
Trainning Epoch:   4%|▍         | 36/823 [6:11:27<135:43:05, 620.82s/it]Trainning Epoch:   4%|▍         | 36/823 [6:11:27<135:43:04, 620.82s/it]Trainning Epoch:   4%|▍         | 36/823 [6:11:27<135:43:10, 620.83s/it]Trainning Epoch:   4%|▍         | 36/823 [6:11:27<135:43:06, 620.82s/it]2025-09-27 17:25:43,161 Stage: Train 0.5 | Epoch: 36 | Iter: 22000 | Total Loss: 0.008931 | Recon Loss: 0.007610 | Commit Loss: 0.002642 | Perplexity: 363.425051
2025-09-27 17:29:05,354 Stage: Train 0.5 | Epoch: 36 | Iter: 22200 | Total Loss: 0.008928 | Recon Loss: 0.007588 | Commit Loss: 0.002680 | Perplexity: 364.383029
2025-09-27 17:32:28,170 Stage: Train 0.5 | Epoch: 36 | Iter: 22400 | Total Loss: 0.008875 | Recon Loss: 0.007557 | Commit Loss: 0.002636 | Perplexity: 363.111161
Trainning Epoch:   4%|▍         | 37/823 [6:21:46<135:26:25, 620.34s/it]Trainning Epoch:   4%|▍         | 37/823 [6:21:46<135:26:29, 620.34s/it]Trainning Epoch:   4%|▍         | 37/823 [6:21:46<135:26:30, 620.34s/it]Trainning Epoch:   4%|▍         | 37/823 [6:21:46<135:26:31, 620.35s/it]2025-09-27 17:35:54,803 Stage: Train 0.5 | Epoch: 37 | Iter: 22600 | Total Loss: 0.008721 | Recon Loss: 0.007395 | Commit Loss: 0.002652 | Perplexity: 363.374763
2025-09-27 17:39:18,240 Stage: Train 0.5 | Epoch: 37 | Iter: 22800 | Total Loss: 0.008896 | Recon Loss: 0.007580 | Commit Loss: 0.002632 | Perplexity: 363.953956
2025-09-27 17:42:41,762 Stage: Train 0.5 | Epoch: 37 | Iter: 23000 | Total Loss: 0.008810 | Recon Loss: 0.007498 | Commit Loss: 0.002625 | Perplexity: 364.218787
Trainning Epoch:   5%|▍         | 38/823 [6:32:08<135:22:06, 620.80s/it]Trainning Epoch:   5%|▍         | 38/823 [6:32:08<135:22:11, 620.80s/it]Trainning Epoch:   5%|▍         | 38/823 [6:32:08<135:22:13, 620.81s/it]Trainning Epoch:   5%|▍         | 38/823 [6:32:08<135:22:11, 620.81s/it]2025-09-27 17:46:07,447 Stage: Train 0.5 | Epoch: 38 | Iter: 23200 | Total Loss: 0.008775 | Recon Loss: 0.007462 | Commit Loss: 0.002626 | Perplexity: 364.260201
2025-09-27 17:49:28,441 Stage: Train 0.5 | Epoch: 38 | Iter: 23400 | Total Loss: 0.008653 | Recon Loss: 0.007329 | Commit Loss: 0.002650 | Perplexity: 364.307168
2025-09-27 17:52:50,370 Stage: Train 0.5 | Epoch: 38 | Iter: 23600 | Total Loss: 0.008729 | Recon Loss: 0.007426 | Commit Loss: 0.002606 | Perplexity: 362.605690
Trainning Epoch:   5%|▍         | 39/823 [6:42:24<134:52:50, 619.35s/it]Trainning Epoch:   5%|▍         | 39/823 [6:42:24<134:52:56, 619.36s/it]Trainning Epoch:   5%|▍         | 39/823 [6:42:24<134:52:54, 619.36s/it]Trainning Epoch:   5%|▍         | 39/823 [6:42:24<134:52:55, 619.36s/it]2025-09-27 17:56:16,104 Stage: Train 0.5 | Epoch: 39 | Iter: 23800 | Total Loss: 0.008684 | Recon Loss: 0.007384 | Commit Loss: 0.002601 | Perplexity: 363.285965
2025-09-27 17:59:38,927 Stage: Train 0.5 | Epoch: 39 | Iter: 24000 | Total Loss: 0.008692 | Recon Loss: 0.007382 | Commit Loss: 0.002620 | Perplexity: 362.444031
2025-09-27 18:03:01,131 Stage: Train 0.5 | Epoch: 39 | Iter: 24200 | Total Loss: 0.008603 | Recon Loss: 0.007305 | Commit Loss: 0.002596 | Perplexity: 362.503646
Trainning Epoch:   5%|▍         | 40/823 [6:52:42<134:40:34, 619.20s/it]Trainning Epoch:   5%|▍         | 40/823 [6:52:42<134:40:38, 619.21s/it]Trainning Epoch:   5%|▍         | 40/823 [6:52:42<134:40:38, 619.21s/it]Trainning Epoch:   5%|▍         | 40/823 [6:52:43<134:40:43, 619.21s/it]2025-09-27 18:06:27,159 Stage: Train 0.5 | Epoch: 40 | Iter: 24400 | Total Loss: 0.008631 | Recon Loss: 0.007329 | Commit Loss: 0.002604 | Perplexity: 364.063033
2025-09-27 18:09:50,977 Stage: Train 0.5 | Epoch: 40 | Iter: 24600 | Total Loss: 0.008608 | Recon Loss: 0.007313 | Commit Loss: 0.002591 | Perplexity: 364.150790
2025-09-27 18:13:15,273 Stage: Train 0.5 | Epoch: 40 | Iter: 24800 | Total Loss: 0.008524 | Recon Loss: 0.007242 | Commit Loss: 0.002565 | Perplexity: 362.017256
Trainning Epoch:   5%|▍         | 41/823 [7:03:07<134:49:21, 620.67s/it]Trainning Epoch:   5%|▍         | 41/823 [7:03:07<134:49:20, 620.67s/it]Trainning Epoch:   5%|▍         | 41/823 [7:03:07<134:49:23, 620.67s/it]Trainning Epoch:   5%|▍         | 41/823 [7:03:07<134:49:23, 620.67s/it]2025-09-27 18:16:43,029 Stage: Train 0.5 | Epoch: 41 | Iter: 25000 | Total Loss: 0.008569 | Recon Loss: 0.007269 | Commit Loss: 0.002598 | Perplexity: 362.935527
2025-09-27 18:20:05,140 Stage: Train 0.5 | Epoch: 41 | Iter: 25200 | Total Loss: 0.008601 | Recon Loss: 0.007318 | Commit Loss: 0.002567 | Perplexity: 360.879729
2025-09-27 18:23:27,587 Stage: Train 0.5 | Epoch: 41 | Iter: 25400 | Total Loss: 0.008468 | Recon Loss: 0.007177 | Commit Loss: 0.002582 | Perplexity: 362.107724
Trainning Epoch:   5%|▌         | 42/823 [7:13:25<134:32:14, 620.15s/it]Trainning Epoch:   5%|▌         | 42/823 [7:13:26<134:32:18, 620.15s/it]Trainning Epoch:   5%|▌         | 42/823 [7:13:26<134:32:20, 620.15s/it]Trainning Epoch:   5%|▌         | 42/823 [7:13:26<134:32:20, 620.15s/it]2025-09-27 18:26:52,921 Stage: Train 0.5 | Epoch: 42 | Iter: 25600 | Total Loss: 0.008457 | Recon Loss: 0.007186 | Commit Loss: 0.002541 | Perplexity: 361.319717
2025-09-27 18:30:13,584 Stage: Train 0.5 | Epoch: 42 | Iter: 25800 | Total Loss: 0.008504 | Recon Loss: 0.007217 | Commit Loss: 0.002574 | Perplexity: 363.235126
2025-09-27 18:33:36,034 Stage: Train 0.5 | Epoch: 42 | Iter: 26000 | Total Loss: 0.008437 | Recon Loss: 0.007165 | Commit Loss: 0.002544 | Perplexity: 362.573601
Trainning Epoch:   5%|▌         | 43/823 [7:23:42<134:08:44, 619.13s/it]Trainning Epoch:   5%|▌         | 43/823 [7:23:42<134:08:40, 619.13s/it]Trainning Epoch:   5%|▌         | 43/823 [7:23:42<134:08:49, 619.14s/it]Trainning Epoch:   5%|▌         | 43/823 [7:23:42<134:08:50, 619.14s/it]2025-09-27 18:37:03,095 Stage: Train 0.5 | Epoch: 43 | Iter: 26200 | Total Loss: 0.008383 | Recon Loss: 0.007103 | Commit Loss: 0.002560 | Perplexity: 362.778085
2025-09-27 18:40:25,758 Stage: Train 0.5 | Epoch: 43 | Iter: 26400 | Total Loss: 0.008431 | Recon Loss: 0.007148 | Commit Loss: 0.002568 | Perplexity: 362.572693
2025-09-27 18:43:48,237 Stage: Train 0.5 | Epoch: 43 | Iter: 26600 | Total Loss: 0.008372 | Recon Loss: 0.007074 | Commit Loss: 0.002596 | Perplexity: 364.227720
Trainning Epoch:   5%|▌         | 44/823 [7:34:03<134:03:00, 619.49s/it]Trainning Epoch:   5%|▌         | 44/823 [7:34:03<134:03:07, 619.50s/it]Trainning Epoch:   5%|▌         | 44/823 [7:34:03<134:03:05, 619.49s/it]Trainning Epoch:   5%|▌         | 44/823 [7:34:03<134:03:09, 619.50s/it]2025-09-27 18:47:14,687 Stage: Train 0.5 | Epoch: 44 | Iter: 26800 | Total Loss: 0.008300 | Recon Loss: 0.007028 | Commit Loss: 0.002543 | Perplexity: 361.835090
2025-09-27 18:50:39,128 Stage: Train 0.5 | Epoch: 44 | Iter: 27000 | Total Loss: 0.008264 | Recon Loss: 0.006992 | Commit Loss: 0.002545 | Perplexity: 364.831303
2025-09-27 18:54:03,153 Stage: Train 0.5 | Epoch: 44 | Iter: 27200 | Total Loss: 0.008304 | Recon Loss: 0.007026 | Commit Loss: 0.002557 | Perplexity: 364.056253
Trainning Epoch:   5%|▌         | 45/823 [7:44:26<134:09:45, 620.80s/it]Trainning Epoch:   5%|▌         | 45/823 [7:44:26<134:09:47, 620.81s/it]Trainning Epoch:   5%|▌         | 45/823 [7:44:26<134:09:48, 620.81s/it]Trainning Epoch:   5%|▌         | 45/823 [7:44:26<134:09:50, 620.81s/it]2025-09-27 18:57:30,427 Stage: Train 0.5 | Epoch: 45 | Iter: 27400 | Total Loss: 0.008226 | Recon Loss: 0.006966 | Commit Loss: 0.002520 | Perplexity: 362.603730
2025-09-27 19:00:54,006 Stage: Train 0.5 | Epoch: 45 | Iter: 27600 | Total Loss: 0.008300 | Recon Loss: 0.007033 | Commit Loss: 0.002533 | Perplexity: 363.553401
2025-09-27 19:04:17,467 Stage: Train 0.5 | Epoch: 45 | Iter: 27800 | Total Loss: 0.008235 | Recon Loss: 0.006973 | Commit Loss: 0.002525 | Perplexity: 364.415250
Trainning Epoch:   6%|▌         | 46/823 [7:54:49<134:04:28, 621.19s/it]Trainning Epoch:   6%|▌         | 46/823 [7:54:49<134:04:33, 621.20s/it]Trainning Epoch:   6%|▌         | 46/823 [7:54:49<134:04:30, 621.20s/it]Trainning Epoch:   6%|▌         | 46/823 [7:54:49<134:04:32, 621.20s/it]2025-09-27 19:07:44,153 Stage: Train 0.5 | Epoch: 46 | Iter: 28000 | Total Loss: 0.008260 | Recon Loss: 0.006990 | Commit Loss: 0.002541 | Perplexity: 365.367322
2025-09-27 19:11:04,633 Stage: Train 0.5 | Epoch: 46 | Iter: 28200 | Total Loss: 0.008208 | Recon Loss: 0.006938 | Commit Loss: 0.002542 | Perplexity: 365.900025
2025-09-27 19:14:25,941 Stage: Train 0.5 | Epoch: 46 | Iter: 28400 | Total Loss: 0.008219 | Recon Loss: 0.006959 | Commit Loss: 0.002520 | Perplexity: 366.557684
Trainning Epoch:   6%|▌         | 47/823 [8:05:04<133:29:48, 619.32s/it]Trainning Epoch:   6%|▌         | 47/823 [8:05:04<133:29:59, 619.33s/it]Trainning Epoch:   6%|▌         | 47/823 [8:05:04<133:30:04, 619.34s/it]Trainning Epoch:   6%|▌         | 47/823 [8:05:04<133:30:00, 619.33s/it]2025-09-27 19:17:51,005 Stage: Train 0.5 | Epoch: 47 | Iter: 28600 | Total Loss: 0.008103 | Recon Loss: 0.006846 | Commit Loss: 0.002515 | Perplexity: 367.647290
2025-09-27 19:21:11,712 Stage: Train 0.5 | Epoch: 47 | Iter: 28800 | Total Loss: 0.008108 | Recon Loss: 0.006844 | Commit Loss: 0.002528 | Perplexity: 366.862155
2025-09-27 19:24:33,880 Stage: Train 0.5 | Epoch: 47 | Iter: 29000 | Total Loss: 0.008139 | Recon Loss: 0.006898 | Commit Loss: 0.002483 | Perplexity: 365.658127
Trainning Epoch:   6%|▌         | 48/823 [8:15:20<133:07:52, 618.42s/it]Trainning Epoch:   6%|▌         | 48/823 [8:15:20<133:07:55, 618.42s/it]Trainning Epoch:   6%|▌         | 48/823 [8:15:20<133:07:56, 618.42s/it]Trainning Epoch:   6%|▌         | 48/823 [8:15:20<133:07:54, 618.42s/it]2025-09-27 19:27:59,223 Stage: Train 0.5 | Epoch: 48 | Iter: 29200 | Total Loss: 0.008080 | Recon Loss: 0.006827 | Commit Loss: 0.002506 | Perplexity: 367.370186
2025-09-27 19:31:21,044 Stage: Train 0.5 | Epoch: 48 | Iter: 29400 | Total Loss: 0.008048 | Recon Loss: 0.006794 | Commit Loss: 0.002507 | Perplexity: 367.002305
2025-09-27 19:34:43,132 Stage: Train 0.5 | Epoch: 48 | Iter: 29600 | Total Loss: 0.008063 | Recon Loss: 0.006810 | Commit Loss: 0.002506 | Perplexity: 367.279232
Trainning Epoch:   6%|▌         | 49/823 [8:25:38<132:56:29, 618.33s/it]Trainning Epoch:   6%|▌         | 49/823 [8:25:38<132:56:31, 618.33s/it]Trainning Epoch:   6%|▌         | 49/823 [8:25:38<132:56:31, 618.33s/it]Trainning Epoch:   6%|▌         | 49/823 [8:25:38<132:56:28, 618.33s/it]2025-09-27 19:38:09,484 Stage: Train 0.5 | Epoch: 49 | Iter: 29800 | Total Loss: 0.008089 | Recon Loss: 0.006845 | Commit Loss: 0.002489 | Perplexity: 366.769963
2025-09-27 19:41:31,756 Stage: Train 0.5 | Epoch: 49 | Iter: 30000 | Total Loss: 0.008003 | Recon Loss: 0.006741 | Commit Loss: 0.002524 | Perplexity: 368.192020
2025-09-27 19:44:55,140 Stage: Train 0.5 | Epoch: 49 | Iter: 30200 | Total Loss: 0.007996 | Recon Loss: 0.006752 | Commit Loss: 0.002489 | Perplexity: 365.645807
2025-09-27 19:48:18,292 Stage: Train 0.5 | Epoch: 49 | Iter: 30400 | Total Loss: 0.008107 | Recon Loss: 0.006845 | Commit Loss: 0.002525 | Perplexity: 367.857447
Trainning Epoch:   6%|▌         | 50/823 [8:35:59<132:54:59, 619.02s/it]Trainning Epoch:   6%|▌         | 50/823 [8:35:59<132:55:03, 619.02s/it]Trainning Epoch:   6%|▌         | 50/823 [8:35:59<132:55:04, 619.02s/it]Trainning Epoch:   6%|▌         | 50/823 [8:35:59<132:55:05, 619.02s/it]2025-09-27 19:51:42,468 Stage: Train 0.5 | Epoch: 50 | Iter: 30600 | Total Loss: 0.007943 | Recon Loss: 0.006682 | Commit Loss: 0.002521 | Perplexity: 367.402899
2025-09-27 19:55:03,707 Stage: Train 0.5 | Epoch: 50 | Iter: 30800 | Total Loss: 0.007889 | Recon Loss: 0.006646 | Commit Loss: 0.002486 | Perplexity: 366.545225
2025-09-27 19:58:24,679 Stage: Train 0.5 | Epoch: 50 | Iter: 31000 | Total Loss: 0.008044 | Recon Loss: 0.006785 | Commit Loss: 0.002519 | Perplexity: 367.792563
Trainning Epoch:   6%|▌         | 51/823 [8:46:13<132:27:46, 617.70s/it]Trainning Epoch:   6%|▌         | 51/823 [8:46:13<132:27:51, 617.71s/it]Trainning Epoch:   6%|▌         | 51/823 [8:46:13<132:27:51, 617.71s/it]Trainning Epoch:   6%|▌         | 51/823 [8:46:13<132:27:52, 617.71s/it]2025-09-27 20:01:50,838 Stage: Train 0.5 | Epoch: 51 | Iter: 31200 | Total Loss: 0.007916 | Recon Loss: 0.006669 | Commit Loss: 0.002494 | Perplexity: 367.267767
2025-09-27 20:05:14,052 Stage: Train 0.5 | Epoch: 51 | Iter: 31400 | Total Loss: 0.007889 | Recon Loss: 0.006640 | Commit Loss: 0.002499 | Perplexity: 366.622115
2025-09-27 20:08:37,433 Stage: Train 0.5 | Epoch: 51 | Iter: 31600 | Total Loss: 0.007924 | Recon Loss: 0.006674 | Commit Loss: 0.002500 | Perplexity: 367.721536
Trainning Epoch:   6%|▋         | 52/823 [8:56:34<132:28:51, 618.59s/it]Trainning Epoch:   6%|▋         | 52/823 [8:56:34<132:28:57, 618.60s/it]Trainning Epoch:   6%|▋         | 52/823 [8:56:34<132:28:53, 618.59s/it]Trainning Epoch:   6%|▋         | 52/823 [8:56:34<132:28:53, 618.59s/it]2025-09-27 20:12:04,421 Stage: Train 0.5 | Epoch: 52 | Iter: 31800 | Total Loss: 0.007923 | Recon Loss: 0.006661 | Commit Loss: 0.002523 | Perplexity: 366.592056
2025-09-27 20:15:27,297 Stage: Train 0.5 | Epoch: 52 | Iter: 32000 | Total Loss: 0.007858 | Recon Loss: 0.006604 | Commit Loss: 0.002507 | Perplexity: 366.725043
2025-09-27 20:18:50,595 Stage: Train 0.5 | Epoch: 52 | Iter: 32200 | Total Loss: 0.007856 | Recon Loss: 0.006621 | Commit Loss: 0.002472 | Perplexity: 365.560707
Trainning Epoch:   6%|▋         | 53/823 [9:06:55<132:28:30, 619.36s/it]Trainning Epoch:   6%|▋         | 53/823 [9:06:55<132:28:27, 619.36s/it]Trainning Epoch:   6%|▋         | 53/823 [9:06:55<132:28:31, 619.37s/it]Trainning Epoch:   6%|▋         | 53/823 [9:06:55<132:28:31, 619.37s/it]2025-09-27 20:22:17,457 Stage: Train 0.5 | Epoch: 53 | Iter: 32400 | Total Loss: 0.007868 | Recon Loss: 0.006617 | Commit Loss: 0.002502 | Perplexity: 367.108316
2025-09-27 20:25:41,481 Stage: Train 0.5 | Epoch: 53 | Iter: 32600 | Total Loss: 0.007847 | Recon Loss: 0.006603 | Commit Loss: 0.002488 | Perplexity: 367.087225
2025-09-27 20:29:05,354 Stage: Train 0.5 | Epoch: 53 | Iter: 32800 | Total Loss: 0.007865 | Recon Loss: 0.006622 | Commit Loss: 0.002486 | Perplexity: 367.973034
Trainning Epoch:   7%|▋         | 54/823 [9:17:18<132:32:34, 620.49s/it]Trainning Epoch:   7%|▋         | 54/823 [9:17:18<132:32:35, 620.49s/it]Trainning Epoch:   7%|▋         | 54/823 [9:17:18<132:32:39, 620.49s/it]Trainning Epoch:   7%|▋         | 54/823 [9:17:18<132:32:37, 620.49s/it]2025-09-27 20:32:29,926 Stage: Train 0.5 | Epoch: 54 | Iter: 33000 | Total Loss: 0.007776 | Recon Loss: 0.006532 | Commit Loss: 0.002487 | Perplexity: 368.343269
2025-09-27 20:35:51,577 Stage: Train 0.5 | Epoch: 54 | Iter: 33200 | Total Loss: 0.007810 | Recon Loss: 0.006554 | Commit Loss: 0.002513 | Perplexity: 368.107742
2025-09-27 20:39:13,568 Stage: Train 0.5 | Epoch: 54 | Iter: 33400 | Total Loss: 0.007812 | Recon Loss: 0.006569 | Commit Loss: 0.002487 | Perplexity: 368.000071
Trainning Epoch:   7%|▋         | 55/823 [9:27:34<132:05:04, 619.15s/it]Trainning Epoch:   7%|▋         | 55/823 [9:27:34<132:05:10, 619.15s/it]Trainning Epoch:   7%|▋         | 55/823 [9:27:34<132:05:10, 619.15s/it]Trainning Epoch:   7%|▋         | 55/823 [9:27:34<132:05:12, 619.16s/it]2025-09-27 20:42:40,639 Stage: Train 0.5 | Epoch: 55 | Iter: 33600 | Total Loss: 0.007860 | Recon Loss: 0.006623 | Commit Loss: 0.002475 | Perplexity: 367.470084
2025-09-27 20:46:04,600 Stage: Train 0.5 | Epoch: 55 | Iter: 33800 | Total Loss: 0.007732 | Recon Loss: 0.006488 | Commit Loss: 0.002488 | Perplexity: 368.008368
2025-09-27 20:49:29,752 Stage: Train 0.5 | Epoch: 55 | Iter: 34000 | Total Loss: 0.007715 | Recon Loss: 0.006479 | Commit Loss: 0.002473 | Perplexity: 367.188790
Trainning Epoch:   7%|▋         | 56/823 [9:37:59<132:16:02, 620.81s/it]Trainning Epoch:   7%|▋         | 56/823 [9:37:59<132:16:01, 620.81s/it]Trainning Epoch:   7%|▋         | 56/823 [9:37:59<132:16:06, 620.82s/it]Trainning Epoch:   7%|▋         | 56/823 [9:37:59<132:16:08, 620.82s/it]2025-09-27 20:52:56,975 Stage: Train 0.5 | Epoch: 56 | Iter: 34200 | Total Loss: 0.007797 | Recon Loss: 0.006552 | Commit Loss: 0.002490 | Perplexity: 368.126510
2025-09-27 20:56:20,737 Stage: Train 0.5 | Epoch: 56 | Iter: 34400 | Total Loss: 0.007665 | Recon Loss: 0.006421 | Commit Loss: 0.002488 | Perplexity: 368.108202
2025-09-27 20:59:44,532 Stage: Train 0.5 | Epoch: 56 | Iter: 34600 | Total Loss: 0.007672 | Recon Loss: 0.006426 | Commit Loss: 0.002492 | Perplexity: 367.397615
Trainning Epoch:   7%|▋         | 57/823 [9:48:22<132:14:26, 621.50s/it]Trainning Epoch:   7%|▋         | 57/823 [9:48:22<132:14:32, 621.50s/it]Trainning Epoch:   7%|▋         | 57/823 [9:48:22<132:14:31, 621.50s/it]Trainning Epoch:   7%|▋         | 57/823 [9:48:22<132:14:33, 621.51s/it]2025-09-27 21:03:10,300 Stage: Train 0.5 | Epoch: 57 | Iter: 34800 | Total Loss: 0.007696 | Recon Loss: 0.006464 | Commit Loss: 0.002462 | Perplexity: 367.380399
2025-09-27 21:06:31,604 Stage: Train 0.5 | Epoch: 57 | Iter: 35000 | Total Loss: 0.007687 | Recon Loss: 0.006451 | Commit Loss: 0.002472 | Perplexity: 367.879337
2025-09-27 21:09:52,596 Stage: Train 0.5 | Epoch: 57 | Iter: 35200 | Total Loss: 0.007683 | Recon Loss: 0.006455 | Commit Loss: 0.002457 | Perplexity: 366.776403
Trainning Epoch:   7%|▋         | 58/823 [9:58:37<131:40:11, 619.62s/it]Trainning Epoch:   7%|▋         | 58/823 [9:58:37<131:40:19, 619.63s/it]Trainning Epoch:   7%|▋         | 58/823 [9:58:37<131:40:19, 619.63s/it]Trainning Epoch:   7%|▋         | 58/823 [9:58:37<131:40:20, 619.63s/it]2025-09-27 21:13:18,276 Stage: Train 0.5 | Epoch: 58 | Iter: 35400 | Total Loss: 0.007694 | Recon Loss: 0.006449 | Commit Loss: 0.002490 | Perplexity: 368.560056
2025-09-27 21:16:40,694 Stage: Train 0.5 | Epoch: 58 | Iter: 35600 | Total Loss: 0.007553 | Recon Loss: 0.006320 | Commit Loss: 0.002465 | Perplexity: 367.433041
2025-09-27 21:20:02,668 Stage: Train 0.5 | Epoch: 58 | Iter: 35800 | Total Loss: 0.007632 | Recon Loss: 0.006392 | Commit Loss: 0.002480 | Perplexity: 367.235713
Trainning Epoch:   7%|▋         | 59/823 [10:08:56<131:26:24, 619.35s/it]Trainning Epoch:   7%|▋         | 59/823 [10:08:56<131:26:19, 619.34s/it]Trainning Epoch:   7%|▋         | 59/823 [10:08:56<131:26:23, 619.35s/it]Trainning Epoch:   7%|▋         | 59/823 [10:08:56<131:26:23, 619.35s/it]2025-09-27 21:23:29,644 Stage: Train 0.5 | Epoch: 59 | Iter: 36000 | Total Loss: 0.007624 | Recon Loss: 0.006369 | Commit Loss: 0.002509 | Perplexity: 366.845151
2025-09-27 21:26:53,187 Stage: Train 0.5 | Epoch: 59 | Iter: 36200 | Total Loss: 0.007589 | Recon Loss: 0.006340 | Commit Loss: 0.002499 | Perplexity: 368.667241
2025-09-27 21:30:16,593 Stage: Train 0.5 | Epoch: 59 | Iter: 36400 | Total Loss: 0.007646 | Recon Loss: 0.006402 | Commit Loss: 0.002489 | Perplexity: 366.672484
Trainning Epoch:   7%|▋         | 60/823 [10:19:19<131:28:50, 620.35s/it]Trainning Epoch:   7%|▋         | 60/823 [10:19:19<131:28:52, 620.36s/it]Trainning Epoch:   7%|▋         | 60/823 [10:19:19<131:28:51, 620.36s/it]Trainning Epoch:   7%|▋         | 60/823 [10:19:19<131:28:53, 620.36s/it]2025-09-27 21:33:44,646 Stage: Train 0.5 | Epoch: 60 | Iter: 36600 | Total Loss: 0.007565 | Recon Loss: 0.006322 | Commit Loss: 0.002488 | Perplexity: 367.418823
2025-09-27 21:37:08,063 Stage: Train 0.5 | Epoch: 60 | Iter: 36800 | Total Loss: 0.007577 | Recon Loss: 0.006362 | Commit Loss: 0.002430 | Perplexity: 365.050595
2025-09-27 21:40:31,888 Stage: Train 0.5 | Epoch: 60 | Iter: 37000 | Total Loss: 0.007548 | Recon Loss: 0.006314 | Commit Loss: 0.002466 | Perplexity: 366.036160
Trainning Epoch:   7%|▋         | 61/823 [10:29:42<131:28:35, 621.15s/it]Trainning Epoch:   7%|▋         | 61/823 [10:29:42<131:28:36, 621.15s/it]Trainning Epoch:   7%|▋         | 61/823 [10:29:42<131:28:35, 621.15s/it]Trainning Epoch:   7%|▋         | 61/823 [10:29:42<131:28:37, 621.15s/it]2025-09-27 21:43:59,535 Stage: Train 0.5 | Epoch: 61 | Iter: 37200 | Total Loss: 0.007552 | Recon Loss: 0.006321 | Commit Loss: 0.002462 | Perplexity: 366.830195
2025-09-27 21:47:23,771 Stage: Train 0.5 | Epoch: 61 | Iter: 37400 | Total Loss: 0.007558 | Recon Loss: 0.006311 | Commit Loss: 0.002494 | Perplexity: 367.199858
2025-09-27 21:50:47,438 Stage: Train 0.5 | Epoch: 61 | Iter: 37600 | Total Loss: 0.007541 | Recon Loss: 0.006316 | Commit Loss: 0.002450 | Perplexity: 366.055543
Trainning Epoch:   8%|▊         | 62/823 [10:40:05<131:28:02, 621.92s/it]Trainning Epoch:   8%|▊         | 62/823 [10:40:05<131:28:02, 621.92s/it]Trainning Epoch:   8%|▊         | 62/823 [10:40:05<131:28:03, 621.92s/it]Trainning Epoch:   8%|▊         | 62/823 [10:40:05<131:28:08, 621.93s/it]2025-09-27 21:54:12,904 Stage: Train 0.5 | Epoch: 62 | Iter: 37800 | Total Loss: 0.007520 | Recon Loss: 0.006286 | Commit Loss: 0.002469 | Perplexity: 366.898092
2025-09-27 21:57:33,128 Stage: Train 0.5 | Epoch: 62 | Iter: 38000 | Total Loss: 0.007488 | Recon Loss: 0.006260 | Commit Loss: 0.002454 | Perplexity: 366.611169
2025-09-27 22:00:52,943 Stage: Train 0.5 | Epoch: 62 | Iter: 38200 | Total Loss: 0.007513 | Recon Loss: 0.006281 | Commit Loss: 0.002465 | Perplexity: 367.360171
Trainning Epoch:   8%|▊         | 63/823 [10:50:17<130:38:48, 618.85s/it]Trainning Epoch:   8%|▊         | 63/823 [10:50:17<130:38:44, 618.85s/it]Trainning Epoch:   8%|▊         | 63/823 [10:50:17<130:38:44, 618.85s/it]Trainning Epoch:   8%|▊         | 63/823 [10:50:17<130:38:45, 618.85s/it]2025-09-27 22:04:18,324 Stage: Train 0.5 | Epoch: 63 | Iter: 38400 | Total Loss: 0.007554 | Recon Loss: 0.006323 | Commit Loss: 0.002463 | Perplexity: 368.393466
2025-09-27 22:07:42,064 Stage: Train 0.5 | Epoch: 63 | Iter: 38600 | Total Loss: 0.007442 | Recon Loss: 0.006211 | Commit Loss: 0.002463 | Perplexity: 367.052752
2025-09-27 22:11:05,765 Stage: Train 0.5 | Epoch: 63 | Iter: 38800 | Total Loss: 0.007441 | Recon Loss: 0.006212 | Commit Loss: 0.002457 | Perplexity: 366.837796
Trainning Epoch:   8%|▊         | 64/823 [11:00:40<130:45:12, 620.17s/it]Trainning Epoch:   8%|▊         | 64/823 [11:00:40<130:45:17, 620.18s/it]Trainning Epoch:   8%|▊         | 64/823 [11:00:40<130:45:14, 620.18s/it]Trainning Epoch:   8%|▊         | 64/823 [11:00:40<130:45:15, 620.18s/it]2025-09-27 22:14:32,925 Stage: Train 0.5 | Epoch: 64 | Iter: 39000 | Total Loss: 0.007495 | Recon Loss: 0.006265 | Commit Loss: 0.002459 | Perplexity: 367.877238
2025-09-27 22:17:55,381 Stage: Train 0.5 | Epoch: 64 | Iter: 39200 | Total Loss: 0.007369 | Recon Loss: 0.006150 | Commit Loss: 0.002437 | Perplexity: 368.288024
2025-09-27 22:21:18,693 Stage: Train 0.5 | Epoch: 64 | Iter: 39400 | Total Loss: 0.007406 | Recon Loss: 0.006179 | Commit Loss: 0.002452 | Perplexity: 368.203166
Trainning Epoch:   8%|▊         | 65/823 [11:11:01<130:36:20, 620.29s/it]Trainning Epoch:   8%|▊         | 65/823 [11:11:01<130:36:23, 620.29s/it]Trainning Epoch:   8%|▊         | 65/823 [11:11:01<130:36:22, 620.29s/it]Trainning Epoch:   8%|▊         | 65/823 [11:11:01<130:36:21, 620.29s/it]2025-09-27 22:24:45,063 Stage: Train 0.5 | Epoch: 65 | Iter: 39600 | Total Loss: 0.007365 | Recon Loss: 0.006144 | Commit Loss: 0.002442 | Perplexity: 367.648685
2025-09-27 22:28:06,958 Stage: Train 0.5 | Epoch: 65 | Iter: 39800 | Total Loss: 0.007409 | Recon Loss: 0.006175 | Commit Loss: 0.002469 | Perplexity: 369.084723
2025-09-27 22:31:29,037 Stage: Train 0.5 | Epoch: 65 | Iter: 40000 | Total Loss: 0.007389 | Recon Loss: 0.006159 | Commit Loss: 0.002460 | Perplexity: 367.313760
2025-09-27 22:31:29,037 Saving model at iteration 40000
2025-09-27 22:31:29,758 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_66_step_40000
2025-09-27 22:31:30,331 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_66_step_40000/model.safetensors
2025-09-27 22:31:30,870 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_66_step_40000/optimizer.bin
2025-09-27 22:31:30,871 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_66_step_40000/scheduler.bin
2025-09-27 22:31:30,871 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_66_step_40000/sampler.bin
2025-09-27 22:31:30,872 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_66_step_40000/random_states_0.pkl
Trainning Epoch:   8%|▊         | 66/823 [11:21:21<130:23:48, 620.12s/it]Trainning Epoch:   8%|▊         | 66/823 [11:21:21<130:23:49, 620.12s/it]Trainning Epoch:   8%|▊         | 66/823 [11:21:21<130:23:51, 620.12s/it]Trainning Epoch:   8%|▊         | 66/823 [11:21:21<130:23:52, 620.12s/it]2025-09-27 22:34:56,470 Stage: Train 0.5 | Epoch: 66 | Iter: 40200 | Total Loss: 0.007331 | Recon Loss: 0.006100 | Commit Loss: 0.002463 | Perplexity: 368.169552
2025-09-27 22:38:17,695 Stage: Train 0.5 | Epoch: 66 | Iter: 40400 | Total Loss: 0.007364 | Recon Loss: 0.006131 | Commit Loss: 0.002466 | Perplexity: 367.696569
2025-09-27 22:41:38,982 Stage: Train 0.5 | Epoch: 66 | Iter: 40600 | Total Loss: 0.007332 | Recon Loss: 0.006115 | Commit Loss: 0.002434 | Perplexity: 368.570044
Trainning Epoch:   8%|▊         | 67/823 [11:31:36<129:56:39, 618.78s/it]Trainning Epoch:   8%|▊         | 67/823 [11:31:36<129:56:39, 618.78s/it]Trainning Epoch:   8%|▊         | 67/823 [11:31:36<129:56:41, 618.79s/it]Trainning Epoch:   8%|▊         | 67/823 [11:31:36<129:56:41, 618.79s/it]2025-09-27 22:45:04,135 Stage: Train 0.5 | Epoch: 67 | Iter: 40800 | Total Loss: 0.007345 | Recon Loss: 0.006133 | Commit Loss: 0.002423 | Perplexity: 367.428904
2025-09-27 22:48:25,483 Stage: Train 0.5 | Epoch: 67 | Iter: 41000 | Total Loss: 0.007303 | Recon Loss: 0.006082 | Commit Loss: 0.002441 | Perplexity: 368.283925
2025-09-27 22:51:46,797 Stage: Train 0.5 | Epoch: 67 | Iter: 41200 | Total Loss: 0.007369 | Recon Loss: 0.006139 | Commit Loss: 0.002460 | Perplexity: 368.210276
Trainning Epoch:   8%|▊         | 68/823 [11:41:53<129:37:48, 618.10s/it]Trainning Epoch:   8%|▊         | 68/823 [11:41:53<129:37:53, 618.11s/it]Trainning Epoch:   8%|▊         | 68/823 [11:41:53<129:37:53, 618.11s/it]Trainning Epoch:   8%|▊         | 68/823 [11:41:53<129:37:56, 618.11s/it]2025-09-27 22:55:12,979 Stage: Train 0.5 | Epoch: 68 | Iter: 41400 | Total Loss: 0.007315 | Recon Loss: 0.006107 | Commit Loss: 0.002416 | Perplexity: 367.752614
2025-09-27 22:58:33,844 Stage: Train 0.5 | Epoch: 68 | Iter: 41600 | Total Loss: 0.007250 | Recon Loss: 0.006035 | Commit Loss: 0.002432 | Perplexity: 368.218306
2025-09-27 23:01:55,443 Stage: Train 0.5 | Epoch: 68 | Iter: 41800 | Total Loss: 0.007357 | Recon Loss: 0.006123 | Commit Loss: 0.002466 | Perplexity: 368.717627
Trainning Epoch:   8%|▊         | 69/823 [11:52:09<129:21:17, 617.61s/it]Trainning Epoch:   8%|▊         | 69/823 [11:52:09<129:21:24, 617.62s/it]Trainning Epoch:   8%|▊         | 69/823 [11:52:09<129:21:20, 617.61s/it]Trainning Epoch:   8%|▊         | 69/823 [11:52:09<129:21:22, 617.62s/it]2025-09-27 23:05:20,907 Stage: Train 0.5 | Epoch: 69 | Iter: 42000 | Total Loss: 0.007329 | Recon Loss: 0.006104 | Commit Loss: 0.002450 | Perplexity: 369.429198
2025-09-27 23:08:42,080 Stage: Train 0.5 | Epoch: 69 | Iter: 42200 | Total Loss: 0.007240 | Recon Loss: 0.006028 | Commit Loss: 0.002423 | Perplexity: 367.527613
2025-09-27 23:12:04,643 Stage: Train 0.5 | Epoch: 69 | Iter: 42400 | Total Loss: 0.007278 | Recon Loss: 0.006058 | Commit Loss: 0.002438 | Perplexity: 368.313475
Trainning Epoch:   9%|▊         | 70/823 [12:02:27<129:12:29, 617.73s/it]Trainning Epoch:   9%|▊         | 70/823 [12:02:27<129:12:27, 617.73s/it]Trainning Epoch:   9%|▊         | 70/823 [12:02:27<129:12:29, 617.73s/it]Trainning Epoch:   9%|▊         | 70/823 [12:02:27<129:12:29, 617.73s/it]2025-09-27 23:15:31,301 Stage: Train 0.5 | Epoch: 70 | Iter: 42600 | Total Loss: 0.007317 | Recon Loss: 0.006097 | Commit Loss: 0.002441 | Perplexity: 370.233227
2025-09-27 23:18:53,365 Stage: Train 0.5 | Epoch: 70 | Iter: 42800 | Total Loss: 0.007222 | Recon Loss: 0.006018 | Commit Loss: 0.002406 | Perplexity: 370.118364
2025-09-27 23:22:15,753 Stage: Train 0.5 | Epoch: 70 | Iter: 43000 | Total Loss: 0.007286 | Recon Loss: 0.006073 | Commit Loss: 0.002426 | Perplexity: 370.292248
Trainning Epoch:   9%|▊         | 71/823 [12:12:47<129:07:53, 618.18s/it]Trainning Epoch:   9%|▊         | 71/823 [12:12:47<129:07:57, 618.19s/it]Trainning Epoch:   9%|▊         | 71/823 [12:12:47<129:07:55, 618.19s/it]Trainning Epoch:   9%|▊         | 71/823 [12:12:47<129:07:56, 618.19s/it]2025-09-27 23:25:42,501 Stage: Train 0.5 | Epoch: 71 | Iter: 43200 | Total Loss: 0.007207 | Recon Loss: 0.006005 | Commit Loss: 0.002403 | Perplexity: 369.274159
2025-09-27 23:29:03,488 Stage: Train 0.5 | Epoch: 71 | Iter: 43400 | Total Loss: 0.007220 | Recon Loss: 0.006023 | Commit Loss: 0.002394 | Perplexity: 368.264106
2025-09-27 23:32:24,692 Stage: Train 0.5 | Epoch: 71 | Iter: 43600 | Total Loss: 0.007203 | Recon Loss: 0.006007 | Commit Loss: 0.002392 | Perplexity: 370.078165
Trainning Epoch:   9%|▊         | 72/823 [12:23:03<128:51:06, 617.67s/it]Trainning Epoch:   9%|▊         | 72/823 [12:23:03<128:51:05, 617.66s/it]Trainning Epoch:   9%|▊         | 72/823 [12:23:03<128:51:07, 617.67s/it]Trainning Epoch:   9%|▊         | 72/823 [12:23:03<128:51:07, 617.67s/it]2025-09-27 23:35:50,607 Stage: Train 0.5 | Epoch: 72 | Iter: 43800 | Total Loss: 0.007229 | Recon Loss: 0.006004 | Commit Loss: 0.002450 | Perplexity: 370.828303
2025-09-27 23:39:13,191 Stage: Train 0.5 | Epoch: 72 | Iter: 44000 | Total Loss: 0.007119 | Recon Loss: 0.005922 | Commit Loss: 0.002394 | Perplexity: 369.527278
2025-09-27 23:42:36,284 Stage: Train 0.5 | Epoch: 72 | Iter: 44200 | Total Loss: 0.007184 | Recon Loss: 0.005973 | Commit Loss: 0.002421 | Perplexity: 369.979342
Trainning Epoch:   9%|▉         | 73/823 [12:33:23<128:49:33, 618.37s/it]Trainning Epoch:   9%|▉         | 73/823 [12:33:23<128:49:38, 618.37s/it]Trainning Epoch:   9%|▉         | 73/823 [12:33:23<128:49:38, 618.37s/it]Trainning Epoch:   9%|▉         | 73/823 [12:33:23<128:49:39, 618.37s/it]2025-09-27 23:46:03,083 Stage: Train 0.5 | Epoch: 73 | Iter: 44400 | Total Loss: 0.007197 | Recon Loss: 0.005993 | Commit Loss: 0.002408 | Perplexity: 370.740104
2025-09-27 23:49:26,886 Stage: Train 0.5 | Epoch: 73 | Iter: 44600 | Total Loss: 0.007249 | Recon Loss: 0.006043 | Commit Loss: 0.002412 | Perplexity: 370.766311
2025-09-27 23:52:51,077 Stage: Train 0.5 | Epoch: 73 | Iter: 44800 | Total Loss: 0.007078 | Recon Loss: 0.005875 | Commit Loss: 0.002407 | Perplexity: 370.318958
Trainning Epoch:   9%|▉         | 74/823 [12:43:47<129:01:55, 620.18s/it]Trainning Epoch:   9%|▉         | 74/823 [12:43:47<129:01:57, 620.18s/it]Trainning Epoch:   9%|▉         | 74/823 [12:43:47<129:01:58, 620.18s/it]Trainning Epoch:   9%|▉         | 74/823 [12:43:47<129:01:59, 620.19s/it]2025-09-27 23:56:19,205 Stage: Train 0.5 | Epoch: 74 | Iter: 45000 | Total Loss: 0.007214 | Recon Loss: 0.006002 | Commit Loss: 0.002423 | Perplexity: 370.456554
2025-09-27 23:59:43,560 Stage: Train 0.5 | Epoch: 74 | Iter: 45200 | Total Loss: 0.007185 | Recon Loss: 0.005969 | Commit Loss: 0.002432 | Perplexity: 371.136678
2025-09-28 00:03:07,954 Stage: Train 0.5 | Epoch: 74 | Iter: 45400 | Total Loss: 0.007084 | Recon Loss: 0.005890 | Commit Loss: 0.002388 | Perplexity: 369.680293
2025-09-28 00:06:32,375 Stage: Train 0.5 | Epoch: 74 | Iter: 45600 | Total Loss: 0.007095 | Recon Loss: 0.005899 | Commit Loss: 0.002393 | Perplexity: 370.244492
Trainning Epoch:   9%|▉         | 75/823 [12:54:13<129:10:33, 621.70s/it]Trainning Epoch:   9%|▉         | 75/823 [12:54:13<129:10:34, 621.70s/it]Trainning Epoch:   9%|▉         | 75/823 [12:54:13<129:10:34, 621.70s/it]Trainning Epoch:   9%|▉         | 75/823 [12:54:13<129:10:38, 621.71s/it]2025-09-28 00:09:56,714 Stage: Train 0.5 | Epoch: 75 | Iter: 45800 | Total Loss: 0.007063 | Recon Loss: 0.005872 | Commit Loss: 0.002382 | Perplexity: 370.346934
2025-09-28 00:13:18,071 Stage: Train 0.5 | Epoch: 75 | Iter: 46000 | Total Loss: 0.007136 | Recon Loss: 0.005940 | Commit Loss: 0.002393 | Perplexity: 370.292884
2025-09-28 00:16:40,131 Stage: Train 0.5 | Epoch: 75 | Iter: 46200 | Total Loss: 0.007094 | Recon Loss: 0.005890 | Commit Loss: 0.002408 | Perplexity: 369.408785
Trainning Epoch:   9%|▉         | 76/823 [13:04:29<128:38:17, 619.94s/it]Trainning Epoch:   9%|▉         | 76/823 [13:04:29<128:38:25, 619.95s/it]Trainning Epoch:   9%|▉         | 76/823 [13:04:29<128:38:25, 619.95s/it]Trainning Epoch:   9%|▉         | 76/823 [13:04:29<128:38:25, 619.95s/it]2025-09-28 00:20:04,146 Stage: Train 0.5 | Epoch: 76 | Iter: 46400 | Total Loss: 0.007132 | Recon Loss: 0.005926 | Commit Loss: 0.002412 | Perplexity: 370.069624
2025-09-28 00:23:24,964 Stage: Train 0.5 | Epoch: 76 | Iter: 46600 | Total Loss: 0.007078 | Recon Loss: 0.005885 | Commit Loss: 0.002387 | Perplexity: 370.696863
2025-09-28 00:26:46,099 Stage: Train 0.5 | Epoch: 76 | Iter: 46800 | Total Loss: 0.007064 | Recon Loss: 0.005867 | Commit Loss: 0.002394 | Perplexity: 369.112436
Trainning Epoch:   9%|▉         | 77/823 [13:14:42<128:05:24, 618.13s/it]Trainning Epoch:   9%|▉         | 77/823 [13:14:42<128:05:20, 618.12s/it]Trainning Epoch:   9%|▉         | 77/823 [13:14:42<128:05:21, 618.12s/it]Trainning Epoch:   9%|▉         | 77/823 [13:14:42<128:05:21, 618.13s/it]2025-09-28 00:30:10,760 Stage: Train 0.5 | Epoch: 77 | Iter: 47000 | Total Loss: 0.007086 | Recon Loss: 0.005883 | Commit Loss: 0.002407 | Perplexity: 371.580046
2025-09-28 00:33:32,936 Stage: Train 0.5 | Epoch: 77 | Iter: 47200 | Total Loss: 0.007022 | Recon Loss: 0.005831 | Commit Loss: 0.002382 | Perplexity: 370.135048
2025-09-28 00:36:54,594 Stage: Train 0.5 | Epoch: 77 | Iter: 47400 | Total Loss: 0.007007 | Recon Loss: 0.005813 | Commit Loss: 0.002388 | Perplexity: 369.578994
Trainning Epoch:   9%|▉         | 78/823 [13:24:59<127:49:29, 617.68s/it]Trainning Epoch:   9%|▉         | 78/823 [13:24:59<127:49:26, 617.67s/it]Trainning Epoch:   9%|▉         | 78/823 [13:24:59<127:49:33, 617.68s/it]Trainning Epoch:   9%|▉         | 78/823 [13:24:59<127:49:33, 617.68s/it]2025-09-28 00:40:20,689 Stage: Train 0.5 | Epoch: 78 | Iter: 47600 | Total Loss: 0.007029 | Recon Loss: 0.005838 | Commit Loss: 0.002381 | Perplexity: 370.069675
2025-09-28 00:43:43,823 Stage: Train 0.5 | Epoch: 78 | Iter: 47800 | Total Loss: 0.006969 | Recon Loss: 0.005789 | Commit Loss: 0.002358 | Perplexity: 369.928387
2025-09-28 00:47:06,696 Stage: Train 0.5 | Epoch: 78 | Iter: 48000 | Total Loss: 0.007036 | Recon Loss: 0.005843 | Commit Loss: 0.002386 | Perplexity: 370.824783
Trainning Epoch:  10%|▉         | 79/823 [13:35:20<127:51:09, 618.64s/it]Trainning Epoch:  10%|▉         | 79/823 [13:35:20<127:51:07, 618.64s/it]Trainning Epoch:  10%|▉         | 79/823 [13:35:20<127:51:09, 618.64s/it]Trainning Epoch:  10%|▉         | 79/823 [13:35:20<127:51:10, 618.64s/it]2025-09-28 00:50:32,359 Stage: Train 0.5 | Epoch: 79 | Iter: 48200 | Total Loss: 0.007011 | Recon Loss: 0.005819 | Commit Loss: 0.002383 | Perplexity: 370.975233
2025-09-28 00:53:54,392 Stage: Train 0.5 | Epoch: 79 | Iter: 48400 | Total Loss: 0.006978 | Recon Loss: 0.005777 | Commit Loss: 0.002402 | Perplexity: 370.391754
2025-09-28 00:57:16,320 Stage: Train 0.5 | Epoch: 79 | Iter: 48600 | Total Loss: 0.007019 | Recon Loss: 0.005823 | Commit Loss: 0.002391 | Perplexity: 370.344030
Trainning Epoch:  10%|▉         | 80/823 [13:45:37<127:34:48, 618.15s/it]Trainning Epoch:  10%|▉         | 80/823 [13:45:37<127:34:46, 618.15s/it]Trainning Epoch:  10%|▉         | 80/823 [13:45:37<127:34:47, 618.15s/it]Trainning Epoch:  10%|▉         | 80/823 [13:45:37<127:34:47, 618.15s/it]2025-09-28 01:00:41,476 Stage: Train 0.5 | Epoch: 80 | Iter: 48800 | Total Loss: 0.007051 | Recon Loss: 0.005855 | Commit Loss: 0.002392 | Perplexity: 370.715074
2025-09-28 01:04:03,407 Stage: Train 0.5 | Epoch: 80 | Iter: 49000 | Total Loss: 0.006933 | Recon Loss: 0.005732 | Commit Loss: 0.002402 | Perplexity: 369.897788
2025-09-28 01:07:25,136 Stage: Train 0.5 | Epoch: 80 | Iter: 49200 | Total Loss: 0.006981 | Recon Loss: 0.005785 | Commit Loss: 0.002392 | Perplexity: 371.312282
Trainning Epoch:  10%|▉         | 81/823 [13:55:54<127:20:13, 617.81s/it]Trainning Epoch:  10%|▉         | 81/823 [13:55:54<127:20:10, 617.80s/it]Trainning Epoch:  10%|▉         | 81/823 [13:55:54<127:20:11, 617.81s/it]Trainning Epoch:  10%|▉         | 81/823 [13:55:54<127:20:15, 617.81s/it]2025-09-28 01:10:49,019 Stage: Train 0.5 | Epoch: 81 | Iter: 49400 | Total Loss: 0.006987 | Recon Loss: 0.005782 | Commit Loss: 0.002411 | Perplexity: 371.730265
2025-09-28 01:14:09,569 Stage: Train 0.5 | Epoch: 81 | Iter: 49600 | Total Loss: 0.006964 | Recon Loss: 0.005777 | Commit Loss: 0.002374 | Perplexity: 370.891580
2025-09-28 01:17:31,030 Stage: Train 0.5 | Epoch: 81 | Iter: 49800 | Total Loss: 0.006908 | Recon Loss: 0.005719 | Commit Loss: 0.002380 | Perplexity: 369.119439
Trainning Epoch:  10%|▉         | 82/823 [14:06:08<126:55:14, 616.62s/it]Trainning Epoch:  10%|▉         | 82/823 [14:06:08<126:55:15, 616.62s/it]Trainning Epoch:  10%|▉         | 82/823 [14:06:08<126:55:18, 616.62s/it]Trainning Epoch:  10%|▉         | 82/823 [14:06:08<126:55:16, 616.62s/it]2025-09-28 01:20:56,660 Stage: Train 0.5 | Epoch: 82 | Iter: 50000 | Total Loss: 0.006930 | Recon Loss: 0.005732 | Commit Loss: 0.002396 | Perplexity: 371.827467
2025-09-28 01:24:18,888 Stage: Train 0.5 | Epoch: 82 | Iter: 50200 | Total Loss: 0.006946 | Recon Loss: 0.005753 | Commit Loss: 0.002386 | Perplexity: 370.174873
2025-09-28 01:27:41,173 Stage: Train 0.5 | Epoch: 82 | Iter: 50400 | Total Loss: 0.006903 | Recon Loss: 0.005709 | Commit Loss: 0.002387 | Perplexity: 370.361355
Trainning Epoch:  10%|█         | 83/823 [14:16:26<126:51:13, 617.13s/it]Trainning Epoch:  10%|█         | 83/823 [14:16:26<126:51:10, 617.12s/it]Trainning Epoch:  10%|█         | 83/823 [14:16:26<126:51:09, 617.12s/it]Trainning Epoch:  10%|█         | 83/823 [14:16:26<126:51:10, 617.12s/it]2025-09-28 01:31:06,878 Stage: Train 0.5 | Epoch: 83 | Iter: 50600 | Total Loss: 0.006955 | Recon Loss: 0.005760 | Commit Loss: 0.002390 | Perplexity: 370.621714
2025-09-28 01:34:29,650 Stage: Train 0.5 | Epoch: 83 | Iter: 50800 | Total Loss: 0.006924 | Recon Loss: 0.005734 | Commit Loss: 0.002380 | Perplexity: 370.183080
2025-09-28 01:37:52,915 Stage: Train 0.5 | Epoch: 83 | Iter: 51000 | Total Loss: 0.006907 | Recon Loss: 0.005701 | Commit Loss: 0.002412 | Perplexity: 369.803713
Trainning Epoch:  10%|█         | 84/823 [14:26:47<126:53:06, 618.11s/it]Trainning Epoch:  10%|█         | 84/823 [14:26:47<126:53:10, 618.12s/it]Trainning Epoch:  10%|█         | 84/823 [14:26:47<126:53:14, 618.12s/it]Trainning Epoch:  10%|█         | 84/823 [14:26:47<126:53:12, 618.12s/it]2025-09-28 01:41:19,202 Stage: Train 0.5 | Epoch: 84 | Iter: 51200 | Total Loss: 0.006885 | Recon Loss: 0.005697 | Commit Loss: 0.002378 | Perplexity: 370.078939
2025-09-28 01:44:41,474 Stage: Train 0.5 | Epoch: 84 | Iter: 51400 | Total Loss: 0.006904 | Recon Loss: 0.005711 | Commit Loss: 0.002385 | Perplexity: 370.392479
2025-09-28 01:48:04,442 Stage: Train 0.5 | Epoch: 84 | Iter: 51600 | Total Loss: 0.006871 | Recon Loss: 0.005680 | Commit Loss: 0.002382 | Perplexity: 370.280642
Trainning Epoch:  10%|█         | 85/823 [14:37:06<126:46:51, 618.44s/it]Trainning Epoch:  10%|█         | 85/823 [14:37:06<126:46:55, 618.45s/it]Trainning Epoch:  10%|█         | 85/823 [14:37:06<126:46:53, 618.45s/it]Trainning Epoch:  10%|█         | 85/823 [14:37:06<126:46:54, 618.45s/it]2025-09-28 01:51:29,965 Stage: Train 0.5 | Epoch: 85 | Iter: 51800 | Total Loss: 0.006855 | Recon Loss: 0.005670 | Commit Loss: 0.002370 | Perplexity: 369.816222
2025-09-28 01:54:51,868 Stage: Train 0.5 | Epoch: 85 | Iter: 52000 | Total Loss: 0.006810 | Recon Loss: 0.005623 | Commit Loss: 0.002373 | Perplexity: 371.057704
2025-09-28 01:58:13,959 Stage: Train 0.5 | Epoch: 85 | Iter: 52200 | Total Loss: 0.006851 | Recon Loss: 0.005663 | Commit Loss: 0.002375 | Perplexity: 369.835223
Trainning Epoch:  10%|█         | 86/823 [14:47:23<126:32:22, 618.10s/it]Trainning Epoch:  10%|█         | 86/823 [14:47:23<126:32:28, 618.11s/it]Trainning Epoch:  10%|█         | 86/823 [14:47:23<126:32:29, 618.11s/it]Trainning Epoch:  10%|█         | 86/823 [14:47:23<126:32:29, 618.11s/it]2025-09-28 02:01:38,329 Stage: Train 0.5 | Epoch: 86 | Iter: 52400 | Total Loss: 0.006897 | Recon Loss: 0.005698 | Commit Loss: 0.002398 | Perplexity: 370.866458
2025-09-28 02:04:59,530 Stage: Train 0.5 | Epoch: 86 | Iter: 52600 | Total Loss: 0.006859 | Recon Loss: 0.005674 | Commit Loss: 0.002371 | Perplexity: 370.102120
2025-09-28 02:08:21,826 Stage: Train 0.5 | Epoch: 86 | Iter: 52800 | Total Loss: 0.006787 | Recon Loss: 0.005606 | Commit Loss: 0.002361 | Perplexity: 370.353150
Trainning Epoch:  11%|█         | 87/823 [14:57:39<126:15:11, 617.54s/it]Trainning Epoch:  11%|█         | 87/823 [14:57:39<126:15:14, 617.55s/it]Trainning Epoch:  11%|█         | 87/823 [14:57:39<126:15:16, 617.55s/it]Trainning Epoch:  11%|█         | 87/823 [14:57:39<126:15:17, 617.55s/it]2025-09-28 02:11:47,884 Stage: Train 0.5 | Epoch: 87 | Iter: 53000 | Total Loss: 0.006844 | Recon Loss: 0.005645 | Commit Loss: 0.002398 | Perplexity: 371.105748
2025-09-28 02:15:09,773 Stage: Train 0.5 | Epoch: 87 | Iter: 53200 | Total Loss: 0.006806 | Recon Loss: 0.005625 | Commit Loss: 0.002362 | Perplexity: 370.913761
2025-09-28 02:18:32,390 Stage: Train 0.5 | Epoch: 87 | Iter: 53400 | Total Loss: 0.006777 | Recon Loss: 0.005595 | Commit Loss: 0.002364 | Perplexity: 370.309010
Trainning Epoch:  11%|█         | 88/823 [15:07:58<126:09:36, 617.93s/it]Trainning Epoch:  11%|█         | 88/823 [15:07:58<126:09:39, 617.93s/it]Trainning Epoch:  11%|█         | 88/823 [15:07:58<126:09:41, 617.93s/it]Trainning Epoch:  11%|█         | 88/823 [15:07:58<126:09:41, 617.93s/it]2025-09-28 02:21:58,465 Stage: Train 0.5 | Epoch: 88 | Iter: 53600 | Total Loss: 0.006817 | Recon Loss: 0.005630 | Commit Loss: 0.002374 | Perplexity: 370.443565
2025-09-28 02:25:21,549 Stage: Train 0.5 | Epoch: 88 | Iter: 53800 | Total Loss: 0.006778 | Recon Loss: 0.005591 | Commit Loss: 0.002375 | Perplexity: 370.809545
2025-09-28 02:28:45,380 Stage: Train 0.5 | Epoch: 88 | Iter: 54000 | Total Loss: 0.006814 | Recon Loss: 0.005630 | Commit Loss: 0.002368 | Perplexity: 370.338877
Trainning Epoch:  11%|█         | 89/823 [15:18:20<126:12:21, 618.99s/it]Trainning Epoch:  11%|█         | 89/823 [15:18:20<126:12:27, 619.00s/it]Trainning Epoch:  11%|█         | 89/823 [15:18:20<126:12:24, 619.00s/it]Trainning Epoch:  11%|█         | 89/823 [15:18:20<126:12:24, 619.00s/it]2025-09-28 02:32:11,926 Stage: Train 0.5 | Epoch: 89 | Iter: 54200 | Total Loss: 0.006750 | Recon Loss: 0.005567 | Commit Loss: 0.002367 | Perplexity: 370.686240
2025-09-28 02:35:34,220 Stage: Train 0.5 | Epoch: 89 | Iter: 54400 | Total Loss: 0.006760 | Recon Loss: 0.005578 | Commit Loss: 0.002365 | Perplexity: 370.760230
2025-09-28 02:38:56,230 Stage: Train 0.5 | Epoch: 89 | Iter: 54600 | Total Loss: 0.006838 | Recon Loss: 0.005655 | Commit Loss: 0.002365 | Perplexity: 370.900862
Trainning Epoch:  11%|█         | 90/823 [15:28:38<125:59:56, 618.82s/it]Trainning Epoch:  11%|█         | 90/823 [15:28:38<125:59:51, 618.82s/it]Trainning Epoch:  11%|█         | 90/823 [15:28:38<125:59:51, 618.82s/it]Trainning Epoch:  11%|█         | 90/823 [15:28:38<125:59:53, 618.82s/it]2025-09-28 02:42:22,527 Stage: Train 0.5 | Epoch: 90 | Iter: 54800 | Total Loss: 0.006817 | Recon Loss: 0.005616 | Commit Loss: 0.002402 | Perplexity: 371.988578
2025-09-28 02:45:46,296 Stage: Train 0.5 | Epoch: 90 | Iter: 55000 | Total Loss: 0.006716 | Recon Loss: 0.005531 | Commit Loss: 0.002370 | Perplexity: 371.547852
2025-09-28 02:49:09,989 Stage: Train 0.5 | Epoch: 90 | Iter: 55200 | Total Loss: 0.006755 | Recon Loss: 0.005580 | Commit Loss: 0.002350 | Perplexity: 371.369727
Trainning Epoch:  11%|█         | 91/823 [15:39:01<126:03:51, 619.99s/it]Trainning Epoch:  11%|█         | 91/823 [15:39:01<126:03:48, 619.98s/it]Trainning Epoch:  11%|█         | 91/823 [15:39:01<126:03:49, 619.99s/it]Trainning Epoch:  11%|█         | 91/823 [15:39:01<126:03:50, 619.99s/it]2025-09-28 02:52:36,447 Stage: Train 0.5 | Epoch: 91 | Iter: 55400 | Total Loss: 0.006785 | Recon Loss: 0.005588 | Commit Loss: 0.002395 | Perplexity: 372.004750
2025-09-28 02:55:57,791 Stage: Train 0.5 | Epoch: 91 | Iter: 55600 | Total Loss: 0.006734 | Recon Loss: 0.005540 | Commit Loss: 0.002388 | Perplexity: 371.596810
2025-09-28 02:59:19,609 Stage: Train 0.5 | Epoch: 91 | Iter: 55800 | Total Loss: 0.006744 | Recon Loss: 0.005561 | Commit Loss: 0.002366 | Perplexity: 371.579173
Trainning Epoch:  11%|█         | 92/823 [15:49:17<125:40:25, 618.91s/it]Trainning Epoch:  11%|█         | 92/823 [15:49:17<125:40:27, 618.92s/it]Trainning Epoch:  11%|█         | 92/823 [15:49:17<125:40:26, 618.92s/it]Trainning Epoch:  11%|█         | 92/823 [15:49:17<125:40:28, 618.92s/it]2025-09-28 03:02:45,415 Stage: Train 0.5 | Epoch: 92 | Iter: 56000 | Total Loss: 0.006690 | Recon Loss: 0.005515 | Commit Loss: 0.002350 | Perplexity: 371.255359
2025-09-28 03:06:08,341 Stage: Train 0.5 | Epoch: 92 | Iter: 56200 | Total Loss: 0.006691 | Recon Loss: 0.005521 | Commit Loss: 0.002339 | Perplexity: 371.582843
2025-09-28 03:09:31,448 Stage: Train 0.5 | Epoch: 92 | Iter: 56400 | Total Loss: 0.006720 | Recon Loss: 0.005541 | Commit Loss: 0.002359 | Perplexity: 371.052742
Trainning Epoch:  11%|█▏        | 93/823 [15:59:38<125:37:45, 619.54s/it]Trainning Epoch:  11%|█▏        | 93/823 [15:59:38<125:37:42, 619.54s/it]Trainning Epoch:  11%|█▏        | 93/823 [15:59:38<125:37:49, 619.55s/it]Trainning Epoch:  11%|█▏        | 93/823 [15:59:38<125:37:50, 619.55s/it]2025-09-28 03:12:58,027 Stage: Train 0.5 | Epoch: 93 | Iter: 56600 | Total Loss: 0.006721 | Recon Loss: 0.005550 | Commit Loss: 0.002343 | Perplexity: 371.333574
2025-09-28 03:16:18,817 Stage: Train 0.5 | Epoch: 93 | Iter: 56800 | Total Loss: 0.006675 | Recon Loss: 0.005495 | Commit Loss: 0.002359 | Perplexity: 371.379282
2025-09-28 03:19:39,357 Stage: Train 0.5 | Epoch: 93 | Iter: 57000 | Total Loss: 0.006705 | Recon Loss: 0.005521 | Commit Loss: 0.002368 | Perplexity: 371.777743
Trainning Epoch:  11%|█▏        | 94/823 [16:09:52<125:08:22, 617.97s/it]Trainning Epoch:  11%|█▏        | 94/823 [16:09:52<125:08:18, 617.97s/it]Trainning Epoch:  11%|█▏        | 94/823 [16:09:52<125:08:22, 617.97s/it]Trainning Epoch:  11%|█▏        | 94/823 [16:09:52<125:08:20, 617.97s/it]2025-09-28 03:23:04,160 Stage: Train 0.5 | Epoch: 94 | Iter: 57200 | Total Loss: 0.006667 | Recon Loss: 0.005496 | Commit Loss: 0.002343 | Perplexity: 370.233991
2025-09-28 03:26:24,589 Stage: Train 0.5 | Epoch: 94 | Iter: 57400 | Total Loss: 0.006625 | Recon Loss: 0.005456 | Commit Loss: 0.002337 | Perplexity: 370.219154
2025-09-28 03:29:45,135 Stage: Train 0.5 | Epoch: 94 | Iter: 57600 | Total Loss: 0.006744 | Recon Loss: 0.005550 | Commit Loss: 0.002387 | Perplexity: 372.829604
Trainning Epoch:  12%|█▏        | 95/823 [16:20:06<124:42:47, 616.71s/it]Trainning Epoch:  12%|█▏        | 95/823 [16:20:06<124:42:52, 616.72s/it]Trainning Epoch:  12%|█▏        | 95/823 [16:20:06<124:42:55, 616.72s/it]Trainning Epoch:  12%|█▏        | 95/823 [16:20:06<124:42:51, 616.72s/it]2025-09-28 03:33:10,005 Stage: Train 0.5 | Epoch: 95 | Iter: 57800 | Total Loss: 0.006695 | Recon Loss: 0.005504 | Commit Loss: 0.002382 | Perplexity: 373.424334
2025-09-28 03:36:31,133 Stage: Train 0.5 | Epoch: 95 | Iter: 58000 | Total Loss: 0.006701 | Recon Loss: 0.005527 | Commit Loss: 0.002350 | Perplexity: 371.543703
2025-09-28 03:39:54,021 Stage: Train 0.5 | Epoch: 95 | Iter: 58200 | Total Loss: 0.006625 | Recon Loss: 0.005452 | Commit Loss: 0.002346 | Perplexity: 371.969801
Trainning Epoch:  12%|█▏        | 96/823 [16:30:25<124:38:46, 617.23s/it]Trainning Epoch:  12%|█▏        | 96/823 [16:30:25<124:38:52, 617.24s/it]Trainning Epoch:  12%|█▏        | 96/823 [16:30:25<124:38:53, 617.24s/it]Trainning Epoch:  12%|█▏        | 96/823 [16:30:25<124:38:51, 617.24s/it]2025-09-28 03:43:20,333 Stage: Train 0.5 | Epoch: 96 | Iter: 58400 | Total Loss: 0.006665 | Recon Loss: 0.005489 | Commit Loss: 0.002354 | Perplexity: 372.384632
2025-09-28 03:46:41,314 Stage: Train 0.5 | Epoch: 96 | Iter: 58600 | Total Loss: 0.006616 | Recon Loss: 0.005444 | Commit Loss: 0.002345 | Perplexity: 371.864014
2025-09-28 03:50:03,739 Stage: Train 0.5 | Epoch: 96 | Iter: 58800 | Total Loss: 0.006639 | Recon Loss: 0.005462 | Commit Loss: 0.002355 | Perplexity: 371.874809
Trainning Epoch:  12%|█▏        | 97/823 [16:40:43<124:31:00, 617.44s/it]Trainning Epoch:  12%|█▏        | 97/823 [16:40:43<124:31:11, 617.45s/it]Trainning Epoch:  12%|█▏        | 97/823 [16:40:43<124:31:15, 617.46s/it]Trainning Epoch:  12%|█▏        | 97/823 [16:40:43<124:31:13, 617.46s/it]2025-09-28 03:53:30,529 Stage: Train 0.5 | Epoch: 97 | Iter: 59000 | Total Loss: 0.006666 | Recon Loss: 0.005487 | Commit Loss: 0.002358 | Perplexity: 372.550596
2025-09-28 03:56:54,693 Stage: Train 0.5 | Epoch: 97 | Iter: 59200 | Total Loss: 0.006601 | Recon Loss: 0.005430 | Commit Loss: 0.002342 | Perplexity: 372.480637
2025-09-28 04:00:18,740 Stage: Train 0.5 | Epoch: 97 | Iter: 59400 | Total Loss: 0.006578 | Recon Loss: 0.005410 | Commit Loss: 0.002336 | Perplexity: 371.742765
Trainning Epoch:  12%|█▏        | 98/823 [16:51:07<124:44:12, 619.38s/it]Trainning Epoch:  12%|█▏        | 98/823 [16:51:07<124:44:17, 619.39s/it]Trainning Epoch:  12%|█▏        | 98/823 [16:51:07<124:44:16, 619.39s/it]Trainning Epoch:  12%|█▏        | 98/823 [16:51:07<124:44:19, 619.39s/it]2025-09-28 04:03:45,923 Stage: Train 0.5 | Epoch: 98 | Iter: 59600 | Total Loss: 0.006597 | Recon Loss: 0.005426 | Commit Loss: 0.002341 | Perplexity: 371.781993
2025-09-28 04:07:06,465 Stage: Train 0.5 | Epoch: 98 | Iter: 59800 | Total Loss: 0.006592 | Recon Loss: 0.005423 | Commit Loss: 0.002339 | Perplexity: 372.949313
2025-09-28 04:10:26,533 Stage: Train 0.5 | Epoch: 98 | Iter: 60000 | Total Loss: 0.006538 | Recon Loss: 0.005372 | Commit Loss: 0.002332 | Perplexity: 372.117495
2025-09-28 04:10:26,534 Saving model at iteration 60000
2025-09-28 04:10:27,258 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_99_step_60000
2025-09-28 04:10:27,899 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_99_step_60000/model.safetensors
2025-09-28 04:10:28,484 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_99_step_60000/optimizer.bin
2025-09-28 04:10:28,485 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_99_step_60000/scheduler.bin
2025-09-28 04:10:28,485 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_99_step_60000/sampler.bin
2025-09-28 04:10:28,487 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_99_step_60000/random_states_0.pkl
Trainning Epoch:  12%|█▏        | 99/823 [17:01:21<124:17:06, 617.99s/it]Trainning Epoch:  12%|█▏        | 99/823 [17:01:21<124:17:01, 617.99s/it]Trainning Epoch:  12%|█▏        | 99/823 [17:01:21<124:17:01, 617.99s/it]Trainning Epoch:  12%|█▏        | 99/823 [17:01:21<124:17:01, 617.99s/it]2025-09-28 04:13:52,701 Stage: Train 0.5 | Epoch: 99 | Iter: 60200 | Total Loss: 0.006584 | Recon Loss: 0.005412 | Commit Loss: 0.002344 | Perplexity: 372.428626
2025-09-28 04:17:13,260 Stage: Train 0.5 | Epoch: 99 | Iter: 60400 | Total Loss: 0.006606 | Recon Loss: 0.005432 | Commit Loss: 0.002349 | Perplexity: 372.610398
2025-09-28 04:20:33,903 Stage: Train 0.5 | Epoch: 99 | Iter: 60600 | Total Loss: 0.006617 | Recon Loss: 0.005448 | Commit Loss: 0.002337 | Perplexity: 372.758818
2025-09-28 04:23:54,836 Stage: Train 0.5 | Epoch: 99 | Iter: 60800 | Total Loss: 0.006581 | Recon Loss: 0.005408 | Commit Loss: 0.002346 | Perplexity: 372.431975
Trainning Epoch:  12%|█▏        | 100/823 [17:11:35<123:51:59, 616.76s/it]Trainning Epoch:  12%|█▏        | 100/823 [17:11:35<123:51:54, 616.76s/it]Trainning Epoch:  12%|█▏        | 100/823 [17:11:35<123:51:54, 616.76s/it]Trainning Epoch:  12%|█▏        | 100/823 [17:11:35<123:51:56, 616.76s/it]2025-09-28 04:27:21,093 Stage: Train 0.5 | Epoch: 100 | Iter: 61000 | Total Loss: 0.006571 | Recon Loss: 0.005398 | Commit Loss: 0.002347 | Perplexity: 372.105216
2025-09-28 04:30:43,689 Stage: Train 0.5 | Epoch: 100 | Iter: 61200 | Total Loss: 0.006572 | Recon Loss: 0.005398 | Commit Loss: 0.002348 | Perplexity: 372.618251
2025-09-28 04:34:06,316 Stage: Train 0.5 | Epoch: 100 | Iter: 61400 | Total Loss: 0.006611 | Recon Loss: 0.005444 | Commit Loss: 0.002334 | Perplexity: 371.292413
Trainning Epoch:  12%|█▏        | 101/823 [17:21:55<123:51:38, 617.59s/it]Trainning Epoch:  12%|█▏        | 101/823 [17:21:55<123:51:41, 617.59s/it]Trainning Epoch:  12%|█▏        | 101/823 [17:21:55<123:51:40, 617.59s/it]Trainning Epoch:  12%|█▏        | 101/823 [17:21:55<123:51:40, 617.59s/it]2025-09-28 04:37:33,057 Stage: Train 0.5 | Epoch: 101 | Iter: 61600 | Total Loss: 0.006550 | Recon Loss: 0.005379 | Commit Loss: 0.002341 | Perplexity: 372.535542
2025-09-28 04:40:55,657 Stage: Train 0.5 | Epoch: 101 | Iter: 61800 | Total Loss: 0.006471 | Recon Loss: 0.005307 | Commit Loss: 0.002328 | Perplexity: 370.930869
2025-09-28 04:44:18,174 Stage: Train 0.5 | Epoch: 101 | Iter: 62000 | Total Loss: 0.006517 | Recon Loss: 0.005355 | Commit Loss: 0.002323 | Perplexity: 371.823230
Trainning Epoch:  12%|█▏        | 102/823 [17:32:15<123:49:45, 618.29s/it]Trainning Epoch:  12%|█▏        | 102/823 [17:32:15<123:49:49, 618.29s/it]Trainning Epoch:  12%|█▏        | 102/823 [17:32:15<123:49:49, 618.29s/it]Trainning Epoch:  12%|█▏        | 102/823 [17:32:15<123:49:52, 618.30s/it]2025-09-28 04:47:42,956 Stage: Train 0.5 | Epoch: 102 | Iter: 62200 | Total Loss: 0.006527 | Recon Loss: 0.005359 | Commit Loss: 0.002335 | Perplexity: 371.588232
2025-09-28 04:51:04,714 Stage: Train 0.5 | Epoch: 102 | Iter: 62400 | Total Loss: 0.006526 | Recon Loss: 0.005358 | Commit Loss: 0.002335 | Perplexity: 372.501889
2025-09-28 04:54:27,070 Stage: Train 0.5 | Epoch: 102 | Iter: 62600 | Total Loss: 0.006542 | Recon Loss: 0.005379 | Commit Loss: 0.002325 | Perplexity: 372.400621
Trainning Epoch:  13%|█▎        | 103/823 [17:42:32<123:34:40, 617.89s/it]Trainning Epoch:  13%|█▎        | 103/823 [17:42:32<123:34:43, 617.89s/it]Trainning Epoch:  13%|█▎        | 103/823 [17:42:32<123:34:43, 617.89s/it]Trainning Epoch:  13%|█▎        | 103/823 [17:42:32<123:34:44, 617.89s/it]2025-09-28 04:57:52,619 Stage: Train 0.5 | Epoch: 103 | Iter: 62800 | Total Loss: 0.006458 | Recon Loss: 0.005301 | Commit Loss: 0.002315 | Perplexity: 373.083288
2025-09-28 05:01:14,975 Stage: Train 0.5 | Epoch: 103 | Iter: 63000 | Total Loss: 0.006491 | Recon Loss: 0.005327 | Commit Loss: 0.002328 | Perplexity: 373.229736
2025-09-28 05:04:38,245 Stage: Train 0.5 | Epoch: 103 | Iter: 63200 | Total Loss: 0.006509 | Recon Loss: 0.005350 | Commit Loss: 0.002318 | Perplexity: 372.283129
Trainning Epoch:  13%|█▎        | 104/823 [17:52:51<123:29:47, 618.34s/it]Trainning Epoch:  13%|█▎        | 104/823 [17:52:51<123:29:49, 618.34s/it]Trainning Epoch:  13%|█▎        | 104/823 [17:52:51<123:29:49, 618.34s/it]Trainning Epoch:  13%|█▎        | 104/823 [17:52:51<123:29:50, 618.35s/it]2025-09-28 05:08:05,343 Stage: Train 0.5 | Epoch: 104 | Iter: 63400 | Total Loss: 0.006485 | Recon Loss: 0.005325 | Commit Loss: 0.002320 | Perplexity: 374.236207
2025-09-28 05:11:29,445 Stage: Train 0.5 | Epoch: 104 | Iter: 63600 | Total Loss: 0.006519 | Recon Loss: 0.005350 | Commit Loss: 0.002338 | Perplexity: 373.549922
2025-09-28 05:14:53,628 Stage: Train 0.5 | Epoch: 104 | Iter: 63800 | Total Loss: 0.006452 | Recon Loss: 0.005287 | Commit Loss: 0.002330 | Perplexity: 373.395340
Trainning Epoch:  13%|█▎        | 105/823 [18:03:15<123:38:11, 619.90s/it]Trainning Epoch:  13%|█▎        | 105/823 [18:03:15<123:38:05, 619.90s/it]Trainning Epoch:  13%|█▎        | 105/823 [18:03:15<123:38:05, 619.90s/it]Trainning Epoch:  13%|█▎        | 105/823 [18:03:15<123:38:06, 619.90s/it]2025-09-28 05:18:19,682 Stage: Train 0.5 | Epoch: 105 | Iter: 64000 | Total Loss: 0.006467 | Recon Loss: 0.005308 | Commit Loss: 0.002320 | Perplexity: 372.429821
2025-09-28 05:21:40,830 Stage: Train 0.5 | Epoch: 105 | Iter: 64200 | Total Loss: 0.006484 | Recon Loss: 0.005321 | Commit Loss: 0.002326 | Perplexity: 373.606951
2025-09-28 05:25:02,488 Stage: Train 0.5 | Epoch: 105 | Iter: 64400 | Total Loss: 0.006480 | Recon Loss: 0.005327 | Commit Loss: 0.002307 | Perplexity: 371.508761
Trainning Epoch:  13%|█▎        | 106/823 [18:13:31<123:15:53, 618.90s/it]Trainning Epoch:  13%|█▎        | 106/823 [18:13:31<123:15:54, 618.90s/it]Trainning Epoch:  13%|█▎        | 106/823 [18:13:31<123:15:59, 618.91s/it]Trainning Epoch:  13%|█▎        | 106/823 [18:13:31<123:15:55, 618.91s/it]2025-09-28 05:28:28,794 Stage: Train 0.5 | Epoch: 106 | Iter: 64600 | Total Loss: 0.006394 | Recon Loss: 0.005237 | Commit Loss: 0.002313 | Perplexity: 372.604470
2025-09-28 05:31:51,765 Stage: Train 0.5 | Epoch: 106 | Iter: 64800 | Total Loss: 0.006426 | Recon Loss: 0.005271 | Commit Loss: 0.002311 | Perplexity: 372.527041
2025-09-28 05:35:14,465 Stage: Train 0.5 | Epoch: 106 | Iter: 65000 | Total Loss: 0.006484 | Recon Loss: 0.005319 | Commit Loss: 0.002329 | Perplexity: 372.993339
Trainning Epoch:  13%|█▎        | 107/823 [18:23:52<123:11:29, 619.40s/it]Trainning Epoch:  13%|█▎        | 107/823 [18:23:52<123:11:36, 619.41s/it]Trainning Epoch:  13%|█▎        | 107/823 [18:23:52<123:11:36, 619.41s/it]Trainning Epoch:  13%|█▎        | 107/823 [18:23:52<123:11:36, 619.41s/it]2025-09-28 05:38:40,983 Stage: Train 0.5 | Epoch: 107 | Iter: 65200 | Total Loss: 0.006418 | Recon Loss: 0.005266 | Commit Loss: 0.002305 | Perplexity: 372.441696
2025-09-28 05:42:03,791 Stage: Train 0.5 | Epoch: 107 | Iter: 65400 | Total Loss: 0.006417 | Recon Loss: 0.005261 | Commit Loss: 0.002313 | Perplexity: 372.516466
2025-09-28 05:45:25,957 Stage: Train 0.5 | Epoch: 107 | Iter: 65600 | Total Loss: 0.006447 | Recon Loss: 0.005283 | Commit Loss: 0.002329 | Perplexity: 372.471620
Trainning Epoch:  13%|█▎        | 108/823 [18:34:11<123:00:06, 619.31s/it]Trainning Epoch:  13%|█▎        | 108/823 [18:34:11<123:00:10, 619.32s/it]Trainning Epoch:  13%|█▎        | 108/823 [18:34:11<123:00:06, 619.31s/it]Trainning Epoch:  13%|█▎        | 108/823 [18:34:11<123:00:05, 619.31s/it]2025-09-28 05:48:51,565 Stage: Train 0.5 | Epoch: 108 | Iter: 65800 | Total Loss: 0.006440 | Recon Loss: 0.005279 | Commit Loss: 0.002323 | Perplexity: 373.174080
2025-09-28 05:52:14,070 Stage: Train 0.5 | Epoch: 108 | Iter: 66000 | Total Loss: 0.006420 | Recon Loss: 0.005245 | Commit Loss: 0.002349 | Perplexity: 372.285410
2025-09-28 05:55:36,570 Stage: Train 0.5 | Epoch: 108 | Iter: 66200 | Total Loss: 0.006439 | Recon Loss: 0.005285 | Commit Loss: 0.002307 | Perplexity: 371.382058
Trainning Epoch:  13%|█▎        | 109/823 [18:44:30<122:47:58, 619.16s/it]Trainning Epoch:  13%|█▎        | 109/823 [18:44:30<122:48:01, 619.16s/it]Trainning Epoch:  13%|█▎        | 109/823 [18:44:30<122:48:01, 619.16s/it]Trainning Epoch:  13%|█▎        | 109/823 [18:44:30<122:48:02, 619.16s/it]2025-09-28 05:59:03,896 Stage: Train 0.5 | Epoch: 109 | Iter: 66400 | Total Loss: 0.006428 | Recon Loss: 0.005272 | Commit Loss: 0.002312 | Perplexity: 373.340453
2025-09-28 06:02:27,262 Stage: Train 0.5 | Epoch: 109 | Iter: 66600 | Total Loss: 0.006341 | Recon Loss: 0.005192 | Commit Loss: 0.002298 | Perplexity: 372.152990
2025-09-28 06:05:50,854 Stage: Train 0.5 | Epoch: 109 | Iter: 66800 | Total Loss: 0.006375 | Recon Loss: 0.005224 | Commit Loss: 0.002301 | Perplexity: 372.739180
Trainning Epoch:  13%|█▎        | 110/823 [18:54:53<122:51:05, 620.29s/it]Trainning Epoch:  13%|█▎        | 110/823 [18:54:53<122:51:07, 620.29s/it]Trainning Epoch:  13%|█▎        | 110/823 [18:54:52<122:51:05, 620.29s/it]Trainning Epoch:  13%|█▎        | 110/823 [18:54:53<122:51:06, 620.29s/it]2025-09-28 06:09:16,813 Stage: Train 0.5 | Epoch: 110 | Iter: 67000 | Total Loss: 0.006425 | Recon Loss: 0.005269 | Commit Loss: 0.002311 | Perplexity: 372.864793
2025-09-28 06:12:38,613 Stage: Train 0.5 | Epoch: 110 | Iter: 67200 | Total Loss: 0.006313 | Recon Loss: 0.005164 | Commit Loss: 0.002298 | Perplexity: 372.532276
2025-09-28 06:16:01,223 Stage: Train 0.5 | Epoch: 110 | Iter: 67400 | Total Loss: 0.006382 | Recon Loss: 0.005226 | Commit Loss: 0.002312 | Perplexity: 372.354805
Trainning Epoch:  13%|█▎        | 111/823 [19:05:10<122:32:07, 619.56s/it]Trainning Epoch:  13%|█▎        | 111/823 [19:05:10<122:32:05, 619.56s/it]Trainning Epoch:  13%|█▎        | 111/823 [19:05:10<122:32:09, 619.56s/it]Trainning Epoch:  13%|█▎        | 111/823 [19:05:10<122:32:12, 619.57s/it]2025-09-28 06:19:26,968 Stage: Train 0.5 | Epoch: 111 | Iter: 67600 | Total Loss: 0.006294 | Recon Loss: 0.005150 | Commit Loss: 0.002288 | Perplexity: 373.351541
2025-09-28 06:22:50,249 Stage: Train 0.5 | Epoch: 111 | Iter: 67800 | Total Loss: 0.006330 | Recon Loss: 0.005182 | Commit Loss: 0.002296 | Perplexity: 373.261492
2025-09-28 06:26:13,313 Stage: Train 0.5 | Epoch: 111 | Iter: 68000 | Total Loss: 0.006352 | Recon Loss: 0.005206 | Commit Loss: 0.002292 | Perplexity: 373.159808
Trainning Epoch:  14%|█▎        | 112/823 [19:15:31<122:25:03, 619.84s/it]Trainning Epoch:  14%|█▎        | 112/823 [19:15:31<122:25:11, 619.85s/it]Trainning Epoch:  14%|█▎        | 112/823 [19:15:31<122:25:10, 619.85s/it]Trainning Epoch:  14%|█▎        | 112/823 [19:15:31<122:25:09, 619.84s/it]2025-09-28 06:29:39,000 Stage: Train 0.5 | Epoch: 112 | Iter: 68200 | Total Loss: 0.006388 | Recon Loss: 0.005229 | Commit Loss: 0.002319 | Perplexity: 373.913704
2025-09-28 06:33:01,140 Stage: Train 0.5 | Epoch: 112 | Iter: 68400 | Total Loss: 0.006313 | Recon Loss: 0.005161 | Commit Loss: 0.002304 | Perplexity: 373.123984
2025-09-28 06:36:23,749 Stage: Train 0.5 | Epoch: 112 | Iter: 68600 | Total Loss: 0.006355 | Recon Loss: 0.005198 | Commit Loss: 0.002315 | Perplexity: 373.324209
Trainning Epoch:  14%|█▎        | 113/823 [19:25:49<122:09:42, 619.41s/it]Trainning Epoch:  14%|█▎        | 113/823 [19:25:49<122:09:44, 619.41s/it]Trainning Epoch:  14%|█▎        | 113/823 [19:25:49<122:09:46, 619.42s/it]Trainning Epoch:  14%|█▎        | 113/823 [19:25:49<122:09:45, 619.42s/it]2025-09-28 06:39:49,852 Stage: Train 0.5 | Epoch: 113 | Iter: 68800 | Total Loss: 0.006362 | Recon Loss: 0.005207 | Commit Loss: 0.002310 | Perplexity: 374.402341
2025-09-28 06:43:12,196 Stage: Train 0.5 | Epoch: 113 | Iter: 69000 | Total Loss: 0.006336 | Recon Loss: 0.005189 | Commit Loss: 0.002293 | Perplexity: 373.407541
2025-09-28 06:46:34,435 Stage: Train 0.5 | Epoch: 113 | Iter: 69200 | Total Loss: 0.006333 | Recon Loss: 0.005171 | Commit Loss: 0.002322 | Perplexity: 373.428892
Trainning Epoch:  14%|█▍        | 114/823 [19:36:08<121:58:39, 619.35s/it]Trainning Epoch:  14%|█▍        | 114/823 [19:36:08<121:58:36, 619.35s/it]Trainning Epoch:  14%|█▍        | 114/823 [19:36:08<121:58:35, 619.35s/it]Trainning Epoch:  14%|█▍        | 114/823 [19:36:08<121:58:36, 619.35s/it]2025-09-28 06:50:00,605 Stage: Train 0.5 | Epoch: 114 | Iter: 69400 | Total Loss: 0.006334 | Recon Loss: 0.005176 | Commit Loss: 0.002315 | Perplexity: 374.637229
2025-09-28 06:53:22,056 Stage: Train 0.5 | Epoch: 114 | Iter: 69600 | Total Loss: 0.006307 | Recon Loss: 0.005155 | Commit Loss: 0.002304 | Perplexity: 372.595564
2025-09-28 06:56:43,790 Stage: Train 0.5 | Epoch: 114 | Iter: 69800 | Total Loss: 0.006351 | Recon Loss: 0.005194 | Commit Loss: 0.002314 | Perplexity: 373.919013
Trainning Epoch:  14%|█▍        | 115/823 [19:46:25<121:38:30, 618.52s/it]Trainning Epoch:  14%|█▍        | 115/823 [19:46:25<121:38:33, 618.52s/it]Trainning Epoch:  14%|█▍        | 115/823 [19:46:25<121:38:33, 618.52s/it]Trainning Epoch:  14%|█▍        | 115/823 [19:46:25<121:38:32, 618.52s/it]2025-09-28 07:00:09,468 Stage: Train 0.5 | Epoch: 115 | Iter: 70000 | Total Loss: 0.006286 | Recon Loss: 0.005135 | Commit Loss: 0.002303 | Perplexity: 373.903233
2025-09-28 07:03:31,897 Stage: Train 0.5 | Epoch: 115 | Iter: 70200 | Total Loss: 0.006283 | Recon Loss: 0.005135 | Commit Loss: 0.002295 | Perplexity: 373.060950
2025-09-28 07:06:54,899 Stage: Train 0.5 | Epoch: 115 | Iter: 70400 | Total Loss: 0.006375 | Recon Loss: 0.005218 | Commit Loss: 0.002315 | Perplexity: 374.243103
Trainning Epoch:  14%|█▍        | 116/823 [19:56:45<121:32:13, 618.86s/it]Trainning Epoch:  14%|█▍        | 116/823 [19:56:45<121:32:13, 618.86s/it]Trainning Epoch:  14%|█▍        | 116/823 [19:56:45<121:32:17, 618.87s/it]Trainning Epoch:  14%|█▍        | 116/823 [19:56:45<121:32:13, 618.86s/it]2025-09-28 07:10:21,096 Stage: Train 0.5 | Epoch: 116 | Iter: 70600 | Total Loss: 0.006305 | Recon Loss: 0.005162 | Commit Loss: 0.002285 | Perplexity: 372.645827
2025-09-28 07:13:43,314 Stage: Train 0.5 | Epoch: 116 | Iter: 70800 | Total Loss: 0.006269 | Recon Loss: 0.005120 | Commit Loss: 0.002299 | Perplexity: 373.104024
2025-09-28 07:17:05,358 Stage: Train 0.5 | Epoch: 116 | Iter: 71000 | Total Loss: 0.006322 | Recon Loss: 0.005169 | Commit Loss: 0.002306 | Perplexity: 372.861935
Trainning Epoch:  14%|█▍        | 117/823 [20:07:03<121:19:49, 618.68s/it]Trainning Epoch:  14%|█▍        | 117/823 [20:07:03<121:19:52, 618.69s/it]Trainning Epoch:  14%|█▍        | 117/823 [20:07:03<121:19:50, 618.68s/it]Trainning Epoch:  14%|█▍        | 117/823 [20:07:03<121:19:51, 618.69s/it]2025-09-28 07:20:31,734 Stage: Train 0.5 | Epoch: 117 | Iter: 71200 | Total Loss: 0.006320 | Recon Loss: 0.005169 | Commit Loss: 0.002302 | Perplexity: 373.840736
2025-09-28 07:23:54,706 Stage: Train 0.5 | Epoch: 117 | Iter: 71400 | Total Loss: 0.006234 | Recon Loss: 0.005092 | Commit Loss: 0.002283 | Perplexity: 374.473767
2025-09-28 07:27:17,842 Stage: Train 0.5 | Epoch: 117 | Iter: 71600 | Total Loss: 0.006276 | Recon Loss: 0.005128 | Commit Loss: 0.002296 | Perplexity: 373.872304
Trainning Epoch:  14%|█▍        | 118/823 [20:17:24<121:17:56, 619.40s/it]Trainning Epoch:  14%|█▍        | 118/823 [20:17:24<121:17:55, 619.40s/it]Trainning Epoch:  14%|█▍        | 118/823 [20:17:24<121:17:54, 619.40s/it]Trainning Epoch:  14%|█▍        | 118/823 [20:17:24<121:17:54, 619.40s/it]2025-09-28 07:30:44,514 Stage: Train 0.5 | Epoch: 118 | Iter: 71800 | Total Loss: 0.006288 | Recon Loss: 0.005129 | Commit Loss: 0.002317 | Perplexity: 374.888206
2025-09-28 07:34:07,497 Stage: Train 0.5 | Epoch: 118 | Iter: 72000 | Total Loss: 0.006275 | Recon Loss: 0.005120 | Commit Loss: 0.002309 | Perplexity: 373.184632
2025-09-28 07:37:31,479 Stage: Train 0.5 | Epoch: 118 | Iter: 72200 | Total Loss: 0.006294 | Recon Loss: 0.005134 | Commit Loss: 0.002320 | Perplexity: 375.849002
Trainning Epoch:  14%|█▍        | 119/823 [20:27:47<121:18:22, 620.32s/it]Trainning Epoch:  14%|█▍        | 119/823 [20:27:47<121:18:26, 620.32s/it]Trainning Epoch:  14%|█▍        | 119/823 [20:27:47<121:18:26, 620.32s/it]Trainning Epoch:  14%|█▍        | 119/823 [20:27:47<121:18:26, 620.32s/it]2025-09-28 07:40:58,446 Stage: Train 0.5 | Epoch: 119 | Iter: 72400 | Total Loss: 0.006280 | Recon Loss: 0.005133 | Commit Loss: 0.002293 | Perplexity: 375.098921
2025-09-28 07:44:21,174 Stage: Train 0.5 | Epoch: 119 | Iter: 72600 | Total Loss: 0.006244 | Recon Loss: 0.005106 | Commit Loss: 0.002275 | Perplexity: 374.267760
2025-09-28 07:47:44,620 Stage: Train 0.5 | Epoch: 119 | Iter: 72800 | Total Loss: 0.006292 | Recon Loss: 0.005138 | Commit Loss: 0.002309 | Perplexity: 374.871280
Trainning Epoch:  15%|█▍        | 120/823 [20:38:08<121:10:20, 620.51s/it]Trainning Epoch:  15%|█▍        | 120/823 [20:38:08<121:10:22, 620.52s/it]Trainning Epoch:  15%|█▍        | 120/823 [20:38:08<121:10:25, 620.52s/it]Trainning Epoch:  15%|█▍        | 120/823 [20:38:07<121:10:23, 620.52s/it]2025-09-28 07:51:11,295 Stage: Train 0.5 | Epoch: 120 | Iter: 73000 | Total Loss: 0.006287 | Recon Loss: 0.005136 | Commit Loss: 0.002302 | Perplexity: 374.554146
2025-09-28 07:54:33,274 Stage: Train 0.5 | Epoch: 120 | Iter: 73200 | Total Loss: 0.006205 | Recon Loss: 0.005063 | Commit Loss: 0.002285 | Perplexity: 374.000613
2025-09-28 07:57:55,113 Stage: Train 0.5 | Epoch: 120 | Iter: 73400 | Total Loss: 0.006218 | Recon Loss: 0.005082 | Commit Loss: 0.002272 | Perplexity: 374.378389
Trainning Epoch:  15%|█▍        | 121/823 [20:48:25<120:49:42, 619.63s/it]Trainning Epoch:  15%|█▍        | 121/823 [20:48:25<120:49:48, 619.64s/it]Trainning Epoch:  15%|█▍        | 121/823 [20:48:25<120:49:47, 619.64s/it]Trainning Epoch:  15%|█▍        | 121/823 [20:48:25<120:49:47, 619.64s/it]2025-09-28 08:01:21,017 Stage: Train 0.5 | Epoch: 121 | Iter: 73600 | Total Loss: 0.006233 | Recon Loss: 0.005085 | Commit Loss: 0.002297 | Perplexity: 375.121865
2025-09-28 08:04:43,570 Stage: Train 0.5 | Epoch: 121 | Iter: 73800 | Total Loss: 0.006243 | Recon Loss: 0.005087 | Commit Loss: 0.002311 | Perplexity: 374.885340
2025-09-28 08:08:06,394 Stage: Train 0.5 | Epoch: 121 | Iter: 74000 | Total Loss: 0.006237 | Recon Loss: 0.005092 | Commit Loss: 0.002289 | Perplexity: 373.978964
Trainning Epoch:  15%|█▍        | 122/823 [20:58:45<120:41:50, 619.84s/it]Trainning Epoch:  15%|█▍        | 122/823 [20:58:45<120:41:47, 619.84s/it]Trainning Epoch:  15%|█▍        | 122/823 [20:58:45<120:41:47, 619.84s/it]Trainning Epoch:  15%|█▍        | 122/823 [20:58:45<120:41:50, 619.84s/it]2025-09-28 08:11:33,173 Stage: Train 0.5 | Epoch: 122 | Iter: 74200 | Total Loss: 0.006208 | Recon Loss: 0.005058 | Commit Loss: 0.002299 | Perplexity: 375.195247
2025-09-28 08:14:55,915 Stage: Train 0.5 | Epoch: 122 | Iter: 74400 | Total Loss: 0.006217 | Recon Loss: 0.005082 | Commit Loss: 0.002270 | Perplexity: 375.237761
2025-09-28 08:18:18,613 Stage: Train 0.5 | Epoch: 122 | Iter: 74600 | Total Loss: 0.006228 | Recon Loss: 0.005075 | Commit Loss: 0.002307 | Perplexity: 376.780603
Trainning Epoch:  15%|█▍        | 123/823 [21:09:06<120:32:29, 619.93s/it]Trainning Epoch:  15%|█▍        | 123/823 [21:09:06<120:32:27, 619.93s/it]Trainning Epoch:  15%|█▍        | 123/823 [21:09:06<120:32:28, 619.93s/it]Trainning Epoch:  15%|█▍        | 123/823 [21:09:06<120:32:29, 619.93s/it]2025-09-28 08:21:45,327 Stage: Train 0.5 | Epoch: 123 | Iter: 74800 | Total Loss: 0.006147 | Recon Loss: 0.005009 | Commit Loss: 0.002276 | Perplexity: 375.739482
2025-09-28 08:25:07,286 Stage: Train 0.5 | Epoch: 123 | Iter: 75000 | Total Loss: 0.006177 | Recon Loss: 0.005036 | Commit Loss: 0.002282 | Perplexity: 375.611769
2025-09-28 08:28:29,787 Stage: Train 0.5 | Epoch: 123 | Iter: 75200 | Total Loss: 0.006224 | Recon Loss: 0.005073 | Commit Loss: 0.002301 | Perplexity: 375.243717
Trainning Epoch:  15%|█▌        | 124/823 [21:19:25<120:19:48, 619.73s/it]Trainning Epoch:  15%|█▌        | 124/823 [21:19:25<120:19:51, 619.73s/it]Trainning Epoch:  15%|█▌        | 124/823 [21:19:25<120:19:50, 619.73s/it]Trainning Epoch:  15%|█▌        | 124/823 [21:19:25<120:19:51, 619.73s/it]2025-09-28 08:31:56,516 Stage: Train 0.5 | Epoch: 124 | Iter: 75400 | Total Loss: 0.006179 | Recon Loss: 0.005036 | Commit Loss: 0.002285 | Perplexity: 375.863190
2025-09-28 08:35:18,750 Stage: Train 0.5 | Epoch: 124 | Iter: 75600 | Total Loss: 0.006181 | Recon Loss: 0.005031 | Commit Loss: 0.002301 | Perplexity: 377.041030
2025-09-28 08:38:41,638 Stage: Train 0.5 | Epoch: 124 | Iter: 75800 | Total Loss: 0.006226 | Recon Loss: 0.005073 | Commit Loss: 0.002305 | Perplexity: 377.322106
2025-09-28 08:42:04,216 Stage: Train 0.5 | Epoch: 124 | Iter: 76000 | Total Loss: 0.006160 | Recon Loss: 0.005020 | Commit Loss: 0.002279 | Perplexity: 377.232319
Trainning Epoch:  15%|█▌        | 125/823 [21:29:45<120:09:25, 619.72s/it]Trainning Epoch:  15%|█▌        | 125/823 [21:29:45<120:09:28, 619.73s/it]Trainning Epoch:  15%|█▌        | 125/823 [21:29:45<120:09:29, 619.73s/it]Trainning Epoch:  15%|█▌        | 125/823 [21:29:45<120:09:28, 619.73s/it]2025-09-28 08:45:31,120 Stage: Train 0.5 | Epoch: 125 | Iter: 76200 | Total Loss: 0.006144 | Recon Loss: 0.005006 | Commit Loss: 0.002274 | Perplexity: 375.972137
2025-09-28 08:48:54,193 Stage: Train 0.5 | Epoch: 125 | Iter: 76400 | Total Loss: 0.006157 | Recon Loss: 0.005034 | Commit Loss: 0.002247 | Perplexity: 376.185731
2025-09-28 08:52:17,200 Stage: Train 0.5 | Epoch: 125 | Iter: 76600 | Total Loss: 0.006199 | Recon Loss: 0.005048 | Commit Loss: 0.002302 | Perplexity: 378.433955
Trainning Epoch:  15%|█▌        | 126/823 [21:40:06<120:03:56, 620.14s/it]Trainning Epoch:  15%|█▌        | 126/823 [21:40:06<120:03:59, 620.14s/it]Trainning Epoch:  15%|█▌        | 126/823 [21:40:06<120:03:59, 620.14s/it]Trainning Epoch:  15%|█▌        | 126/823 [21:40:06<120:03:59, 620.14s/it]2025-09-28 08:55:43,300 Stage: Train 0.5 | Epoch: 126 | Iter: 76800 | Total Loss: 0.006102 | Recon Loss: 0.004976 | Commit Loss: 0.002252 | Perplexity: 376.786378
2025-09-28 08:59:05,084 Stage: Train 0.5 | Epoch: 126 | Iter: 77000 | Total Loss: 0.006207 | Recon Loss: 0.005057 | Commit Loss: 0.002300 | Perplexity: 377.415216
2025-09-28 09:02:28,178 Stage: Train 0.5 | Epoch: 126 | Iter: 77200 | Total Loss: 0.006159 | Recon Loss: 0.005023 | Commit Loss: 0.002270 | Perplexity: 377.484556
Trainning Epoch:  15%|█▌        | 127/823 [21:50:25<119:49:27, 619.78s/it]Trainning Epoch:  15%|█▌        | 127/823 [21:50:25<119:49:30, 619.78s/it]Trainning Epoch:  15%|█▌        | 127/823 [21:50:25<119:49:37, 619.80s/it]Trainning Epoch:  15%|█▌        | 127/823 [21:50:25<119:49:41, 619.80s/it]2025-09-28 09:05:54,518 Stage: Train 0.5 | Epoch: 127 | Iter: 77400 | Total Loss: 0.006107 | Recon Loss: 0.004980 | Commit Loss: 0.002253 | Perplexity: 378.071530
2025-09-28 09:09:16,776 Stage: Train 0.5 | Epoch: 127 | Iter: 77600 | Total Loss: 0.006080 | Recon Loss: 0.004952 | Commit Loss: 0.002256 | Perplexity: 377.010547
2025-09-28 09:12:39,728 Stage: Train 0.5 | Epoch: 127 | Iter: 77800 | Total Loss: 0.006162 | Recon Loss: 0.005028 | Commit Loss: 0.002267 | Perplexity: 377.683954
Trainning Epoch:  16%|█▌        | 128/823 [22:00:44<119:38:49, 619.75s/it]Trainning Epoch:  16%|█▌        | 128/823 [22:00:44<119:38:48, 619.75s/it]Trainning Epoch:  16%|█▌        | 128/823 [22:00:44<119:38:46, 619.75s/it]Trainning Epoch:  16%|█▌        | 128/823 [22:00:44<119:38:46, 619.75s/it]2025-09-28 09:16:05,708 Stage: Train 0.5 | Epoch: 128 | Iter: 78000 | Total Loss: 0.006132 | Recon Loss: 0.004990 | Commit Loss: 0.002283 | Perplexity: 378.097558
2025-09-28 09:19:27,752 Stage: Train 0.5 | Epoch: 128 | Iter: 78200 | Total Loss: 0.006080 | Recon Loss: 0.004957 | Commit Loss: 0.002246 | Perplexity: 377.353613
2025-09-28 09:22:50,102 Stage: Train 0.5 | Epoch: 128 | Iter: 78400 | Total Loss: 0.006120 | Recon Loss: 0.004982 | Commit Loss: 0.002276 | Perplexity: 377.403520
Trainning Epoch:  16%|█▌        | 129/823 [22:11:03<119:23:39, 619.34s/it]Trainning Epoch:  16%|█▌        | 129/823 [22:11:03<119:23:41, 619.34s/it]Trainning Epoch:  16%|█▌        | 129/823 [22:11:03<119:23:37, 619.33s/it]Trainning Epoch:  16%|█▌        | 129/823 [22:11:03<119:23:38, 619.34s/it]2025-09-28 09:26:15,856 Stage: Train 0.5 | Epoch: 129 | Iter: 78600 | Total Loss: 0.006074 | Recon Loss: 0.004946 | Commit Loss: 0.002257 | Perplexity: 377.314188
2025-09-28 09:29:38,109 Stage: Train 0.5 | Epoch: 129 | Iter: 78800 | Total Loss: 0.006143 | Recon Loss: 0.005011 | Commit Loss: 0.002264 | Perplexity: 377.094110
2025-09-28 09:33:00,945 Stage: Train 0.5 | Epoch: 129 | Iter: 79000 | Total Loss: 0.006059 | Recon Loss: 0.004937 | Commit Loss: 0.002243 | Perplexity: 377.311339
Trainning Epoch:  16%|█▌        | 130/823 [22:21:22<119:13:29, 619.35s/it]Trainning Epoch:  16%|█▌        | 130/823 [22:21:22<119:13:28, 619.35s/it]Trainning Epoch:  16%|█▌        | 130/823 [22:21:22<119:13:25, 619.34s/it]Trainning Epoch:  16%|█▌        | 130/823 [22:21:22<119:13:25, 619.34s/it]2025-09-28 09:36:26,334 Stage: Train 0.5 | Epoch: 130 | Iter: 79200 | Total Loss: 0.006086 | Recon Loss: 0.004970 | Commit Loss: 0.002231 | Perplexity: 377.199121
2025-09-28 09:39:47,941 Stage: Train 0.5 | Epoch: 130 | Iter: 79400 | Total Loss: 0.006121 | Recon Loss: 0.004984 | Commit Loss: 0.002275 | Perplexity: 378.282791
2025-09-28 09:43:09,983 Stage: Train 0.5 | Epoch: 130 | Iter: 79600 | Total Loss: 0.006068 | Recon Loss: 0.004948 | Commit Loss: 0.002240 | Perplexity: 377.590473
Trainning Epoch:  16%|█▌        | 131/823 [22:31:39<118:53:47, 618.54s/it]Trainning Epoch:  16%|█▌        | 131/823 [22:31:39<118:53:48, 618.54s/it]Trainning Epoch:  16%|█▌        | 131/823 [22:31:39<118:53:48, 618.54s/it]Trainning Epoch:  16%|█▌        | 131/823 [22:31:39<118:53:48, 618.54s/it]2025-09-28 09:46:35,315 Stage: Train 0.5 | Epoch: 131 | Iter: 79800 | Total Loss: 0.006040 | Recon Loss: 0.004919 | Commit Loss: 0.002242 | Perplexity: 377.563041
2025-09-28 09:49:57,425 Stage: Train 0.5 | Epoch: 131 | Iter: 80000 | Total Loss: 0.006034 | Recon Loss: 0.004907 | Commit Loss: 0.002254 | Perplexity: 377.487782
2025-09-28 09:49:57,425 Saving model at iteration 80000
2025-09-28 09:49:57,937 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_132_step_80000
2025-09-28 09:49:58,573 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_132_step_80000/model.safetensors
2025-09-28 09:49:59,166 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_132_step_80000/optimizer.bin
2025-09-28 09:49:59,167 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_132_step_80000/scheduler.bin
2025-09-28 09:49:59,167 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_132_step_80000/sampler.bin
2025-09-28 09:49:59,168 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_132_step_80000/random_states_0.pkl
2025-09-28 09:53:20,693 Stage: Train 0.5 | Epoch: 131 | Iter: 80200 | Total Loss: 0.006090 | Recon Loss: 0.004960 | Commit Loss: 0.002259 | Perplexity: 378.851321
Trainning Epoch:  16%|█▌        | 132/823 [22:41:57<118:44:17, 618.61s/it]Trainning Epoch:  16%|█▌        | 132/823 [22:41:57<118:44:24, 618.62s/it]Trainning Epoch:  16%|█▌        | 132/823 [22:41:57<118:44:21, 618.61s/it]Trainning Epoch:  16%|█▌        | 132/823 [22:41:57<118:44:25, 618.62s/it]2025-09-28 09:56:46,269 Stage: Train 0.5 | Epoch: 132 | Iter: 80400 | Total Loss: 0.006042 | Recon Loss: 0.004923 | Commit Loss: 0.002238 | Perplexity: 377.395498
2025-09-28 10:00:08,359 Stage: Train 0.5 | Epoch: 132 | Iter: 80600 | Total Loss: 0.006054 | Recon Loss: 0.004918 | Commit Loss: 0.002272 | Perplexity: 380.610200
2025-09-28 10:03:30,613 Stage: Train 0.5 | Epoch: 132 | Iter: 80800 | Total Loss: 0.006118 | Recon Loss: 0.004989 | Commit Loss: 0.002259 | Perplexity: 380.040982
Trainning Epoch:  16%|█▌        | 133/823 [22:52:16<118:32:31, 618.48s/it]Trainning Epoch:  16%|█▌        | 133/823 [22:52:16<118:32:35, 618.49s/it]Trainning Epoch:  16%|█▌        | 133/823 [22:52:16<118:32:37, 618.49s/it]Trainning Epoch:  16%|█▌        | 133/823 [22:52:16<118:32:37, 618.49s/it]2025-09-28 10:06:56,533 Stage: Train 0.5 | Epoch: 133 | Iter: 81000 | Total Loss: 0.006061 | Recon Loss: 0.004934 | Commit Loss: 0.002254 | Perplexity: 380.422265
2025-09-28 10:10:19,357 Stage: Train 0.5 | Epoch: 133 | Iter: 81200 | Total Loss: 0.006041 | Recon Loss: 0.004920 | Commit Loss: 0.002241 | Perplexity: 380.164312
2025-09-28 10:13:43,219 Stage: Train 0.5 | Epoch: 133 | Iter: 81400 | Total Loss: 0.006030 | Recon Loss: 0.004906 | Commit Loss: 0.002248 | Perplexity: 379.683221
Trainning Epoch:  16%|█▋        | 134/823 [23:02:37<118:30:59, 619.24s/it]Trainning Epoch:  16%|█▋        | 134/823 [23:02:37<118:31:03, 619.25s/it]Trainning Epoch:  16%|█▋        | 134/823 [23:02:37<118:31:03, 619.25s/it]Trainning Epoch:  16%|█▋        | 134/823 [23:02:37<118:31:02, 619.25s/it]2025-09-28 10:17:09,472 Stage: Train 0.5 | Epoch: 134 | Iter: 81600 | Total Loss: 0.005999 | Recon Loss: 0.004881 | Commit Loss: 0.002236 | Perplexity: 380.155810
2025-09-28 10:20:31,836 Stage: Train 0.5 | Epoch: 134 | Iter: 81800 | Total Loss: 0.006050 | Recon Loss: 0.004925 | Commit Loss: 0.002250 | Perplexity: 380.391127
2025-09-28 10:23:54,294 Stage: Train 0.5 | Epoch: 134 | Iter: 82000 | Total Loss: 0.006024 | Recon Loss: 0.004912 | Commit Loss: 0.002224 | Perplexity: 379.531748
Trainning Epoch:  16%|█▋        | 135/823 [23:12:56<118:19:49, 619.17s/it]Trainning Epoch:  16%|█▋        | 135/823 [23:12:56<118:19:53, 619.18s/it]Trainning Epoch:  16%|█▋        | 135/823 [23:12:56<118:19:52, 619.18s/it]Trainning Epoch:  16%|█▋        | 135/823 [23:12:56<118:19:53, 619.18s/it]2025-09-28 10:27:20,762 Stage: Train 0.5 | Epoch: 135 | Iter: 82200 | Total Loss: 0.005987 | Recon Loss: 0.004870 | Commit Loss: 0.002233 | Perplexity: 380.349318
2025-09-28 10:30:43,807 Stage: Train 0.5 | Epoch: 135 | Iter: 82400 | Total Loss: 0.005993 | Recon Loss: 0.004886 | Commit Loss: 0.002213 | Perplexity: 380.281067
2025-09-28 10:34:07,393 Stage: Train 0.5 | Epoch: 135 | Iter: 82600 | Total Loss: 0.005988 | Recon Loss: 0.004878 | Commit Loss: 0.002221 | Perplexity: 381.435844
Trainning Epoch:  17%|█▋        | 136/823 [23:23:17<118:17:02, 619.83s/it]Trainning Epoch:  17%|█▋        | 136/823 [23:23:17<118:17:05, 619.83s/it]Trainning Epoch:  17%|█▋        | 136/823 [23:23:17<118:17:06, 619.83s/it]Trainning Epoch:  17%|█▋        | 136/823 [23:23:17<118:17:06, 619.83s/it]2025-09-28 10:37:33,486 Stage: Train 0.5 | Epoch: 136 | Iter: 82800 | Total Loss: 0.005990 | Recon Loss: 0.004874 | Commit Loss: 0.002230 | Perplexity: 380.880645
2025-09-28 10:40:56,322 Stage: Train 0.5 | Epoch: 136 | Iter: 83000 | Total Loss: 0.005994 | Recon Loss: 0.004881 | Commit Loss: 0.002226 | Perplexity: 380.155198
2025-09-28 10:44:18,802 Stage: Train 0.5 | Epoch: 136 | Iter: 83200 | Total Loss: 0.005994 | Recon Loss: 0.004882 | Commit Loss: 0.002224 | Perplexity: 381.246372
Trainning Epoch:  17%|█▋        | 137/823 [23:33:36<118:04:44, 619.66s/it]Trainning Epoch:  17%|█▋        | 137/823 [23:33:36<118:04:39, 619.65s/it]Trainning Epoch:  17%|█▋        | 137/823 [23:33:36<118:04:42, 619.65s/it]Trainning Epoch:  17%|█▋        | 137/823 [23:33:36<118:04:43, 619.66s/it]2025-09-28 10:47:45,029 Stage: Train 0.5 | Epoch: 137 | Iter: 83400 | Total Loss: 0.005941 | Recon Loss: 0.004830 | Commit Loss: 0.002222 | Perplexity: 381.670097
2025-09-28 10:51:07,820 Stage: Train 0.5 | Epoch: 137 | Iter: 83600 | Total Loss: 0.006010 | Recon Loss: 0.004905 | Commit Loss: 0.002210 | Perplexity: 381.219111
2025-09-28 10:54:31,525 Stage: Train 0.5 | Epoch: 137 | Iter: 83800 | Total Loss: 0.005957 | Recon Loss: 0.004852 | Commit Loss: 0.002210 | Perplexity: 380.847703
Trainning Epoch:  17%|█▋        | 138/823 [23:43:58<118:00:21, 620.18s/it]Trainning Epoch:  17%|█▋        | 138/823 [23:43:58<118:00:24, 620.18s/it]Trainning Epoch:  17%|█▋        | 138/823 [23:43:58<118:00:26, 620.18s/it]Trainning Epoch:  17%|█▋        | 138/823 [23:43:58<118:00:25, 620.18s/it]2025-09-28 10:57:57,993 Stage: Train 0.5 | Epoch: 138 | Iter: 84000 | Total Loss: 0.005962 | Recon Loss: 0.004858 | Commit Loss: 0.002207 | Perplexity: 380.258400
2025-09-28 11:01:19,586 Stage: Train 0.5 | Epoch: 138 | Iter: 84200 | Total Loss: 0.005960 | Recon Loss: 0.004847 | Commit Loss: 0.002226 | Perplexity: 381.604302
2025-09-28 11:04:41,242 Stage: Train 0.5 | Epoch: 138 | Iter: 84400 | Total Loss: 0.006011 | Recon Loss: 0.004899 | Commit Loss: 0.002224 | Perplexity: 381.402730
Trainning Epoch:  17%|█▋        | 139/823 [23:54:14<117:38:25, 619.16s/it]Trainning Epoch:  17%|█▋        | 139/823 [23:54:14<117:38:28, 619.16s/it]Trainning Epoch:  17%|█▋        | 139/823 [23:54:14<117:38:27, 619.16s/it]Trainning Epoch:  17%|█▋        | 139/823 [23:54:14<117:38:33, 619.17s/it]2025-09-28 11:08:06,733 Stage: Train 0.5 | Epoch: 139 | Iter: 84600 | Total Loss: 0.005952 | Recon Loss: 0.004843 | Commit Loss: 0.002218 | Perplexity: 382.901698
2025-09-28 11:11:29,173 Stage: Train 0.5 | Epoch: 139 | Iter: 84800 | Total Loss: 0.005968 | Recon Loss: 0.004858 | Commit Loss: 0.002221 | Perplexity: 382.765427
2025-09-28 11:14:51,563 Stage: Train 0.5 | Epoch: 139 | Iter: 85000 | Total Loss: 0.005922 | Recon Loss: 0.004813 | Commit Loss: 0.002217 | Perplexity: 381.301571
Trainning Epoch:  17%|█▋        | 140/823 [24:04:33<117:26:56, 619.06s/it]Trainning Epoch:  17%|█▋        | 140/823 [24:04:33<117:27:00, 619.06s/it]Trainning Epoch:  17%|█▋        | 140/823 [24:04:33<117:26:58, 619.06s/it]Trainning Epoch:  17%|█▋        | 140/823 [24:04:33<117:26:59, 619.06s/it]2025-09-28 11:18:17,550 Stage: Train 0.5 | Epoch: 140 | Iter: 85200 | Total Loss: 0.005923 | Recon Loss: 0.004819 | Commit Loss: 0.002208 | Perplexity: 381.409136
2025-09-28 11:21:39,833 Stage: Train 0.5 | Epoch: 140 | Iter: 85400 | Total Loss: 0.005934 | Recon Loss: 0.004830 | Commit Loss: 0.002209 | Perplexity: 382.019259
2025-09-28 11:25:02,408 Stage: Train 0.5 | Epoch: 140 | Iter: 85600 | Total Loss: 0.005922 | Recon Loss: 0.004821 | Commit Loss: 0.002204 | Perplexity: 381.795908
Trainning Epoch:  17%|█▋        | 141/823 [24:14:53<117:17:55, 619.17s/it]Trainning Epoch:  17%|█▋        | 141/823 [24:14:53<117:17:59, 619.18s/it]Trainning Epoch:  17%|█▋        | 141/823 [24:14:53<117:17:59, 619.18s/it]Trainning Epoch:  17%|█▋        | 141/823 [24:14:53<117:17:59, 619.18s/it]2025-09-28 11:28:28,923 Stage: Train 0.5 | Epoch: 141 | Iter: 85800 | Total Loss: 0.005934 | Recon Loss: 0.004828 | Commit Loss: 0.002213 | Perplexity: 383.080330
2025-09-28 11:31:50,628 Stage: Train 0.5 | Epoch: 141 | Iter: 86000 | Total Loss: 0.005962 | Recon Loss: 0.004852 | Commit Loss: 0.002221 | Perplexity: 383.352627
2025-09-28 11:35:12,686 Stage: Train 0.5 | Epoch: 141 | Iter: 86200 | Total Loss: 0.005930 | Recon Loss: 0.004831 | Commit Loss: 0.002197 | Perplexity: 381.443465
Trainning Epoch:  17%|█▋        | 142/823 [24:25:11<117:03:43, 618.83s/it]Trainning Epoch:  17%|█▋        | 142/823 [24:25:11<117:03:45, 618.83s/it]Trainning Epoch:  17%|█▋        | 142/823 [24:25:11<117:03:46, 618.84s/it]Trainning Epoch:  17%|█▋        | 142/823 [24:25:11<117:03:45, 618.83s/it]2025-09-28 11:38:39,124 Stage: Train 0.5 | Epoch: 142 | Iter: 86400 | Total Loss: 0.005913 | Recon Loss: 0.004805 | Commit Loss: 0.002217 | Perplexity: 382.627030
2025-09-28 11:42:02,380 Stage: Train 0.5 | Epoch: 142 | Iter: 86600 | Total Loss: 0.005946 | Recon Loss: 0.004848 | Commit Loss: 0.002196 | Perplexity: 381.978453
2025-09-28 11:45:25,277 Stage: Train 0.5 | Epoch: 142 | Iter: 86800 | Total Loss: 0.005878 | Recon Loss: 0.004771 | Commit Loss: 0.002214 | Perplexity: 382.075625
Trainning Epoch:  17%|█▋        | 143/823 [24:35:31<116:58:56, 619.32s/it]Trainning Epoch:  17%|█▋        | 143/823 [24:35:31<116:58:59, 619.32s/it]Trainning Epoch:  17%|█▋        | 143/823 [24:35:31<116:59:03, 619.33s/it]Trainning Epoch:  17%|█▋        | 143/823 [24:35:31<116:58:59, 619.32s/it]2025-09-28 11:48:50,968 Stage: Train 0.5 | Epoch: 143 | Iter: 87000 | Total Loss: 0.005889 | Recon Loss: 0.004798 | Commit Loss: 0.002182 | Perplexity: 381.760233
2025-09-28 11:52:12,945 Stage: Train 0.5 | Epoch: 143 | Iter: 87200 | Total Loss: 0.005877 | Recon Loss: 0.004781 | Commit Loss: 0.002191 | Perplexity: 382.540753
2025-09-28 11:55:35,108 Stage: Train 0.5 | Epoch: 143 | Iter: 87400 | Total Loss: 0.005913 | Recon Loss: 0.004805 | Commit Loss: 0.002215 | Perplexity: 382.922030
Trainning Epoch:  17%|█▋        | 144/823 [24:45:49<116:44:12, 618.93s/it]Trainning Epoch:  17%|█▋        | 144/823 [24:45:49<116:44:15, 618.93s/it]Trainning Epoch:  17%|█▋        | 144/823 [24:45:49<116:44:15, 618.93s/it]Trainning Epoch:  17%|█▋        | 144/823 [24:45:49<116:44:16, 618.93s/it]2025-09-28 11:59:01,181 Stage: Train 0.5 | Epoch: 144 | Iter: 87600 | Total Loss: 0.005874 | Recon Loss: 0.004771 | Commit Loss: 0.002207 | Perplexity: 381.968130
2025-09-28 12:02:24,071 Stage: Train 0.5 | Epoch: 144 | Iter: 87800 | Total Loss: 0.005920 | Recon Loss: 0.004805 | Commit Loss: 0.002229 | Perplexity: 383.012338
2025-09-28 12:05:47,030 Stage: Train 0.5 | Epoch: 144 | Iter: 88000 | Total Loss: 0.005887 | Recon Loss: 0.004786 | Commit Loss: 0.002201 | Perplexity: 382.181374
Trainning Epoch:  18%|█▊        | 145/823 [24:56:10<116:38:59, 619.38s/it]Trainning Epoch:  18%|█▊        | 145/823 [24:56:10<116:39:01, 619.38s/it]Trainning Epoch:  18%|█▊        | 145/823 [24:56:10<116:39:01, 619.38s/it]Trainning Epoch:  18%|█▊        | 145/823 [24:56:10<116:39:02, 619.38s/it]2025-09-28 12:09:13,631 Stage: Train 0.5 | Epoch: 145 | Iter: 88200 | Total Loss: 0.005910 | Recon Loss: 0.004808 | Commit Loss: 0.002203 | Perplexity: 381.948871
2025-09-28 12:12:36,096 Stage: Train 0.5 | Epoch: 145 | Iter: 88400 | Total Loss: 0.005894 | Recon Loss: 0.004801 | Commit Loss: 0.002186 | Perplexity: 383.132625
2025-09-28 12:15:58,219 Stage: Train 0.5 | Epoch: 145 | Iter: 88600 | Total Loss: 0.005851 | Recon Loss: 0.004763 | Commit Loss: 0.002177 | Perplexity: 381.545549
Trainning Epoch:  18%|█▊        | 146/823 [25:06:29<116:27:39, 619.29s/it]Trainning Epoch:  18%|█▊        | 146/823 [25:06:29<116:27:39, 619.29s/it]Trainning Epoch:  18%|█▊        | 146/823 [25:06:29<116:27:40, 619.29s/it]Trainning Epoch:  18%|█▊        | 146/823 [25:06:29<116:27:39, 619.29s/it]2025-09-28 12:19:24,692 Stage: Train 0.5 | Epoch: 146 | Iter: 88800 | Total Loss: 0.005872 | Recon Loss: 0.004776 | Commit Loss: 0.002192 | Perplexity: 382.463131
2025-09-28 12:22:46,596 Stage: Train 0.5 | Epoch: 146 | Iter: 89000 | Total Loss: 0.005858 | Recon Loss: 0.004764 | Commit Loss: 0.002188 | Perplexity: 381.327150
2025-09-28 12:26:09,023 Stage: Train 0.5 | Epoch: 146 | Iter: 89200 | Total Loss: 0.005850 | Recon Loss: 0.004753 | Commit Loss: 0.002194 | Perplexity: 382.748459
Trainning Epoch:  18%|█▊        | 147/823 [25:16:48<116:18:24, 619.38s/it]Trainning Epoch:  18%|█▊        | 147/823 [25:16:48<116:18:29, 619.39s/it]Trainning Epoch:  18%|█▊        | 147/823 [25:16:48<116:18:26, 619.39s/it]Trainning Epoch:  18%|█▊        | 147/823 [25:16:48<116:18:27, 619.39s/it]2025-09-28 12:29:36,104 Stage: Train 0.5 | Epoch: 147 | Iter: 89400 | Total Loss: 0.005872 | Recon Loss: 0.004777 | Commit Loss: 0.002189 | Perplexity: 381.294666
2025-09-28 12:32:58,867 Stage: Train 0.5 | Epoch: 147 | Iter: 89600 | Total Loss: 0.005797 | Recon Loss: 0.004701 | Commit Loss: 0.002192 | Perplexity: 381.658072
2025-09-28 12:36:20,273 Stage: Train 0.5 | Epoch: 147 | Iter: 89800 | Total Loss: 0.005864 | Recon Loss: 0.004769 | Commit Loss: 0.002190 | Perplexity: 381.698062
Trainning Epoch:  18%|█▊        | 148/823 [25:27:06<116:01:47, 618.83s/it]Trainning Epoch:  18%|█▊        | 148/823 [25:27:06<116:01:47, 618.83s/it]Trainning Epoch:  18%|█▊        | 148/823 [25:27:06<116:01:48, 618.83s/it]Trainning Epoch:  18%|█▊        | 148/823 [25:27:06<116:01:52, 618.83s/it]2025-09-28 12:39:45,705 Stage: Train 0.5 | Epoch: 148 | Iter: 90000 | Total Loss: 0.005857 | Recon Loss: 0.004755 | Commit Loss: 0.002205 | Perplexity: 382.442902
2025-09-28 12:43:08,417 Stage: Train 0.5 | Epoch: 148 | Iter: 90200 | Total Loss: 0.005823 | Recon Loss: 0.004728 | Commit Loss: 0.002192 | Perplexity: 382.140650
2025-09-28 12:46:31,677 Stage: Train 0.5 | Epoch: 148 | Iter: 90400 | Total Loss: 0.005848 | Recon Loss: 0.004747 | Commit Loss: 0.002202 | Perplexity: 382.830364
Trainning Epoch:  18%|█▊        | 149/823 [25:37:27<116:00:21, 619.62s/it]Trainning Epoch:  18%|█▊        | 149/823 [25:37:27<116:00:25, 619.62s/it]Trainning Epoch:  18%|█▊        | 149/823 [25:37:27<116:00:25, 619.62s/it]Trainning Epoch:  18%|█▊        | 149/823 [25:37:27<116:00:25, 619.62s/it]2025-09-28 12:49:59,274 Stage: Train 0.5 | Epoch: 149 | Iter: 90600 | Total Loss: 0.005860 | Recon Loss: 0.004754 | Commit Loss: 0.002211 | Perplexity: 380.963322
2025-09-28 12:53:23,449 Stage: Train 0.5 | Epoch: 149 | Iter: 90800 | Total Loss: 0.005829 | Recon Loss: 0.004732 | Commit Loss: 0.002193 | Perplexity: 382.297409
2025-09-28 12:56:47,927 Stage: Train 0.5 | Epoch: 149 | Iter: 91000 | Total Loss: 0.005826 | Recon Loss: 0.004725 | Commit Loss: 0.002201 | Perplexity: 382.276581
2025-09-28 13:00:12,344 Stage: Train 0.5 | Epoch: 149 | Iter: 91200 | Total Loss: 0.005832 | Recon Loss: 0.004734 | Commit Loss: 0.002196 | Perplexity: 382.567910
Trainning Epoch:  18%|█▊        | 150/823 [25:47:53<116:09:07, 621.32s/it]Trainning Epoch:  18%|█▊        | 150/823 [25:47:53<116:09:07, 621.32s/it]Trainning Epoch:  18%|█▊        | 150/823 [25:47:53<116:09:07, 621.32s/it]Trainning Epoch:  18%|█▊        | 150/823 [25:47:53<116:09:07, 621.32s/it]2025-09-28 13:03:40,093 Stage: Train 0.5 | Epoch: 150 | Iter: 91400 | Total Loss: 0.005814 | Recon Loss: 0.004717 | Commit Loss: 0.002193 | Perplexity: 382.268226
2025-09-28 13:07:04,239 Stage: Train 0.5 | Epoch: 150 | Iter: 91600 | Total Loss: 0.005860 | Recon Loss: 0.004761 | Commit Loss: 0.002198 | Perplexity: 382.916993
2025-09-28 13:10:28,308 Stage: Train 0.5 | Epoch: 150 | Iter: 91800 | Total Loss: 0.005797 | Recon Loss: 0.004697 | Commit Loss: 0.002200 | Perplexity: 380.660737
Trainning Epoch:  18%|█▊        | 151/823 [25:58:17<116:08:15, 622.17s/it]Trainning Epoch:  18%|█▊        | 151/823 [25:58:17<116:08:16, 622.17s/it]Trainning Epoch:  18%|█▊        | 151/823 [25:58:17<116:08:16, 622.17s/it]Trainning Epoch:  18%|█▊        | 151/823 [25:58:17<116:08:16, 622.17s/it]2025-09-28 13:13:55,894 Stage: Train 0.5 | Epoch: 151 | Iter: 92000 | Total Loss: 0.005740 | Recon Loss: 0.004654 | Commit Loss: 0.002172 | Perplexity: 382.549481
2025-09-28 13:17:19,735 Stage: Train 0.5 | Epoch: 151 | Iter: 92200 | Total Loss: 0.005849 | Recon Loss: 0.004748 | Commit Loss: 0.002202 | Perplexity: 383.326886
2025-09-28 13:20:43,528 Stage: Train 0.5 | Epoch: 151 | Iter: 92400 | Total Loss: 0.005807 | Recon Loss: 0.004707 | Commit Loss: 0.002199 | Perplexity: 382.793607
Trainning Epoch:  18%|█▊        | 152/823 [26:08:40<116:01:31, 622.49s/it]Trainning Epoch:  18%|█▊        | 152/823 [26:08:40<116:01:32, 622.49s/it]Trainning Epoch:  18%|█▊        | 152/823 [26:08:40<116:01:32, 622.49s/it]Trainning Epoch:  18%|█▊        | 152/823 [26:08:40<116:01:32, 622.49s/it]2025-09-28 13:24:09,360 Stage: Train 0.5 | Epoch: 152 | Iter: 92600 | Total Loss: 0.005768 | Recon Loss: 0.004686 | Commit Loss: 0.002165 | Perplexity: 382.944520
2025-09-28 13:27:30,842 Stage: Train 0.5 | Epoch: 152 | Iter: 92800 | Total Loss: 0.005790 | Recon Loss: 0.004693 | Commit Loss: 0.002194 | Perplexity: 383.423735
2025-09-28 13:30:52,642 Stage: Train 0.5 | Epoch: 152 | Iter: 93000 | Total Loss: 0.005839 | Recon Loss: 0.004746 | Commit Loss: 0.002186 | Perplexity: 382.837816
Trainning Epoch:  19%|█▊        | 153/823 [26:18:57<115:33:05, 620.87s/it]Trainning Epoch:  19%|█▊        | 153/823 [26:18:57<115:33:00, 620.87s/it]Trainning Epoch:  19%|█▊        | 153/823 [26:18:57<115:33:03, 620.87s/it]Trainning Epoch:  19%|█▊        | 153/823 [26:18:57<115:33:03, 620.87s/it]2025-09-28 13:34:18,996 Stage: Train 0.5 | Epoch: 153 | Iter: 93200 | Total Loss: 0.005820 | Recon Loss: 0.004729 | Commit Loss: 0.002181 | Perplexity: 383.785460
2025-09-28 13:37:42,044 Stage: Train 0.5 | Epoch: 153 | Iter: 93400 | Total Loss: 0.005773 | Recon Loss: 0.004682 | Commit Loss: 0.002183 | Perplexity: 383.386849
2025-09-28 13:41:05,755 Stage: Train 0.5 | Epoch: 153 | Iter: 93600 | Total Loss: 0.005811 | Recon Loss: 0.004714 | Commit Loss: 0.002193 | Perplexity: 383.500898
Trainning Epoch:  19%|█▊        | 154/823 [26:29:19<115:24:30, 621.03s/it]Trainning Epoch:  19%|█▊        | 154/823 [26:29:19<115:24:32, 621.03s/it]Trainning Epoch:  19%|█▊        | 154/823 [26:29:19<115:24:32, 621.03s/it]Trainning Epoch:  19%|█▊        | 154/823 [26:29:19<115:24:32, 621.04s/it]2025-09-28 13:44:31,853 Stage: Train 0.5 | Epoch: 154 | Iter: 93800 | Total Loss: 0.005755 | Recon Loss: 0.004664 | Commit Loss: 0.002182 | Perplexity: 383.426466
2025-09-28 13:47:55,496 Stage: Train 0.5 | Epoch: 154 | Iter: 94000 | Total Loss: 0.005789 | Recon Loss: 0.004695 | Commit Loss: 0.002188 | Perplexity: 383.498155
2025-09-28 13:51:19,278 Stage: Train 0.5 | Epoch: 154 | Iter: 94200 | Total Loss: 0.005815 | Recon Loss: 0.004721 | Commit Loss: 0.002188 | Perplexity: 384.656384
Trainning Epoch:  19%|█▉        | 155/823 [26:39:41<115:17:14, 621.31s/it]Trainning Epoch:  19%|█▉        | 155/823 [26:39:41<115:17:13, 621.31s/it]Trainning Epoch:  19%|█▉        | 155/823 [26:39:40<115:17:13, 621.31s/it]Trainning Epoch:  19%|█▉        | 155/823 [26:39:41<115:17:15, 621.31s/it]2025-09-28 13:54:46,242 Stage: Train 0.5 | Epoch: 155 | Iter: 94400 | Total Loss: 0.005747 | Recon Loss: 0.004656 | Commit Loss: 0.002181 | Perplexity: 383.358847
2025-09-28 13:58:09,699 Stage: Train 0.5 | Epoch: 155 | Iter: 94600 | Total Loss: 0.005808 | Recon Loss: 0.004710 | Commit Loss: 0.002196 | Perplexity: 384.198670
2025-09-28 14:01:32,796 Stage: Train 0.5 | Epoch: 155 | Iter: 94800 | Total Loss: 0.005779 | Recon Loss: 0.004692 | Commit Loss: 0.002173 | Perplexity: 383.216328
Trainning Epoch:  19%|█▉        | 156/823 [26:50:02<115:06:51, 621.31s/it]Trainning Epoch:  19%|█▉        | 156/823 [26:50:02<115:06:52, 621.31s/it]Trainning Epoch:  19%|█▉        | 156/823 [26:50:02<115:06:51, 621.31s/it]Trainning Epoch:  19%|█▉        | 156/823 [26:50:02<115:06:52, 621.31s/it]2025-09-28 14:04:58,656 Stage: Train 0.5 | Epoch: 156 | Iter: 95000 | Total Loss: 0.005774 | Recon Loss: 0.004680 | Commit Loss: 0.002187 | Perplexity: 383.679131
2025-09-28 14:08:21,285 Stage: Train 0.5 | Epoch: 156 | Iter: 95200 | Total Loss: 0.005779 | Recon Loss: 0.004678 | Commit Loss: 0.002202 | Perplexity: 384.131148
2025-09-28 14:11:44,087 Stage: Train 0.5 | Epoch: 156 | Iter: 95400 | Total Loss: 0.005785 | Recon Loss: 0.004694 | Commit Loss: 0.002182 | Perplexity: 384.025888
Trainning Epoch:  19%|█▉        | 157/823 [27:00:21<114:49:41, 620.69s/it]Trainning Epoch:  19%|█▉        | 157/823 [27:00:21<114:49:36, 620.69s/it]Trainning Epoch:  19%|█▉        | 157/823 [27:00:21<114:49:38, 620.69s/it]Trainning Epoch:  19%|█▉        | 157/823 [27:00:21<114:49:39, 620.69s/it]2025-09-28 14:15:11,318 Stage: Train 0.5 | Epoch: 157 | Iter: 95600 | Total Loss: 0.005703 | Recon Loss: 0.004614 | Commit Loss: 0.002179 | Perplexity: 384.057723
2025-09-28 14:18:35,281 Stage: Train 0.5 | Epoch: 157 | Iter: 95800 | Total Loss: 0.005733 | Recon Loss: 0.004640 | Commit Loss: 0.002185 | Perplexity: 383.678737
2025-09-28 14:21:59,169 Stage: Train 0.5 | Epoch: 157 | Iter: 96000 | Total Loss: 0.005802 | Recon Loss: 0.004705 | Commit Loss: 0.002194 | Perplexity: 384.451101
Trainning Epoch:  19%|█▉        | 158/823 [27:10:45<114:49:05, 621.57s/it]Trainning Epoch:  19%|█▉        | 158/823 [27:10:45<114:49:04, 621.57s/it]Trainning Epoch:  19%|█▉        | 158/823 [27:10:45<114:49:05, 621.57s/it]Trainning Epoch:  19%|█▉        | 158/823 [27:10:45<114:49:05, 621.57s/it]2025-09-28 14:25:26,039 Stage: Train 0.5 | Epoch: 158 | Iter: 96200 | Total Loss: 0.005761 | Recon Loss: 0.004668 | Commit Loss: 0.002187 | Perplexity: 384.355020
2025-09-28 14:28:49,216 Stage: Train 0.5 | Epoch: 158 | Iter: 96400 | Total Loss: 0.005754 | Recon Loss: 0.004661 | Commit Loss: 0.002186 | Perplexity: 384.951450
2025-09-28 14:32:12,094 Stage: Train 0.5 | Epoch: 158 | Iter: 96600 | Total Loss: 0.005734 | Recon Loss: 0.004640 | Commit Loss: 0.002189 | Perplexity: 384.859514
Trainning Epoch:  19%|█▉        | 159/823 [27:21:06<114:36:17, 621.35s/it]Trainning Epoch:  19%|█▉        | 159/823 [27:21:06<114:36:14, 621.35s/it]Trainning Epoch:  19%|█▉        | 159/823 [27:21:06<114:36:16, 621.35s/it]Trainning Epoch:  19%|█▉        | 159/823 [27:21:06<114:36:16, 621.35s/it]2025-09-28 14:35:40,258 Stage: Train 0.5 | Epoch: 159 | Iter: 96800 | Total Loss: 0.005709 | Recon Loss: 0.004620 | Commit Loss: 0.002178 | Perplexity: 383.647116
2025-09-28 14:39:04,590 Stage: Train 0.5 | Epoch: 159 | Iter: 97000 | Total Loss: 0.005716 | Recon Loss: 0.004633 | Commit Loss: 0.002164 | Perplexity: 383.339692
2025-09-28 14:42:29,208 Stage: Train 0.5 | Epoch: 159 | Iter: 97200 | Total Loss: 0.005758 | Recon Loss: 0.004658 | Commit Loss: 0.002201 | Perplexity: 385.171003
Trainning Epoch:  19%|█▉        | 160/823 [27:31:31<114:40:07, 622.64s/it]Trainning Epoch:  19%|█▉        | 160/823 [27:31:31<114:40:09, 622.64s/it]Trainning Epoch:  19%|█▉        | 160/823 [27:31:31<114:40:09, 622.64s/it]Trainning Epoch:  19%|█▉        | 160/823 [27:31:31<114:40:09, 622.64s/it]2025-09-28 14:45:56,161 Stage: Train 0.5 | Epoch: 160 | Iter: 97400 | Total Loss: 0.005720 | Recon Loss: 0.004632 | Commit Loss: 0.002176 | Perplexity: 383.969450
2025-09-28 14:49:19,085 Stage: Train 0.5 | Epoch: 160 | Iter: 97600 | Total Loss: 0.005690 | Recon Loss: 0.004596 | Commit Loss: 0.002189 | Perplexity: 383.515972
2025-09-28 14:52:42,220 Stage: Train 0.5 | Epoch: 160 | Iter: 97800 | Total Loss: 0.005726 | Recon Loss: 0.004642 | Commit Loss: 0.002169 | Perplexity: 384.208587
Trainning Epoch:  20%|█▉        | 161/823 [27:41:52<114:23:06, 622.03s/it]Trainning Epoch:  20%|█▉        | 161/823 [27:41:52<114:23:09, 622.04s/it]Trainning Epoch:  20%|█▉        | 161/823 [27:41:52<114:23:10, 622.04s/it]Trainning Epoch:  20%|█▉        | 161/823 [27:41:52<114:23:10, 622.04s/it]2025-09-28 14:56:06,893 Stage: Train 0.5 | Epoch: 161 | Iter: 98000 | Total Loss: 0.005701 | Recon Loss: 0.004608 | Commit Loss: 0.002186 | Perplexity: 384.064642
2025-09-28 14:59:26,274 Stage: Train 0.5 | Epoch: 161 | Iter: 98200 | Total Loss: 0.005738 | Recon Loss: 0.004647 | Commit Loss: 0.002183 | Perplexity: 384.975778
2025-09-28 15:02:46,106 Stage: Train 0.5 | Epoch: 161 | Iter: 98400 | Total Loss: 0.005715 | Recon Loss: 0.004621 | Commit Loss: 0.002188 | Perplexity: 383.713689
Trainning Epoch:  20%|█▉        | 162/823 [27:52:02<113:34:36, 618.57s/it]Trainning Epoch:  20%|█▉        | 162/823 [27:52:02<113:34:41, 618.58s/it]Trainning Epoch:  20%|█▉        | 162/823 [27:52:02<113:34:39, 618.58s/it]Trainning Epoch:  20%|█▉        | 162/823 [27:52:02<113:34:40, 618.58s/it]2025-09-28 15:06:09,941 Stage: Train 0.5 | Epoch: 162 | Iter: 98600 | Total Loss: 0.005705 | Recon Loss: 0.004610 | Commit Loss: 0.002189 | Perplexity: 384.631101
2025-09-28 15:09:30,446 Stage: Train 0.5 | Epoch: 162 | Iter: 98800 | Total Loss: 0.005690 | Recon Loss: 0.004602 | Commit Loss: 0.002177 | Perplexity: 384.577625
2025-09-28 15:12:51,061 Stage: Train 0.5 | Epoch: 162 | Iter: 99000 | Total Loss: 0.005700 | Recon Loss: 0.004615 | Commit Loss: 0.002170 | Perplexity: 383.540090
Trainning Epoch:  20%|█▉        | 163/823 [28:02:16<113:07:56, 617.09s/it]Trainning Epoch:  20%|█▉        | 163/823 [28:02:16<113:07:54, 617.08s/it]Trainning Epoch:  20%|█▉        | 163/823 [28:02:16<113:07:57, 617.09s/it]Trainning Epoch:  20%|█▉        | 163/823 [28:02:16<113:07:56, 617.09s/it]2025-09-28 15:16:15,844 Stage: Train 0.5 | Epoch: 163 | Iter: 99200 | Total Loss: 0.005739 | Recon Loss: 0.004641 | Commit Loss: 0.002197 | Perplexity: 384.530136
2025-09-28 15:19:36,973 Stage: Train 0.5 | Epoch: 163 | Iter: 99400 | Total Loss: 0.005703 | Recon Loss: 0.004612 | Commit Loss: 0.002182 | Perplexity: 383.634278
2025-09-28 15:22:57,916 Stage: Train 0.5 | Epoch: 163 | Iter: 99600 | Total Loss: 0.005700 | Recon Loss: 0.004603 | Commit Loss: 0.002195 | Perplexity: 383.678430
Trainning Epoch:  20%|█▉        | 164/823 [28:12:31<112:50:28, 616.43s/it]Trainning Epoch:  20%|█▉        | 164/823 [28:12:31<112:50:30, 616.43s/it]Trainning Epoch:  20%|█▉        | 164/823 [28:12:31<112:50:30, 616.43s/it]Trainning Epoch:  20%|█▉        | 164/823 [28:12:31<112:50:31, 616.44s/it]2025-09-28 15:26:23,218 Stage: Train 0.5 | Epoch: 164 | Iter: 99800 | Total Loss: 0.005729 | Recon Loss: 0.004635 | Commit Loss: 0.002187 | Perplexity: 384.707910
2025-09-28 15:29:46,481 Stage: Train 0.5 | Epoch: 164 | Iter: 100000 | Total Loss: 0.005665 | Recon Loss: 0.004583 | Commit Loss: 0.002164 | Perplexity: 383.997245
2025-09-28 15:29:46,482 Saving model at iteration 100000
2025-09-28 15:29:46,786 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_165_step_100000
2025-09-28 15:29:47,356 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_165_step_100000/model.safetensors
2025-09-28 15:29:47,927 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_165_step_100000/optimizer.bin
2025-09-28 15:29:47,927 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_165_step_100000/scheduler.bin
2025-09-28 15:29:47,927 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_165_step_100000/sampler.bin
2025-09-28 15:29:47,928 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_165_step_100000/random_states_0.pkl
2025-09-28 15:33:11,573 Stage: Train 0.5 | Epoch: 164 | Iter: 100200 | Total Loss: 0.005685 | Recon Loss: 0.004588 | Commit Loss: 0.002195 | Perplexity: 384.753578
Trainning Epoch:  20%|██        | 165/823 [28:22:53<113:00:26, 618.28s/it]Trainning Epoch:  20%|██        | 165/823 [28:22:53<113:00:23, 618.27s/it]Trainning Epoch:  20%|██        | 165/823 [28:22:53<113:00:24, 618.27s/it]Trainning Epoch:  20%|██        | 165/823 [28:22:53<113:00:26, 618.28s/it]2025-09-28 15:36:37,298 Stage: Train 0.5 | Epoch: 165 | Iter: 100400 | Total Loss: 0.005671 | Recon Loss: 0.004578 | Commit Loss: 0.002186 | Perplexity: 383.674286
2025-09-28 15:39:58,446 Stage: Train 0.5 | Epoch: 165 | Iter: 100600 | Total Loss: 0.005709 | Recon Loss: 0.004626 | Commit Loss: 0.002167 | Perplexity: 384.457707
2025-09-28 15:43:20,199 Stage: Train 0.5 | Epoch: 165 | Iter: 100800 | Total Loss: 0.005707 | Recon Loss: 0.004618 | Commit Loss: 0.002177 | Perplexity: 384.772091
Trainning Epoch:  20%|██        | 166/823 [28:33:09<112:42:45, 617.60s/it]Trainning Epoch:  20%|██        | 166/823 [28:33:10<112:42:58, 617.62s/it]Trainning Epoch:  20%|██        | 166/823 [28:33:10<112:43:00, 617.63s/it]Trainning Epoch:  20%|██        | 166/823 [28:33:10<112:42:58, 617.62s/it]2025-09-28 15:46:46,020 Stage: Train 0.5 | Epoch: 166 | Iter: 101000 | Total Loss: 0.005710 | Recon Loss: 0.004617 | Commit Loss: 0.002186 | Perplexity: 384.497849
2025-09-28 15:50:09,655 Stage: Train 0.5 | Epoch: 166 | Iter: 101200 | Total Loss: 0.005700 | Recon Loss: 0.004613 | Commit Loss: 0.002173 | Perplexity: 384.744405
2025-09-28 15:53:33,002 Stage: Train 0.5 | Epoch: 166 | Iter: 101400 | Total Loss: 0.005665 | Recon Loss: 0.004572 | Commit Loss: 0.002185 | Perplexity: 384.518085
Trainning Epoch:  20%|██        | 167/823 [28:43:31<112:46:29, 618.89s/it]Trainning Epoch:  20%|██        | 167/823 [28:43:31<112:46:28, 618.88s/it]Trainning Epoch:  20%|██        | 167/823 [28:43:31<112:46:30, 618.89s/it]Trainning Epoch:  20%|██        | 167/823 [28:43:31<112:46:35, 618.90s/it]2025-09-28 15:56:59,991 Stage: Train 0.5 | Epoch: 167 | Iter: 101600 | Total Loss: 0.005673 | Recon Loss: 0.004587 | Commit Loss: 0.002172 | Perplexity: 384.848328
2025-09-28 16:00:22,855 Stage: Train 0.5 | Epoch: 167 | Iter: 101800 | Total Loss: 0.005639 | Recon Loss: 0.004556 | Commit Loss: 0.002165 | Perplexity: 384.573608
2025-09-28 16:03:45,304 Stage: Train 0.5 | Epoch: 167 | Iter: 102000 | Total Loss: 0.005657 | Recon Loss: 0.004567 | Commit Loss: 0.002181 | Perplexity: 385.809343
Trainning Epoch:  20%|██        | 168/823 [28:53:52<112:40:27, 619.28s/it]Trainning Epoch:  20%|██        | 168/823 [28:53:52<112:40:29, 619.28s/it]Trainning Epoch:  20%|██        | 168/823 [28:53:52<112:40:29, 619.28s/it]Trainning Epoch:  20%|██        | 168/823 [28:53:52<112:40:28, 619.28s/it]2025-09-28 16:07:11,796 Stage: Train 0.5 | Epoch: 168 | Iter: 102200 | Total Loss: 0.005662 | Recon Loss: 0.004579 | Commit Loss: 0.002166 | Perplexity: 385.194624
2025-09-28 16:10:35,278 Stage: Train 0.5 | Epoch: 168 | Iter: 102400 | Total Loss: 0.005578 | Recon Loss: 0.004497 | Commit Loss: 0.002163 | Perplexity: 384.934085
2025-09-28 16:13:58,817 Stage: Train 0.5 | Epoch: 168 | Iter: 102600 | Total Loss: 0.005686 | Recon Loss: 0.004607 | Commit Loss: 0.002157 | Perplexity: 385.290560
Trainning Epoch:  21%|██        | 169/823 [29:04:14<112:38:57, 620.09s/it]Trainning Epoch:  21%|██        | 169/823 [29:04:14<112:39:00, 620.09s/it]Trainning Epoch:  21%|██        | 169/823 [29:04:14<112:39:01, 620.09s/it]Trainning Epoch:  21%|██        | 169/823 [29:04:14<112:39:03, 620.10s/it]2025-09-28 16:17:24,856 Stage: Train 0.5 | Epoch: 169 | Iter: 102800 | Total Loss: 0.005670 | Recon Loss: 0.004577 | Commit Loss: 0.002187 | Perplexity: 385.241678
2025-09-28 16:20:46,033 Stage: Train 0.5 | Epoch: 169 | Iter: 103000 | Total Loss: 0.005605 | Recon Loss: 0.004522 | Commit Loss: 0.002165 | Perplexity: 384.112233
2025-09-28 16:24:07,177 Stage: Train 0.5 | Epoch: 169 | Iter: 103200 | Total Loss: 0.005671 | Recon Loss: 0.004592 | Commit Loss: 0.002159 | Perplexity: 385.860151
Trainning Epoch:  21%|██        | 170/823 [29:14:28<112:10:39, 618.44s/it]Trainning Epoch:  21%|██        | 170/823 [29:14:28<112:10:36, 618.43s/it]Trainning Epoch:  21%|██        | 170/823 [29:14:28<112:10:39, 618.44s/it]Trainning Epoch:  21%|██        | 170/823 [29:14:28<112:10:41, 618.44s/it]2025-09-28 16:27:32,118 Stage: Train 0.5 | Epoch: 170 | Iter: 103400 | Total Loss: 0.005630 | Recon Loss: 0.004551 | Commit Loss: 0.002157 | Perplexity: 384.526105
2025-09-28 16:30:54,088 Stage: Train 0.5 | Epoch: 170 | Iter: 103600 | Total Loss: 0.005611 | Recon Loss: 0.004528 | Commit Loss: 0.002167 | Perplexity: 385.336075
2025-09-28 16:34:16,820 Stage: Train 0.5 | Epoch: 170 | Iter: 103800 | Total Loss: 0.005620 | Recon Loss: 0.004544 | Commit Loss: 0.002152 | Perplexity: 385.411440
Trainning Epoch:  21%|██        | 171/823 [29:24:47<112:02:01, 618.59s/it]Trainning Epoch:  21%|██        | 171/823 [29:24:47<112:02:04, 618.60s/it]Trainning Epoch:  21%|██        | 171/823 [29:24:47<112:02:04, 618.60s/it]Trainning Epoch:  21%|██        | 171/823 [29:24:47<112:02:05, 618.60s/it]2025-09-28 16:37:43,054 Stage: Train 0.5 | Epoch: 171 | Iter: 104000 | Total Loss: 0.005615 | Recon Loss: 0.004532 | Commit Loss: 0.002165 | Perplexity: 385.071937
2025-09-28 16:41:05,179 Stage: Train 0.5 | Epoch: 171 | Iter: 104200 | Total Loss: 0.005659 | Recon Loss: 0.004568 | Commit Loss: 0.002182 | Perplexity: 385.038956
2025-09-28 16:44:26,888 Stage: Train 0.5 | Epoch: 171 | Iter: 104400 | Total Loss: 0.005599 | Recon Loss: 0.004519 | Commit Loss: 0.002158 | Perplexity: 384.592291
Trainning Epoch:  21%|██        | 172/823 [29:35:05<111:49:57, 618.43s/it]Trainning Epoch:  21%|██        | 172/823 [29:35:05<111:50:00, 618.43s/it]Trainning Epoch:  21%|██        | 172/823 [29:35:05<111:49:59, 618.43s/it]Trainning Epoch:  21%|██        | 172/823 [29:35:05<111:50:00, 618.43s/it]2025-09-28 16:47:52,246 Stage: Train 0.5 | Epoch: 172 | Iter: 104600 | Total Loss: 0.005674 | Recon Loss: 0.004589 | Commit Loss: 0.002171 | Perplexity: 385.272476
2025-09-28 16:51:13,319 Stage: Train 0.5 | Epoch: 172 | Iter: 104800 | Total Loss: 0.005608 | Recon Loss: 0.004530 | Commit Loss: 0.002156 | Perplexity: 384.421150
2025-09-28 16:54:35,525 Stage: Train 0.5 | Epoch: 172 | Iter: 105000 | Total Loss: 0.005663 | Recon Loss: 0.004573 | Commit Loss: 0.002179 | Perplexity: 386.219478
Trainning Epoch:  21%|██        | 173/823 [29:45:22<111:33:34, 617.87s/it]Trainning Epoch:  21%|██        | 173/823 [29:45:22<111:33:38, 617.87s/it]Trainning Epoch:  21%|██        | 173/823 [29:45:22<111:33:37, 617.87s/it]Trainning Epoch:  21%|██        | 173/823 [29:45:22<111:33:40, 617.88s/it]2025-09-28 16:58:01,056 Stage: Train 0.5 | Epoch: 173 | Iter: 105200 | Total Loss: 0.005599 | Recon Loss: 0.004518 | Commit Loss: 0.002162 | Perplexity: 385.163650
2025-09-28 17:01:20,823 Stage: Train 0.5 | Epoch: 173 | Iter: 105400 | Total Loss: 0.005641 | Recon Loss: 0.004566 | Commit Loss: 0.002152 | Perplexity: 385.198157
2025-09-28 17:04:41,241 Stage: Train 0.5 | Epoch: 173 | Iter: 105600 | Total Loss: 0.005613 | Recon Loss: 0.004544 | Commit Loss: 0.002137 | Perplexity: 385.046516
Trainning Epoch:  21%|██        | 174/823 [29:55:35<111:07:55, 616.45s/it]Trainning Epoch:  21%|██        | 174/823 [29:55:35<111:07:53, 616.45s/it]Trainning Epoch:  21%|██        | 174/823 [29:55:35<111:07:55, 616.45s/it]Trainning Epoch:  21%|██        | 174/823 [29:55:35<111:07:55, 616.45s/it]2025-09-28 17:08:06,199 Stage: Train 0.5 | Epoch: 174 | Iter: 105800 | Total Loss: 0.005637 | Recon Loss: 0.004549 | Commit Loss: 0.002175 | Perplexity: 385.686522
2025-09-28 17:11:27,330 Stage: Train 0.5 | Epoch: 174 | Iter: 106000 | Total Loss: 0.005545 | Recon Loss: 0.004477 | Commit Loss: 0.002135 | Perplexity: 384.760696
2025-09-28 17:14:48,613 Stage: Train 0.5 | Epoch: 174 | Iter: 106200 | Total Loss: 0.005641 | Recon Loss: 0.004555 | Commit Loss: 0.002172 | Perplexity: 385.943459
2025-09-28 17:18:10,240 Stage: Train 0.5 | Epoch: 174 | Iter: 106400 | Total Loss: 0.005630 | Recon Loss: 0.004551 | Commit Loss: 0.002158 | Perplexity: 384.380105
Trainning Epoch:  21%|██▏       | 175/823 [30:05:51<110:55:19, 616.23s/it]Trainning Epoch:  21%|██▏       | 175/823 [30:05:51<110:55:26, 616.24s/it]Trainning Epoch:  21%|██▏       | 175/823 [30:05:51<110:55:26, 616.24s/it]Trainning Epoch:  21%|██▏       | 175/823 [30:05:51<110:55:26, 616.24s/it]2025-09-28 17:21:34,400 Stage: Train 0.5 | Epoch: 175 | Iter: 106600 | Total Loss: 0.005520 | Recon Loss: 0.004450 | Commit Loss: 0.002139 | Perplexity: 384.538119
2025-09-28 17:24:54,894 Stage: Train 0.5 | Epoch: 175 | Iter: 106800 | Total Loss: 0.005606 | Recon Loss: 0.004527 | Commit Loss: 0.002158 | Perplexity: 384.866899
2025-09-28 17:28:15,981 Stage: Train 0.5 | Epoch: 175 | Iter: 107000 | Total Loss: 0.005618 | Recon Loss: 0.004537 | Commit Loss: 0.002162 | Perplexity: 385.606788
Trainning Epoch:  21%|██▏       | 176/823 [30:16:04<110:37:04, 615.49s/it]Trainning Epoch:  21%|██▏       | 176/823 [30:16:04<110:37:12, 615.51s/it]Trainning Epoch:  21%|██▏       | 176/823 [30:16:04<110:37:12, 615.51s/it]Trainning Epoch:  21%|██▏       | 176/823 [30:16:04<110:37:16, 615.51s/it]2025-09-28 17:31:41,568 Stage: Train 0.5 | Epoch: 176 | Iter: 107200 | Total Loss: 0.005575 | Recon Loss: 0.004493 | Commit Loss: 0.002165 | Perplexity: 385.197141
2025-09-28 17:35:03,903 Stage: Train 0.5 | Epoch: 176 | Iter: 107400 | Total Loss: 0.005608 | Recon Loss: 0.004535 | Commit Loss: 0.002147 | Perplexity: 384.967343
2025-09-28 17:38:26,480 Stage: Train 0.5 | Epoch: 176 | Iter: 107600 | Total Loss: 0.005576 | Recon Loss: 0.004498 | Commit Loss: 0.002157 | Perplexity: 385.461872
Trainning Epoch:  22%|██▏       | 177/823 [30:26:23<110:37:17, 616.47s/it]Trainning Epoch:  22%|██▏       | 177/823 [30:26:23<110:37:20, 616.47s/it]Trainning Epoch:  22%|██▏       | 177/823 [30:26:23<110:37:20, 616.47s/it]Trainning Epoch:  22%|██▏       | 177/823 [30:26:23<110:37:19, 616.47s/it]2025-09-28 17:41:52,419 Stage: Train 0.5 | Epoch: 177 | Iter: 107800 | Total Loss: 0.005600 | Recon Loss: 0.004517 | Commit Loss: 0.002167 | Perplexity: 384.783448
2025-09-28 17:45:14,111 Stage: Train 0.5 | Epoch: 177 | Iter: 108000 | Total Loss: 0.005587 | Recon Loss: 0.004511 | Commit Loss: 0.002152 | Perplexity: 385.495578
2025-09-28 17:48:35,736 Stage: Train 0.5 | Epoch: 177 | Iter: 108200 | Total Loss: 0.005595 | Recon Loss: 0.004516 | Commit Loss: 0.002157 | Perplexity: 384.736103
Trainning Epoch:  22%|██▏       | 178/823 [30:36:40<110:29:18, 616.68s/it]Trainning Epoch:  22%|██▏       | 178/823 [30:36:40<110:29:18, 616.68s/it]Trainning Epoch:  22%|██▏       | 178/823 [30:36:40<110:29:18, 616.68s/it]Trainning Epoch:  22%|██▏       | 178/823 [30:36:40<110:29:19, 616.68s/it]2025-09-28 17:52:01,069 Stage: Train 0.5 | Epoch: 178 | Iter: 108400 | Total Loss: 0.005541 | Recon Loss: 0.004469 | Commit Loss: 0.002143 | Perplexity: 385.145828
2025-09-28 17:55:23,199 Stage: Train 0.5 | Epoch: 178 | Iter: 108600 | Total Loss: 0.005600 | Recon Loss: 0.004522 | Commit Loss: 0.002156 | Perplexity: 385.966157
2025-09-28 17:58:45,408 Stage: Train 0.5 | Epoch: 178 | Iter: 108800 | Total Loss: 0.005578 | Recon Loss: 0.004494 | Commit Loss: 0.002167 | Perplexity: 385.447509
Trainning Epoch:  22%|██▏       | 179/823 [30:46:58<110:22:33, 617.01s/it]Trainning Epoch:  22%|██▏       | 179/823 [30:46:58<110:22:35, 617.01s/it]Trainning Epoch:  22%|██▏       | 179/823 [30:46:58<110:22:43, 617.02s/it]Trainning Epoch:  22%|██▏       | 179/823 [30:46:58<110:22:45, 617.03s/it]2025-09-28 18:02:11,917 Stage: Train 0.5 | Epoch: 179 | Iter: 109000 | Total Loss: 0.005552 | Recon Loss: 0.004477 | Commit Loss: 0.002149 | Perplexity: 384.026543
2025-09-28 18:05:33,936 Stage: Train 0.5 | Epoch: 179 | Iter: 109200 | Total Loss: 0.005564 | Recon Loss: 0.004497 | Commit Loss: 0.002133 | Perplexity: 385.349147
2025-09-28 18:08:56,377 Stage: Train 0.5 | Epoch: 179 | Iter: 109400 | Total Loss: 0.005599 | Recon Loss: 0.004514 | Commit Loss: 0.002169 | Perplexity: 386.141632
Trainning Epoch:  22%|██▏       | 180/823 [30:57:17<110:18:43, 617.61s/it]Trainning Epoch:  22%|██▏       | 180/823 [30:57:17<110:18:45, 617.61s/it]Trainning Epoch:  22%|██▏       | 180/823 [30:57:17<110:18:48, 617.62s/it]Trainning Epoch:  22%|██▏       | 180/823 [30:57:17<110:18:46, 617.62s/it]2025-09-28 18:12:20,246 Stage: Train 0.5 | Epoch: 180 | Iter: 109600 | Total Loss: 0.005546 | Recon Loss: 0.004470 | Commit Loss: 0.002153 | Perplexity: 385.351363
2025-09-28 18:15:40,849 Stage: Train 0.5 | Epoch: 180 | Iter: 109800 | Total Loss: 0.005534 | Recon Loss: 0.004457 | Commit Loss: 0.002155 | Perplexity: 385.908197
2025-09-28 18:19:02,073 Stage: Train 0.5 | Epoch: 180 | Iter: 110000 | Total Loss: 0.005541 | Recon Loss: 0.004479 | Commit Loss: 0.002124 | Perplexity: 384.353413
Trainning Epoch:  22%|██▏       | 181/823 [31:07:31<109:55:16, 616.38s/it]Trainning Epoch:  22%|██▏       | 181/823 [31:07:31<109:55:20, 616.39s/it]Trainning Epoch:  22%|██▏       | 181/823 [31:07:31<109:55:19, 616.39s/it]Trainning Epoch:  22%|██▏       | 181/823 [31:07:31<109:55:21, 616.39s/it]2025-09-28 18:22:26,779 Stage: Train 0.5 | Epoch: 181 | Iter: 110200 | Total Loss: 0.005568 | Recon Loss: 0.004487 | Commit Loss: 0.002161 | Perplexity: 386.534013
2025-09-28 18:25:47,246 Stage: Train 0.5 | Epoch: 181 | Iter: 110400 | Total Loss: 0.005573 | Recon Loss: 0.004492 | Commit Loss: 0.002162 | Perplexity: 385.974464
2025-09-28 18:29:07,692 Stage: Train 0.5 | Epoch: 181 | Iter: 110600 | Total Loss: 0.005513 | Recon Loss: 0.004448 | Commit Loss: 0.002130 | Perplexity: 384.649569
Trainning Epoch:  22%|██▏       | 182/823 [31:17:44<109:35:48, 615.52s/it]Trainning Epoch:  22%|██▏       | 182/823 [31:17:44<109:35:46, 615.52s/it]Trainning Epoch:  22%|██▏       | 182/823 [31:17:44<109:35:47, 615.52s/it]Trainning Epoch:  22%|██▏       | 182/823 [31:17:44<109:35:49, 615.52s/it]2025-09-28 18:32:33,761 Stage: Train 0.5 | Epoch: 182 | Iter: 110800 | Total Loss: 0.005558 | Recon Loss: 0.004482 | Commit Loss: 0.002152 | Perplexity: 385.778653
2025-09-28 18:35:57,895 Stage: Train 0.5 | Epoch: 182 | Iter: 111000 | Total Loss: 0.005520 | Recon Loss: 0.004445 | Commit Loss: 0.002151 | Perplexity: 384.647106
2025-09-28 18:39:21,573 Stage: Train 0.5 | Epoch: 182 | Iter: 111200 | Total Loss: 0.005515 | Recon Loss: 0.004443 | Commit Loss: 0.002144 | Perplexity: 384.404754
Trainning Epoch:  22%|██▏       | 183/823 [31:28:07<109:49:07, 617.73s/it]Trainning Epoch:  22%|██▏       | 183/823 [31:28:07<109:49:10, 617.74s/it]Trainning Epoch:  22%|██▏       | 183/823 [31:28:07<109:49:09, 617.73s/it]Trainning Epoch:  22%|██▏       | 183/823 [31:28:07<109:49:12, 617.74s/it]2025-09-28 18:42:48,435 Stage: Train 0.5 | Epoch: 183 | Iter: 111400 | Total Loss: 0.005516 | Recon Loss: 0.004438 | Commit Loss: 0.002155 | Perplexity: 385.322950
2025-09-28 18:46:11,309 Stage: Train 0.5 | Epoch: 183 | Iter: 111600 | Total Loss: 0.005521 | Recon Loss: 0.004445 | Commit Loss: 0.002151 | Perplexity: 384.730454
2025-09-28 18:49:34,726 Stage: Train 0.5 | Epoch: 183 | Iter: 111800 | Total Loss: 0.005539 | Recon Loss: 0.004471 | Commit Loss: 0.002135 | Perplexity: 385.973545
Trainning Epoch:  22%|██▏       | 184/823 [31:38:28<109:49:09, 618.70s/it]Trainning Epoch:  22%|██▏       | 184/823 [31:38:28<109:49:07, 618.70s/it]Trainning Epoch:  22%|██▏       | 184/823 [31:38:28<109:49:10, 618.70s/it]Trainning Epoch:  22%|██▏       | 184/823 [31:38:28<109:49:12, 618.70s/it]2025-09-28 18:53:01,288 Stage: Train 0.5 | Epoch: 184 | Iter: 112000 | Total Loss: 0.005553 | Recon Loss: 0.004476 | Commit Loss: 0.002154 | Perplexity: 385.216572
2025-09-28 18:56:23,746 Stage: Train 0.5 | Epoch: 184 | Iter: 112200 | Total Loss: 0.005518 | Recon Loss: 0.004452 | Commit Loss: 0.002132 | Perplexity: 385.194128
2025-09-28 18:59:45,957 Stage: Train 0.5 | Epoch: 184 | Iter: 112400 | Total Loss: 0.005515 | Recon Loss: 0.004439 | Commit Loss: 0.002153 | Perplexity: 384.945551
Trainning Epoch:  22%|██▏       | 185/823 [31:48:47<109:40:27, 618.85s/it]Trainning Epoch:  22%|██▏       | 185/823 [31:48:47<109:40:30, 618.86s/it]Trainning Epoch:  22%|██▏       | 185/823 [31:48:47<109:40:33, 618.86s/it]Trainning Epoch:  22%|██▏       | 185/823 [31:48:47<109:40:31, 618.86s/it]2025-09-28 19:03:12,774 Stage: Train 0.5 | Epoch: 185 | Iter: 112600 | Total Loss: 0.005488 | Recon Loss: 0.004422 | Commit Loss: 0.002131 | Perplexity: 385.076976
2025-09-28 19:06:37,036 Stage: Train 0.5 | Epoch: 185 | Iter: 112800 | Total Loss: 0.005474 | Recon Loss: 0.004407 | Commit Loss: 0.002133 | Perplexity: 385.453861
2025-09-28 19:10:00,595 Stage: Train 0.5 | Epoch: 185 | Iter: 113000 | Total Loss: 0.005521 | Recon Loss: 0.004440 | Commit Loss: 0.002163 | Perplexity: 386.423702
Trainning Epoch:  23%|██▎       | 186/823 [31:59:11<109:44:50, 620.24s/it]Trainning Epoch:  23%|██▎       | 186/823 [31:59:11<109:44:51, 620.24s/it]Trainning Epoch:  23%|██▎       | 186/823 [31:59:11<109:44:53, 620.24s/it]Trainning Epoch:  23%|██▎       | 186/823 [31:59:11<109:44:52, 620.24s/it]2025-09-28 19:13:27,397 Stage: Train 0.5 | Epoch: 186 | Iter: 113200 | Total Loss: 0.005500 | Recon Loss: 0.004436 | Commit Loss: 0.002128 | Perplexity: 386.126768
2025-09-28 19:16:49,750 Stage: Train 0.5 | Epoch: 186 | Iter: 113400 | Total Loss: 0.005557 | Recon Loss: 0.004484 | Commit Loss: 0.002147 | Perplexity: 386.276928
2025-09-28 19:20:12,149 Stage: Train 0.5 | Epoch: 186 | Iter: 113600 | Total Loss: 0.005471 | Recon Loss: 0.004409 | Commit Loss: 0.002124 | Perplexity: 385.978491
Trainning Epoch:  23%|██▎       | 187/823 [32:09:30<109:30:52, 619.89s/it]Trainning Epoch:  23%|██▎       | 187/823 [32:09:30<109:30:58, 619.90s/it]Trainning Epoch:  23%|██▎       | 187/823 [32:09:30<109:30:56, 619.90s/it]Trainning Epoch:  23%|██▎       | 187/823 [32:09:30<109:30:57, 619.90s/it]2025-09-28 19:23:38,197 Stage: Train 0.5 | Epoch: 187 | Iter: 113800 | Total Loss: 0.005489 | Recon Loss: 0.004429 | Commit Loss: 0.002120 | Perplexity: 386.311903
2025-09-28 19:27:01,015 Stage: Train 0.5 | Epoch: 187 | Iter: 114000 | Total Loss: 0.005434 | Recon Loss: 0.004370 | Commit Loss: 0.002127 | Perplexity: 385.697722
2025-09-28 19:30:23,888 Stage: Train 0.5 | Epoch: 187 | Iter: 114200 | Total Loss: 0.005483 | Recon Loss: 0.004416 | Commit Loss: 0.002133 | Perplexity: 386.835789
Trainning Epoch:  23%|██▎       | 188/823 [32:19:50<109:21:05, 619.95s/it]Trainning Epoch:  23%|██▎       | 188/823 [32:19:50<109:21:01, 619.94s/it]Trainning Epoch:  23%|██▎       | 188/823 [32:19:50<109:21:05, 619.95s/it]Trainning Epoch:  23%|██▎       | 188/823 [32:19:50<109:21:06, 619.95s/it]2025-09-28 19:33:49,262 Stage: Train 0.5 | Epoch: 188 | Iter: 114400 | Total Loss: 0.005516 | Recon Loss: 0.004451 | Commit Loss: 0.002131 | Perplexity: 387.052968
2025-09-28 19:37:09,841 Stage: Train 0.5 | Epoch: 188 | Iter: 114600 | Total Loss: 0.005454 | Recon Loss: 0.004394 | Commit Loss: 0.002119 | Perplexity: 385.314983
2025-09-28 19:40:31,155 Stage: Train 0.5 | Epoch: 188 | Iter: 114800 | Total Loss: 0.005472 | Recon Loss: 0.004405 | Commit Loss: 0.002133 | Perplexity: 385.983494
Trainning Epoch:  23%|██▎       | 189/823 [32:30:04<108:52:56, 618.26s/it]Trainning Epoch:  23%|██▎       | 189/823 [32:30:04<108:52:54, 618.26s/it]Trainning Epoch:  23%|██▎       | 189/823 [32:30:04<108:52:52, 618.25s/it]Trainning Epoch:  23%|██▎       | 189/823 [32:30:04<108:52:53, 618.25s/it]2025-09-28 19:43:56,087 Stage: Train 0.5 | Epoch: 189 | Iter: 115000 | Total Loss: 0.005440 | Recon Loss: 0.004386 | Commit Loss: 0.002107 | Perplexity: 385.952759
2025-09-28 19:47:17,897 Stage: Train 0.5 | Epoch: 189 | Iter: 115200 | Total Loss: 0.005502 | Recon Loss: 0.004433 | Commit Loss: 0.002137 | Perplexity: 387.518947
2025-09-28 19:50:39,902 Stage: Train 0.5 | Epoch: 189 | Iter: 115400 | Total Loss: 0.005490 | Recon Loss: 0.004426 | Commit Loss: 0.002127 | Perplexity: 386.437002
Trainning Epoch:  23%|██▎       | 190/823 [32:40:21<108:39:27, 617.96s/it]Trainning Epoch:  23%|██▎       | 190/823 [32:40:21<108:39:27, 617.96s/it]Trainning Epoch:  23%|██▎       | 190/823 [32:40:21<108:39:30, 617.96s/it]Trainning Epoch:  23%|██▎       | 190/823 [32:40:21<108:39:28, 617.96s/it]2025-09-28 19:54:06,028 Stage: Train 0.5 | Epoch: 190 | Iter: 115600 | Total Loss: 0.005433 | Recon Loss: 0.004375 | Commit Loss: 0.002117 | Perplexity: 386.519435
2025-09-28 19:57:29,072 Stage: Train 0.5 | Epoch: 190 | Iter: 115800 | Total Loss: 0.005497 | Recon Loss: 0.004439 | Commit Loss: 0.002116 | Perplexity: 387.230258
2025-09-28 20:00:51,986 Stage: Train 0.5 | Epoch: 190 | Iter: 116000 | Total Loss: 0.005447 | Recon Loss: 0.004384 | Commit Loss: 0.002126 | Perplexity: 387.642451
Trainning Epoch:  23%|██▎       | 191/823 [32:50:42<108:37:49, 618.78s/it]Trainning Epoch:  23%|██▎       | 191/823 [32:50:42<108:37:46, 618.78s/it]Trainning Epoch:  23%|██▎       | 191/823 [32:50:42<108:37:47, 618.78s/it]Trainning Epoch:  23%|██▎       | 191/823 [32:50:42<108:37:48, 618.78s/it]2025-09-28 20:04:17,604 Stage: Train 0.5 | Epoch: 191 | Iter: 116200 | Total Loss: 0.005481 | Recon Loss: 0.004406 | Commit Loss: 0.002149 | Perplexity: 388.408163
2025-09-28 20:07:38,141 Stage: Train 0.5 | Epoch: 191 | Iter: 116400 | Total Loss: 0.005451 | Recon Loss: 0.004393 | Commit Loss: 0.002115 | Perplexity: 388.354248
2025-09-28 20:10:59,095 Stage: Train 0.5 | Epoch: 191 | Iter: 116600 | Total Loss: 0.005449 | Recon Loss: 0.004383 | Commit Loss: 0.002133 | Perplexity: 387.514374
Trainning Epoch:  23%|██▎       | 192/823 [33:00:56<108:12:03, 617.31s/it]Trainning Epoch:  23%|██▎       | 192/823 [33:00:56<108:12:05, 617.31s/it]Trainning Epoch:  23%|██▎       | 192/823 [33:00:56<108:12:06, 617.32s/it]Trainning Epoch:  23%|██▎       | 192/823 [33:00:56<108:12:06, 617.32s/it]2025-09-28 20:14:23,957 Stage: Train 0.5 | Epoch: 192 | Iter: 116800 | Total Loss: 0.005450 | Recon Loss: 0.004395 | Commit Loss: 0.002110 | Perplexity: 387.794317
2025-09-28 20:17:46,448 Stage: Train 0.5 | Epoch: 192 | Iter: 117000 | Total Loss: 0.005472 | Recon Loss: 0.004401 | Commit Loss: 0.002144 | Perplexity: 388.076785
2025-09-28 20:21:09,349 Stage: Train 0.5 | Epoch: 192 | Iter: 117200 | Total Loss: 0.005440 | Recon Loss: 0.004371 | Commit Loss: 0.002138 | Perplexity: 387.223311
Trainning Epoch:  23%|██▎       | 193/823 [33:11:16<108:10:08, 618.11s/it]Trainning Epoch:  23%|██▎       | 193/823 [33:11:16<108:10:16, 618.12s/it]Trainning Epoch:  23%|██▎       | 193/823 [33:11:16<108:10:17, 618.12s/it]Trainning Epoch:  23%|██▎       | 193/823 [33:11:16<108:10:18, 618.12s/it]2025-09-28 20:24:36,029 Stage: Train 0.5 | Epoch: 193 | Iter: 117400 | Total Loss: 0.005430 | Recon Loss: 0.004374 | Commit Loss: 0.002112 | Perplexity: 386.830131
2025-09-28 20:27:58,683 Stage: Train 0.5 | Epoch: 193 | Iter: 117600 | Total Loss: 0.005464 | Recon Loss: 0.004400 | Commit Loss: 0.002130 | Perplexity: 388.584837
2025-09-28 20:31:21,042 Stage: Train 0.5 | Epoch: 193 | Iter: 117800 | Total Loss: 0.005428 | Recon Loss: 0.004362 | Commit Loss: 0.002131 | Perplexity: 388.228842
Trainning Epoch:  24%|██▎       | 194/823 [33:21:35<108:02:57, 618.41s/it]Trainning Epoch:  24%|██▎       | 194/823 [33:21:35<108:03:00, 618.41s/it]Trainning Epoch:  24%|██▎       | 194/823 [33:21:35<108:03:00, 618.41s/it]Trainning Epoch:  24%|██▎       | 194/823 [33:21:35<108:03:01, 618.41s/it]2025-09-28 20:34:46,338 Stage: Train 0.5 | Epoch: 194 | Iter: 118000 | Total Loss: 0.005435 | Recon Loss: 0.004379 | Commit Loss: 0.002113 | Perplexity: 387.943934
2025-09-28 20:38:07,215 Stage: Train 0.5 | Epoch: 194 | Iter: 118200 | Total Loss: 0.005435 | Recon Loss: 0.004371 | Commit Loss: 0.002129 | Perplexity: 388.600069
2025-09-28 20:41:28,544 Stage: Train 0.5 | Epoch: 194 | Iter: 118400 | Total Loss: 0.005412 | Recon Loss: 0.004360 | Commit Loss: 0.002105 | Perplexity: 387.479878
Trainning Epoch:  24%|██▎       | 195/823 [33:31:51<107:43:34, 617.54s/it]Trainning Epoch:  24%|██▎       | 195/823 [33:31:51<107:43:33, 617.54s/it]Trainning Epoch:  24%|██▎       | 195/823 [33:31:51<107:43:33, 617.54s/it]Trainning Epoch:  24%|██▎       | 195/823 [33:31:51<107:43:34, 617.54s/it]2025-09-28 20:44:54,149 Stage: Train 0.5 | Epoch: 195 | Iter: 118600 | Total Loss: 0.005405 | Recon Loss: 0.004354 | Commit Loss: 0.002101 | Perplexity: 387.529016
2025-09-28 20:48:15,664 Stage: Train 0.5 | Epoch: 195 | Iter: 118800 | Total Loss: 0.005400 | Recon Loss: 0.004346 | Commit Loss: 0.002108 | Perplexity: 387.668663
2025-09-28 20:51:37,575 Stage: Train 0.5 | Epoch: 195 | Iter: 119000 | Total Loss: 0.005424 | Recon Loss: 0.004366 | Commit Loss: 0.002117 | Perplexity: 387.888920
Trainning Epoch:  24%|██▍       | 196/823 [33:42:07<107:31:26, 617.36s/it]Trainning Epoch:  24%|██▍       | 196/823 [33:42:07<107:31:22, 617.36s/it]Trainning Epoch:  24%|██▍       | 196/823 [33:42:07<107:31:24, 617.36s/it]Trainning Epoch:  24%|██▍       | 196/823 [33:42:08<107:31:26, 617.36s/it]2025-09-28 20:55:02,817 Stage: Train 0.5 | Epoch: 196 | Iter: 119200 | Total Loss: 0.005436 | Recon Loss: 0.004378 | Commit Loss: 0.002115 | Perplexity: 388.015468
2025-09-28 20:58:24,562 Stage: Train 0.5 | Epoch: 196 | Iter: 119400 | Total Loss: 0.005386 | Recon Loss: 0.004330 | Commit Loss: 0.002111 | Perplexity: 388.131337
2025-09-28 21:01:47,068 Stage: Train 0.5 | Epoch: 196 | Iter: 119600 | Total Loss: 0.005420 | Recon Loss: 0.004362 | Commit Loss: 0.002116 | Perplexity: 387.552164
Trainning Epoch:  24%|██▍       | 197/823 [33:52:25<107:22:26, 617.49s/it]Trainning Epoch:  24%|██▍       | 197/823 [33:52:25<107:22:22, 617.48s/it]Trainning Epoch:  24%|██▍       | 197/823 [33:52:25<107:22:22, 617.48s/it]Trainning Epoch:  24%|██▍       | 197/823 [33:52:25<107:22:24, 617.48s/it]2025-09-28 21:05:12,482 Stage: Train 0.5 | Epoch: 197 | Iter: 119800 | Total Loss: 0.005451 | Recon Loss: 0.004396 | Commit Loss: 0.002110 | Perplexity: 388.119317
2025-09-28 21:08:32,511 Stage: Train 0.5 | Epoch: 197 | Iter: 120000 | Total Loss: 0.005362 | Recon Loss: 0.004317 | Commit Loss: 0.002088 | Perplexity: 386.908871
2025-09-28 21:08:32,511 Saving model at iteration 120000
2025-09-28 21:08:33,063 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_198_step_120000
2025-09-28 21:08:33,630 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_198_step_120000/model.safetensors
2025-09-28 21:08:34,162 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_198_step_120000/optimizer.bin
2025-09-28 21:08:34,162 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_198_step_120000/scheduler.bin
2025-09-28 21:08:34,162 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_198_step_120000/sampler.bin
2025-09-28 21:08:34,163 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_198_step_120000/random_states_0.pkl
2025-09-28 21:11:54,979 Stage: Train 0.5 | Epoch: 197 | Iter: 120200 | Total Loss: 0.005410 | Recon Loss: 0.004355 | Commit Loss: 0.002110 | Perplexity: 389.081170
Trainning Epoch:  24%|██▍       | 198/823 [34:02:40<107:03:25, 616.65s/it]Trainning Epoch:  24%|██▍       | 198/823 [34:02:40<107:03:27, 616.65s/it]Trainning Epoch:  24%|██▍       | 198/823 [34:02:40<107:03:30, 616.66s/it]Trainning Epoch:  24%|██▍       | 198/823 [34:02:40<107:03:27, 616.65s/it]2025-09-28 21:15:19,493 Stage: Train 0.5 | Epoch: 198 | Iter: 120400 | Total Loss: 0.005388 | Recon Loss: 0.004336 | Commit Loss: 0.002105 | Perplexity: 388.040746
2025-09-28 21:18:40,693 Stage: Train 0.5 | Epoch: 198 | Iter: 120600 | Total Loss: 0.005356 | Recon Loss: 0.004310 | Commit Loss: 0.002093 | Perplexity: 387.143266
2025-09-28 21:22:01,762 Stage: Train 0.5 | Epoch: 198 | Iter: 120800 | Total Loss: 0.005420 | Recon Loss: 0.004372 | Commit Loss: 0.002095 | Perplexity: 386.917289
Trainning Epoch:  24%|██▍       | 199/823 [34:12:55<106:49:17, 616.28s/it]Trainning Epoch:  24%|██▍       | 199/823 [34:12:55<106:49:15, 616.27s/it]Trainning Epoch:  24%|██▍       | 199/823 [34:12:55<106:49:15, 616.28s/it]Trainning Epoch:  24%|██▍       | 199/823 [34:12:55<106:49:16, 616.28s/it]2025-09-28 21:25:26,734 Stage: Train 0.5 | Epoch: 199 | Iter: 121000 | Total Loss: 0.005385 | Recon Loss: 0.004329 | Commit Loss: 0.002112 | Perplexity: 388.032871
2025-09-28 21:28:48,245 Stage: Train 0.5 | Epoch: 199 | Iter: 121200 | Total Loss: 0.005363 | Recon Loss: 0.004317 | Commit Loss: 0.002091 | Perplexity: 387.112170
2025-09-28 21:32:10,077 Stage: Train 0.5 | Epoch: 199 | Iter: 121400 | Total Loss: 0.005377 | Recon Loss: 0.004333 | Commit Loss: 0.002088 | Perplexity: 387.827490
2025-09-28 21:35:32,169 Stage: Train 0.5 | Epoch: 199 | Iter: 121600 | Total Loss: 0.005369 | Recon Loss: 0.004327 | Commit Loss: 0.002083 | Perplexity: 386.906687
Trainning Epoch:  24%|██▍       | 200/823 [34:23:12<106:41:36, 616.53s/it]Trainning Epoch:  24%|██▍       | 200/823 [34:23:13<106:41:42, 616.54s/it]Trainning Epoch:  24%|██▍       | 200/823 [34:23:13<106:41:42, 616.54s/it]Trainning Epoch:  24%|██▍       | 200/823 [34:23:12<106:41:43, 616.54s/it]2025-09-28 21:38:56,438 Stage: Train 0.5 | Epoch: 200 | Iter: 121800 | Total Loss: 0.005335 | Recon Loss: 0.004294 | Commit Loss: 0.002083 | Perplexity: 386.299777
2025-09-28 21:42:17,740 Stage: Train 0.5 | Epoch: 200 | Iter: 122000 | Total Loss: 0.005391 | Recon Loss: 0.004337 | Commit Loss: 0.002108 | Perplexity: 387.631978
2025-09-28 21:45:39,493 Stage: Train 0.5 | Epoch: 200 | Iter: 122200 | Total Loss: 0.005433 | Recon Loss: 0.004377 | Commit Loss: 0.002114 | Perplexity: 387.602734
Trainning Epoch:  24%|██▍       | 201/823 [34:33:28<106:27:45, 616.18s/it]Trainning Epoch:  24%|██▍       | 201/823 [34:33:28<106:27:49, 616.19s/it]Trainning Epoch:  24%|██▍       | 201/823 [34:33:28<106:27:49, 616.19s/it]Trainning Epoch:  24%|██▍       | 201/823 [34:33:28<106:27:49, 616.19s/it]2025-09-28 21:49:04,119 Stage: Train 0.5 | Epoch: 201 | Iter: 122400 | Total Loss: 0.005357 | Recon Loss: 0.004315 | Commit Loss: 0.002085 | Perplexity: 387.251208
2025-09-28 21:52:25,712 Stage: Train 0.5 | Epoch: 201 | Iter: 122600 | Total Loss: 0.005417 | Recon Loss: 0.004362 | Commit Loss: 0.002110 | Perplexity: 388.341599
2025-09-28 21:55:46,767 Stage: Train 0.5 | Epoch: 201 | Iter: 122800 | Total Loss: 0.005316 | Recon Loss: 0.004274 | Commit Loss: 0.002083 | Perplexity: 386.589409
Trainning Epoch:  25%|██▍       | 202/823 [34:43:43<106:14:38, 615.91s/it]Trainning Epoch:  25%|██▍       | 202/823 [34:43:43<106:14:34, 615.90s/it]Trainning Epoch:  25%|██▍       | 202/823 [34:43:43<106:14:38, 615.91s/it]Trainning Epoch:  25%|██▍       | 202/823 [34:43:43<106:14:38, 615.91s/it]2025-09-28 21:59:12,323 Stage: Train 0.5 | Epoch: 202 | Iter: 123000 | Total Loss: 0.005349 | Recon Loss: 0.004309 | Commit Loss: 0.002082 | Perplexity: 387.252770
2025-09-28 22:02:34,344 Stage: Train 0.5 | Epoch: 202 | Iter: 123200 | Total Loss: 0.005381 | Recon Loss: 0.004340 | Commit Loss: 0.002083 | Perplexity: 387.789725
2025-09-28 22:05:56,409 Stage: Train 0.5 | Epoch: 202 | Iter: 123400 | Total Loss: 0.005343 | Recon Loss: 0.004303 | Commit Loss: 0.002079 | Perplexity: 386.455299
Trainning Epoch:  25%|██▍       | 203/823 [34:54:01<106:10:22, 616.49s/it]Trainning Epoch:  25%|██▍       | 203/823 [34:54:01<106:10:19, 616.48s/it]Trainning Epoch:  25%|██▍       | 203/823 [34:54:01<106:10:25, 616.49s/it]Trainning Epoch:  25%|██▍       | 203/823 [34:54:01<106:10:25, 616.49s/it]2025-09-28 22:09:20,676 Stage: Train 0.5 | Epoch: 203 | Iter: 123600 | Total Loss: 0.005323 | Recon Loss: 0.004282 | Commit Loss: 0.002082 | Perplexity: 387.814476
2025-09-28 22:12:41,567 Stage: Train 0.5 | Epoch: 203 | Iter: 123800 | Total Loss: 0.005355 | Recon Loss: 0.004311 | Commit Loss: 0.002089 | Perplexity: 387.690722
2025-09-28 22:16:01,699 Stage: Train 0.5 | Epoch: 203 | Iter: 124000 | Total Loss: 0.005344 | Recon Loss: 0.004294 | Commit Loss: 0.002100 | Perplexity: 387.482094
Trainning Epoch:  25%|██▍       | 204/823 [35:04:14<105:49:25, 615.45s/it]Trainning Epoch:  25%|██▍       | 204/823 [35:04:14<105:49:23, 615.45s/it]Trainning Epoch:  25%|██▍       | 204/823 [35:04:14<105:49:20, 615.45s/it]Trainning Epoch:  25%|██▍       | 204/823 [35:04:14<105:49:21, 615.45s/it]2025-09-28 22:19:26,024 Stage: Train 0.5 | Epoch: 204 | Iter: 124200 | Total Loss: 0.005329 | Recon Loss: 0.004285 | Commit Loss: 0.002088 | Perplexity: 387.359821
2025-09-28 22:22:48,049 Stage: Train 0.5 | Epoch: 204 | Iter: 124400 | Total Loss: 0.005353 | Recon Loss: 0.004307 | Commit Loss: 0.002092 | Perplexity: 386.721690
2025-09-28 22:26:09,787 Stage: Train 0.5 | Epoch: 204 | Iter: 124600 | Total Loss: 0.005352 | Recon Loss: 0.004301 | Commit Loss: 0.002102 | Perplexity: 387.338174
Trainning Epoch:  25%|██▍       | 205/823 [35:14:30<105:42:10, 615.74s/it]Trainning Epoch:  25%|██▍       | 205/823 [35:14:30<105:42:11, 615.75s/it]Trainning Epoch:  25%|██▍       | 205/823 [35:14:30<105:42:14, 615.75s/it]Trainning Epoch:  25%|██▍       | 205/823 [35:14:30<105:42:11, 615.75s/it]2025-09-28 22:29:34,177 Stage: Train 0.5 | Epoch: 205 | Iter: 124800 | Total Loss: 0.005350 | Recon Loss: 0.004314 | Commit Loss: 0.002072 | Perplexity: 387.118260
2025-09-28 22:32:55,436 Stage: Train 0.5 | Epoch: 205 | Iter: 125000 | Total Loss: 0.005355 | Recon Loss: 0.004311 | Commit Loss: 0.002087 | Perplexity: 388.103550
2025-09-28 22:36:17,834 Stage: Train 0.5 | Epoch: 205 | Iter: 125200 | Total Loss: 0.005366 | Recon Loss: 0.004321 | Commit Loss: 0.002090 | Perplexity: 386.853558
Trainning Epoch:  25%|██▌       | 206/823 [35:24:47<105:33:16, 615.88s/it]Trainning Epoch:  25%|██▌       | 206/823 [35:24:47<105:33:12, 615.87s/it]Trainning Epoch:  25%|██▌       | 206/823 [35:24:47<105:33:15, 615.88s/it]Trainning Epoch:  25%|██▌       | 206/823 [35:24:47<105:33:13, 615.87s/it]2025-09-28 22:39:43,403 Stage: Train 0.5 | Epoch: 206 | Iter: 125400 | Total Loss: 0.005273 | Recon Loss: 0.004240 | Commit Loss: 0.002066 | Perplexity: 386.693063
2025-09-28 22:43:05,127 Stage: Train 0.5 | Epoch: 206 | Iter: 125600 | Total Loss: 0.005337 | Recon Loss: 0.004288 | Commit Loss: 0.002098 | Perplexity: 387.945231
2025-09-28 22:46:27,061 Stage: Train 0.5 | Epoch: 206 | Iter: 125800 | Total Loss: 0.005338 | Recon Loss: 0.004294 | Commit Loss: 0.002088 | Perplexity: 387.534991
Trainning Epoch:  25%|██▌       | 207/823 [35:35:04<105:27:49, 616.35s/it]Trainning Epoch:  25%|██▌       | 207/823 [35:35:04<105:27:57, 616.36s/it]Trainning Epoch:  25%|██▌       | 207/823 [35:35:04<105:27:57, 616.36s/it]Trainning Epoch:  25%|██▌       | 207/823 [35:35:04<105:27:58, 616.36s/it]2025-09-28 22:49:52,625 Stage: Train 0.5 | Epoch: 207 | Iter: 126000 | Total Loss: 0.005308 | Recon Loss: 0.004263 | Commit Loss: 0.002089 | Perplexity: 387.650821
2025-09-28 22:53:14,426 Stage: Train 0.5 | Epoch: 207 | Iter: 126200 | Total Loss: 0.005310 | Recon Loss: 0.004274 | Commit Loss: 0.002071 | Perplexity: 387.163761
2025-09-28 22:56:36,778 Stage: Train 0.5 | Epoch: 207 | Iter: 126400 | Total Loss: 0.005325 | Recon Loss: 0.004276 | Commit Loss: 0.002099 | Perplexity: 387.862510
Trainning Epoch:  25%|██▌       | 208/823 [35:45:21<105:20:41, 616.65s/it]Trainning Epoch:  25%|██▌       | 208/823 [35:45:21<105:20:46, 616.66s/it]Trainning Epoch:  25%|██▌       | 208/823 [35:45:21<105:20:46, 616.66s/it]Trainning Epoch:  25%|██▌       | 208/823 [35:45:21<105:20:52, 616.67s/it]2025-09-28 23:00:01,867 Stage: Train 0.5 | Epoch: 208 | Iter: 126600 | Total Loss: 0.005282 | Recon Loss: 0.004245 | Commit Loss: 0.002073 | Perplexity: 387.813394
2025-09-28 23:03:23,694 Stage: Train 0.5 | Epoch: 208 | Iter: 126800 | Total Loss: 0.005342 | Recon Loss: 0.004293 | Commit Loss: 0.002099 | Perplexity: 387.754785
2025-09-28 23:06:45,348 Stage: Train 0.5 | Epoch: 208 | Iter: 127000 | Total Loss: 0.005314 | Recon Loss: 0.004272 | Commit Loss: 0.002085 | Perplexity: 387.953502
Trainning Epoch:  25%|██▌       | 209/823 [35:55:38<105:10:30, 616.66s/it]Trainning Epoch:  25%|██▌       | 209/823 [35:55:38<105:10:33, 616.67s/it]Trainning Epoch:  25%|██▌       | 209/823 [35:55:38<105:10:29, 616.66s/it]Trainning Epoch:  25%|██▌       | 209/823 [35:55:38<105:10:30, 616.66s/it]2025-09-28 23:10:11,563 Stage: Train 0.5 | Epoch: 209 | Iter: 127200 | Total Loss: 0.005305 | Recon Loss: 0.004262 | Commit Loss: 0.002085 | Perplexity: 387.139892
2025-09-28 23:13:35,481 Stage: Train 0.5 | Epoch: 209 | Iter: 127400 | Total Loss: 0.005354 | Recon Loss: 0.004312 | Commit Loss: 0.002083 | Perplexity: 387.558451
2025-09-28 23:16:59,698 Stage: Train 0.5 | Epoch: 209 | Iter: 127600 | Total Loss: 0.005343 | Recon Loss: 0.004293 | Commit Loss: 0.002101 | Perplexity: 387.358690
Trainning Epoch:  26%|██▌       | 210/823 [36:06:01<105:20:26, 618.64s/it]Trainning Epoch:  26%|██▌       | 210/823 [36:06:01<105:20:29, 618.65s/it]Trainning Epoch:  26%|██▌       | 210/823 [36:06:01<105:20:29, 618.65s/it]Trainning Epoch:  26%|██▌       | 210/823 [36:06:01<105:20:28, 618.64s/it]2025-09-28 23:20:25,412 Stage: Train 0.5 | Epoch: 210 | Iter: 127800 | Total Loss: 0.005289 | Recon Loss: 0.004254 | Commit Loss: 0.002071 | Perplexity: 387.437775
2025-09-28 23:23:46,359 Stage: Train 0.5 | Epoch: 210 | Iter: 128000 | Total Loss: 0.005313 | Recon Loss: 0.004274 | Commit Loss: 0.002078 | Perplexity: 387.753116
2025-09-28 23:27:07,842 Stage: Train 0.5 | Epoch: 210 | Iter: 128200 | Total Loss: 0.005305 | Recon Loss: 0.004262 | Commit Loss: 0.002085 | Perplexity: 386.787759
Trainning Epoch:  26%|██▌       | 211/823 [36:16:17<105:00:57, 617.74s/it]Trainning Epoch:  26%|██▌       | 211/823 [36:16:17<105:00:59, 617.74s/it]Trainning Epoch:  26%|██▌       | 211/823 [36:16:17<105:01:00, 617.75s/it]Trainning Epoch:  26%|██▌       | 211/823 [36:16:17<105:01:02, 617.75s/it]2025-09-28 23:30:32,883 Stage: Train 0.5 | Epoch: 211 | Iter: 128400 | Total Loss: 0.005296 | Recon Loss: 0.004252 | Commit Loss: 0.002087 | Perplexity: 388.058427
2025-09-28 23:33:54,108 Stage: Train 0.5 | Epoch: 211 | Iter: 128600 | Total Loss: 0.005299 | Recon Loss: 0.004255 | Commit Loss: 0.002089 | Perplexity: 387.548271
2025-09-28 23:37:15,222 Stage: Train 0.5 | Epoch: 211 | Iter: 128800 | Total Loss: 0.005317 | Recon Loss: 0.004265 | Commit Loss: 0.002105 | Perplexity: 388.406693
Trainning Epoch:  26%|██▌       | 212/823 [36:26:32<104:41:59, 616.89s/it]Trainning Epoch:  26%|██▌       | 212/823 [36:26:32<104:42:00, 616.89s/it]Trainning Epoch:  26%|██▌       | 212/823 [36:26:32<104:42:02, 616.89s/it]Trainning Epoch:  26%|██▌       | 212/823 [36:26:32<104:42:02, 616.89s/it]2025-09-28 23:40:39,463 Stage: Train 0.5 | Epoch: 212 | Iter: 129000 | Total Loss: 0.005289 | Recon Loss: 0.004254 | Commit Loss: 0.002071 | Perplexity: 388.138143
2025-09-28 23:43:59,459 Stage: Train 0.5 | Epoch: 212 | Iter: 129200 | Total Loss: 0.005277 | Recon Loss: 0.004238 | Commit Loss: 0.002079 | Perplexity: 386.741216
2025-09-28 23:47:19,804 Stage: Train 0.5 | Epoch: 212 | Iter: 129400 | Total Loss: 0.005297 | Recon Loss: 0.004262 | Commit Loss: 0.002069 | Perplexity: 387.318553
Trainning Epoch:  26%|██▌       | 213/823 [36:36:44<104:17:30, 615.49s/it]Trainning Epoch:  26%|██▌       | 213/823 [36:36:44<104:17:30, 615.49s/it]Trainning Epoch:  26%|██▌       | 213/823 [36:36:44<104:17:31, 615.49s/it]Trainning Epoch:  26%|██▌       | 213/823 [36:36:44<104:17:31, 615.49s/it]2025-09-28 23:50:44,484 Stage: Train 0.5 | Epoch: 213 | Iter: 129600 | Total Loss: 0.005277 | Recon Loss: 0.004237 | Commit Loss: 0.002079 | Perplexity: 388.225580
2025-09-28 23:54:06,666 Stage: Train 0.5 | Epoch: 213 | Iter: 129800 | Total Loss: 0.005288 | Recon Loss: 0.004251 | Commit Loss: 0.002074 | Perplexity: 387.763602
2025-09-28 23:57:28,906 Stage: Train 0.5 | Epoch: 213 | Iter: 130000 | Total Loss: 0.005275 | Recon Loss: 0.004242 | Commit Loss: 0.002068 | Perplexity: 387.823880
Trainning Epoch:  26%|██▌       | 214/823 [36:47:02<104:14:49, 616.24s/it]Trainning Epoch:  26%|██▌       | 214/823 [36:47:02<104:14:51, 616.24s/it]Trainning Epoch:  26%|██▌       | 214/823 [36:47:02<104:14:54, 616.25s/it]Trainning Epoch:  26%|██▌       | 214/823 [36:47:02<104:14:54, 616.25s/it]2025-09-29 00:00:54,370 Stage: Train 0.5 | Epoch: 214 | Iter: 130200 | Total Loss: 0.005284 | Recon Loss: 0.004243 | Commit Loss: 0.002083 | Perplexity: 389.180224
2025-09-29 00:04:16,084 Stage: Train 0.5 | Epoch: 214 | Iter: 130400 | Total Loss: 0.005274 | Recon Loss: 0.004237 | Commit Loss: 0.002074 | Perplexity: 387.922159
2025-09-29 00:07:38,424 Stage: Train 0.5 | Epoch: 214 | Iter: 130600 | Total Loss: 0.005293 | Recon Loss: 0.004251 | Commit Loss: 0.002085 | Perplexity: 388.962855
Trainning Epoch:  26%|██▌       | 215/823 [36:57:20<104:10:40, 616.84s/it]Trainning Epoch:  26%|██▌       | 215/823 [36:57:20<104:10:45, 616.85s/it]Trainning Epoch:  26%|██▌       | 215/823 [36:57:20<104:10:44, 616.85s/it]Trainning Epoch:  26%|██▌       | 215/823 [36:57:20<104:10:46, 616.85s/it]2025-09-29 00:11:04,533 Stage: Train 0.5 | Epoch: 215 | Iter: 130800 | Total Loss: 0.005316 | Recon Loss: 0.004273 | Commit Loss: 0.002085 | Perplexity: 387.554774
2025-09-29 00:14:26,670 Stage: Train 0.5 | Epoch: 215 | Iter: 131000 | Total Loss: 0.005234 | Recon Loss: 0.004201 | Commit Loss: 0.002066 | Perplexity: 386.984677
2025-09-29 00:17:49,809 Stage: Train 0.5 | Epoch: 215 | Iter: 131200 | Total Loss: 0.005269 | Recon Loss: 0.004233 | Commit Loss: 0.002072 | Perplexity: 387.914248
Trainning Epoch:  26%|██▌       | 216/823 [37:07:40<104:07:38, 617.56s/it]Trainning Epoch:  26%|██▌       | 216/823 [37:07:40<104:07:40, 617.56s/it]Trainning Epoch:  26%|██▌       | 216/823 [37:07:40<104:07:40, 617.56s/it]Trainning Epoch:  26%|██▌       | 216/823 [37:07:40<104:07:40, 617.56s/it]2025-09-29 00:21:15,430 Stage: Train 0.5 | Epoch: 216 | Iter: 131400 | Total Loss: 0.005238 | Recon Loss: 0.004200 | Commit Loss: 0.002077 | Perplexity: 388.098017
2025-09-29 00:24:36,333 Stage: Train 0.5 | Epoch: 216 | Iter: 131600 | Total Loss: 0.005266 | Recon Loss: 0.004233 | Commit Loss: 0.002066 | Perplexity: 388.832442
2025-09-29 00:27:56,977 Stage: Train 0.5 | Epoch: 216 | Iter: 131800 | Total Loss: 0.005253 | Recon Loss: 0.004213 | Commit Loss: 0.002081 | Perplexity: 388.035547
Trainning Epoch:  26%|██▋       | 217/823 [37:17:54<103:47:21, 616.57s/it]Trainning Epoch:  26%|██▋       | 217/823 [37:17:54<103:47:19, 616.57s/it]Trainning Epoch:  26%|██▋       | 217/823 [37:17:54<103:47:20, 616.57s/it]Trainning Epoch:  26%|██▋       | 217/823 [37:17:54<103:47:20, 616.57s/it]2025-09-29 00:31:21,389 Stage: Train 0.5 | Epoch: 217 | Iter: 132000 | Total Loss: 0.005245 | Recon Loss: 0.004212 | Commit Loss: 0.002065 | Perplexity: 387.294748
2025-09-29 00:34:42,810 Stage: Train 0.5 | Epoch: 217 | Iter: 132200 | Total Loss: 0.005285 | Recon Loss: 0.004241 | Commit Loss: 0.002088 | Perplexity: 388.380675
2025-09-29 00:38:04,456 Stage: Train 0.5 | Epoch: 217 | Iter: 132400 | Total Loss: 0.005224 | Recon Loss: 0.004196 | Commit Loss: 0.002056 | Perplexity: 386.762969
Trainning Epoch:  26%|██▋       | 218/823 [37:28:10<103:34:54, 616.35s/it]Trainning Epoch:  26%|██▋       | 218/823 [37:28:10<103:34:57, 616.36s/it]Trainning Epoch:  26%|██▋       | 218/823 [37:28:10<103:34:57, 616.36s/it]Trainning Epoch:  26%|██▋       | 218/823 [37:28:10<103:34:59, 616.36s/it]2025-09-29 00:41:29,744 Stage: Train 0.5 | Epoch: 218 | Iter: 132600 | Total Loss: 0.005239 | Recon Loss: 0.004207 | Commit Loss: 0.002064 | Perplexity: 388.646580
2025-09-29 00:44:51,539 Stage: Train 0.5 | Epoch: 218 | Iter: 132800 | Total Loss: 0.005240 | Recon Loss: 0.004204 | Commit Loss: 0.002072 | Perplexity: 387.359586
2025-09-29 00:48:13,836 Stage: Train 0.5 | Epoch: 218 | Iter: 133000 | Total Loss: 0.005300 | Recon Loss: 0.004260 | Commit Loss: 0.002079 | Perplexity: 388.211309
Trainning Epoch:  27%|██▋       | 219/823 [37:38:28<103:30:31, 616.94s/it]Trainning Epoch:  27%|██▋       | 219/823 [37:38:28<103:30:33, 616.94s/it]Trainning Epoch:  27%|██▋       | 219/823 [37:38:28<103:30:33, 616.94s/it]Trainning Epoch:  27%|██▋       | 219/823 [37:38:28<103:30:34, 616.95s/it]2025-09-29 00:51:39,642 Stage: Train 0.5 | Epoch: 219 | Iter: 133200 | Total Loss: 0.005238 | Recon Loss: 0.004207 | Commit Loss: 0.002063 | Perplexity: 388.123911
2025-09-29 00:55:00,740 Stage: Train 0.5 | Epoch: 219 | Iter: 133400 | Total Loss: 0.005227 | Recon Loss: 0.004194 | Commit Loss: 0.002067 | Perplexity: 388.319415
2025-09-29 00:58:22,120 Stage: Train 0.5 | Epoch: 219 | Iter: 133600 | Total Loss: 0.005279 | Recon Loss: 0.004242 | Commit Loss: 0.002073 | Perplexity: 388.467405
Trainning Epoch:  27%|██▋       | 220/823 [37:48:43<103:14:27, 616.36s/it]Trainning Epoch:  27%|██▋       | 220/823 [37:48:43<103:14:24, 616.36s/it]Trainning Epoch:  27%|██▋       | 220/823 [37:48:43<103:14:26, 616.36s/it]Trainning Epoch:  27%|██▋       | 220/823 [37:48:43<103:14:26, 616.36s/it]2025-09-29 01:01:46,417 Stage: Train 0.5 | Epoch: 220 | Iter: 133800 | Total Loss: 0.005197 | Recon Loss: 0.004163 | Commit Loss: 0.002069 | Perplexity: 388.021513
2025-09-29 01:05:07,749 Stage: Train 0.5 | Epoch: 220 | Iter: 134000 | Total Loss: 0.005210 | Recon Loss: 0.004180 | Commit Loss: 0.002061 | Perplexity: 387.537868
2025-09-29 01:08:30,540 Stage: Train 0.5 | Epoch: 220 | Iter: 134200 | Total Loss: 0.005271 | Recon Loss: 0.004233 | Commit Loss: 0.002077 | Perplexity: 389.498406
Trainning Epoch:  27%|██▋       | 221/823 [37:59:01<103:07:21, 616.68s/it]Trainning Epoch:  27%|██▋       | 221/823 [37:59:01<103:07:23, 616.68s/it]Trainning Epoch:  27%|██▋       | 221/823 [37:59:01<103:07:23, 616.68s/it]Trainning Epoch:  27%|██▋       | 221/823 [37:59:01<103:07:24, 616.69s/it]2025-09-29 01:11:56,620 Stage: Train 0.5 | Epoch: 221 | Iter: 134400 | Total Loss: 0.005231 | Recon Loss: 0.004184 | Commit Loss: 0.002094 | Perplexity: 388.633898
2025-09-29 01:15:18,213 Stage: Train 0.5 | Epoch: 221 | Iter: 134600 | Total Loss: 0.005197 | Recon Loss: 0.004167 | Commit Loss: 0.002060 | Perplexity: 387.723817
2025-09-29 01:18:40,826 Stage: Train 0.5 | Epoch: 221 | Iter: 134800 | Total Loss: 0.005177 | Recon Loss: 0.004152 | Commit Loss: 0.002050 | Perplexity: 387.566285
Trainning Epoch:  27%|██▋       | 222/823 [38:09:19<103:02:40, 617.24s/it]Trainning Epoch:  27%|██▋       | 222/823 [38:09:19<103:02:44, 617.25s/it]Trainning Epoch:  27%|██▋       | 222/823 [38:09:19<103:02:41, 617.24s/it]Trainning Epoch:  27%|██▋       | 222/823 [38:09:19<103:02:43, 617.24s/it]2025-09-29 01:22:07,504 Stage: Train 0.5 | Epoch: 222 | Iter: 135000 | Total Loss: 0.005252 | Recon Loss: 0.004214 | Commit Loss: 0.002075 | Perplexity: 388.281409
2025-09-29 01:25:32,357 Stage: Train 0.5 | Epoch: 222 | Iter: 135200 | Total Loss: 0.005273 | Recon Loss: 0.004244 | Commit Loss: 0.002059 | Perplexity: 388.470372
2025-09-29 01:28:56,478 Stage: Train 0.5 | Epoch: 222 | Iter: 135400 | Total Loss: 0.005216 | Recon Loss: 0.004182 | Commit Loss: 0.002068 | Perplexity: 389.246713
Trainning Epoch:  27%|██▋       | 223/823 [38:19:45<103:18:47, 619.88s/it]Trainning Epoch:  27%|██▋       | 223/823 [38:19:45<103:18:50, 619.88s/it]Trainning Epoch:  27%|██▋       | 223/823 [38:19:45<103:18:50, 619.88s/it]Trainning Epoch:  27%|██▋       | 223/823 [38:19:45<103:18:50, 619.88s/it]2025-09-29 01:32:24,203 Stage: Train 0.5 | Epoch: 223 | Iter: 135600 | Total Loss: 0.005215 | Recon Loss: 0.004188 | Commit Loss: 0.002055 | Perplexity: 389.577841
2025-09-29 01:35:44,534 Stage: Train 0.5 | Epoch: 223 | Iter: 135800 | Total Loss: 0.005181 | Recon Loss: 0.004152 | Commit Loss: 0.002059 | Perplexity: 389.655682
2025-09-29 01:39:05,498 Stage: Train 0.5 | Epoch: 223 | Iter: 136000 | Total Loss: 0.005202 | Recon Loss: 0.004177 | Commit Loss: 0.002051 | Perplexity: 389.132949
Trainning Epoch:  27%|██▋       | 224/823 [38:29:59<102:51:54, 618.22s/it]Trainning Epoch:  27%|██▋       | 224/823 [38:29:59<102:51:51, 618.22s/it]Trainning Epoch:  27%|██▋       | 224/823 [38:29:59<102:51:53, 618.22s/it]Trainning Epoch:  27%|██▋       | 224/823 [38:29:59<102:51:55, 618.22s/it]2025-09-29 01:42:31,153 Stage: Train 0.5 | Epoch: 224 | Iter: 136200 | Total Loss: 0.005246 | Recon Loss: 0.004214 | Commit Loss: 0.002064 | Perplexity: 389.587653
2025-09-29 01:45:53,720 Stage: Train 0.5 | Epoch: 224 | Iter: 136400 | Total Loss: 0.005188 | Recon Loss: 0.004157 | Commit Loss: 0.002063 | Perplexity: 389.376760
2025-09-29 01:49:16,553 Stage: Train 0.5 | Epoch: 224 | Iter: 136600 | Total Loss: 0.005236 | Recon Loss: 0.004203 | Commit Loss: 0.002066 | Perplexity: 389.111151
2025-09-29 01:52:39,044 Stage: Train 0.5 | Epoch: 224 | Iter: 136800 | Total Loss: 0.005211 | Recon Loss: 0.004178 | Commit Loss: 0.002065 | Perplexity: 389.381116
Trainning Epoch:  27%|██▋       | 225/823 [38:40:19<102:46:36, 618.72s/it]Trainning Epoch:  27%|██▋       | 225/823 [38:40:19<102:46:39, 618.73s/it]Trainning Epoch:  27%|██▋       | 225/823 [38:40:19<102:46:36, 618.72s/it]Trainning Epoch:  27%|██▋       | 225/823 [38:40:19<102:46:37, 618.73s/it]2025-09-29 01:56:04,251 Stage: Train 0.5 | Epoch: 225 | Iter: 137000 | Total Loss: 0.005154 | Recon Loss: 0.004137 | Commit Loss: 0.002035 | Perplexity: 389.580580
2025-09-29 01:59:26,463 Stage: Train 0.5 | Epoch: 225 | Iter: 137200 | Total Loss: 0.005152 | Recon Loss: 0.004129 | Commit Loss: 0.002046 | Perplexity: 389.374068
2025-09-29 02:02:48,698 Stage: Train 0.5 | Epoch: 225 | Iter: 137400 | Total Loss: 0.005189 | Recon Loss: 0.004161 | Commit Loss: 0.002057 | Perplexity: 390.026125
Trainning Epoch:  27%|██▋       | 226/823 [38:50:37<102:33:24, 618.43s/it]Trainning Epoch:  27%|██▋       | 226/823 [38:50:37<102:33:27, 618.44s/it]Trainning Epoch:  27%|██▋       | 226/823 [38:50:37<102:33:27, 618.44s/it]Trainning Epoch:  27%|██▋       | 226/823 [38:50:37<102:33:29, 618.44s/it]2025-09-29 02:06:13,954 Stage: Train 0.5 | Epoch: 226 | Iter: 137600 | Total Loss: 0.005165 | Recon Loss: 0.004143 | Commit Loss: 0.002044 | Perplexity: 388.965471
2025-09-29 02:09:35,449 Stage: Train 0.5 | Epoch: 226 | Iter: 137800 | Total Loss: 0.005177 | Recon Loss: 0.004143 | Commit Loss: 0.002068 | Perplexity: 390.071354
2025-09-29 02:12:57,129 Stage: Train 0.5 | Epoch: 226 | Iter: 138000 | Total Loss: 0.005211 | Recon Loss: 0.004181 | Commit Loss: 0.002059 | Perplexity: 389.096040
Trainning Epoch:  28%|██▊       | 227/823 [39:00:53<102:16:58, 617.82s/it]Trainning Epoch:  28%|██▊       | 227/823 [39:00:54<102:17:00, 617.82s/it]Trainning Epoch:  28%|██▊       | 227/823 [39:00:54<102:17:00, 617.82s/it]Trainning Epoch:  28%|██▊       | 227/823 [39:00:53<102:16:59, 617.82s/it]2025-09-29 02:16:22,730 Stage: Train 0.5 | Epoch: 227 | Iter: 138200 | Total Loss: 0.005134 | Recon Loss: 0.004115 | Commit Loss: 0.002038 | Perplexity: 389.355342
2025-09-29 02:19:44,597 Stage: Train 0.5 | Epoch: 227 | Iter: 138400 | Total Loss: 0.005138 | Recon Loss: 0.004118 | Commit Loss: 0.002039 | Perplexity: 390.137932
2025-09-29 02:23:06,564 Stage: Train 0.5 | Epoch: 227 | Iter: 138600 | Total Loss: 0.005211 | Recon Loss: 0.004180 | Commit Loss: 0.002062 | Perplexity: 390.263245
Trainning Epoch:  28%|██▊       | 228/823 [39:11:11<102:05:57, 617.74s/it]Trainning Epoch:  28%|██▊       | 228/823 [39:11:11<102:05:52, 617.74s/it]Trainning Epoch:  28%|██▊       | 228/823 [39:11:11<102:05:56, 617.74s/it]Trainning Epoch:  28%|██▊       | 228/823 [39:11:11<102:05:57, 617.74s/it]2025-09-29 02:26:32,882 Stage: Train 0.5 | Epoch: 228 | Iter: 138800 | Total Loss: 0.005192 | Recon Loss: 0.004163 | Commit Loss: 0.002058 | Perplexity: 390.152275
2025-09-29 02:29:55,989 Stage: Train 0.5 | Epoch: 228 | Iter: 139000 | Total Loss: 0.005161 | Recon Loss: 0.004129 | Commit Loss: 0.002064 | Perplexity: 390.771434
2025-09-29 02:33:18,808 Stage: Train 0.5 | Epoch: 228 | Iter: 139200 | Total Loss: 0.005181 | Recon Loss: 0.004151 | Commit Loss: 0.002058 | Perplexity: 389.362687
Trainning Epoch:  28%|██▊       | 229/823 [39:21:32<102:04:11, 618.61s/it]Trainning Epoch:  28%|██▊       | 229/823 [39:21:32<102:04:15, 618.61s/it]Trainning Epoch:  28%|██▊       | 229/823 [39:21:32<102:04:11, 618.61s/it]Trainning Epoch:  28%|██▊       | 229/823 [39:21:32<102:04:12, 618.61s/it]2025-09-29 02:36:43,658 Stage: Train 0.5 | Epoch: 229 | Iter: 139400 | Total Loss: 0.005146 | Recon Loss: 0.004127 | Commit Loss: 0.002038 | Perplexity: 389.658448
2025-09-29 02:40:04,910 Stage: Train 0.5 | Epoch: 229 | Iter: 139600 | Total Loss: 0.005182 | Recon Loss: 0.004148 | Commit Loss: 0.002067 | Perplexity: 390.275222
2025-09-29 02:43:26,832 Stage: Train 0.5 | Epoch: 229 | Iter: 139800 | Total Loss: 0.005181 | Recon Loss: 0.004166 | Commit Loss: 0.002029 | Perplexity: 389.880014
Trainning Epoch:  28%|██▊       | 230/823 [39:31:47<101:45:36, 617.77s/it]Trainning Epoch:  28%|██▊       | 230/823 [39:31:47<101:45:34, 617.76s/it]Trainning Epoch:  28%|██▊       | 230/823 [39:31:48<101:45:38, 617.77s/it]Trainning Epoch:  28%|██▊       | 230/823 [39:31:47<101:45:38, 617.77s/it]2025-09-29 02:46:53,140 Stage: Train 0.5 | Epoch: 230 | Iter: 140000 | Total Loss: 0.005125 | Recon Loss: 0.004103 | Commit Loss: 0.002044 | Perplexity: 389.724715
2025-09-29 02:46:53,140 Saving model at iteration 140000
2025-09-29 02:46:53,439 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_231_step_140000
2025-09-29 02:46:54,049 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_231_step_140000/model.safetensors
2025-09-29 02:46:54,632 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_231_step_140000/optimizer.bin
2025-09-29 02:46:54,633 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_231_step_140000/scheduler.bin
2025-09-29 02:46:54,633 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_231_step_140000/sampler.bin
2025-09-29 02:46:54,634 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_231_step_140000/random_states_0.pkl
2025-09-29 02:50:17,656 Stage: Train 0.5 | Epoch: 230 | Iter: 140200 | Total Loss: 0.005171 | Recon Loss: 0.004140 | Commit Loss: 0.002061 | Perplexity: 391.005856
2025-09-29 02:53:40,640 Stage: Train 0.5 | Epoch: 230 | Iter: 140400 | Total Loss: 0.005163 | Recon Loss: 0.004143 | Commit Loss: 0.002041 | Perplexity: 389.989726
Trainning Epoch:  28%|██▊       | 231/823 [39:42:10<101:48:34, 619.11s/it]Trainning Epoch:  28%|██▊       | 231/823 [39:42:10<101:48:36, 619.12s/it]Trainning Epoch:  28%|██▊       | 231/823 [39:42:10<101:48:37, 619.12s/it]Trainning Epoch:  28%|██▊       | 231/823 [39:42:10<101:48:36, 619.12s/it]2025-09-29 02:57:06,601 Stage: Train 0.5 | Epoch: 231 | Iter: 140600 | Total Loss: 0.005170 | Recon Loss: 0.004143 | Commit Loss: 0.002054 | Perplexity: 390.357302
2025-09-29 03:00:28,502 Stage: Train 0.5 | Epoch: 231 | Iter: 140800 | Total Loss: 0.005141 | Recon Loss: 0.004119 | Commit Loss: 0.002044 | Perplexity: 389.697486
2025-09-29 03:03:50,230 Stage: Train 0.5 | Epoch: 231 | Iter: 141000 | Total Loss: 0.005127 | Recon Loss: 0.004112 | Commit Loss: 0.002031 | Perplexity: 389.712205
Trainning Epoch:  28%|██▊       | 232/823 [39:52:27<101:33:00, 618.58s/it]Trainning Epoch:  28%|██▊       | 232/823 [39:52:27<101:33:01, 618.58s/it]Trainning Epoch:  28%|██▊       | 232/823 [39:52:27<101:33:01, 618.58s/it]Trainning Epoch:  28%|██▊       | 232/823 [39:52:27<101:33:02, 618.58s/it]2025-09-29 03:07:15,947 Stage: Train 0.5 | Epoch: 232 | Iter: 141200 | Total Loss: 0.005164 | Recon Loss: 0.004145 | Commit Loss: 0.002039 | Perplexity: 390.391065
2025-09-29 03:10:38,764 Stage: Train 0.5 | Epoch: 232 | Iter: 141400 | Total Loss: 0.005162 | Recon Loss: 0.004141 | Commit Loss: 0.002042 | Perplexity: 391.102873
2025-09-29 03:14:01,661 Stage: Train 0.5 | Epoch: 232 | Iter: 141600 | Total Loss: 0.005133 | Recon Loss: 0.004108 | Commit Loss: 0.002049 | Perplexity: 389.989187
Trainning Epoch:  28%|██▊       | 233/823 [40:02:47<101:26:08, 618.93s/it]Trainning Epoch:  28%|██▊       | 233/823 [40:02:47<101:26:10, 618.93s/it]Trainning Epoch:  28%|██▊       | 233/823 [40:02:47<101:26:11, 618.93s/it]Trainning Epoch:  28%|██▊       | 233/823 [40:02:47<101:26:11, 618.93s/it]2025-09-29 03:17:27,217 Stage: Train 0.5 | Epoch: 233 | Iter: 141800 | Total Loss: 0.005140 | Recon Loss: 0.004110 | Commit Loss: 0.002061 | Perplexity: 390.859312
2025-09-29 03:20:49,393 Stage: Train 0.5 | Epoch: 233 | Iter: 142000 | Total Loss: 0.005142 | Recon Loss: 0.004123 | Commit Loss: 0.002038 | Perplexity: 389.981465
2025-09-29 03:24:11,715 Stage: Train 0.5 | Epoch: 233 | Iter: 142200 | Total Loss: 0.005145 | Recon Loss: 0.004115 | Commit Loss: 0.002060 | Perplexity: 390.456570
Trainning Epoch:  28%|██▊       | 234/823 [40:13:05<101:12:42, 618.61s/it]Trainning Epoch:  28%|██▊       | 234/823 [40:13:05<101:12:37, 618.60s/it]Trainning Epoch:  28%|██▊       | 234/823 [40:13:05<101:12:42, 618.61s/it]Trainning Epoch:  28%|██▊       | 234/823 [40:13:05<101:12:42, 618.61s/it]2025-09-29 03:27:37,019 Stage: Train 0.5 | Epoch: 234 | Iter: 142400 | Total Loss: 0.005149 | Recon Loss: 0.004131 | Commit Loss: 0.002037 | Perplexity: 389.885446
2025-09-29 03:30:59,748 Stage: Train 0.5 | Epoch: 234 | Iter: 142600 | Total Loss: 0.005125 | Recon Loss: 0.004101 | Commit Loss: 0.002047 | Perplexity: 389.315367
2025-09-29 03:34:22,508 Stage: Train 0.5 | Epoch: 234 | Iter: 142800 | Total Loss: 0.005115 | Recon Loss: 0.004094 | Commit Loss: 0.002042 | Perplexity: 389.749067
Trainning Epoch:  29%|██▊       | 235/823 [40:23:24<101:04:24, 618.82s/it]Trainning Epoch:  29%|██▊       | 235/823 [40:23:24<101:04:26, 618.82s/it]Trainning Epoch:  29%|██▊       | 235/823 [40:23:24<101:04:26, 618.82s/it]Trainning Epoch:  29%|██▊       | 235/823 [40:23:24<101:04:27, 618.82s/it]2025-09-29 03:37:48,953 Stage: Train 0.5 | Epoch: 235 | Iter: 143000 | Total Loss: 0.005119 | Recon Loss: 0.004100 | Commit Loss: 0.002036 | Perplexity: 390.011511
2025-09-29 03:41:11,801 Stage: Train 0.5 | Epoch: 235 | Iter: 143200 | Total Loss: 0.005117 | Recon Loss: 0.004110 | Commit Loss: 0.002015 | Perplexity: 390.279873
2025-09-29 03:44:34,795 Stage: Train 0.5 | Epoch: 235 | Iter: 143400 | Total Loss: 0.005137 | Recon Loss: 0.004106 | Commit Loss: 0.002062 | Perplexity: 390.669852
Trainning Epoch:  29%|██▊       | 236/823 [40:33:44<100:58:48, 619.30s/it]Trainning Epoch:  29%|██▊       | 236/823 [40:33:44<100:58:44, 619.29s/it]Trainning Epoch:  29%|██▊       | 236/823 [40:33:44<100:58:44, 619.29s/it]Trainning Epoch:  29%|██▊       | 236/823 [40:33:44<100:58:44, 619.29s/it]2025-09-29 03:48:01,341 Stage: Train 0.5 | Epoch: 236 | Iter: 143600 | Total Loss: 0.005163 | Recon Loss: 0.004143 | Commit Loss: 0.002040 | Perplexity: 390.646263
2025-09-29 03:51:25,425 Stage: Train 0.5 | Epoch: 236 | Iter: 143800 | Total Loss: 0.005119 | Recon Loss: 0.004097 | Commit Loss: 0.002044 | Perplexity: 390.207619
2025-09-29 03:54:49,185 Stage: Train 0.5 | Epoch: 236 | Iter: 144000 | Total Loss: 0.005137 | Recon Loss: 0.004120 | Commit Loss: 0.002035 | Perplexity: 389.639960
Trainning Epoch:  29%|██▉       | 237/823 [40:44:07<100:58:11, 620.29s/it]Trainning Epoch:  29%|██▉       | 237/823 [40:44:07<100:58:15, 620.30s/it]Trainning Epoch:  29%|██▉       | 237/823 [40:44:07<100:58:11, 620.29s/it]Trainning Epoch:  29%|██▉       | 237/823 [40:44:07<100:58:11, 620.29s/it]2025-09-29 03:58:15,348 Stage: Train 0.5 | Epoch: 237 | Iter: 144200 | Total Loss: 0.005109 | Recon Loss: 0.004092 | Commit Loss: 0.002034 | Perplexity: 389.777625
2025-09-29 04:01:37,721 Stage: Train 0.5 | Epoch: 237 | Iter: 144400 | Total Loss: 0.005127 | Recon Loss: 0.004109 | Commit Loss: 0.002036 | Perplexity: 390.054501
2025-09-29 04:05:00,640 Stage: Train 0.5 | Epoch: 237 | Iter: 144600 | Total Loss: 0.005088 | Recon Loss: 0.004074 | Commit Loss: 0.002027 | Perplexity: 389.156336
Trainning Epoch:  29%|██▉       | 238/823 [40:54:26<100:45:01, 620.00s/it]Trainning Epoch:  29%|██▉       | 238/823 [40:54:26<100:45:04, 620.01s/it]Trainning Epoch:  29%|██▉       | 238/823 [40:54:26<100:45:04, 620.01s/it]Trainning Epoch:  29%|██▉       | 238/823 [40:54:26<100:45:05, 620.01s/it]2025-09-29 04:08:26,722 Stage: Train 0.5 | Epoch: 238 | Iter: 144800 | Total Loss: 0.005130 | Recon Loss: 0.004105 | Commit Loss: 0.002048 | Perplexity: 390.800791
2025-09-29 04:11:49,266 Stage: Train 0.5 | Epoch: 238 | Iter: 145000 | Total Loss: 0.005097 | Recon Loss: 0.004080 | Commit Loss: 0.002034 | Perplexity: 389.953714
2025-09-29 04:15:12,112 Stage: Train 0.5 | Epoch: 238 | Iter: 145200 | Total Loss: 0.005128 | Recon Loss: 0.004107 | Commit Loss: 0.002042 | Perplexity: 390.415523
Trainning Epoch:  29%|██▉       | 239/823 [41:04:46<100:33:08, 619.84s/it]Trainning Epoch:  29%|██▉       | 239/823 [41:04:46<100:33:09, 619.84s/it]Trainning Epoch:  29%|██▉       | 239/823 [41:04:46<100:33:12, 619.85s/it]Trainning Epoch:  29%|██▉       | 239/823 [41:04:46<100:33:10, 619.85s/it]2025-09-29 04:18:37,155 Stage: Train 0.5 | Epoch: 239 | Iter: 145400 | Total Loss: 0.005146 | Recon Loss: 0.004126 | Commit Loss: 0.002040 | Perplexity: 390.639132
2025-09-29 04:21:57,204 Stage: Train 0.5 | Epoch: 239 | Iter: 145600 | Total Loss: 0.005090 | Recon Loss: 0.004078 | Commit Loss: 0.002024 | Perplexity: 389.726452
2025-09-29 04:25:17,997 Stage: Train 0.5 | Epoch: 239 | Iter: 145800 | Total Loss: 0.005143 | Recon Loss: 0.004122 | Commit Loss: 0.002041 | Perplexity: 391.638907
Trainning Epoch:  29%|██▉       | 240/823 [41:14:59<100:03:18, 617.84s/it]Trainning Epoch:  29%|██▉       | 240/823 [41:14:59<100:03:16, 617.83s/it]Trainning Epoch:  29%|██▉       | 240/823 [41:14:59<100:03:16, 617.83s/it]Trainning Epoch:  29%|██▉       | 240/823 [41:14:59<100:03:17, 617.83s/it]2025-09-29 04:28:43,509 Stage: Train 0.5 | Epoch: 240 | Iter: 146000 | Total Loss: 0.005070 | Recon Loss: 0.004047 | Commit Loss: 0.002045 | Perplexity: 390.913549
2025-09-29 04:32:07,459 Stage: Train 0.5 | Epoch: 240 | Iter: 146200 | Total Loss: 0.005099 | Recon Loss: 0.004088 | Commit Loss: 0.002021 | Perplexity: 391.059735
2025-09-29 04:35:31,289 Stage: Train 0.5 | Epoch: 240 | Iter: 146400 | Total Loss: 0.005163 | Recon Loss: 0.004139 | Commit Loss: 0.002049 | Perplexity: 390.521448
Trainning Epoch:  29%|██▉       | 241/823 [41:25:22<100:08:10, 619.40s/it]Trainning Epoch:  29%|██▉       | 241/823 [41:25:22<100:08:09, 619.40s/it]Trainning Epoch:  29%|██▉       | 241/823 [41:25:22<100:08:10, 619.40s/it]Trainning Epoch:  29%|██▉       | 241/823 [41:25:22<100:08:12, 619.40s/it]2025-09-29 04:38:58,840 Stage: Train 0.5 | Epoch: 241 | Iter: 146600 | Total Loss: 0.005083 | Recon Loss: 0.004065 | Commit Loss: 0.002037 | Perplexity: 390.192085
2025-09-29 04:42:22,769 Stage: Train 0.5 | Epoch: 241 | Iter: 146800 | Total Loss: 0.005148 | Recon Loss: 0.004122 | Commit Loss: 0.002052 | Perplexity: 391.909347
2025-09-29 04:45:46,113 Stage: Train 0.5 | Epoch: 241 | Iter: 147000 | Total Loss: 0.005089 | Recon Loss: 0.004080 | Commit Loss: 0.002018 | Perplexity: 389.734011
Trainning Epoch:  29%|██▉       | 242/823 [41:35:45<100:06:59, 620.34s/it]Trainning Epoch:  29%|██▉       | 242/823 [41:35:45<100:07:03, 620.35s/it]Trainning Epoch:  29%|██▉       | 242/823 [41:35:45<100:07:04, 620.35s/it]Trainning Epoch:  29%|██▉       | 242/823 [41:35:45<100:07:03, 620.35s/it]2025-09-29 04:49:12,409 Stage: Train 0.5 | Epoch: 242 | Iter: 147200 | Total Loss: 0.005139 | Recon Loss: 0.004108 | Commit Loss: 0.002062 | Perplexity: 390.992638
2025-09-29 04:52:33,712 Stage: Train 0.5 | Epoch: 242 | Iter: 147400 | Total Loss: 0.005089 | Recon Loss: 0.004069 | Commit Loss: 0.002040 | Perplexity: 391.282807
2025-09-29 04:55:55,254 Stage: Train 0.5 | Epoch: 242 | Iter: 147600 | Total Loss: 0.005097 | Recon Loss: 0.004075 | Commit Loss: 0.002043 | Perplexity: 390.392671
Trainning Epoch:  30%|██▉       | 243/823 [41:46:01<99:46:11, 619.26s/it] Trainning Epoch:  30%|██▉       | 243/823 [41:46:01<99:46:16, 619.27s/it] Trainning Epoch:  30%|██▉       | 243/823 [41:46:01<99:46:13, 619.26s/it] Trainning Epoch:  30%|██▉       | 243/823 [41:46:01<99:46:13, 619.27s/it] 2025-09-29 04:59:21,018 Stage: Train 0.5 | Epoch: 243 | Iter: 147800 | Total Loss: 0.005091 | Recon Loss: 0.004078 | Commit Loss: 0.002026 | Perplexity: 391.049917
2025-09-29 05:02:42,008 Stage: Train 0.5 | Epoch: 243 | Iter: 148000 | Total Loss: 0.005087 | Recon Loss: 0.004072 | Commit Loss: 0.002030 | Perplexity: 390.822630
2025-09-29 05:06:03,151 Stage: Train 0.5 | Epoch: 243 | Iter: 148200 | Total Loss: 0.005093 | Recon Loss: 0.004074 | Commit Loss: 0.002038 | Perplexity: 390.841277
Trainning Epoch:  30%|██▉       | 244/823 [41:56:17<99:24:59, 618.13s/it]Trainning Epoch:  30%|██▉       | 244/823 [41:56:17<99:25:00, 618.14s/it]Trainning Epoch:  30%|██▉       | 244/823 [41:56:17<99:24:59, 618.13s/it]Trainning Epoch:  30%|██▉       | 244/823 [41:56:17<99:25:00, 618.14s/it]2025-09-29 05:09:28,413 Stage: Train 0.5 | Epoch: 244 | Iter: 148400 | Total Loss: 0.005119 | Recon Loss: 0.004096 | Commit Loss: 0.002047 | Perplexity: 391.673125
2025-09-29 05:12:50,452 Stage: Train 0.5 | Epoch: 244 | Iter: 148600 | Total Loss: 0.005046 | Recon Loss: 0.004031 | Commit Loss: 0.002030 | Perplexity: 390.438630
2025-09-29 05:16:12,321 Stage: Train 0.5 | Epoch: 244 | Iter: 148800 | Total Loss: 0.005096 | Recon Loss: 0.004078 | Commit Loss: 0.002037 | Perplexity: 391.760304
Trainning Epoch:  30%|██▉       | 245/823 [42:06:34<99:12:04, 617.86s/it]Trainning Epoch:  30%|██▉       | 245/823 [42:06:34<99:12:07, 617.87s/it]Trainning Epoch:  30%|██▉       | 245/823 [42:06:34<99:12:08, 617.87s/it]Trainning Epoch:  30%|██▉       | 245/823 [42:06:34<99:12:07, 617.87s/it]2025-09-29 05:19:37,721 Stage: Train 0.5 | Epoch: 245 | Iter: 149000 | Total Loss: 0.005063 | Recon Loss: 0.004045 | Commit Loss: 0.002036 | Perplexity: 391.871758
2025-09-29 05:22:58,379 Stage: Train 0.5 | Epoch: 245 | Iter: 149200 | Total Loss: 0.005088 | Recon Loss: 0.004075 | Commit Loss: 0.002026 | Perplexity: 391.234847
2025-09-29 05:26:19,293 Stage: Train 0.5 | Epoch: 245 | Iter: 149400 | Total Loss: 0.005089 | Recon Loss: 0.004063 | Commit Loss: 0.002052 | Perplexity: 391.836055
Trainning Epoch:  30%|██▉       | 246/823 [42:16:48<98:51:16, 616.77s/it]Trainning Epoch:  30%|██▉       | 246/823 [42:16:48<98:51:18, 616.77s/it]Trainning Epoch:  30%|██▉       | 246/823 [42:16:48<98:51:19, 616.78s/it]Trainning Epoch:  30%|██▉       | 246/823 [42:16:48<98:51:20, 616.78s/it]2025-09-29 05:29:43,809 Stage: Train 0.5 | Epoch: 246 | Iter: 149600 | Total Loss: 0.005096 | Recon Loss: 0.004073 | Commit Loss: 0.002046 | Perplexity: 392.159460
2025-09-29 05:33:04,460 Stage: Train 0.5 | Epoch: 246 | Iter: 149800 | Total Loss: 0.005046 | Recon Loss: 0.004036 | Commit Loss: 0.002019 | Perplexity: 390.949690
2025-09-29 05:36:25,912 Stage: Train 0.5 | Epoch: 246 | Iter: 150000 | Total Loss: 0.005043 | Recon Loss: 0.004026 | Commit Loss: 0.002034 | Perplexity: 392.220826
Trainning Epoch:  30%|███       | 247/823 [42:27:04<98:37:54, 616.45s/it]Trainning Epoch:  30%|███       | 247/823 [42:27:04<98:37:53, 616.45s/it]Trainning Epoch:  30%|███       | 247/823 [42:27:04<98:37:54, 616.45s/it]Trainning Epoch:  30%|███       | 247/823 [42:27:04<98:37:54, 616.45s/it]2025-09-29 05:39:52,372 Stage: Train 0.5 | Epoch: 247 | Iter: 150200 | Total Loss: 0.005082 | Recon Loss: 0.004061 | Commit Loss: 0.002043 | Perplexity: 391.595727
2025-09-29 05:43:15,153 Stage: Train 0.5 | Epoch: 247 | Iter: 150400 | Total Loss: 0.005058 | Recon Loss: 0.004041 | Commit Loss: 0.002033 | Perplexity: 391.387545
2025-09-29 05:46:38,137 Stage: Train 0.5 | Epoch: 247 | Iter: 150600 | Total Loss: 0.005077 | Recon Loss: 0.004052 | Commit Loss: 0.002049 | Perplexity: 392.133999
Trainning Epoch:  30%|███       | 248/823 [42:37:24<98:38:55, 617.63s/it]Trainning Epoch:  30%|███       | 248/823 [42:37:24<98:38:58, 617.63s/it]Trainning Epoch:  30%|███       | 248/823 [42:37:24<98:38:58, 617.63s/it]Trainning Epoch:  30%|███       | 248/823 [42:37:24<98:39:00, 617.64s/it]2025-09-29 05:50:04,131 Stage: Train 0.5 | Epoch: 248 | Iter: 150800 | Total Loss: 0.005068 | Recon Loss: 0.004055 | Commit Loss: 0.002026 | Perplexity: 390.877003
2025-09-29 05:53:27,746 Stage: Train 0.5 | Epoch: 248 | Iter: 151000 | Total Loss: 0.005044 | Recon Loss: 0.004033 | Commit Loss: 0.002022 | Perplexity: 391.362437
2025-09-29 05:56:52,323 Stage: Train 0.5 | Epoch: 248 | Iter: 151200 | Total Loss: 0.005046 | Recon Loss: 0.004031 | Commit Loss: 0.002029 | Perplexity: 391.574848
Trainning Epoch:  30%|███       | 249/823 [42:47:49<98:48:38, 619.72s/it]Trainning Epoch:  30%|███       | 249/823 [42:47:49<98:48:40, 619.72s/it]Trainning Epoch:  30%|███       | 249/823 [42:47:49<98:48:39, 619.72s/it]Trainning Epoch:  30%|███       | 249/823 [42:47:49<98:48:40, 619.72s/it]2025-09-29 06:00:20,261 Stage: Train 0.5 | Epoch: 249 | Iter: 151400 | Total Loss: 0.005080 | Recon Loss: 0.004061 | Commit Loss: 0.002036 | Perplexity: 391.690697
2025-09-29 06:03:42,661 Stage: Train 0.5 | Epoch: 249 | Iter: 151600 | Total Loss: 0.005094 | Recon Loss: 0.004074 | Commit Loss: 0.002042 | Perplexity: 392.465969
2025-09-29 06:07:05,312 Stage: Train 0.5 | Epoch: 249 | Iter: 151800 | Total Loss: 0.005078 | Recon Loss: 0.004066 | Commit Loss: 0.002026 | Perplexity: 390.982781
2025-09-29 06:10:28,046 Stage: Train 0.5 | Epoch: 249 | Iter: 152000 | Total Loss: 0.005043 | Recon Loss: 0.004031 | Commit Loss: 0.002022 | Perplexity: 391.501754
Trainning Epoch:  30%|███       | 250/823 [42:58:08<98:37:18, 619.61s/it]Trainning Epoch:  30%|███       | 250/823 [42:58:08<98:37:20, 619.62s/it]Trainning Epoch:  30%|███       | 250/823 [42:58:08<98:37:24, 619.62s/it]Trainning Epoch:  30%|███       | 250/823 [42:58:08<98:37:22, 619.62s/it]2025-09-29 06:13:53,591 Stage: Train 0.5 | Epoch: 250 | Iter: 152200 | Total Loss: 0.005042 | Recon Loss: 0.004035 | Commit Loss: 0.002014 | Perplexity: 392.405216
2025-09-29 06:17:16,655 Stage: Train 0.5 | Epoch: 250 | Iter: 152400 | Total Loss: 0.005084 | Recon Loss: 0.004063 | Commit Loss: 0.002042 | Perplexity: 393.622261
2025-09-29 06:20:40,209 Stage: Train 0.5 | Epoch: 250 | Iter: 152600 | Total Loss: 0.005060 | Recon Loss: 0.004042 | Commit Loss: 0.002035 | Perplexity: 393.005191
Trainning Epoch:  30%|███       | 251/823 [43:08:29<98:28:56, 619.82s/it]Trainning Epoch:  30%|███       | 251/823 [43:08:29<98:28:58, 619.82s/it]Trainning Epoch:  30%|███       | 251/823 [43:08:29<98:28:57, 619.82s/it]Trainning Epoch:  30%|███       | 251/823 [43:08:29<98:28:58, 619.82s/it]2025-09-29 06:24:06,074 Stage: Train 0.5 | Epoch: 251 | Iter: 152800 | Total Loss: 0.005053 | Recon Loss: 0.004033 | Commit Loss: 0.002039 | Perplexity: 393.094165
2025-09-29 06:27:29,296 Stage: Train 0.5 | Epoch: 251 | Iter: 153000 | Total Loss: 0.005035 | Recon Loss: 0.004026 | Commit Loss: 0.002018 | Perplexity: 392.651392
2025-09-29 06:30:52,962 Stage: Train 0.5 | Epoch: 251 | Iter: 153200 | Total Loss: 0.005088 | Recon Loss: 0.004067 | Commit Loss: 0.002042 | Perplexity: 393.094691
Trainning Epoch:  31%|███       | 252/823 [43:18:49<98:21:30, 620.12s/it]Trainning Epoch:  31%|███       | 252/823 [43:18:50<98:21:33, 620.13s/it]Trainning Epoch:  31%|███       | 252/823 [43:18:50<98:21:32, 620.13s/it]Trainning Epoch:  31%|███       | 252/823 [43:18:49<98:21:32, 620.13s/it]2025-09-29 06:34:18,212 Stage: Train 0.5 | Epoch: 252 | Iter: 153400 | Total Loss: 0.004992 | Recon Loss: 0.003982 | Commit Loss: 0.002020 | Perplexity: 392.613457
2025-09-29 06:37:40,776 Stage: Train 0.5 | Epoch: 252 | Iter: 153600 | Total Loss: 0.005034 | Recon Loss: 0.004028 | Commit Loss: 0.002013 | Perplexity: 392.344739
2025-09-29 06:41:03,435 Stage: Train 0.5 | Epoch: 252 | Iter: 153800 | Total Loss: 0.005034 | Recon Loss: 0.004023 | Commit Loss: 0.002023 | Perplexity: 392.744161
Trainning Epoch:  31%|███       | 253/823 [43:29:08<98:06:41, 619.65s/it]Trainning Epoch:  31%|███       | 253/823 [43:29:08<98:06:37, 619.65s/it]Trainning Epoch:  31%|███       | 253/823 [43:29:08<98:06:39, 619.65s/it]Trainning Epoch:  31%|███       | 253/823 [43:29:08<98:06:39, 619.65s/it]2025-09-29 06:44:30,267 Stage: Train 0.5 | Epoch: 253 | Iter: 154000 | Total Loss: 0.005019 | Recon Loss: 0.004010 | Commit Loss: 0.002019 | Perplexity: 393.023928
2025-09-29 06:47:53,447 Stage: Train 0.5 | Epoch: 253 | Iter: 154200 | Total Loss: 0.005037 | Recon Loss: 0.004022 | Commit Loss: 0.002029 | Perplexity: 393.382768
2025-09-29 06:51:16,923 Stage: Train 0.5 | Epoch: 253 | Iter: 154400 | Total Loss: 0.005045 | Recon Loss: 0.004027 | Commit Loss: 0.002035 | Perplexity: 393.213492
Trainning Epoch:  31%|███       | 254/823 [43:39:30<98:03:37, 620.42s/it]Trainning Epoch:  31%|███       | 254/823 [43:39:30<98:03:41, 620.42s/it]Trainning Epoch:  31%|███       | 254/823 [43:39:30<98:03:39, 620.42s/it]Trainning Epoch:  31%|███       | 254/823 [43:39:30<98:03:40, 620.42s/it]2025-09-29 06:54:44,082 Stage: Train 0.5 | Epoch: 254 | Iter: 154600 | Total Loss: 0.005022 | Recon Loss: 0.004013 | Commit Loss: 0.002018 | Perplexity: 392.694679
2025-09-29 06:58:06,778 Stage: Train 0.5 | Epoch: 254 | Iter: 154800 | Total Loss: 0.004988 | Recon Loss: 0.003980 | Commit Loss: 0.002016 | Perplexity: 392.250787
2025-09-29 07:01:29,406 Stage: Train 0.5 | Epoch: 254 | Iter: 155000 | Total Loss: 0.005011 | Recon Loss: 0.004008 | Commit Loss: 0.002005 | Perplexity: 392.656226
Trainning Epoch:  31%|███       | 255/823 [43:49:50<97:52:41, 620.35s/it]Trainning Epoch:  31%|███       | 255/823 [43:49:50<97:52:44, 620.36s/it]Trainning Epoch:  31%|███       | 255/823 [43:49:50<97:52:44, 620.36s/it]Trainning Epoch:  31%|███       | 255/823 [43:49:50<97:52:43, 620.36s/it]2025-09-29 07:04:55,610 Stage: Train 0.5 | Epoch: 255 | Iter: 155200 | Total Loss: 0.005020 | Recon Loss: 0.004009 | Commit Loss: 0.002021 | Perplexity: 392.867742
2025-09-29 07:08:18,952 Stage: Train 0.5 | Epoch: 255 | Iter: 155400 | Total Loss: 0.004976 | Recon Loss: 0.003977 | Commit Loss: 0.001998 | Perplexity: 392.295665
2025-09-29 07:11:41,903 Stage: Train 0.5 | Epoch: 255 | Iter: 155600 | Total Loss: 0.005024 | Recon Loss: 0.004012 | Commit Loss: 0.002023 | Perplexity: 392.610884
Trainning Epoch:  31%|███       | 256/823 [44:00:11<97:42:39, 620.39s/it]Trainning Epoch:  31%|███       | 256/823 [44:00:11<97:42:40, 620.39s/it]Trainning Epoch:  31%|███       | 256/823 [44:00:11<97:42:40, 620.39s/it]Trainning Epoch:  31%|███       | 256/823 [44:00:11<97:42:40, 620.39s/it]2025-09-29 07:15:08,326 Stage: Train 0.5 | Epoch: 256 | Iter: 155800 | Total Loss: 0.005013 | Recon Loss: 0.004005 | Commit Loss: 0.002015 | Perplexity: 391.988154
2025-09-29 07:18:31,413 Stage: Train 0.5 | Epoch: 256 | Iter: 156000 | Total Loss: 0.005054 | Recon Loss: 0.004040 | Commit Loss: 0.002029 | Perplexity: 393.643145
2025-09-29 07:21:55,064 Stage: Train 0.5 | Epoch: 256 | Iter: 156200 | Total Loss: 0.005014 | Recon Loss: 0.003999 | Commit Loss: 0.002031 | Perplexity: 393.485575
Trainning Epoch:  31%|███       | 257/823 [44:10:32<97:35:04, 620.68s/it]Trainning Epoch:  31%|███       | 257/823 [44:10:32<97:35:10, 620.69s/it]Trainning Epoch:  31%|███       | 257/823 [44:10:32<97:35:07, 620.68s/it]Trainning Epoch:  31%|███       | 257/823 [44:10:32<97:35:07, 620.69s/it]2025-09-29 07:25:21,996 Stage: Train 0.5 | Epoch: 257 | Iter: 156400 | Total Loss: 0.005023 | Recon Loss: 0.004017 | Commit Loss: 0.002013 | Perplexity: 393.158146
2025-09-29 07:28:44,365 Stage: Train 0.5 | Epoch: 257 | Iter: 156600 | Total Loss: 0.005006 | Recon Loss: 0.003999 | Commit Loss: 0.002013 | Perplexity: 392.139813
2025-09-29 07:32:06,662 Stage: Train 0.5 | Epoch: 257 | Iter: 156800 | Total Loss: 0.005026 | Recon Loss: 0.004011 | Commit Loss: 0.002032 | Perplexity: 393.912805
Trainning Epoch:  31%|███▏      | 258/823 [44:20:52<97:20:48, 620.26s/it]Trainning Epoch:  31%|███▏      | 258/823 [44:20:52<97:20:50, 620.27s/it]Trainning Epoch:  31%|███▏      | 258/823 [44:20:52<97:20:51, 620.27s/it]Trainning Epoch:  31%|███▏      | 258/823 [44:20:52<97:20:49, 620.27s/it]2025-09-29 07:35:32,380 Stage: Train 0.5 | Epoch: 258 | Iter: 157000 | Total Loss: 0.005025 | Recon Loss: 0.004010 | Commit Loss: 0.002031 | Perplexity: 393.318277
2025-09-29 07:38:54,788 Stage: Train 0.5 | Epoch: 258 | Iter: 157200 | Total Loss: 0.004987 | Recon Loss: 0.003976 | Commit Loss: 0.002022 | Perplexity: 393.344574
2025-09-29 07:42:17,672 Stage: Train 0.5 | Epoch: 258 | Iter: 157400 | Total Loss: 0.005026 | Recon Loss: 0.004013 | Commit Loss: 0.002027 | Perplexity: 392.625462
Trainning Epoch:  31%|███▏      | 259/823 [44:31:11<97:07:40, 619.96s/it]Trainning Epoch:  31%|███▏      | 259/823 [44:31:11<97:07:36, 619.96s/it]Trainning Epoch:  31%|███▏      | 259/823 [44:31:11<97:07:38, 619.96s/it]Trainning Epoch:  31%|███▏      | 259/823 [44:31:11<97:07:38, 619.96s/it]2025-09-29 07:45:43,508 Stage: Train 0.5 | Epoch: 259 | Iter: 157600 | Total Loss: 0.004964 | Recon Loss: 0.003958 | Commit Loss: 0.002011 | Perplexity: 392.569046
2025-09-29 07:49:04,797 Stage: Train 0.5 | Epoch: 259 | Iter: 157800 | Total Loss: 0.005000 | Recon Loss: 0.003988 | Commit Loss: 0.002025 | Perplexity: 393.214169
2025-09-29 07:52:26,146 Stage: Train 0.5 | Epoch: 259 | Iter: 158000 | Total Loss: 0.005019 | Recon Loss: 0.004008 | Commit Loss: 0.002022 | Perplexity: 393.232590
Trainning Epoch:  32%|███▏      | 260/823 [44:41:27<96:47:02, 618.87s/it]Trainning Epoch:  32%|███▏      | 260/823 [44:41:27<96:47:05, 618.87s/it]Trainning Epoch:  32%|███▏      | 260/823 [44:41:27<96:47:05, 618.87s/it]Trainning Epoch:  32%|███▏      | 260/823 [44:41:27<96:47:05, 618.87s/it]2025-09-29 07:55:51,179 Stage: Train 0.5 | Epoch: 260 | Iter: 158200 | Total Loss: 0.005021 | Recon Loss: 0.004006 | Commit Loss: 0.002030 | Perplexity: 393.561762
2025-09-29 07:59:12,637 Stage: Train 0.5 | Epoch: 260 | Iter: 158400 | Total Loss: 0.005009 | Recon Loss: 0.003993 | Commit Loss: 0.002033 | Perplexity: 393.215514
2025-09-29 08:02:33,481 Stage: Train 0.5 | Epoch: 260 | Iter: 158600 | Total Loss: 0.005023 | Recon Loss: 0.004009 | Commit Loss: 0.002027 | Perplexity: 393.270823
Trainning Epoch:  32%|███▏      | 261/823 [44:51:42<96:25:50, 617.70s/it]Trainning Epoch:  32%|███▏      | 261/823 [44:51:42<96:25:47, 617.70s/it]Trainning Epoch:  32%|███▏      | 261/823 [44:51:42<96:25:51, 617.71s/it]Trainning Epoch:  32%|███▏      | 261/823 [44:51:42<96:25:51, 617.71s/it]2025-09-29 08:05:57,671 Stage: Train 0.5 | Epoch: 261 | Iter: 158800 | Total Loss: 0.004987 | Recon Loss: 0.003986 | Commit Loss: 0.002002 | Perplexity: 392.546078
2025-09-29 08:09:19,424 Stage: Train 0.5 | Epoch: 261 | Iter: 159000 | Total Loss: 0.005031 | Recon Loss: 0.004012 | Commit Loss: 0.002039 | Perplexity: 393.880257
2025-09-29 08:12:41,501 Stage: Train 0.5 | Epoch: 261 | Iter: 159200 | Total Loss: 0.005024 | Recon Loss: 0.004007 | Commit Loss: 0.002034 | Perplexity: 393.086689
Trainning Epoch:  32%|███▏      | 262/823 [45:01:59<96:14:17, 617.57s/it]Trainning Epoch:  32%|███▏      | 262/823 [45:01:59<96:14:20, 617.58s/it]Trainning Epoch:  32%|███▏      | 262/823 [45:01:59<96:14:21, 617.58s/it]Trainning Epoch:  32%|███▏      | 262/823 [45:01:59<96:14:20, 617.58s/it]2025-09-29 08:16:06,964 Stage: Train 0.5 | Epoch: 262 | Iter: 159400 | Total Loss: 0.004980 | Recon Loss: 0.003969 | Commit Loss: 0.002021 | Perplexity: 393.280062
2025-09-29 08:19:27,681 Stage: Train 0.5 | Epoch: 262 | Iter: 159600 | Total Loss: 0.005011 | Recon Loss: 0.004008 | Commit Loss: 0.002007 | Perplexity: 393.570306
2025-09-29 08:22:49,236 Stage: Train 0.5 | Epoch: 262 | Iter: 159800 | Total Loss: 0.004957 | Recon Loss: 0.003949 | Commit Loss: 0.002015 | Perplexity: 392.679204
Trainning Epoch:  32%|███▏      | 263/823 [45:12:14<95:56:56, 616.81s/it]Trainning Epoch:  32%|███▏      | 263/823 [45:12:14<95:56:53, 616.81s/it]Trainning Epoch:  32%|███▏      | 263/823 [45:12:14<95:56:56, 616.81s/it]Trainning Epoch:  32%|███▏      | 263/823 [45:12:14<95:56:56, 616.82s/it]2025-09-29 08:26:14,469 Stage: Train 0.5 | Epoch: 263 | Iter: 160000 | Total Loss: 0.005024 | Recon Loss: 0.004011 | Commit Loss: 0.002028 | Perplexity: 394.042309
2025-09-29 08:26:14,469 Saving model at iteration 160000
2025-09-29 08:26:15,209 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_264_step_160000
2025-09-29 08:26:15,833 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_264_step_160000/model.safetensors
2025-09-29 08:26:16,396 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_264_step_160000/optimizer.bin
2025-09-29 08:26:16,397 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_264_step_160000/scheduler.bin
2025-09-29 08:26:16,397 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_264_step_160000/sampler.bin
2025-09-29 08:26:16,398 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_264_step_160000/random_states_0.pkl
2025-09-29 08:29:37,594 Stage: Train 0.5 | Epoch: 263 | Iter: 160200 | Total Loss: 0.004995 | Recon Loss: 0.003994 | Commit Loss: 0.002004 | Perplexity: 392.669050
2025-09-29 08:32:59,420 Stage: Train 0.5 | Epoch: 263 | Iter: 160400 | Total Loss: 0.004982 | Recon Loss: 0.003974 | Commit Loss: 0.002015 | Perplexity: 392.832085
Trainning Epoch:  32%|███▏      | 264/823 [45:22:33<95:50:22, 617.21s/it]Trainning Epoch:  32%|███▏      | 264/823 [45:22:33<95:50:24, 617.22s/it]Trainning Epoch:  32%|███▏      | 264/823 [45:22:33<95:50:25, 617.22s/it]Trainning Epoch:  32%|███▏      | 264/823 [45:22:33<95:50:25, 617.22s/it]2025-09-29 08:36:24,240 Stage: Train 0.5 | Epoch: 264 | Iter: 160600 | Total Loss: 0.004980 | Recon Loss: 0.003971 | Commit Loss: 0.002018 | Perplexity: 392.738905
2025-09-29 08:39:45,987 Stage: Train 0.5 | Epoch: 264 | Iter: 160800 | Total Loss: 0.005008 | Recon Loss: 0.003989 | Commit Loss: 0.002040 | Perplexity: 393.705912
2025-09-29 08:43:08,233 Stage: Train 0.5 | Epoch: 264 | Iter: 161000 | Total Loss: 0.005000 | Recon Loss: 0.003993 | Commit Loss: 0.002013 | Perplexity: 393.175087
Trainning Epoch:  32%|███▏      | 265/823 [45:32:50<95:39:40, 617.17s/it]Trainning Epoch:  32%|███▏      | 265/823 [45:32:50<95:39:40, 617.17s/it]Trainning Epoch:  32%|███▏      | 265/823 [45:32:50<95:39:41, 617.17s/it]Trainning Epoch:  32%|███▏      | 265/823 [45:32:50<95:39:43, 617.17s/it]2025-09-29 08:46:34,100 Stage: Train 0.5 | Epoch: 265 | Iter: 161200 | Total Loss: 0.004973 | Recon Loss: 0.003968 | Commit Loss: 0.002010 | Perplexity: 393.119895
2025-09-29 08:49:56,837 Stage: Train 0.5 | Epoch: 265 | Iter: 161400 | Total Loss: 0.004967 | Recon Loss: 0.003962 | Commit Loss: 0.002008 | Perplexity: 392.619457
2025-09-29 08:53:18,869 Stage: Train 0.5 | Epoch: 265 | Iter: 161600 | Total Loss: 0.004999 | Recon Loss: 0.003988 | Commit Loss: 0.002022 | Perplexity: 393.683412
Trainning Epoch:  32%|███▏      | 266/823 [45:43:09<95:34:20, 617.70s/it]Trainning Epoch:  32%|███▏      | 266/823 [45:43:09<95:34:18, 617.70s/it]Trainning Epoch:  32%|███▏      | 266/823 [45:43:09<95:34:18, 617.70s/it]Trainning Epoch:  32%|███▏      | 266/823 [45:43:09<95:34:19, 617.70s/it]2025-09-29 08:56:43,906 Stage: Train 0.5 | Epoch: 266 | Iter: 161800 | Total Loss: 0.004967 | Recon Loss: 0.003960 | Commit Loss: 0.002014 | Perplexity: 392.728743
2025-09-29 09:00:04,950 Stage: Train 0.5 | Epoch: 266 | Iter: 162000 | Total Loss: 0.004972 | Recon Loss: 0.003964 | Commit Loss: 0.002016 | Perplexity: 393.292279
2025-09-29 09:03:26,106 Stage: Train 0.5 | Epoch: 266 | Iter: 162200 | Total Loss: 0.004976 | Recon Loss: 0.003966 | Commit Loss: 0.002021 | Perplexity: 392.684174
Trainning Epoch:  32%|███▏      | 267/823 [45:53:23<95:15:00, 616.73s/it]Trainning Epoch:  32%|███▏      | 267/823 [45:53:23<95:15:00, 616.73s/it]Trainning Epoch:  32%|███▏      | 267/823 [45:53:23<95:15:03, 616.73s/it]Trainning Epoch:  32%|███▏      | 267/823 [45:53:23<95:15:02, 616.73s/it]2025-09-29 09:06:51,278 Stage: Train 0.5 | Epoch: 267 | Iter: 162400 | Total Loss: 0.004975 | Recon Loss: 0.003969 | Commit Loss: 0.002013 | Perplexity: 393.415329
2025-09-29 09:10:13,937 Stage: Train 0.5 | Epoch: 267 | Iter: 162600 | Total Loss: 0.004975 | Recon Loss: 0.003964 | Commit Loss: 0.002023 | Perplexity: 393.143071
2025-09-29 09:13:36,510 Stage: Train 0.5 | Epoch: 267 | Iter: 162800 | Total Loss: 0.004958 | Recon Loss: 0.003954 | Commit Loss: 0.002007 | Perplexity: 393.042988
Trainning Epoch:  33%|███▎      | 268/823 [46:03:43<95:12:30, 617.57s/it]Trainning Epoch:  33%|███▎      | 268/823 [46:03:43<95:12:29, 617.57s/it]Trainning Epoch:  33%|███▎      | 268/823 [46:03:43<95:12:30, 617.57s/it]Trainning Epoch:  33%|███▎      | 268/823 [46:03:43<95:12:28, 617.57s/it]2025-09-29 09:17:01,865 Stage: Train 0.5 | Epoch: 268 | Iter: 163000 | Total Loss: 0.004961 | Recon Loss: 0.003953 | Commit Loss: 0.002014 | Perplexity: 392.865324
2025-09-29 09:20:22,846 Stage: Train 0.5 | Epoch: 268 | Iter: 163200 | Total Loss: 0.004960 | Recon Loss: 0.003958 | Commit Loss: 0.002005 | Perplexity: 392.894490
2025-09-29 09:23:44,098 Stage: Train 0.5 | Epoch: 268 | Iter: 163400 | Total Loss: 0.004985 | Recon Loss: 0.003974 | Commit Loss: 0.002024 | Perplexity: 393.783325
Trainning Epoch:  33%|███▎      | 269/823 [46:13:57<94:54:14, 616.70s/it]Trainning Epoch:  33%|███▎      | 269/823 [46:13:57<94:54:13, 616.70s/it]Trainning Epoch:  33%|███▎      | 269/823 [46:13:57<94:54:14, 616.70s/it]Trainning Epoch:  33%|███▎      | 269/823 [46:13:57<94:54:14, 616.70s/it]2025-09-29 09:27:08,787 Stage: Train 0.5 | Epoch: 269 | Iter: 163600 | Total Loss: 0.004948 | Recon Loss: 0.003939 | Commit Loss: 0.002016 | Perplexity: 394.408735
2025-09-29 09:30:30,411 Stage: Train 0.5 | Epoch: 269 | Iter: 163800 | Total Loss: 0.004984 | Recon Loss: 0.003971 | Commit Loss: 0.002026 | Perplexity: 393.964356
2025-09-29 09:33:52,243 Stage: Train 0.5 | Epoch: 269 | Iter: 164000 | Total Loss: 0.004918 | Recon Loss: 0.003916 | Commit Loss: 0.002004 | Perplexity: 393.261903
Trainning Epoch:  33%|███▎      | 270/823 [46:24:14<94:42:38, 616.56s/it]Trainning Epoch:  33%|███▎      | 270/823 [46:24:13<94:42:37, 616.56s/it]Trainning Epoch:  33%|███▎      | 270/823 [46:24:14<94:42:45, 616.57s/it]Trainning Epoch:  33%|███▎      | 270/823 [46:24:14<94:42:45, 616.57s/it]2025-09-29 09:37:16,964 Stage: Train 0.5 | Epoch: 270 | Iter: 164200 | Total Loss: 0.004956 | Recon Loss: 0.003957 | Commit Loss: 0.002000 | Perplexity: 392.438671
2025-09-29 09:40:37,860 Stage: Train 0.5 | Epoch: 270 | Iter: 164400 | Total Loss: 0.004937 | Recon Loss: 0.003932 | Commit Loss: 0.002010 | Perplexity: 393.535110
2025-09-29 09:43:59,277 Stage: Train 0.5 | Epoch: 270 | Iter: 164600 | Total Loss: 0.004978 | Recon Loss: 0.003970 | Commit Loss: 0.002016 | Perplexity: 392.990375
Trainning Epoch:  33%|███▎      | 271/823 [46:34:29<94:30:03, 616.31s/it]Trainning Epoch:  33%|███▎      | 271/823 [46:34:29<94:30:02, 616.31s/it]Trainning Epoch:  33%|███▎      | 271/823 [46:34:29<94:30:00, 616.31s/it]Trainning Epoch:  33%|███▎      | 271/823 [46:34:29<94:30:01, 616.31s/it]2025-09-29 09:47:24,794 Stage: Train 0.5 | Epoch: 271 | Iter: 164800 | Total Loss: 0.004943 | Recon Loss: 0.003943 | Commit Loss: 0.002001 | Perplexity: 392.099591
2025-09-29 09:50:47,096 Stage: Train 0.5 | Epoch: 271 | Iter: 165000 | Total Loss: 0.004937 | Recon Loss: 0.003936 | Commit Loss: 0.002002 | Perplexity: 393.553376
2025-09-29 09:54:11,144 Stage: Train 0.5 | Epoch: 271 | Iter: 165200 | Total Loss: 0.004912 | Recon Loss: 0.003912 | Commit Loss: 0.002000 | Perplexity: 393.420756
Trainning Epoch:  33%|███▎      | 272/823 [46:44:50<94:32:14, 617.67s/it]Trainning Epoch:  33%|███▎      | 272/823 [46:44:50<94:32:17, 617.67s/it]Trainning Epoch:  33%|███▎      | 272/823 [46:44:50<94:32:16, 617.67s/it]Trainning Epoch:  33%|███▎      | 272/823 [46:44:50<94:32:19, 617.68s/it]2025-09-29 09:57:38,180 Stage: Train 0.5 | Epoch: 272 | Iter: 165400 | Total Loss: 0.005004 | Recon Loss: 0.003986 | Commit Loss: 0.002036 | Perplexity: 393.806780
2025-09-29 10:01:02,029 Stage: Train 0.5 | Epoch: 272 | Iter: 165600 | Total Loss: 0.004923 | Recon Loss: 0.003916 | Commit Loss: 0.002014 | Perplexity: 394.153666
2025-09-29 10:04:26,005 Stage: Train 0.5 | Epoch: 272 | Iter: 165800 | Total Loss: 0.004935 | Recon Loss: 0.003937 | Commit Loss: 0.001997 | Perplexity: 393.158521
Trainning Epoch:  33%|███▎      | 273/823 [46:55:14<94:39:19, 619.56s/it]Trainning Epoch:  33%|███▎      | 273/823 [46:55:14<94:39:21, 619.57s/it]Trainning Epoch:  33%|███▎      | 273/823 [46:55:14<94:39:21, 619.57s/it]Trainning Epoch:  33%|███▎      | 273/823 [46:55:14<94:39:24, 619.57s/it]2025-09-29 10:07:53,419 Stage: Train 0.5 | Epoch: 273 | Iter: 166000 | Total Loss: 0.004982 | Recon Loss: 0.003969 | Commit Loss: 0.002025 | Perplexity: 393.199325
2025-09-29 10:11:15,256 Stage: Train 0.5 | Epoch: 273 | Iter: 166200 | Total Loss: 0.004924 | Recon Loss: 0.003925 | Commit Loss: 0.001998 | Perplexity: 392.453182
2025-09-29 10:14:38,716 Stage: Train 0.5 | Epoch: 273 | Iter: 166400 | Total Loss: 0.004946 | Recon Loss: 0.003935 | Commit Loss: 0.002022 | Perplexity: 393.054926
Trainning Epoch:  33%|███▎      | 274/823 [47:05:34<94:29:15, 619.59s/it]Trainning Epoch:  33%|███▎      | 274/823 [47:05:34<94:29:11, 619.58s/it]Trainning Epoch:  33%|███▎      | 274/823 [47:05:34<94:29:12, 619.58s/it]Trainning Epoch:  33%|███▎      | 274/823 [47:05:34<94:29:12, 619.59s/it]2025-09-29 10:18:05,084 Stage: Train 0.5 | Epoch: 274 | Iter: 166600 | Total Loss: 0.004965 | Recon Loss: 0.003954 | Commit Loss: 0.002020 | Perplexity: 393.824116
2025-09-29 10:21:27,437 Stage: Train 0.5 | Epoch: 274 | Iter: 166800 | Total Loss: 0.004916 | Recon Loss: 0.003914 | Commit Loss: 0.002005 | Perplexity: 393.246811
2025-09-29 10:24:49,992 Stage: Train 0.5 | Epoch: 274 | Iter: 167000 | Total Loss: 0.004922 | Recon Loss: 0.003919 | Commit Loss: 0.002005 | Perplexity: 393.400702
2025-09-29 10:28:13,144 Stage: Train 0.5 | Epoch: 274 | Iter: 167200 | Total Loss: 0.004981 | Recon Loss: 0.003968 | Commit Loss: 0.002027 | Perplexity: 393.601355
Trainning Epoch:  33%|███▎      | 275/823 [47:15:53<94:19:19, 619.63s/it]Trainning Epoch:  33%|███▎      | 275/823 [47:15:53<94:19:22, 619.64s/it]Trainning Epoch:  33%|███▎      | 275/823 [47:15:53<94:19:22, 619.64s/it]Trainning Epoch:  33%|███▎      | 275/823 [47:15:53<94:19:24, 619.64s/it]2025-09-29 10:31:37,318 Stage: Train 0.5 | Epoch: 275 | Iter: 167400 | Total Loss: 0.004928 | Recon Loss: 0.003927 | Commit Loss: 0.002000 | Perplexity: 392.678990
2025-09-29 10:34:59,266 Stage: Train 0.5 | Epoch: 275 | Iter: 167600 | Total Loss: 0.004909 | Recon Loss: 0.003902 | Commit Loss: 0.002014 | Perplexity: 393.724863
2025-09-29 10:38:21,589 Stage: Train 0.5 | Epoch: 275 | Iter: 167800 | Total Loss: 0.004931 | Recon Loss: 0.003931 | Commit Loss: 0.002000 | Perplexity: 391.721377
Trainning Epoch:  34%|███▎      | 276/823 [47:26:10<94:00:33, 618.71s/it]Trainning Epoch:  34%|███▎      | 276/823 [47:26:10<94:00:34, 618.71s/it]Trainning Epoch:  34%|███▎      | 276/823 [47:26:10<94:00:39, 618.72s/it]Trainning Epoch:  34%|███▎      | 276/823 [47:26:10<94:00:34, 618.71s/it]2025-09-29 10:41:45,884 Stage: Train 0.5 | Epoch: 276 | Iter: 168000 | Total Loss: 0.004904 | Recon Loss: 0.003900 | Commit Loss: 0.002007 | Perplexity: 393.258862
2025-09-29 10:45:06,924 Stage: Train 0.5 | Epoch: 276 | Iter: 168200 | Total Loss: 0.004934 | Recon Loss: 0.003923 | Commit Loss: 0.002024 | Perplexity: 393.825388
2025-09-29 10:48:28,325 Stage: Train 0.5 | Epoch: 276 | Iter: 168400 | Total Loss: 0.004952 | Recon Loss: 0.003941 | Commit Loss: 0.002023 | Perplexity: 393.824603
Trainning Epoch:  34%|███▎      | 277/823 [47:36:25<93:39:30, 617.53s/it]Trainning Epoch:  34%|███▎      | 277/823 [47:36:25<93:39:27, 617.52s/it]Trainning Epoch:  34%|███▎      | 277/823 [47:36:25<93:39:27, 617.52s/it]Trainning Epoch:  34%|███▎      | 277/823 [47:36:25<93:39:28, 617.52s/it]2025-09-29 10:51:54,094 Stage: Train 0.5 | Epoch: 277 | Iter: 168600 | Total Loss: 0.004906 | Recon Loss: 0.003901 | Commit Loss: 0.002010 | Perplexity: 393.609652
2025-09-29 10:55:16,920 Stage: Train 0.5 | Epoch: 277 | Iter: 168800 | Total Loss: 0.004967 | Recon Loss: 0.003951 | Commit Loss: 0.002033 | Perplexity: 394.726227
2025-09-29 10:58:40,211 Stage: Train 0.5 | Epoch: 277 | Iter: 169000 | Total Loss: 0.004928 | Recon Loss: 0.003922 | Commit Loss: 0.002013 | Perplexity: 393.745715
Trainning Epoch:  34%|███▍      | 278/823 [47:46:45<93:36:07, 618.29s/it]Trainning Epoch:  34%|███▍      | 278/823 [47:46:45<93:36:13, 618.30s/it]Trainning Epoch:  34%|███▍      | 278/823 [47:46:45<93:36:11, 618.30s/it]Trainning Epoch:  34%|███▍      | 278/823 [47:46:45<93:36:10, 618.30s/it]2025-09-29 11:02:04,117 Stage: Train 0.5 | Epoch: 278 | Iter: 169200 | Total Loss: 0.004899 | Recon Loss: 0.003899 | Commit Loss: 0.002000 | Perplexity: 392.774860
2025-09-29 11:05:24,598 Stage: Train 0.5 | Epoch: 278 | Iter: 169400 | Total Loss: 0.004901 | Recon Loss: 0.003901 | Commit Loss: 0.002000 | Perplexity: 392.582772
2025-09-29 11:08:45,776 Stage: Train 0.5 | Epoch: 278 | Iter: 169600 | Total Loss: 0.004967 | Recon Loss: 0.003955 | Commit Loss: 0.002022 | Perplexity: 393.418537
Trainning Epoch:  34%|███▍      | 279/823 [47:56:58<93:12:31, 616.82s/it]Trainning Epoch:  34%|███▍      | 279/823 [47:56:58<93:12:30, 616.82s/it]Trainning Epoch:  34%|███▍      | 279/823 [47:56:58<93:12:31, 616.82s/it]Trainning Epoch:  34%|███▍      | 279/823 [47:56:58<93:12:33, 616.83s/it]2025-09-29 11:12:09,739 Stage: Train 0.5 | Epoch: 279 | Iter: 169800 | Total Loss: 0.004872 | Recon Loss: 0.003875 | Commit Loss: 0.001994 | Perplexity: 392.501487
2025-09-29 11:15:31,288 Stage: Train 0.5 | Epoch: 279 | Iter: 170000 | Total Loss: 0.004912 | Recon Loss: 0.003910 | Commit Loss: 0.002004 | Perplexity: 393.499173
2025-09-29 11:18:52,507 Stage: Train 0.5 | Epoch: 279 | Iter: 170200 | Total Loss: 0.004953 | Recon Loss: 0.003945 | Commit Loss: 0.002016 | Perplexity: 395.390443
Trainning Epoch:  34%|███▍      | 280/823 [48:07:13<92:57:18, 616.28s/it]Trainning Epoch:  34%|███▍      | 280/823 [48:07:13<92:57:21, 616.28s/it]Trainning Epoch:  34%|███▍      | 280/823 [48:07:13<92:57:21, 616.28s/it]Trainning Epoch:  34%|███▍      | 280/823 [48:07:13<92:57:22, 616.29s/it]2025-09-29 11:22:18,055 Stage: Train 0.5 | Epoch: 280 | Iter: 170400 | Total Loss: 0.004923 | Recon Loss: 0.003914 | Commit Loss: 0.002020 | Perplexity: 394.180768
2025-09-29 11:25:40,787 Stage: Train 0.5 | Epoch: 280 | Iter: 170600 | Total Loss: 0.004884 | Recon Loss: 0.003885 | Commit Loss: 0.001997 | Perplexity: 393.847843
2025-09-29 11:29:03,652 Stage: Train 0.5 | Epoch: 280 | Iter: 170800 | Total Loss: 0.004928 | Recon Loss: 0.003913 | Commit Loss: 0.002031 | Perplexity: 395.186044
Trainning Epoch:  34%|███▍      | 281/823 [48:17:32<92:54:58, 617.16s/it]Trainning Epoch:  34%|███▍      | 281/823 [48:17:33<92:55:03, 617.17s/it]Trainning Epoch:  34%|███▍      | 281/823 [48:17:32<92:55:03, 617.17s/it]Trainning Epoch:  34%|███▍      | 281/823 [48:17:33<92:55:04, 617.17s/it]2025-09-29 11:32:30,241 Stage: Train 0.5 | Epoch: 281 | Iter: 171000 | Total Loss: 0.004909 | Recon Loss: 0.003906 | Commit Loss: 0.002006 | Perplexity: 393.932044
2025-09-29 11:35:52,967 Stage: Train 0.5 | Epoch: 281 | Iter: 171200 | Total Loss: 0.004921 | Recon Loss: 0.003922 | Commit Loss: 0.001998 | Perplexity: 394.419692
2025-09-29 11:39:16,666 Stage: Train 0.5 | Epoch: 281 | Iter: 171400 | Total Loss: 0.004869 | Recon Loss: 0.003875 | Commit Loss: 0.001989 | Perplexity: 394.071065
Trainning Epoch:  34%|███▍      | 282/823 [48:27:54<92:55:59, 618.41s/it]Trainning Epoch:  34%|███▍      | 282/823 [48:27:54<92:56:02, 618.42s/it]Trainning Epoch:  34%|███▍      | 282/823 [48:27:54<92:56:02, 618.42s/it]Trainning Epoch:  34%|███▍      | 282/823 [48:27:54<92:56:02, 618.42s/it]2025-09-29 11:42:41,680 Stage: Train 0.5 | Epoch: 282 | Iter: 171600 | Total Loss: 0.004934 | Recon Loss: 0.003927 | Commit Loss: 0.002013 | Perplexity: 394.398475
2025-09-29 11:46:03,502 Stage: Train 0.5 | Epoch: 282 | Iter: 171800 | Total Loss: 0.004884 | Recon Loss: 0.003887 | Commit Loss: 0.001995 | Perplexity: 393.784758
2025-09-29 11:49:25,129 Stage: Train 0.5 | Epoch: 282 | Iter: 172000 | Total Loss: 0.004889 | Recon Loss: 0.003887 | Commit Loss: 0.002004 | Perplexity: 393.818877
Trainning Epoch:  34%|███▍      | 283/823 [48:38:10<92:39:21, 617.71s/it]Trainning Epoch:  34%|███▍      | 283/823 [48:38:10<92:39:18, 617.70s/it]Trainning Epoch:  34%|███▍      | 283/823 [48:38:10<92:39:19, 617.70s/it]Trainning Epoch:  34%|███▍      | 283/823 [48:38:10<92:39:20, 617.70s/it]2025-09-29 11:52:51,543 Stage: Train 0.5 | Epoch: 283 | Iter: 172200 | Total Loss: 0.004881 | Recon Loss: 0.003883 | Commit Loss: 0.001994 | Perplexity: 393.717961
2025-09-29 11:56:15,418 Stage: Train 0.5 | Epoch: 283 | Iter: 172400 | Total Loss: 0.004892 | Recon Loss: 0.003891 | Commit Loss: 0.002003 | Perplexity: 393.880824
2025-09-29 11:59:39,599 Stage: Train 0.5 | Epoch: 283 | Iter: 172600 | Total Loss: 0.004900 | Recon Loss: 0.003900 | Commit Loss: 0.002000 | Perplexity: 394.397743
Trainning Epoch:  35%|███▍      | 284/823 [48:48:33<92:43:47, 619.35s/it]Trainning Epoch:  35%|███▍      | 284/823 [48:48:33<92:43:48, 619.35s/it]Trainning Epoch:  35%|███▍      | 284/823 [48:48:33<92:43:48, 619.35s/it]Trainning Epoch:  35%|███▍      | 284/823 [48:48:33<92:43:48, 619.35s/it]2025-09-29 12:03:04,012 Stage: Train 0.5 | Epoch: 284 | Iter: 172800 | Total Loss: 0.004896 | Recon Loss: 0.003894 | Commit Loss: 0.002005 | Perplexity: 394.738151
2025-09-29 12:06:24,278 Stage: Train 0.5 | Epoch: 284 | Iter: 173000 | Total Loss: 0.004906 | Recon Loss: 0.003907 | Commit Loss: 0.001999 | Perplexity: 394.244926
2025-09-29 12:09:44,078 Stage: Train 0.5 | Epoch: 284 | Iter: 173200 | Total Loss: 0.004903 | Recon Loss: 0.003904 | Commit Loss: 0.001998 | Perplexity: 393.258078
Trainning Epoch:  35%|███▍      | 285/823 [48:58:45<92:12:19, 616.99s/it]Trainning Epoch:  35%|███▍      | 285/823 [48:58:45<92:12:17, 616.98s/it]Trainning Epoch:  35%|███▍      | 285/823 [48:58:45<92:12:19, 616.99s/it]Trainning Epoch:  35%|███▍      | 285/823 [48:58:45<92:12:19, 616.99s/it]2025-09-29 12:13:08,599 Stage: Train 0.5 | Epoch: 285 | Iter: 173400 | Total Loss: 0.004877 | Recon Loss: 0.003879 | Commit Loss: 0.001995 | Perplexity: 394.510529
2025-09-29 12:16:29,595 Stage: Train 0.5 | Epoch: 285 | Iter: 173600 | Total Loss: 0.004888 | Recon Loss: 0.003888 | Commit Loss: 0.002001 | Perplexity: 395.139444
2025-09-29 12:19:51,192 Stage: Train 0.5 | Epoch: 285 | Iter: 173800 | Total Loss: 0.004873 | Recon Loss: 0.003876 | Commit Loss: 0.001992 | Perplexity: 392.947701
Trainning Epoch:  35%|███▍      | 286/823 [49:09:01<91:59:50, 616.74s/it]Trainning Epoch:  35%|███▍      | 286/823 [49:09:01<91:59:48, 616.74s/it]Trainning Epoch:  35%|███▍      | 286/823 [49:09:01<91:59:49, 616.74s/it]Trainning Epoch:  35%|███▍      | 286/823 [49:09:01<91:59:49, 616.74s/it]2025-09-29 12:23:16,048 Stage: Train 0.5 | Epoch: 286 | Iter: 174000 | Total Loss: 0.004892 | Recon Loss: 0.003887 | Commit Loss: 0.002009 | Perplexity: 393.960859
2025-09-29 12:26:37,494 Stage: Train 0.5 | Epoch: 286 | Iter: 174200 | Total Loss: 0.004835 | Recon Loss: 0.003841 | Commit Loss: 0.001989 | Perplexity: 392.781460
2025-09-29 12:29:58,793 Stage: Train 0.5 | Epoch: 286 | Iter: 174400 | Total Loss: 0.004907 | Recon Loss: 0.003908 | Commit Loss: 0.001998 | Perplexity: 394.128903
Trainning Epoch:  35%|███▍      | 287/823 [49:19:16<91:45:11, 616.25s/it]Trainning Epoch:  35%|███▍      | 287/823 [49:19:16<91:45:13, 616.26s/it]Trainning Epoch:  35%|███▍      | 287/823 [49:19:16<91:45:16, 616.26s/it]Trainning Epoch:  35%|███▍      | 287/823 [49:19:16<91:45:15, 616.26s/it]2025-09-29 12:33:25,466 Stage: Train 0.5 | Epoch: 287 | Iter: 174600 | Total Loss: 0.004853 | Recon Loss: 0.003859 | Commit Loss: 0.001988 | Perplexity: 394.404530
2025-09-29 12:36:48,946 Stage: Train 0.5 | Epoch: 287 | Iter: 174800 | Total Loss: 0.004858 | Recon Loss: 0.003867 | Commit Loss: 0.001981 | Perplexity: 394.447330
2025-09-29 12:40:12,513 Stage: Train 0.5 | Epoch: 287 | Iter: 175000 | Total Loss: 0.004868 | Recon Loss: 0.003862 | Commit Loss: 0.002011 | Perplexity: 395.718891
Trainning Epoch:  35%|███▍      | 288/823 [49:29:39<91:52:13, 618.19s/it]Trainning Epoch:  35%|███▍      | 288/823 [49:29:39<91:52:15, 618.20s/it]Trainning Epoch:  35%|███▍      | 288/823 [49:29:39<91:52:14, 618.20s/it]Trainning Epoch:  35%|███▍      | 288/823 [49:29:39<91:52:14, 618.20s/it]2025-09-29 12:43:39,200 Stage: Train 0.5 | Epoch: 288 | Iter: 175200 | Total Loss: 0.004854 | Recon Loss: 0.003861 | Commit Loss: 0.001986 | Perplexity: 395.051154
2025-09-29 12:47:02,440 Stage: Train 0.5 | Epoch: 288 | Iter: 175400 | Total Loss: 0.004875 | Recon Loss: 0.003880 | Commit Loss: 0.001990 | Perplexity: 395.224470
2025-09-29 12:50:25,485 Stage: Train 0.5 | Epoch: 288 | Iter: 175600 | Total Loss: 0.004889 | Recon Loss: 0.003885 | Commit Loss: 0.002009 | Perplexity: 395.269068
Trainning Epoch:  35%|███▌      | 289/823 [49:40:00<91:49:35, 619.06s/it]Trainning Epoch:  35%|███▌      | 289/823 [49:40:00<91:49:41, 619.07s/it]Trainning Epoch:  35%|███▌      | 289/823 [49:40:00<91:49:42, 619.07s/it]Trainning Epoch:  35%|███▌      | 289/823 [49:40:00<91:49:42, 619.07s/it]2025-09-29 12:53:51,933 Stage: Train 0.5 | Epoch: 289 | Iter: 175800 | Total Loss: 0.004877 | Recon Loss: 0.003890 | Commit Loss: 0.001974 | Perplexity: 395.126783
2025-09-29 12:57:14,501 Stage: Train 0.5 | Epoch: 289 | Iter: 176000 | Total Loss: 0.004863 | Recon Loss: 0.003871 | Commit Loss: 0.001985 | Perplexity: 394.318288
2025-09-29 13:00:37,201 Stage: Train 0.5 | Epoch: 289 | Iter: 176200 | Total Loss: 0.004840 | Recon Loss: 0.003847 | Commit Loss: 0.001985 | Perplexity: 394.282525
Trainning Epoch:  35%|███▌      | 290/823 [49:50:19<91:40:55, 619.24s/it]Trainning Epoch:  35%|███▌      | 290/823 [49:50:19<91:41:03, 619.26s/it]Trainning Epoch:  35%|███▌      | 290/823 [49:50:19<91:41:03, 619.26s/it]Trainning Epoch:  35%|███▌      | 290/823 [49:50:19<91:41:04, 619.26s/it]2025-09-29 13:04:04,145 Stage: Train 0.5 | Epoch: 290 | Iter: 176400 | Total Loss: 0.004873 | Recon Loss: 0.003873 | Commit Loss: 0.002002 | Perplexity: 395.150981
2025-09-29 13:07:28,199 Stage: Train 0.5 | Epoch: 290 | Iter: 176600 | Total Loss: 0.004869 | Recon Loss: 0.003867 | Commit Loss: 0.002004 | Perplexity: 395.198961
2025-09-29 13:10:52,009 Stage: Train 0.5 | Epoch: 290 | Iter: 176800 | Total Loss: 0.004860 | Recon Loss: 0.003861 | Commit Loss: 0.001999 | Perplexity: 394.957809
Trainning Epoch:  35%|███▌      | 291/823 [50:00:43<91:41:13, 620.44s/it]Trainning Epoch:  35%|███▌      | 291/823 [50:00:43<91:41:17, 620.45s/it]Trainning Epoch:  35%|███▌      | 291/823 [50:00:43<91:41:17, 620.45s/it]Trainning Epoch:  35%|███▌      | 291/823 [50:00:43<91:41:18, 620.45s/it]2025-09-29 13:14:19,086 Stage: Train 0.5 | Epoch: 291 | Iter: 177000 | Total Loss: 0.004883 | Recon Loss: 0.003889 | Commit Loss: 0.001989 | Perplexity: 395.757765
2025-09-29 13:17:42,317 Stage: Train 0.5 | Epoch: 291 | Iter: 177200 | Total Loss: 0.004823 | Recon Loss: 0.003825 | Commit Loss: 0.001996 | Perplexity: 396.249695
2025-09-29 13:21:05,936 Stage: Train 0.5 | Epoch: 291 | Iter: 177400 | Total Loss: 0.004827 | Recon Loss: 0.003835 | Commit Loss: 0.001985 | Perplexity: 395.482911
Trainning Epoch:  35%|███▌      | 292/823 [50:11:05<91:35:25, 620.95s/it]Trainning Epoch:  35%|███▌      | 292/823 [50:11:05<91:35:19, 620.94s/it]Trainning Epoch:  35%|███▌      | 292/823 [50:11:05<91:35:19, 620.94s/it]Trainning Epoch:  35%|███▌      | 292/823 [50:11:05<91:35:19, 620.94s/it]2025-09-29 13:24:32,727 Stage: Train 0.5 | Epoch: 292 | Iter: 177600 | Total Loss: 0.004854 | Recon Loss: 0.003865 | Commit Loss: 0.001979 | Perplexity: 395.698573
2025-09-29 13:27:55,461 Stage: Train 0.5 | Epoch: 292 | Iter: 177800 | Total Loss: 0.004868 | Recon Loss: 0.003871 | Commit Loss: 0.001994 | Perplexity: 396.739312
2025-09-29 13:31:17,890 Stage: Train 0.5 | Epoch: 292 | Iter: 178000 | Total Loss: 0.004870 | Recon Loss: 0.003877 | Commit Loss: 0.001987 | Perplexity: 396.477271
Trainning Epoch:  36%|███▌      | 293/823 [50:21:24<91:20:27, 620.43s/it]Trainning Epoch:  36%|███▌      | 293/823 [50:21:24<91:20:23, 620.42s/it]Trainning Epoch:  36%|███▌      | 293/823 [50:21:24<91:20:25, 620.43s/it]Trainning Epoch:  36%|███▌      | 293/823 [50:21:24<91:20:26, 620.43s/it]2025-09-29 13:34:44,048 Stage: Train 0.5 | Epoch: 293 | Iter: 178200 | Total Loss: 0.004826 | Recon Loss: 0.003843 | Commit Loss: 0.001966 | Perplexity: 396.320867
2025-09-29 13:38:06,433 Stage: Train 0.5 | Epoch: 293 | Iter: 178400 | Total Loss: 0.004850 | Recon Loss: 0.003850 | Commit Loss: 0.001999 | Perplexity: 396.470604
2025-09-29 13:41:28,532 Stage: Train 0.5 | Epoch: 293 | Iter: 178600 | Total Loss: 0.004864 | Recon Loss: 0.003867 | Commit Loss: 0.001992 | Perplexity: 396.571334
Trainning Epoch:  36%|███▌      | 294/823 [50:31:43<91:06:35, 620.03s/it]Trainning Epoch:  36%|███▌      | 294/823 [50:31:43<91:06:38, 620.04s/it]Trainning Epoch:  36%|███▌      | 294/823 [50:31:43<91:06:37, 620.03s/it]Trainning Epoch:  36%|███▌      | 294/823 [50:31:43<91:06:37, 620.03s/it]2025-09-29 13:44:54,625 Stage: Train 0.5 | Epoch: 294 | Iter: 178800 | Total Loss: 0.004849 | Recon Loss: 0.003852 | Commit Loss: 0.001994 | Perplexity: 396.292117
2025-09-29 13:48:16,258 Stage: Train 0.5 | Epoch: 294 | Iter: 179000 | Total Loss: 0.004816 | Recon Loss: 0.003829 | Commit Loss: 0.001973 | Perplexity: 396.432870
2025-09-29 13:51:38,298 Stage: Train 0.5 | Epoch: 294 | Iter: 179200 | Total Loss: 0.004873 | Recon Loss: 0.003874 | Commit Loss: 0.001999 | Perplexity: 396.900123
Trainning Epoch:  36%|███▌      | 295/823 [50:42:00<90:48:10, 619.11s/it]Trainning Epoch:  36%|███▌      | 295/823 [50:42:00<90:48:10, 619.11s/it]Trainning Epoch:  36%|███▌      | 295/823 [50:42:00<90:48:11, 619.11s/it]Trainning Epoch:  36%|███▌      | 295/823 [50:42:00<90:48:09, 619.11s/it]2025-09-29 13:55:03,500 Stage: Train 0.5 | Epoch: 295 | Iter: 179400 | Total Loss: 0.004849 | Recon Loss: 0.003856 | Commit Loss: 0.001986 | Perplexity: 395.798171
2025-09-29 13:58:24,961 Stage: Train 0.5 | Epoch: 295 | Iter: 179600 | Total Loss: 0.004855 | Recon Loss: 0.003861 | Commit Loss: 0.001988 | Perplexity: 396.429741
2025-09-29 14:01:46,457 Stage: Train 0.5 | Epoch: 295 | Iter: 179800 | Total Loss: 0.004832 | Recon Loss: 0.003844 | Commit Loss: 0.001976 | Perplexity: 395.844498
Trainning Epoch:  36%|███▌      | 296/823 [50:52:16<90:29:50, 618.20s/it]Trainning Epoch:  36%|███▌      | 296/823 [50:52:16<90:29:55, 618.21s/it]Trainning Epoch:  36%|███▌      | 296/823 [50:52:16<90:29:52, 618.20s/it]Trainning Epoch:  36%|███▌      | 296/823 [50:52:16<90:29:53, 618.20s/it]2025-09-29 14:05:12,080 Stage: Train 0.5 | Epoch: 296 | Iter: 180000 | Total Loss: 0.004846 | Recon Loss: 0.003848 | Commit Loss: 0.001995 | Perplexity: 396.530048
2025-09-29 14:05:12,080 Saving model at iteration 180000
2025-09-29 14:05:12,591 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_297_step_180000
2025-09-29 14:05:13,240 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_297_step_180000/model.safetensors
2025-09-29 14:05:13,862 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_297_step_180000/optimizer.bin
2025-09-29 14:05:13,862 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_297_step_180000/scheduler.bin
2025-09-29 14:05:13,863 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_297_step_180000/sampler.bin
2025-09-29 14:05:13,864 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_297_step_180000/random_states_0.pkl
2025-09-29 14:08:37,205 Stage: Train 0.5 | Epoch: 296 | Iter: 180200 | Total Loss: 0.004828 | Recon Loss: 0.003829 | Commit Loss: 0.001997 | Perplexity: 397.316029
2025-09-29 14:12:00,427 Stage: Train 0.5 | Epoch: 296 | Iter: 180400 | Total Loss: 0.004857 | Recon Loss: 0.003864 | Commit Loss: 0.001987 | Perplexity: 396.357569
Trainning Epoch:  36%|███▌      | 297/823 [51:02:40<90:33:24, 619.78s/it]Trainning Epoch:  36%|███▌      | 297/823 [51:02:40<90:33:27, 619.79s/it]Trainning Epoch:  36%|███▌      | 297/823 [51:02:40<90:33:29, 619.79s/it]Trainning Epoch:  36%|███▌      | 297/823 [51:02:40<90:33:29, 619.79s/it]2025-09-29 14:15:27,732 Stage: Train 0.5 | Epoch: 297 | Iter: 180600 | Total Loss: 0.004851 | Recon Loss: 0.003851 | Commit Loss: 0.002000 | Perplexity: 396.810020
2025-09-29 14:18:47,968 Stage: Train 0.5 | Epoch: 297 | Iter: 180800 | Total Loss: 0.004866 | Recon Loss: 0.003871 | Commit Loss: 0.001991 | Perplexity: 395.967231
2025-09-29 14:22:09,087 Stage: Train 0.5 | Epoch: 297 | Iter: 181000 | Total Loss: 0.004815 | Recon Loss: 0.003825 | Commit Loss: 0.001980 | Perplexity: 397.115201
Trainning Epoch:  36%|███▌      | 298/823 [51:12:55<90:11:09, 618.42s/it]Trainning Epoch:  36%|███▌      | 298/823 [51:12:55<90:11:05, 618.41s/it]Trainning Epoch:  36%|███▌      | 298/823 [51:12:55<90:11:06, 618.41s/it]Trainning Epoch:  36%|███▌      | 298/823 [51:12:55<90:11:07, 618.41s/it]2025-09-29 14:25:34,240 Stage: Train 0.5 | Epoch: 298 | Iter: 181200 | Total Loss: 0.004837 | Recon Loss: 0.003841 | Commit Loss: 0.001992 | Perplexity: 396.014262
2025-09-29 14:28:56,005 Stage: Train 0.5 | Epoch: 298 | Iter: 181400 | Total Loss: 0.004832 | Recon Loss: 0.003834 | Commit Loss: 0.001995 | Perplexity: 397.076855
2025-09-29 14:32:17,598 Stage: Train 0.5 | Epoch: 298 | Iter: 181600 | Total Loss: 0.004801 | Recon Loss: 0.003812 | Commit Loss: 0.001978 | Perplexity: 396.296734
Trainning Epoch:  36%|███▋      | 299/823 [51:23:11<89:55:52, 617.85s/it]Trainning Epoch:  36%|███▋      | 299/823 [51:23:11<89:55:53, 617.85s/it]Trainning Epoch:  36%|███▋      | 299/823 [51:23:11<89:55:56, 617.86s/it]Trainning Epoch:  36%|███▋      | 299/823 [51:23:11<89:55:53, 617.85s/it]2025-09-29 14:35:42,626 Stage: Train 0.5 | Epoch: 299 | Iter: 181800 | Total Loss: 0.004853 | Recon Loss: 0.003860 | Commit Loss: 0.001985 | Perplexity: 396.840796
2025-09-29 14:39:05,800 Stage: Train 0.5 | Epoch: 299 | Iter: 182000 | Total Loss: 0.004804 | Recon Loss: 0.003808 | Commit Loss: 0.001991 | Perplexity: 395.716783
2025-09-29 14:42:29,290 Stage: Train 0.5 | Epoch: 299 | Iter: 182200 | Total Loss: 0.004822 | Recon Loss: 0.003831 | Commit Loss: 0.001983 | Perplexity: 396.608635
2025-09-29 14:45:52,474 Stage: Train 0.5 | Epoch: 299 | Iter: 182400 | Total Loss: 0.004841 | Recon Loss: 0.003851 | Commit Loss: 0.001981 | Perplexity: 396.259026
Trainning Epoch:  36%|███▋      | 300/823 [51:33:33<89:55:08, 618.94s/it]Trainning Epoch:  36%|███▋      | 300/823 [51:33:33<89:55:10, 618.95s/it]Trainning Epoch:  36%|███▋      | 300/823 [51:33:33<89:55:11, 618.95s/it]Trainning Epoch:  36%|███▋      | 300/823 [51:33:33<89:55:11, 618.95s/it]2025-09-29 14:49:18,045 Stage: Train 0.5 | Epoch: 300 | Iter: 182600 | Total Loss: 0.004803 | Recon Loss: 0.003813 | Commit Loss: 0.001981 | Perplexity: 396.576675
2025-09-29 14:52:40,755 Stage: Train 0.5 | Epoch: 300 | Iter: 182800 | Total Loss: 0.004845 | Recon Loss: 0.003859 | Commit Loss: 0.001974 | Perplexity: 396.216257
2025-09-29 14:56:03,503 Stage: Train 0.5 | Epoch: 300 | Iter: 183000 | Total Loss: 0.004808 | Recon Loss: 0.003814 | Commit Loss: 0.001986 | Perplexity: 395.327255
Trainning Epoch:  37%|███▋      | 301/823 [51:43:52<89:45:12, 618.99s/it]Trainning Epoch:  37%|███▋      | 301/823 [51:43:52<89:45:20, 619.00s/it]Trainning Epoch:  37%|███▋      | 301/823 [51:43:52<89:45:19, 619.00s/it]Trainning Epoch:  37%|███▋      | 301/823 [51:43:52<89:45:19, 619.00s/it]2025-09-29 14:59:30,550 Stage: Train 0.5 | Epoch: 301 | Iter: 183200 | Total Loss: 0.004790 | Recon Loss: 0.003802 | Commit Loss: 0.001977 | Perplexity: 396.468321
2025-09-29 15:02:54,079 Stage: Train 0.5 | Epoch: 301 | Iter: 183400 | Total Loss: 0.004785 | Recon Loss: 0.003796 | Commit Loss: 0.001978 | Perplexity: 396.097585
2025-09-29 15:06:17,602 Stage: Train 0.5 | Epoch: 301 | Iter: 183600 | Total Loss: 0.004862 | Recon Loss: 0.003864 | Commit Loss: 0.001994 | Perplexity: 396.533376
Trainning Epoch:  37%|███▋      | 302/823 [51:54:14<89:43:20, 619.96s/it]Trainning Epoch:  37%|███▋      | 302/823 [51:54:14<89:43:21, 619.96s/it]Trainning Epoch:  37%|███▋      | 302/823 [51:54:14<89:43:21, 619.97s/it]Trainning Epoch:  37%|███▋      | 302/823 [51:54:14<89:43:21, 619.96s/it]2025-09-29 15:09:43,825 Stage: Train 0.5 | Epoch: 302 | Iter: 183800 | Total Loss: 0.004816 | Recon Loss: 0.003823 | Commit Loss: 0.001987 | Perplexity: 396.662630
2025-09-29 15:13:07,245 Stage: Train 0.5 | Epoch: 302 | Iter: 184000 | Total Loss: 0.004807 | Recon Loss: 0.003821 | Commit Loss: 0.001971 | Perplexity: 396.121112
2025-09-29 15:16:30,113 Stage: Train 0.5 | Epoch: 302 | Iter: 184200 | Total Loss: 0.004824 | Recon Loss: 0.003824 | Commit Loss: 0.002000 | Perplexity: 397.042514
Trainning Epoch:  37%|███▋      | 303/823 [52:04:35<89:34:39, 620.15s/it]Trainning Epoch:  37%|███▋      | 303/823 [52:04:35<89:34:39, 620.15s/it]Trainning Epoch:  37%|███▋      | 303/823 [52:04:35<89:34:39, 620.15s/it]Trainning Epoch:  37%|███▋      | 303/823 [52:04:35<89:34:39, 620.15s/it]2025-09-29 15:19:54,409 Stage: Train 0.5 | Epoch: 303 | Iter: 184400 | Total Loss: 0.004796 | Recon Loss: 0.003811 | Commit Loss: 0.001969 | Perplexity: 395.193523
2025-09-29 15:23:15,356 Stage: Train 0.5 | Epoch: 303 | Iter: 184600 | Total Loss: 0.004783 | Recon Loss: 0.003795 | Commit Loss: 0.001977 | Perplexity: 396.306536
2025-09-29 15:26:36,169 Stage: Train 0.5 | Epoch: 303 | Iter: 184800 | Total Loss: 0.004826 | Recon Loss: 0.003834 | Commit Loss: 0.001985 | Perplexity: 397.681709
Trainning Epoch:  37%|███▋      | 304/823 [52:14:48<89:07:39, 618.23s/it]Trainning Epoch:  37%|███▋      | 304/823 [52:14:48<89:07:44, 618.24s/it]Trainning Epoch:  37%|███▋      | 304/823 [52:14:49<89:07:46, 618.24s/it]Trainning Epoch:  37%|███▋      | 304/823 [52:14:49<89:07:47, 618.24s/it]2025-09-29 15:30:00,550 Stage: Train 0.5 | Epoch: 304 | Iter: 185000 | Total Loss: 0.004768 | Recon Loss: 0.003779 | Commit Loss: 0.001979 | Perplexity: 396.334498
2025-09-29 15:33:21,868 Stage: Train 0.5 | Epoch: 304 | Iter: 185200 | Total Loss: 0.004801 | Recon Loss: 0.003812 | Commit Loss: 0.001979 | Perplexity: 396.696570
2025-09-29 15:36:43,144 Stage: Train 0.5 | Epoch: 304 | Iter: 185400 | Total Loss: 0.004857 | Recon Loss: 0.003861 | Commit Loss: 0.001992 | Perplexity: 396.901375
Trainning Epoch:  37%|███▋      | 305/823 [52:25:04<88:50:03, 617.38s/it]Trainning Epoch:  37%|███▋      | 305/823 [52:25:04<88:50:01, 617.38s/it]Trainning Epoch:  37%|███▋      | 305/823 [52:25:04<88:50:00, 617.37s/it]Trainning Epoch:  37%|███▋      | 305/823 [52:25:04<88:50:00, 617.38s/it]2025-09-29 15:40:10,562 Stage: Train 0.5 | Epoch: 305 | Iter: 185600 | Total Loss: 0.004780 | Recon Loss: 0.003788 | Commit Loss: 0.001984 | Perplexity: 396.851418
2025-09-29 15:43:34,006 Stage: Train 0.5 | Epoch: 305 | Iter: 185800 | Total Loss: 0.004800 | Recon Loss: 0.003806 | Commit Loss: 0.001989 | Perplexity: 396.205892
2025-09-29 15:46:57,198 Stage: Train 0.5 | Epoch: 305 | Iter: 186000 | Total Loss: 0.004813 | Recon Loss: 0.003826 | Commit Loss: 0.001974 | Perplexity: 396.347436
Trainning Epoch:  37%|███▋      | 306/823 [52:35:26<88:52:30, 618.86s/it]Trainning Epoch:  37%|███▋      | 306/823 [52:35:26<88:52:30, 618.86s/it]Trainning Epoch:  37%|███▋      | 306/823 [52:35:26<88:52:30, 618.86s/it]Trainning Epoch:  37%|███▋      | 306/823 [52:35:26<88:52:32, 618.86s/it]2025-09-29 15:50:24,073 Stage: Train 0.5 | Epoch: 306 | Iter: 186200 | Total Loss: 0.004792 | Recon Loss: 0.003802 | Commit Loss: 0.001981 | Perplexity: 395.892393
2025-09-29 15:53:48,046 Stage: Train 0.5 | Epoch: 306 | Iter: 186400 | Total Loss: 0.004820 | Recon Loss: 0.003820 | Commit Loss: 0.002001 | Perplexity: 396.593488
2025-09-29 15:57:12,012 Stage: Train 0.5 | Epoch: 306 | Iter: 186600 | Total Loss: 0.004801 | Recon Loss: 0.003809 | Commit Loss: 0.001982 | Perplexity: 396.521774
Trainning Epoch:  37%|███▋      | 307/823 [52:45:49<88:53:18, 620.15s/it]Trainning Epoch:  37%|███▋      | 307/823 [52:45:49<88:53:18, 620.15s/it]Trainning Epoch:  37%|███▋      | 307/823 [52:45:49<88:53:18, 620.15s/it]Trainning Epoch:  37%|███▋      | 307/823 [52:45:49<88:53:19, 620.15s/it]2025-09-29 16:00:38,561 Stage: Train 0.5 | Epoch: 307 | Iter: 186800 | Total Loss: 0.004771 | Recon Loss: 0.003783 | Commit Loss: 0.001977 | Perplexity: 396.823734
2025-09-29 16:04:00,746 Stage: Train 0.5 | Epoch: 307 | Iter: 187000 | Total Loss: 0.004797 | Recon Loss: 0.003799 | Commit Loss: 0.001996 | Perplexity: 397.661114
2025-09-29 16:07:22,789 Stage: Train 0.5 | Epoch: 307 | Iter: 187200 | Total Loss: 0.004815 | Recon Loss: 0.003820 | Commit Loss: 0.001990 | Perplexity: 395.946079
Trainning Epoch:  37%|███▋      | 308/823 [52:56:08<88:38:21, 619.61s/it]Trainning Epoch:  37%|███▋      | 308/823 [52:56:08<88:38:21, 619.61s/it]Trainning Epoch:  37%|███▋      | 308/823 [52:56:08<88:38:21, 619.61s/it]Trainning Epoch:  37%|███▋      | 308/823 [52:56:08<88:38:22, 619.62s/it]2025-09-29 16:10:49,619 Stage: Train 0.5 | Epoch: 308 | Iter: 187400 | Total Loss: 0.004794 | Recon Loss: 0.003801 | Commit Loss: 0.001985 | Perplexity: 396.759993
2025-09-29 16:14:13,695 Stage: Train 0.5 | Epoch: 308 | Iter: 187600 | Total Loss: 0.004802 | Recon Loss: 0.003812 | Commit Loss: 0.001979 | Perplexity: 396.279286
2025-09-29 16:17:37,891 Stage: Train 0.5 | Epoch: 308 | Iter: 187800 | Total Loss: 0.004820 | Recon Loss: 0.003824 | Commit Loss: 0.001992 | Perplexity: 396.772179
Trainning Epoch:  38%|███▊      | 309/823 [53:06:31<88:38:27, 620.83s/it]Trainning Epoch:  38%|███▊      | 309/823 [53:06:31<88:38:29, 620.83s/it]Trainning Epoch:  38%|███▊      | 309/823 [53:06:31<88:38:29, 620.83s/it]Trainning Epoch:  38%|███▊      | 309/823 [53:06:31<88:38:29, 620.84s/it]2025-09-29 16:21:05,751 Stage: Train 0.5 | Epoch: 309 | Iter: 188000 | Total Loss: 0.004771 | Recon Loss: 0.003788 | Commit Loss: 0.001966 | Perplexity: 396.403772
2025-09-29 16:24:29,990 Stage: Train 0.5 | Epoch: 309 | Iter: 188200 | Total Loss: 0.004797 | Recon Loss: 0.003805 | Commit Loss: 0.001984 | Perplexity: 397.588652
2025-09-29 16:27:54,054 Stage: Train 0.5 | Epoch: 309 | Iter: 188400 | Total Loss: 0.004838 | Recon Loss: 0.003843 | Commit Loss: 0.001989 | Perplexity: 397.797332
Trainning Epoch:  38%|███▊      | 310/823 [53:16:56<88:36:39, 621.83s/it]Trainning Epoch:  38%|███▊      | 310/823 [53:16:56<88:36:39, 621.83s/it]Trainning Epoch:  38%|███▊      | 310/823 [53:16:56<88:36:43, 621.84s/it]Trainning Epoch:  38%|███▊      | 310/823 [53:16:56<88:36:40, 621.83s/it]2025-09-29 16:31:20,633 Stage: Train 0.5 | Epoch: 310 | Iter: 188600 | Total Loss: 0.004790 | Recon Loss: 0.003804 | Commit Loss: 0.001972 | Perplexity: 397.580768
2025-09-29 16:34:43,572 Stage: Train 0.5 | Epoch: 310 | Iter: 188800 | Total Loss: 0.004753 | Recon Loss: 0.003765 | Commit Loss: 0.001976 | Perplexity: 397.470936
2025-09-29 16:38:07,009 Stage: Train 0.5 | Epoch: 310 | Iter: 189000 | Total Loss: 0.004779 | Recon Loss: 0.003786 | Commit Loss: 0.001986 | Perplexity: 397.453312
Trainning Epoch:  38%|███▊      | 311/823 [53:27:17<88:24:32, 621.63s/it]Trainning Epoch:  38%|███▊      | 311/823 [53:27:17<88:24:29, 621.62s/it]Trainning Epoch:  38%|███▊      | 311/823 [53:27:17<88:24:32, 621.63s/it]Trainning Epoch:  38%|███▊      | 311/823 [53:27:17<88:24:32, 621.63s/it]2025-09-29 16:41:33,676 Stage: Train 0.5 | Epoch: 311 | Iter: 189200 | Total Loss: 0.004773 | Recon Loss: 0.003785 | Commit Loss: 0.001977 | Perplexity: 397.955267
2025-09-29 16:44:56,562 Stage: Train 0.5 | Epoch: 311 | Iter: 189400 | Total Loss: 0.004767 | Recon Loss: 0.003786 | Commit Loss: 0.001962 | Perplexity: 397.941660
2025-09-29 16:48:19,616 Stage: Train 0.5 | Epoch: 311 | Iter: 189600 | Total Loss: 0.004819 | Recon Loss: 0.003825 | Commit Loss: 0.001988 | Perplexity: 398.579310
Trainning Epoch:  38%|███▊      | 312/823 [53:37:37<88:11:12, 621.28s/it]Trainning Epoch:  38%|███▊      | 312/823 [53:37:37<88:11:14, 621.28s/it]Trainning Epoch:  38%|███▊      | 312/823 [53:37:37<88:11:14, 621.28s/it]Trainning Epoch:  38%|███▊      | 312/823 [53:37:37<88:11:15, 621.28s/it]2025-09-29 16:51:44,896 Stage: Train 0.5 | Epoch: 312 | Iter: 189800 | Total Loss: 0.004776 | Recon Loss: 0.003793 | Commit Loss: 0.001966 | Perplexity: 398.331083
2025-09-29 16:55:06,845 Stage: Train 0.5 | Epoch: 312 | Iter: 190000 | Total Loss: 0.004734 | Recon Loss: 0.003750 | Commit Loss: 0.001969 | Perplexity: 397.027585
2025-09-29 16:58:29,546 Stage: Train 0.5 | Epoch: 312 | Iter: 190200 | Total Loss: 0.004788 | Recon Loss: 0.003800 | Commit Loss: 0.001977 | Perplexity: 397.157467
Trainning Epoch:  38%|███▊      | 313/823 [53:47:56<87:53:36, 620.43s/it]Trainning Epoch:  38%|███▊      | 313/823 [53:47:56<87:53:36, 620.43s/it]Trainning Epoch:  38%|███▊      | 313/823 [53:47:56<87:53:36, 620.43s/it]Trainning Epoch:  38%|███▊      | 313/823 [53:47:56<87:53:37, 620.43s/it]2025-09-29 17:01:55,456 Stage: Train 0.5 | Epoch: 313 | Iter: 190400 | Total Loss: 0.004761 | Recon Loss: 0.003771 | Commit Loss: 0.001981 | Perplexity: 398.710133
2025-09-29 17:05:18,019 Stage: Train 0.5 | Epoch: 313 | Iter: 190600 | Total Loss: 0.004786 | Recon Loss: 0.003793 | Commit Loss: 0.001987 | Perplexity: 398.154430
2025-09-29 17:08:40,665 Stage: Train 0.5 | Epoch: 313 | Iter: 190800 | Total Loss: 0.004755 | Recon Loss: 0.003770 | Commit Loss: 0.001970 | Perplexity: 396.715480
Trainning Epoch:  38%|███▊      | 314/823 [53:58:14<87:39:18, 619.96s/it]Trainning Epoch:  38%|███▊      | 314/823 [53:58:14<87:39:22, 619.97s/it]Trainning Epoch:  38%|███▊      | 314/823 [53:58:14<87:39:26, 619.97s/it]Trainning Epoch:  38%|███▊      | 314/823 [53:58:14<87:39:22, 619.97s/it]2025-09-29 17:12:06,498 Stage: Train 0.5 | Epoch: 314 | Iter: 191000 | Total Loss: 0.004763 | Recon Loss: 0.003775 | Commit Loss: 0.001974 | Perplexity: 397.193600
2025-09-29 17:15:28,528 Stage: Train 0.5 | Epoch: 314 | Iter: 191200 | Total Loss: 0.004774 | Recon Loss: 0.003785 | Commit Loss: 0.001978 | Perplexity: 398.793782
2025-09-29 17:18:50,280 Stage: Train 0.5 | Epoch: 314 | Iter: 191400 | Total Loss: 0.004744 | Recon Loss: 0.003757 | Commit Loss: 0.001974 | Perplexity: 397.107547
Trainning Epoch:  38%|███▊      | 315/823 [54:08:32<87:22:43, 619.22s/it]Trainning Epoch:  38%|███▊      | 315/823 [54:08:32<87:22:47, 619.23s/it]Trainning Epoch:  38%|███▊      | 315/823 [54:08:32<87:22:45, 619.22s/it]Trainning Epoch:  38%|███▊      | 315/823 [54:08:32<87:22:45, 619.22s/it]2025-09-29 17:22:16,406 Stage: Train 0.5 | Epoch: 315 | Iter: 191600 | Total Loss: 0.004772 | Recon Loss: 0.003783 | Commit Loss: 0.001979 | Perplexity: 398.052829
2025-09-29 17:25:39,656 Stage: Train 0.5 | Epoch: 315 | Iter: 191800 | Total Loss: 0.004738 | Recon Loss: 0.003752 | Commit Loss: 0.001973 | Perplexity: 397.281692
2025-09-29 17:29:02,728 Stage: Train 0.5 | Epoch: 315 | Iter: 192000 | Total Loss: 0.004782 | Recon Loss: 0.003794 | Commit Loss: 0.001976 | Perplexity: 398.372471
Trainning Epoch:  38%|███▊      | 316/823 [54:18:53<87:16:53, 619.75s/it]Trainning Epoch:  38%|███▊      | 316/823 [54:18:53<87:16:59, 619.76s/it]Trainning Epoch:  38%|███▊      | 316/823 [54:18:53<87:16:57, 619.76s/it]Trainning Epoch:  38%|███▊      | 316/823 [54:18:53<87:16:58, 619.76s/it]2025-09-29 17:32:29,332 Stage: Train 0.5 | Epoch: 316 | Iter: 192200 | Total Loss: 0.004762 | Recon Loss: 0.003776 | Commit Loss: 0.001971 | Perplexity: 397.411777
2025-09-29 17:35:51,107 Stage: Train 0.5 | Epoch: 316 | Iter: 192400 | Total Loss: 0.004753 | Recon Loss: 0.003773 | Commit Loss: 0.001960 | Perplexity: 397.127692
2025-09-29 17:39:13,266 Stage: Train 0.5 | Epoch: 316 | Iter: 192600 | Total Loss: 0.004754 | Recon Loss: 0.003769 | Commit Loss: 0.001970 | Perplexity: 397.680292
Trainning Epoch:  39%|███▊      | 317/823 [54:29:11<87:03:12, 619.35s/it]Trainning Epoch:  39%|███▊      | 317/823 [54:29:11<87:03:14, 619.36s/it]Trainning Epoch:  39%|███▊      | 317/823 [54:29:11<87:03:16, 619.36s/it]Trainning Epoch:  39%|███▊      | 317/823 [54:29:11<87:03:15, 619.36s/it]2025-09-29 17:42:39,502 Stage: Train 0.5 | Epoch: 317 | Iter: 192800 | Total Loss: 0.004720 | Recon Loss: 0.003737 | Commit Loss: 0.001966 | Perplexity: 397.187122
2025-09-29 17:46:00,955 Stage: Train 0.5 | Epoch: 317 | Iter: 193000 | Total Loss: 0.004778 | Recon Loss: 0.003788 | Commit Loss: 0.001980 | Perplexity: 398.619462
2025-09-29 17:49:23,033 Stage: Train 0.5 | Epoch: 317 | Iter: 193200 | Total Loss: 0.004767 | Recon Loss: 0.003780 | Commit Loss: 0.001974 | Perplexity: 397.904554
Trainning Epoch:  39%|███▊      | 318/823 [54:39:29<86:47:12, 618.68s/it]Trainning Epoch:  39%|███▊      | 318/823 [54:39:29<86:47:15, 618.68s/it]Trainning Epoch:  39%|███▊      | 318/823 [54:39:29<86:47:13, 618.68s/it]Trainning Epoch:  39%|███▊      | 318/823 [54:39:28<86:47:13, 618.68s/it]2025-09-29 17:52:48,782 Stage: Train 0.5 | Epoch: 318 | Iter: 193400 | Total Loss: 0.004798 | Recon Loss: 0.003807 | Commit Loss: 0.001982 | Perplexity: 398.594066
2025-09-29 17:56:12,705 Stage: Train 0.5 | Epoch: 318 | Iter: 193600 | Total Loss: 0.004722 | Recon Loss: 0.003745 | Commit Loss: 0.001953 | Perplexity: 397.324974
2025-09-29 17:59:36,605 Stage: Train 0.5 | Epoch: 318 | Iter: 193800 | Total Loss: 0.004729 | Recon Loss: 0.003741 | Commit Loss: 0.001976 | Perplexity: 396.895547
Trainning Epoch:  39%|███▉      | 319/823 [54:49:52<86:49:17, 620.15s/it]Trainning Epoch:  39%|███▉      | 319/823 [54:49:52<86:49:19, 620.16s/it]Trainning Epoch:  39%|███▉      | 319/823 [54:49:52<86:49:21, 620.16s/it]Trainning Epoch:  39%|███▉      | 319/823 [54:49:52<86:49:19, 620.16s/it]2025-09-29 18:03:03,914 Stage: Train 0.5 | Epoch: 319 | Iter: 194000 | Total Loss: 0.004736 | Recon Loss: 0.003756 | Commit Loss: 0.001959 | Perplexity: 396.616277
2025-09-29 18:06:25,084 Stage: Train 0.5 | Epoch: 319 | Iter: 194200 | Total Loss: 0.004721 | Recon Loss: 0.003730 | Commit Loss: 0.001983 | Perplexity: 398.482855
2025-09-29 18:09:46,251 Stage: Train 0.5 | Epoch: 319 | Iter: 194400 | Total Loss: 0.004739 | Recon Loss: 0.003754 | Commit Loss: 0.001969 | Perplexity: 397.972755
Trainning Epoch:  39%|███▉      | 320/823 [55:00:08<86:28:28, 618.90s/it]Trainning Epoch:  39%|███▉      | 320/823 [55:00:08<86:28:29, 618.91s/it]Trainning Epoch:  39%|███▉      | 320/823 [55:00:08<86:28:30, 618.91s/it]Trainning Epoch:  39%|███▉      | 320/823 [55:00:08<86:28:29, 618.91s/it]2025-09-29 18:13:12,216 Stage: Train 0.5 | Epoch: 320 | Iter: 194600 | Total Loss: 0.004726 | Recon Loss: 0.003745 | Commit Loss: 0.001961 | Perplexity: 396.628790
2025-09-29 18:16:35,109 Stage: Train 0.5 | Epoch: 320 | Iter: 194800 | Total Loss: 0.004731 | Recon Loss: 0.003750 | Commit Loss: 0.001963 | Perplexity: 398.144671
2025-09-29 18:19:58,361 Stage: Train 0.5 | Epoch: 320 | Iter: 195000 | Total Loss: 0.004723 | Recon Loss: 0.003739 | Commit Loss: 0.001968 | Perplexity: 397.331878
Trainning Epoch:  39%|███▉      | 321/823 [55:10:29<86:23:29, 619.54s/it]Trainning Epoch:  39%|███▉      | 321/823 [55:10:29<86:23:25, 619.53s/it]Trainning Epoch:  39%|███▉      | 321/823 [55:10:29<86:23:26, 619.54s/it]Trainning Epoch:  39%|███▉      | 321/823 [55:10:29<86:23:28, 619.54s/it]2025-09-29 18:23:24,634 Stage: Train 0.5 | Epoch: 321 | Iter: 195200 | Total Loss: 0.004757 | Recon Loss: 0.003771 | Commit Loss: 0.001973 | Perplexity: 397.993008
2025-09-29 18:26:46,637 Stage: Train 0.5 | Epoch: 321 | Iter: 195400 | Total Loss: 0.004704 | Recon Loss: 0.003721 | Commit Loss: 0.001966 | Perplexity: 398.060240
2025-09-29 18:30:08,211 Stage: Train 0.5 | Epoch: 321 | Iter: 195600 | Total Loss: 0.004739 | Recon Loss: 0.003758 | Commit Loss: 0.001962 | Perplexity: 397.502544
Trainning Epoch:  39%|███▉      | 322/823 [55:20:46<86:06:04, 618.69s/it]Trainning Epoch:  39%|███▉      | 322/823 [55:20:46<86:06:02, 618.69s/it]Trainning Epoch:  39%|███▉      | 322/823 [55:20:46<86:06:04, 618.69s/it]Trainning Epoch:  39%|███▉      | 322/823 [55:20:46<86:06:05, 618.69s/it]2025-09-29 18:33:33,297 Stage: Train 0.5 | Epoch: 322 | Iter: 195800 | Total Loss: 0.004710 | Recon Loss: 0.003732 | Commit Loss: 0.001955 | Perplexity: 397.973515
2025-09-29 18:36:53,961 Stage: Train 0.5 | Epoch: 322 | Iter: 196000 | Total Loss: 0.004720 | Recon Loss: 0.003741 | Commit Loss: 0.001957 | Perplexity: 397.674654
2025-09-29 18:40:15,853 Stage: Train 0.5 | Epoch: 322 | Iter: 196200 | Total Loss: 0.004747 | Recon Loss: 0.003755 | Commit Loss: 0.001984 | Perplexity: 398.320463
Trainning Epoch:  39%|███▉      | 323/823 [55:31:02<85:48:18, 617.80s/it]Trainning Epoch:  39%|███▉      | 323/823 [55:31:01<85:48:14, 617.79s/it]Trainning Epoch:  39%|███▉      | 323/823 [55:31:02<85:48:16, 617.79s/it]Trainning Epoch:  39%|███▉      | 323/823 [55:31:02<85:48:17, 617.80s/it]2025-09-29 18:43:41,296 Stage: Train 0.5 | Epoch: 323 | Iter: 196400 | Total Loss: 0.004727 | Recon Loss: 0.003745 | Commit Loss: 0.001963 | Perplexity: 397.209776
2025-09-29 18:47:02,625 Stage: Train 0.5 | Epoch: 323 | Iter: 196600 | Total Loss: 0.004696 | Recon Loss: 0.003720 | Commit Loss: 0.001952 | Perplexity: 397.819212
2025-09-29 18:50:23,844 Stage: Train 0.5 | Epoch: 323 | Iter: 196800 | Total Loss: 0.004727 | Recon Loss: 0.003740 | Commit Loss: 0.001975 | Perplexity: 397.634587
Trainning Epoch:  39%|███▉      | 324/823 [55:41:18<85:34:45, 617.40s/it]Trainning Epoch:  39%|███▉      | 324/823 [55:41:18<85:34:45, 617.41s/it]Trainning Epoch:  39%|███▉      | 324/823 [55:41:18<85:34:46, 617.41s/it]Trainning Epoch:  39%|███▉      | 324/823 [55:41:18<85:34:46, 617.41s/it]2025-09-29 18:53:49,530 Stage: Train 0.5 | Epoch: 324 | Iter: 197000 | Total Loss: 0.004748 | Recon Loss: 0.003759 | Commit Loss: 0.001977 | Perplexity: 398.562458
2025-09-29 18:57:11,747 Stage: Train 0.5 | Epoch: 324 | Iter: 197200 | Total Loss: 0.004690 | Recon Loss: 0.003710 | Commit Loss: 0.001960 | Perplexity: 398.397166
2025-09-29 19:00:34,067 Stage: Train 0.5 | Epoch: 324 | Iter: 197400 | Total Loss: 0.004732 | Recon Loss: 0.003747 | Commit Loss: 0.001969 | Perplexity: 397.733497
2025-09-29 19:03:56,342 Stage: Train 0.5 | Epoch: 324 | Iter: 197600 | Total Loss: 0.004719 | Recon Loss: 0.003732 | Commit Loss: 0.001974 | Perplexity: 397.620503
Trainning Epoch:  39%|███▉      | 325/823 [55:51:37<85:27:32, 617.78s/it]Trainning Epoch:  39%|███▉      | 325/823 [55:51:37<85:27:33, 617.78s/it]Trainning Epoch:  39%|███▉      | 325/823 [55:51:37<85:27:33, 617.78s/it]Trainning Epoch:  39%|███▉      | 325/823 [55:51:37<85:27:34, 617.78s/it]2025-09-29 19:07:23,787 Stage: Train 0.5 | Epoch: 325 | Iter: 197800 | Total Loss: 0.004738 | Recon Loss: 0.003753 | Commit Loss: 0.001969 | Perplexity: 397.614668
2025-09-29 19:10:47,369 Stage: Train 0.5 | Epoch: 325 | Iter: 198000 | Total Loss: 0.004705 | Recon Loss: 0.003723 | Commit Loss: 0.001963 | Perplexity: 397.541704
2025-09-29 19:14:10,368 Stage: Train 0.5 | Epoch: 325 | Iter: 198200 | Total Loss: 0.004711 | Recon Loss: 0.003731 | Commit Loss: 0.001960 | Perplexity: 397.774815
Trainning Epoch:  40%|███▉      | 326/823 [56:01:59<85:28:02, 619.08s/it]Trainning Epoch:  40%|███▉      | 326/823 [56:01:59<85:28:03, 619.08s/it]Trainning Epoch:  40%|███▉      | 326/823 [56:01:59<85:28:03, 619.08s/it]Trainning Epoch:  40%|███▉      | 326/823 [56:01:59<85:28:02, 619.08s/it]2025-09-29 19:17:37,749 Stage: Train 0.5 | Epoch: 326 | Iter: 198400 | Total Loss: 0.004707 | Recon Loss: 0.003725 | Commit Loss: 0.001963 | Perplexity: 397.206177
2025-09-29 19:21:01,094 Stage: Train 0.5 | Epoch: 326 | Iter: 198600 | Total Loss: 0.004726 | Recon Loss: 0.003738 | Commit Loss: 0.001975 | Perplexity: 397.767768
2025-09-29 19:24:24,512 Stage: Train 0.5 | Epoch: 326 | Iter: 198800 | Total Loss: 0.004716 | Recon Loss: 0.003731 | Commit Loss: 0.001970 | Perplexity: 398.127995
Trainning Epoch:  40%|███▉      | 327/823 [56:12:21<85:25:28, 620.02s/it]Trainning Epoch:  40%|███▉      | 327/823 [56:12:21<85:25:29, 620.02s/it]Trainning Epoch:  40%|███▉      | 327/823 [56:12:21<85:25:29, 620.02s/it]Trainning Epoch:  40%|███▉      | 327/823 [56:12:21<85:25:30, 620.02s/it]2025-09-29 19:27:51,838 Stage: Train 0.5 | Epoch: 327 | Iter: 199000 | Total Loss: 0.004710 | Recon Loss: 0.003730 | Commit Loss: 0.001960 | Perplexity: 398.631650
2025-09-29 19:31:14,653 Stage: Train 0.5 | Epoch: 327 | Iter: 199200 | Total Loss: 0.004731 | Recon Loss: 0.003739 | Commit Loss: 0.001984 | Perplexity: 398.200035
2025-09-29 19:34:37,577 Stage: Train 0.5 | Epoch: 327 | Iter: 199400 | Total Loss: 0.004769 | Recon Loss: 0.003776 | Commit Loss: 0.001985 | Perplexity: 398.347175
Trainning Epoch:  40%|███▉      | 328/823 [56:22:42<85:17:59, 620.36s/it]Trainning Epoch:  40%|███▉      | 328/823 [56:22:42<85:18:03, 620.37s/it]Trainning Epoch:  40%|███▉      | 328/823 [56:22:42<85:18:00, 620.36s/it]Trainning Epoch:  40%|███▉      | 328/823 [56:22:42<85:18:00, 620.36s/it]2025-09-29 19:38:03,951 Stage: Train 0.5 | Epoch: 328 | Iter: 199600 | Total Loss: 0.004707 | Recon Loss: 0.003724 | Commit Loss: 0.001966 | Perplexity: 397.659921
2025-09-29 19:41:27,088 Stage: Train 0.5 | Epoch: 328 | Iter: 199800 | Total Loss: 0.004716 | Recon Loss: 0.003735 | Commit Loss: 0.001963 | Perplexity: 397.321416
2025-09-29 19:44:50,688 Stage: Train 0.5 | Epoch: 328 | Iter: 200000 | Total Loss: 0.004732 | Recon Loss: 0.003745 | Commit Loss: 0.001975 | Perplexity: 398.136902
2025-09-29 19:44:50,689 Saving model at iteration 200000
2025-09-29 19:44:50,995 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_329_step_200000
2025-09-29 19:44:51,582 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_329_step_200000/model.safetensors
2025-09-29 19:44:52,138 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_329_step_200000/optimizer.bin
2025-09-29 19:44:52,138 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_329_step_200000/scheduler.bin
2025-09-29 19:44:52,138 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_329_step_200000/sampler.bin
2025-09-29 19:44:52,139 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_329_step_200000/random_states_0.pkl
Trainning Epoch:  40%|███▉      | 329/823 [56:33:06<85:15:06, 621.27s/it]Trainning Epoch:  40%|███▉      | 329/823 [56:33:06<85:15:08, 621.27s/it]Trainning Epoch:  40%|███▉      | 329/823 [56:33:06<85:15:08, 621.27s/it]Trainning Epoch:  40%|███▉      | 329/823 [56:33:06<85:15:09, 621.27s/it]2025-09-29 19:48:18,867 Stage: Train 0.5 | Epoch: 329 | Iter: 200200 | Total Loss: 0.004703 | Recon Loss: 0.003726 | Commit Loss: 0.001954 | Perplexity: 397.996653
2025-09-29 19:51:41,933 Stage: Train 0.5 | Epoch: 329 | Iter: 200400 | Total Loss: 0.004703 | Recon Loss: 0.003724 | Commit Loss: 0.001958 | Perplexity: 397.348167
2025-09-29 19:55:05,190 Stage: Train 0.5 | Epoch: 329 | Iter: 200600 | Total Loss: 0.004739 | Recon Loss: 0.003750 | Commit Loss: 0.001978 | Perplexity: 398.165128
Trainning Epoch:  40%|████      | 330/823 [56:43:26<85:03:01, 621.06s/it]Trainning Epoch:  40%|████      | 330/823 [56:43:26<85:03:03, 621.06s/it]Trainning Epoch:  40%|████      | 330/823 [56:43:26<85:03:06, 621.07s/it]Trainning Epoch:  40%|████      | 330/823 [56:43:26<85:03:03, 621.06s/it]2025-09-29 19:58:29,817 Stage: Train 0.5 | Epoch: 330 | Iter: 200800 | Total Loss: 0.004665 | Recon Loss: 0.003688 | Commit Loss: 0.001956 | Perplexity: 397.933250
2025-09-29 20:01:51,400 Stage: Train 0.5 | Epoch: 330 | Iter: 201000 | Total Loss: 0.004697 | Recon Loss: 0.003721 | Commit Loss: 0.001952 | Perplexity: 397.345493
2025-09-29 20:05:13,115 Stage: Train 0.5 | Epoch: 330 | Iter: 201200 | Total Loss: 0.004720 | Recon Loss: 0.003732 | Commit Loss: 0.001978 | Perplexity: 398.367736
Trainning Epoch:  40%|████      | 331/823 [56:53:42<84:40:01, 619.52s/it]Trainning Epoch:  40%|████      | 331/823 [56:53:42<84:40:02, 619.52s/it]Trainning Epoch:  40%|████      | 331/823 [56:53:42<84:40:03, 619.52s/it]Trainning Epoch:  40%|████      | 331/823 [56:53:42<84:40:03, 619.52s/it]2025-09-29 20:08:39,154 Stage: Train 0.5 | Epoch: 331 | Iter: 201400 | Total Loss: 0.004708 | Recon Loss: 0.003724 | Commit Loss: 0.001968 | Perplexity: 397.493543
2025-09-29 20:12:01,986 Stage: Train 0.5 | Epoch: 331 | Iter: 201600 | Total Loss: 0.004665 | Recon Loss: 0.003689 | Commit Loss: 0.001951 | Perplexity: 397.457315
2025-09-29 20:15:25,215 Stage: Train 0.5 | Epoch: 331 | Iter: 201800 | Total Loss: 0.004717 | Recon Loss: 0.003733 | Commit Loss: 0.001967 | Perplexity: 398.029229
Trainning Epoch:  40%|████      | 332/823 [57:04:02<84:31:13, 619.70s/it]Trainning Epoch:  40%|████      | 332/823 [57:04:02<84:31:16, 619.71s/it]Trainning Epoch:  40%|████      | 332/823 [57:04:02<84:31:15, 619.71s/it]Trainning Epoch:  40%|████      | 332/823 [57:04:02<84:31:15, 619.71s/it]2025-09-29 20:18:51,639 Stage: Train 0.5 | Epoch: 332 | Iter: 202000 | Total Loss: 0.004701 | Recon Loss: 0.003718 | Commit Loss: 0.001966 | Perplexity: 397.605536
2025-09-29 20:22:13,805 Stage: Train 0.5 | Epoch: 332 | Iter: 202200 | Total Loss: 0.004692 | Recon Loss: 0.003708 | Commit Loss: 0.001968 | Perplexity: 398.148654
2025-09-29 20:25:35,975 Stage: Train 0.5 | Epoch: 332 | Iter: 202400 | Total Loss: 0.004716 | Recon Loss: 0.003731 | Commit Loss: 0.001969 | Perplexity: 398.602366
Trainning Epoch:  40%|████      | 333/823 [57:14:21<84:18:37, 619.42s/it]Trainning Epoch:  40%|████      | 333/823 [57:14:21<84:18:35, 619.42s/it]Trainning Epoch:  40%|████      | 333/823 [57:14:21<84:18:36, 619.42s/it]Trainning Epoch:  40%|████      | 333/823 [57:14:21<84:18:37, 619.42s/it]2025-09-29 20:29:03,386 Stage: Train 0.5 | Epoch: 333 | Iter: 202600 | Total Loss: 0.004693 | Recon Loss: 0.003709 | Commit Loss: 0.001968 | Perplexity: 398.332527
2025-09-29 20:32:27,381 Stage: Train 0.5 | Epoch: 333 | Iter: 202800 | Total Loss: 0.004738 | Recon Loss: 0.003755 | Commit Loss: 0.001967 | Perplexity: 397.695954
2025-09-29 20:35:51,645 Stage: Train 0.5 | Epoch: 333 | Iter: 203000 | Total Loss: 0.004655 | Recon Loss: 0.003681 | Commit Loss: 0.001948 | Perplexity: 397.157627
Trainning Epoch:  41%|████      | 334/823 [57:24:45<84:20:05, 620.87s/it]Trainning Epoch:  41%|████      | 334/823 [57:24:45<84:20:07, 620.87s/it]Trainning Epoch:  41%|████      | 334/823 [57:24:45<84:20:08, 620.88s/it]Trainning Epoch:  41%|████      | 334/823 [57:24:45<84:20:08, 620.88s/it]2025-09-29 20:39:18,002 Stage: Train 0.5 | Epoch: 334 | Iter: 203200 | Total Loss: 0.004699 | Recon Loss: 0.003716 | Commit Loss: 0.001967 | Perplexity: 397.859992
2025-09-29 20:42:40,626 Stage: Train 0.5 | Epoch: 334 | Iter: 203400 | Total Loss: 0.004699 | Recon Loss: 0.003715 | Commit Loss: 0.001968 | Perplexity: 398.362075
2025-09-29 20:46:03,480 Stage: Train 0.5 | Epoch: 334 | Iter: 203600 | Total Loss: 0.004717 | Recon Loss: 0.003729 | Commit Loss: 0.001975 | Perplexity: 398.228116
Trainning Epoch:  41%|████      | 335/823 [57:35:05<84:06:10, 620.43s/it]Trainning Epoch:  41%|████      | 335/823 [57:35:05<84:06:08, 620.43s/it]Trainning Epoch:  41%|████      | 335/823 [57:35:05<84:06:10, 620.43s/it]Trainning Epoch:  41%|████      | 335/823 [57:35:05<84:06:09, 620.43s/it]2025-09-29 20:49:29,523 Stage: Train 0.5 | Epoch: 335 | Iter: 203800 | Total Loss: 0.004721 | Recon Loss: 0.003733 | Commit Loss: 0.001975 | Perplexity: 397.791539
2025-09-29 20:52:52,519 Stage: Train 0.5 | Epoch: 335 | Iter: 204000 | Total Loss: 0.004660 | Recon Loss: 0.003684 | Commit Loss: 0.001952 | Perplexity: 397.993267
2025-09-29 20:56:15,296 Stage: Train 0.5 | Epoch: 335 | Iter: 204200 | Total Loss: 0.004706 | Recon Loss: 0.003729 | Commit Loss: 0.001955 | Perplexity: 397.946558
Trainning Epoch:  41%|████      | 336/823 [57:45:25<83:55:32, 620.40s/it]Trainning Epoch:  41%|████      | 336/823 [57:45:25<83:55:34, 620.40s/it]Trainning Epoch:  41%|████      | 336/823 [57:45:25<83:55:36, 620.40s/it]Trainning Epoch:  41%|████      | 336/823 [57:45:25<83:55:34, 620.40s/it]2025-09-29 20:59:40,484 Stage: Train 0.5 | Epoch: 336 | Iter: 204400 | Total Loss: 0.004660 | Recon Loss: 0.003679 | Commit Loss: 0.001961 | Perplexity: 397.837696
2025-09-29 21:03:01,590 Stage: Train 0.5 | Epoch: 336 | Iter: 204600 | Total Loss: 0.004683 | Recon Loss: 0.003699 | Commit Loss: 0.001967 | Perplexity: 397.733460
2025-09-29 21:06:22,892 Stage: Train 0.5 | Epoch: 336 | Iter: 204800 | Total Loss: 0.004741 | Recon Loss: 0.003753 | Commit Loss: 0.001976 | Perplexity: 398.886287
Trainning Epoch:  41%|████      | 337/823 [57:55:40<83:32:38, 618.84s/it]Trainning Epoch:  41%|████      | 337/823 [57:55:40<83:32:37, 618.84s/it]Trainning Epoch:  41%|████      | 337/823 [57:55:40<83:32:38, 618.85s/it]Trainning Epoch:  41%|████      | 337/823 [57:55:40<83:32:38, 618.85s/it]2025-09-29 21:09:48,193 Stage: Train 0.5 | Epoch: 337 | Iter: 205000 | Total Loss: 0.004655 | Recon Loss: 0.003684 | Commit Loss: 0.001942 | Perplexity: 397.403251
2025-09-29 21:13:09,884 Stage: Train 0.5 | Epoch: 337 | Iter: 205200 | Total Loss: 0.004671 | Recon Loss: 0.003694 | Commit Loss: 0.001955 | Perplexity: 397.431800
2025-09-29 21:16:31,900 Stage: Train 0.5 | Epoch: 337 | Iter: 205400 | Total Loss: 0.004710 | Recon Loss: 0.003726 | Commit Loss: 0.001967 | Perplexity: 398.321582
Trainning Epoch:  41%|████      | 338/823 [58:05:57<83:18:36, 618.38s/it]Trainning Epoch:  41%|████      | 338/823 [58:05:57<83:18:38, 618.39s/it]Trainning Epoch:  41%|████      | 338/823 [58:05:57<83:18:38, 618.39s/it]Trainning Epoch:  41%|████      | 338/823 [58:05:57<83:18:39, 618.39s/it]2025-09-29 21:19:58,904 Stage: Train 0.5 | Epoch: 338 | Iter: 205600 | Total Loss: 0.004653 | Recon Loss: 0.003674 | Commit Loss: 0.001958 | Perplexity: 398.357688
2025-09-29 21:23:23,110 Stage: Train 0.5 | Epoch: 338 | Iter: 205800 | Total Loss: 0.004669 | Recon Loss: 0.003690 | Commit Loss: 0.001959 | Perplexity: 398.363130
2025-09-29 21:26:47,152 Stage: Train 0.5 | Epoch: 338 | Iter: 206000 | Total Loss: 0.004696 | Recon Loss: 0.003710 | Commit Loss: 0.001972 | Perplexity: 397.942686
Trainning Epoch:  41%|████      | 339/823 [58:16:22<83:22:16, 620.12s/it]Trainning Epoch:  41%|████      | 339/823 [58:16:22<83:22:18, 620.12s/it]Trainning Epoch:  41%|████      | 339/823 [58:16:22<83:22:18, 620.12s/it]Trainning Epoch:  41%|████      | 339/823 [58:16:22<83:22:19, 620.12s/it]2025-09-29 21:30:13,501 Stage: Train 0.5 | Epoch: 339 | Iter: 206200 | Total Loss: 0.004653 | Recon Loss: 0.003674 | Commit Loss: 0.001958 | Perplexity: 398.159713
2025-09-29 21:33:35,704 Stage: Train 0.5 | Epoch: 339 | Iter: 206400 | Total Loss: 0.004684 | Recon Loss: 0.003706 | Commit Loss: 0.001957 | Perplexity: 398.671931
2025-09-29 21:36:58,097 Stage: Train 0.5 | Epoch: 339 | Iter: 206600 | Total Loss: 0.004667 | Recon Loss: 0.003688 | Commit Loss: 0.001958 | Perplexity: 397.086642
Trainning Epoch:  41%|████▏     | 340/823 [58:26:40<83:08:47, 619.73s/it]Trainning Epoch:  41%|████▏     | 340/823 [58:26:40<83:08:45, 619.72s/it]Trainning Epoch:  41%|████▏     | 340/823 [58:26:40<83:08:47, 619.72s/it]Trainning Epoch:  41%|████▏     | 340/823 [58:26:40<83:08:47, 619.73s/it]2025-09-29 21:40:24,588 Stage: Train 0.5 | Epoch: 340 | Iter: 206800 | Total Loss: 0.004667 | Recon Loss: 0.003688 | Commit Loss: 0.001957 | Perplexity: 397.848416
2025-09-29 21:43:47,652 Stage: Train 0.5 | Epoch: 340 | Iter: 207000 | Total Loss: 0.004691 | Recon Loss: 0.003709 | Commit Loss: 0.001964 | Perplexity: 398.234273
2025-09-29 21:47:11,064 Stage: Train 0.5 | Epoch: 340 | Iter: 207200 | Total Loss: 0.004681 | Recon Loss: 0.003698 | Commit Loss: 0.001967 | Perplexity: 398.069641
Trainning Epoch:  41%|████▏     | 341/823 [58:37:02<83:01:56, 620.16s/it]Trainning Epoch:  41%|████▏     | 341/823 [58:37:02<83:01:53, 620.15s/it]Trainning Epoch:  41%|████▏     | 341/823 [58:37:02<83:01:55, 620.16s/it]Trainning Epoch:  41%|████▏     | 341/823 [58:37:02<83:01:56, 620.16s/it]2025-09-29 21:50:37,110 Stage: Train 0.5 | Epoch: 341 | Iter: 207400 | Total Loss: 0.004671 | Recon Loss: 0.003686 | Commit Loss: 0.001971 | Perplexity: 398.612588
2025-09-29 21:53:58,797 Stage: Train 0.5 | Epoch: 341 | Iter: 207600 | Total Loss: 0.004704 | Recon Loss: 0.003721 | Commit Loss: 0.001968 | Perplexity: 398.934521
2025-09-29 21:57:19,883 Stage: Train 0.5 | Epoch: 341 | Iter: 207800 | Total Loss: 0.004637 | Recon Loss: 0.003660 | Commit Loss: 0.001954 | Perplexity: 397.910853
Trainning Epoch:  42%|████▏     | 342/823 [58:47:17<82:40:36, 618.79s/it]Trainning Epoch:  42%|████▏     | 342/823 [58:47:17<82:40:36, 618.79s/it]Trainning Epoch:  42%|████▏     | 342/823 [58:47:17<82:40:39, 618.79s/it]Trainning Epoch:  42%|████▏     | 342/823 [58:47:17<82:40:37, 618.79s/it]2025-09-29 22:00:45,430 Stage: Train 0.5 | Epoch: 342 | Iter: 208000 | Total Loss: 0.004685 | Recon Loss: 0.003705 | Commit Loss: 0.001961 | Perplexity: 396.681310
2025-09-29 22:04:09,321 Stage: Train 0.5 | Epoch: 342 | Iter: 208200 | Total Loss: 0.004712 | Recon Loss: 0.003719 | Commit Loss: 0.001987 | Perplexity: 398.853978
2025-09-29 22:07:33,639 Stage: Train 0.5 | Epoch: 342 | Iter: 208400 | Total Loss: 0.004686 | Recon Loss: 0.003702 | Commit Loss: 0.001969 | Perplexity: 398.073007
Trainning Epoch:  42%|████▏     | 343/823 [58:57:41<82:41:46, 620.22s/it]Trainning Epoch:  42%|████▏     | 343/823 [58:57:41<82:41:48, 620.23s/it]Trainning Epoch:  42%|████▏     | 343/823 [58:57:41<82:41:48, 620.23s/it]Trainning Epoch:  42%|████▏     | 343/823 [58:57:41<82:41:48, 620.23s/it]2025-09-29 22:11:01,062 Stage: Train 0.5 | Epoch: 343 | Iter: 208600 | Total Loss: 0.004637 | Recon Loss: 0.003657 | Commit Loss: 0.001960 | Perplexity: 398.146496
2025-09-29 22:14:23,305 Stage: Train 0.5 | Epoch: 343 | Iter: 208800 | Total Loss: 0.004664 | Recon Loss: 0.003685 | Commit Loss: 0.001958 | Perplexity: 398.112907
2025-09-29 22:17:46,425 Stage: Train 0.5 | Epoch: 343 | Iter: 209000 | Total Loss: 0.004674 | Recon Loss: 0.003691 | Commit Loss: 0.001965 | Perplexity: 398.815275
Trainning Epoch:  42%|████▏     | 344/823 [59:08:00<82:29:39, 620.00s/it]Trainning Epoch:  42%|████▏     | 344/823 [59:08:00<82:29:42, 620.01s/it]Trainning Epoch:  42%|████▏     | 344/823 [59:08:00<82:29:42, 620.01s/it]Trainning Epoch:  42%|████▏     | 344/823 [59:08:00<82:29:42, 620.01s/it]2025-09-29 22:21:11,671 Stage: Train 0.5 | Epoch: 344 | Iter: 209200 | Total Loss: 0.004658 | Recon Loss: 0.003683 | Commit Loss: 0.001949 | Perplexity: 397.484444
2025-09-29 22:24:31,928 Stage: Train 0.5 | Epoch: 344 | Iter: 209400 | Total Loss: 0.004644 | Recon Loss: 0.003668 | Commit Loss: 0.001953 | Perplexity: 397.654079
2025-09-29 22:27:53,161 Stage: Train 0.5 | Epoch: 344 | Iter: 209600 | Total Loss: 0.004647 | Recon Loss: 0.003668 | Commit Loss: 0.001957 | Perplexity: 397.335226
Trainning Epoch:  42%|████▏     | 345/823 [59:18:15<82:05:37, 618.28s/it]Trainning Epoch:  42%|████▏     | 345/823 [59:18:14<82:05:34, 618.27s/it]Trainning Epoch:  42%|████▏     | 345/823 [59:18:15<82:05:40, 618.29s/it]Trainning Epoch:  42%|████▏     | 345/823 [59:18:15<82:05:40, 618.29s/it]2025-09-29 22:31:18,114 Stage: Train 0.5 | Epoch: 345 | Iter: 209800 | Total Loss: 0.004668 | Recon Loss: 0.003684 | Commit Loss: 0.001968 | Perplexity: 398.338832
2025-09-29 22:34:38,961 Stage: Train 0.5 | Epoch: 345 | Iter: 210000 | Total Loss: 0.004664 | Recon Loss: 0.003680 | Commit Loss: 0.001968 | Perplexity: 397.739283
2025-09-29 22:38:00,641 Stage: Train 0.5 | Epoch: 345 | Iter: 210200 | Total Loss: 0.004637 | Recon Loss: 0.003658 | Commit Loss: 0.001958 | Perplexity: 397.736183
Trainning Epoch:  42%|████▏     | 346/823 [59:28:31<81:50:42, 617.70s/it]Trainning Epoch:  42%|████▏     | 346/823 [59:28:31<81:50:40, 617.70s/it]Trainning Epoch:  42%|████▏     | 346/823 [59:28:31<81:50:40, 617.69s/it]Trainning Epoch:  42%|████▏     | 346/823 [59:28:31<81:50:41, 617.70s/it]2025-09-29 22:41:26,800 Stage: Train 0.5 | Epoch: 346 | Iter: 210400 | Total Loss: 0.004651 | Recon Loss: 0.003673 | Commit Loss: 0.001956 | Perplexity: 397.635881
2025-09-29 22:44:50,021 Stage: Train 0.5 | Epoch: 346 | Iter: 210600 | Total Loss: 0.004653 | Recon Loss: 0.003671 | Commit Loss: 0.001964 | Perplexity: 397.426574
2025-09-29 22:48:13,108 Stage: Train 0.5 | Epoch: 346 | Iter: 210800 | Total Loss: 0.004681 | Recon Loss: 0.003699 | Commit Loss: 0.001964 | Perplexity: 398.690277
Trainning Epoch:  42%|████▏     | 347/823 [59:38:52<81:49:14, 618.81s/it]Trainning Epoch:  42%|████▏     | 347/823 [59:38:52<81:49:13, 618.81s/it]Trainning Epoch:  42%|████▏     | 347/823 [59:38:52<81:49:15, 618.81s/it]Trainning Epoch:  42%|████▏     | 347/823 [59:38:52<81:49:14, 618.81s/it]2025-09-29 22:51:40,365 Stage: Train 0.5 | Epoch: 347 | Iter: 211000 | Total Loss: 0.004640 | Recon Loss: 0.003660 | Commit Loss: 0.001959 | Perplexity: 398.431921
2025-09-29 22:55:03,792 Stage: Train 0.5 | Epoch: 347 | Iter: 211200 | Total Loss: 0.004629 | Recon Loss: 0.003656 | Commit Loss: 0.001947 | Perplexity: 398.269667
2025-09-29 22:58:28,059 Stage: Train 0.5 | Epoch: 347 | Iter: 211400 | Total Loss: 0.004656 | Recon Loss: 0.003676 | Commit Loss: 0.001960 | Perplexity: 398.473567
Trainning Epoch:  42%|████▏     | 348/823 [59:49:16<81:51:30, 620.40s/it]Trainning Epoch:  42%|████▏     | 348/823 [59:49:16<81:51:30, 620.40s/it]Trainning Epoch:  42%|████▏     | 348/823 [59:49:16<81:51:30, 620.40s/it]Trainning Epoch:  42%|████▏     | 348/823 [59:49:16<81:51:31, 620.40s/it]2025-09-29 23:01:55,940 Stage: Train 0.5 | Epoch: 348 | Iter: 211600 | Total Loss: 0.004652 | Recon Loss: 0.003675 | Commit Loss: 0.001954 | Perplexity: 398.407741
2025-09-29 23:05:17,143 Stage: Train 0.5 | Epoch: 348 | Iter: 211800 | Total Loss: 0.004610 | Recon Loss: 0.003637 | Commit Loss: 0.001945 | Perplexity: 397.929533
2025-09-29 23:08:38,698 Stage: Train 0.5 | Epoch: 348 | Iter: 212000 | Total Loss: 0.004633 | Recon Loss: 0.003658 | Commit Loss: 0.001949 | Perplexity: 398.392773
Trainning Epoch:  42%|████▏     | 349/823 [59:59:33<81:31:53, 619.23s/it]Trainning Epoch:  42%|████▏     | 349/823 [59:59:33<81:31:55, 619.23s/it]Trainning Epoch:  42%|████▏     | 349/823 [59:59:33<81:31:55, 619.23s/it]Trainning Epoch:  42%|████▏     | 349/823 [59:59:33<81:31:56, 619.23s/it]2025-09-29 23:12:04,645 Stage: Train 0.5 | Epoch: 349 | Iter: 212200 | Total Loss: 0.004657 | Recon Loss: 0.003678 | Commit Loss: 0.001957 | Perplexity: 398.257874
2025-09-29 23:15:26,813 Stage: Train 0.5 | Epoch: 349 | Iter: 212400 | Total Loss: 0.004663 | Recon Loss: 0.003692 | Commit Loss: 0.001943 | Perplexity: 398.404462
2025-09-29 23:18:50,544 Stage: Train 0.5 | Epoch: 349 | Iter: 212600 | Total Loss: 0.004610 | Recon Loss: 0.003632 | Commit Loss: 0.001957 | Perplexity: 398.166566
2025-09-29 23:22:14,359 Stage: Train 0.5 | Epoch: 349 | Iter: 212800 | Total Loss: 0.004647 | Recon Loss: 0.003669 | Commit Loss: 0.001956 | Perplexity: 399.092542
Trainning Epoch:  43%|████▎     | 350/823 [60:09:55<81:27:42, 620.00s/it]Trainning Epoch:  43%|████▎     | 350/823 [60:09:55<81:27:38, 620.00s/it]Trainning Epoch:  43%|████▎     | 350/823 [60:09:55<81:27:39, 620.00s/it]Trainning Epoch:  43%|████▎     | 350/823 [60:09:55<81:27:41, 620.00s/it]2025-09-29 23:25:40,399 Stage: Train 0.5 | Epoch: 350 | Iter: 213000 | Total Loss: 0.004652 | Recon Loss: 0.003679 | Commit Loss: 0.001945 | Perplexity: 398.086055
2025-09-29 23:29:02,528 Stage: Train 0.5 | Epoch: 350 | Iter: 213200 | Total Loss: 0.004651 | Recon Loss: 0.003674 | Commit Loss: 0.001955 | Perplexity: 397.933555
2025-09-29 23:32:24,607 Stage: Train 0.5 | Epoch: 350 | Iter: 213400 | Total Loss: 0.004627 | Recon Loss: 0.003648 | Commit Loss: 0.001958 | Perplexity: 398.296142
Trainning Epoch:  43%|████▎     | 351/823 [60:20:13<81:13:30, 619.51s/it]Trainning Epoch:  43%|████▎     | 351/823 [60:20:13<81:13:31, 619.52s/it]Trainning Epoch:  43%|████▎     | 351/823 [60:20:13<81:13:32, 619.52s/it]Trainning Epoch:  43%|████▎     | 351/823 [60:20:13<81:13:31, 619.52s/it]2025-09-29 23:35:49,480 Stage: Train 0.5 | Epoch: 351 | Iter: 213600 | Total Loss: 0.004612 | Recon Loss: 0.003637 | Commit Loss: 0.001950 | Perplexity: 398.546264
2025-09-29 23:39:11,940 Stage: Train 0.5 | Epoch: 351 | Iter: 213800 | Total Loss: 0.004667 | Recon Loss: 0.003681 | Commit Loss: 0.001973 | Perplexity: 398.746962
2025-09-29 23:42:34,522 Stage: Train 0.5 | Epoch: 351 | Iter: 214000 | Total Loss: 0.004625 | Recon Loss: 0.003654 | Commit Loss: 0.001942 | Perplexity: 397.766332
Trainning Epoch:  43%|████▎     | 352/823 [60:30:31<80:59:34, 619.05s/it]Trainning Epoch:  43%|████▎     | 352/823 [60:30:31<80:59:31, 619.05s/it]Trainning Epoch:  43%|████▎     | 352/823 [60:30:31<80:59:32, 619.05s/it]Trainning Epoch:  43%|████▎     | 352/823 [60:30:31<80:59:33, 619.05s/it]2025-09-29 23:45:59,597 Stage: Train 0.5 | Epoch: 352 | Iter: 214200 | Total Loss: 0.004644 | Recon Loss: 0.003664 | Commit Loss: 0.001959 | Perplexity: 399.354799
2025-09-29 23:49:21,669 Stage: Train 0.5 | Epoch: 352 | Iter: 214400 | Total Loss: 0.004612 | Recon Loss: 0.003636 | Commit Loss: 0.001953 | Perplexity: 398.112302
2025-09-29 23:52:43,833 Stage: Train 0.5 | Epoch: 352 | Iter: 214600 | Total Loss: 0.004628 | Recon Loss: 0.003650 | Commit Loss: 0.001955 | Perplexity: 398.967432
Trainning Epoch:  43%|████▎     | 353/823 [60:40:48<80:45:13, 618.54s/it]Trainning Epoch:  43%|████▎     | 353/823 [60:40:48<80:45:16, 618.55s/it]Trainning Epoch:  43%|████▎     | 353/823 [60:40:48<80:45:15, 618.54s/it]Trainning Epoch:  43%|████▎     | 353/823 [60:40:48<80:45:15, 618.54s/it]2025-09-29 23:56:09,964 Stage: Train 0.5 | Epoch: 353 | Iter: 214800 | Total Loss: 0.004604 | Recon Loss: 0.003638 | Commit Loss: 0.001933 | Perplexity: 398.208438
2025-09-29 23:59:33,653 Stage: Train 0.5 | Epoch: 353 | Iter: 215000 | Total Loss: 0.004638 | Recon Loss: 0.003664 | Commit Loss: 0.001948 | Perplexity: 398.552235
2025-09-30 00:02:57,418 Stage: Train 0.5 | Epoch: 353 | Iter: 215200 | Total Loss: 0.004646 | Recon Loss: 0.003667 | Commit Loss: 0.001959 | Perplexity: 398.489730
Trainning Epoch:  43%|████▎     | 354/823 [60:51:10<80:43:07, 619.59s/it]Trainning Epoch:  43%|████▎     | 354/823 [60:51:10<80:43:09, 619.59s/it]Trainning Epoch:  43%|████▎     | 354/823 [60:51:10<80:43:10, 619.60s/it]Trainning Epoch:  43%|████▎     | 354/823 [60:51:10<80:43:10, 619.60s/it]2025-09-30 00:06:23,507 Stage: Train 0.5 | Epoch: 354 | Iter: 215400 | Total Loss: 0.004630 | Recon Loss: 0.003655 | Commit Loss: 0.001951 | Perplexity: 398.141379
2025-09-30 00:09:45,293 Stage: Train 0.5 | Epoch: 354 | Iter: 215600 | Total Loss: 0.004632 | Recon Loss: 0.003651 | Commit Loss: 0.001962 | Perplexity: 399.026377
2025-09-30 00:13:07,403 Stage: Train 0.5 | Epoch: 354 | Iter: 215800 | Total Loss: 0.004648 | Recon Loss: 0.003665 | Commit Loss: 0.001966 | Perplexity: 399.275546
Trainning Epoch:  43%|████▎     | 355/823 [61:01:28<80:27:56, 618.97s/it]Trainning Epoch:  43%|████▎     | 355/823 [61:01:28<80:27:58, 618.97s/it]Trainning Epoch:  43%|████▎     | 355/823 [61:01:28<80:27:58, 618.97s/it]Trainning Epoch:  43%|████▎     | 355/823 [61:01:28<80:27:59, 618.97s/it]2025-09-30 00:16:31,970 Stage: Train 0.5 | Epoch: 355 | Iter: 216000 | Total Loss: 0.004626 | Recon Loss: 0.003645 | Commit Loss: 0.001961 | Perplexity: 399.051696
2025-09-30 00:19:53,412 Stage: Train 0.5 | Epoch: 355 | Iter: 216200 | Total Loss: 0.004634 | Recon Loss: 0.003656 | Commit Loss: 0.001954 | Perplexity: 398.403178
2025-09-30 00:23:14,914 Stage: Train 0.5 | Epoch: 355 | Iter: 216400 | Total Loss: 0.004647 | Recon Loss: 0.003666 | Commit Loss: 0.001961 | Perplexity: 399.066274
Trainning Epoch:  43%|████▎     | 356/823 [61:11:44<80:10:08, 618.01s/it]Trainning Epoch:  43%|████▎     | 356/823 [61:11:44<80:10:08, 618.01s/it]Trainning Epoch:  43%|████▎     | 356/823 [61:11:44<80:10:08, 618.01s/it]Trainning Epoch:  43%|████▎     | 356/823 [61:11:44<80:10:09, 618.01s/it]2025-09-30 00:26:41,930 Stage: Train 0.5 | Epoch: 356 | Iter: 216600 | Total Loss: 0.004603 | Recon Loss: 0.003625 | Commit Loss: 0.001956 | Perplexity: 398.616402
2025-09-30 00:30:05,318 Stage: Train 0.5 | Epoch: 356 | Iter: 216800 | Total Loss: 0.004604 | Recon Loss: 0.003633 | Commit Loss: 0.001941 | Perplexity: 398.602895
2025-09-30 00:33:28,939 Stage: Train 0.5 | Epoch: 356 | Iter: 217000 | Total Loss: 0.004643 | Recon Loss: 0.003662 | Commit Loss: 0.001963 | Perplexity: 398.714073
Trainning Epoch:  43%|████▎     | 357/823 [61:22:06<80:10:12, 619.34s/it]Trainning Epoch:  43%|████▎     | 357/823 [61:22:06<80:10:14, 619.34s/it]Trainning Epoch:  43%|████▎     | 357/823 [61:22:06<80:10:13, 619.34s/it]Trainning Epoch:  43%|████▎     | 357/823 [61:22:06<80:10:14, 619.34s/it]2025-09-30 00:36:54,192 Stage: Train 0.5 | Epoch: 357 | Iter: 217200 | Total Loss: 0.004611 | Recon Loss: 0.003634 | Commit Loss: 0.001954 | Perplexity: 398.424841
2025-09-30 00:40:15,713 Stage: Train 0.5 | Epoch: 357 | Iter: 217400 | Total Loss: 0.004631 | Recon Loss: 0.003657 | Commit Loss: 0.001948 | Perplexity: 398.461036
2025-09-30 00:43:36,937 Stage: Train 0.5 | Epoch: 357 | Iter: 217600 | Total Loss: 0.004610 | Recon Loss: 0.003637 | Commit Loss: 0.001946 | Perplexity: 398.282086
Trainning Epoch:  43%|████▎     | 358/823 [61:32:22<79:51:23, 618.24s/it]Trainning Epoch:  43%|████▎     | 358/823 [61:32:22<79:51:19, 618.24s/it]Trainning Epoch:  43%|████▎     | 358/823 [61:32:22<79:51:20, 618.24s/it]Trainning Epoch:  43%|████▎     | 358/823 [61:32:22<79:51:22, 618.24s/it]2025-09-30 00:47:01,936 Stage: Train 0.5 | Epoch: 358 | Iter: 217800 | Total Loss: 0.004607 | Recon Loss: 0.003626 | Commit Loss: 0.001962 | Perplexity: 398.812082
2025-09-30 00:50:23,408 Stage: Train 0.5 | Epoch: 358 | Iter: 218000 | Total Loss: 0.004613 | Recon Loss: 0.003633 | Commit Loss: 0.001960 | Perplexity: 399.186308
2025-09-30 00:53:45,116 Stage: Train 0.5 | Epoch: 358 | Iter: 218200 | Total Loss: 0.004660 | Recon Loss: 0.003672 | Commit Loss: 0.001974 | Perplexity: 398.372153
Trainning Epoch:  44%|████▎     | 359/823 [61:42:38<79:36:39, 617.67s/it]Trainning Epoch:  44%|████▎     | 359/823 [61:42:38<79:36:36, 617.67s/it]Trainning Epoch:  44%|████▎     | 359/823 [61:42:38<79:36:38, 617.67s/it]Trainning Epoch:  44%|████▎     | 359/823 [61:42:38<79:36:37, 617.67s/it]2025-09-30 00:57:11,388 Stage: Train 0.5 | Epoch: 359 | Iter: 218400 | Total Loss: 0.004603 | Recon Loss: 0.003628 | Commit Loss: 0.001950 | Perplexity: 398.425598
2025-09-30 01:00:34,767 Stage: Train 0.5 | Epoch: 359 | Iter: 218600 | Total Loss: 0.004657 | Recon Loss: 0.003672 | Commit Loss: 0.001971 | Perplexity: 399.787868
2025-09-30 01:03:58,333 Stage: Train 0.5 | Epoch: 359 | Iter: 218800 | Total Loss: 0.004611 | Recon Loss: 0.003629 | Commit Loss: 0.001963 | Perplexity: 398.744272
Trainning Epoch:  44%|████▎     | 360/823 [61:53:00<79:36:25, 618.97s/it]Trainning Epoch:  44%|████▎     | 360/823 [61:53:00<79:36:23, 618.97s/it]Trainning Epoch:  44%|████▎     | 360/823 [61:53:00<79:36:24, 618.97s/it]Trainning Epoch:  44%|████▎     | 360/823 [61:53:00<79:36:24, 618.97s/it]2025-09-30 01:07:25,100 Stage: Train 0.5 | Epoch: 360 | Iter: 219000 | Total Loss: 0.004608 | Recon Loss: 0.003628 | Commit Loss: 0.001960 | Perplexity: 398.472696
2025-09-30 01:10:47,664 Stage: Train 0.5 | Epoch: 360 | Iter: 219200 | Total Loss: 0.004610 | Recon Loss: 0.003635 | Commit Loss: 0.001951 | Perplexity: 398.404476
2025-09-30 01:14:10,499 Stage: Train 0.5 | Epoch: 360 | Iter: 219400 | Total Loss: 0.004606 | Recon Loss: 0.003633 | Commit Loss: 0.001946 | Perplexity: 398.406332
Trainning Epoch:  44%|████▍     | 361/823 [62:03:20<79:27:35, 619.17s/it]Trainning Epoch:  44%|████▍     | 361/823 [62:03:20<79:27:35, 619.17s/it]Trainning Epoch:  44%|████▍     | 361/823 [62:03:20<79:27:37, 619.17s/it]Trainning Epoch:  44%|████▍     | 361/823 [62:03:20<79:27:36, 619.17s/it]2025-09-30 01:17:35,586 Stage: Train 0.5 | Epoch: 361 | Iter: 219600 | Total Loss: 0.004582 | Recon Loss: 0.003608 | Commit Loss: 0.001948 | Perplexity: 399.053139
2025-09-30 01:20:56,764 Stage: Train 0.5 | Epoch: 361 | Iter: 219800 | Total Loss: 0.004590 | Recon Loss: 0.003616 | Commit Loss: 0.001947 | Perplexity: 397.468634
2025-09-30 01:24:18,727 Stage: Train 0.5 | Epoch: 361 | Iter: 220000 | Total Loss: 0.004628 | Recon Loss: 0.003648 | Commit Loss: 0.001960 | Perplexity: 398.840854
2025-09-30 01:24:18,728 Saving model at iteration 220000
2025-09-30 01:24:19,470 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_362_step_220000
2025-09-30 01:24:20,110 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_362_step_220000/model.safetensors
2025-09-30 01:24:20,699 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_362_step_220000/optimizer.bin
2025-09-30 01:24:20,700 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_362_step_220000/scheduler.bin
2025-09-30 01:24:20,700 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_362_step_220000/sampler.bin
2025-09-30 01:24:20,701 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_362_step_220000/random_states_0.pkl
Trainning Epoch:  44%|████▍     | 362/823 [62:13:38<79:15:06, 618.89s/it]Trainning Epoch:  44%|████▍     | 362/823 [62:13:38<79:15:08, 618.89s/it]Trainning Epoch:  44%|████▍     | 362/823 [62:13:38<79:15:08, 618.89s/it]Trainning Epoch:  44%|████▍     | 362/823 [62:13:38<79:15:09, 618.89s/it]2025-09-30 01:27:46,140 Stage: Train 0.5 | Epoch: 362 | Iter: 220200 | Total Loss: 0.004574 | Recon Loss: 0.003603 | Commit Loss: 0.001942 | Perplexity: 398.569758
2025-09-30 01:31:07,106 Stage: Train 0.5 | Epoch: 362 | Iter: 220400 | Total Loss: 0.004611 | Recon Loss: 0.003638 | Commit Loss: 0.001945 | Perplexity: 398.142291
2025-09-30 01:34:27,908 Stage: Train 0.5 | Epoch: 362 | Iter: 220600 | Total Loss: 0.004597 | Recon Loss: 0.003625 | Commit Loss: 0.001944 | Perplexity: 398.183055
Trainning Epoch:  44%|████▍     | 363/823 [62:23:53<78:55:36, 617.69s/it]Trainning Epoch:  44%|████▍     | 363/823 [62:23:53<78:55:38, 617.69s/it]Trainning Epoch:  44%|████▍     | 363/823 [62:23:53<78:55:37, 617.69s/it]Trainning Epoch:  44%|████▍     | 363/823 [62:23:53<78:55:37, 617.69s/it]2025-09-30 01:37:54,182 Stage: Train 0.5 | Epoch: 363 | Iter: 220800 | Total Loss: 0.004614 | Recon Loss: 0.003640 | Commit Loss: 0.001947 | Perplexity: 398.882515
2025-09-30 01:41:18,391 Stage: Train 0.5 | Epoch: 363 | Iter: 221000 | Total Loss: 0.004612 | Recon Loss: 0.003634 | Commit Loss: 0.001957 | Perplexity: 400.146624
2025-09-30 01:44:42,580 Stage: Train 0.5 | Epoch: 363 | Iter: 221200 | Total Loss: 0.004594 | Recon Loss: 0.003623 | Commit Loss: 0.001943 | Perplexity: 399.219174
Trainning Epoch:  44%|████▍     | 364/823 [62:34:17<79:00:38, 619.69s/it]Trainning Epoch:  44%|████▍     | 364/823 [62:34:17<79:00:38, 619.69s/it]Trainning Epoch:  44%|████▍     | 364/823 [62:34:17<79:00:40, 619.70s/it]Trainning Epoch:  44%|████▍     | 364/823 [62:34:17<79:00:38, 619.69s/it]2025-09-30 01:48:09,101 Stage: Train 0.5 | Epoch: 364 | Iter: 221400 | Total Loss: 0.004640 | Recon Loss: 0.003658 | Commit Loss: 0.001963 | Perplexity: 400.340453
2025-09-30 01:51:30,276 Stage: Train 0.5 | Epoch: 364 | Iter: 221600 | Total Loss: 0.004589 | Recon Loss: 0.003619 | Commit Loss: 0.001939 | Perplexity: 399.472664
2025-09-30 01:54:51,594 Stage: Train 0.5 | Epoch: 364 | Iter: 221800 | Total Loss: 0.004579 | Recon Loss: 0.003614 | Commit Loss: 0.001930 | Perplexity: 398.848608
Trainning Epoch:  44%|████▍     | 365/823 [62:44:33<78:40:35, 618.42s/it]Trainning Epoch:  44%|████▍     | 365/823 [62:44:33<78:40:38, 618.42s/it]Trainning Epoch:  44%|████▍     | 365/823 [62:44:33<78:40:38, 618.42s/it]Trainning Epoch:  44%|████▍     | 365/823 [62:44:33<78:40:39, 618.43s/it]2025-09-30 01:58:17,392 Stage: Train 0.5 | Epoch: 365 | Iter: 222000 | Total Loss: 0.004602 | Recon Loss: 0.003623 | Commit Loss: 0.001958 | Perplexity: 399.892870
2025-09-30 02:01:40,311 Stage: Train 0.5 | Epoch: 365 | Iter: 222200 | Total Loss: 0.004593 | Recon Loss: 0.003623 | Commit Loss: 0.001941 | Perplexity: 399.431256
2025-09-30 02:05:03,573 Stage: Train 0.5 | Epoch: 365 | Iter: 222400 | Total Loss: 0.004599 | Recon Loss: 0.003625 | Commit Loss: 0.001948 | Perplexity: 399.594517
Trainning Epoch:  44%|████▍     | 366/823 [62:54:54<78:36:53, 619.29s/it]Trainning Epoch:  44%|████▍     | 366/823 [62:54:54<78:36:54, 619.29s/it]Trainning Epoch:  44%|████▍     | 366/823 [62:54:54<78:36:54, 619.29s/it]Trainning Epoch:  44%|████▍     | 366/823 [62:54:54<78:36:55, 619.29s/it]2025-09-30 02:08:30,755 Stage: Train 0.5 | Epoch: 366 | Iter: 222600 | Total Loss: 0.004597 | Recon Loss: 0.003621 | Commit Loss: 0.001951 | Perplexity: 399.616620
2025-09-30 02:11:54,347 Stage: Train 0.5 | Epoch: 366 | Iter: 222800 | Total Loss: 0.004555 | Recon Loss: 0.003590 | Commit Loss: 0.001931 | Perplexity: 399.600672
2025-09-30 02:15:17,918 Stage: Train 0.5 | Epoch: 366 | Iter: 223000 | Total Loss: 0.004635 | Recon Loss: 0.003659 | Commit Loss: 0.001951 | Perplexity: 399.618354
Trainning Epoch:  45%|████▍     | 367/823 [63:05:17<78:35:26, 620.45s/it]Trainning Epoch:  45%|████▍     | 367/823 [63:05:17<78:35:29, 620.46s/it]Trainning Epoch:  45%|████▍     | 367/823 [63:05:17<78:35:29, 620.46s/it]Trainning Epoch:  45%|████▍     | 367/823 [63:05:17<78:35:30, 620.46s/it]2025-09-30 02:18:45,238 Stage: Train 0.5 | Epoch: 367 | Iter: 223200 | Total Loss: 0.004597 | Recon Loss: 0.003614 | Commit Loss: 0.001966 | Perplexity: 400.151619
2025-09-30 02:22:08,285 Stage: Train 0.5 | Epoch: 367 | Iter: 223400 | Total Loss: 0.004589 | Recon Loss: 0.003621 | Commit Loss: 0.001936 | Perplexity: 399.593138
2025-09-30 02:25:31,337 Stage: Train 0.5 | Epoch: 367 | Iter: 223600 | Total Loss: 0.004554 | Recon Loss: 0.003592 | Commit Loss: 0.001924 | Perplexity: 398.043733
Trainning Epoch:  45%|████▍     | 368/823 [63:15:38<78:25:11, 620.47s/it]Trainning Epoch:  45%|████▍     | 368/823 [63:15:38<78:25:13, 620.47s/it]Trainning Epoch:  45%|████▍     | 368/823 [63:15:38<78:25:12, 620.47s/it]Trainning Epoch:  45%|████▍     | 368/823 [63:15:38<78:25:16, 620.48s/it]2025-09-30 02:28:59,060 Stage: Train 0.5 | Epoch: 368 | Iter: 223800 | Total Loss: 0.004591 | Recon Loss: 0.003615 | Commit Loss: 0.001954 | Perplexity: 399.578541
2025-09-30 02:32:22,850 Stage: Train 0.5 | Epoch: 368 | Iter: 224000 | Total Loss: 0.004606 | Recon Loss: 0.003636 | Commit Loss: 0.001939 | Perplexity: 399.389997
2025-09-30 02:35:46,234 Stage: Train 0.5 | Epoch: 368 | Iter: 224200 | Total Loss: 0.004597 | Recon Loss: 0.003626 | Commit Loss: 0.001942 | Perplexity: 399.855822
Trainning Epoch:  45%|████▍     | 369/823 [63:26:01<78:20:19, 621.19s/it]Trainning Epoch:  45%|████▍     | 369/823 [63:26:01<78:20:21, 621.19s/it]Trainning Epoch:  45%|████▍     | 369/823 [63:26:01<78:20:22, 621.20s/it]Trainning Epoch:  45%|████▍     | 369/823 [63:26:01<78:20:21, 621.19s/it]2025-09-30 02:39:12,814 Stage: Train 0.5 | Epoch: 369 | Iter: 224400 | Total Loss: 0.004597 | Recon Loss: 0.003622 | Commit Loss: 0.001951 | Perplexity: 399.083739
2025-09-30 02:42:35,360 Stage: Train 0.5 | Epoch: 369 | Iter: 224600 | Total Loss: 0.004565 | Recon Loss: 0.003598 | Commit Loss: 0.001934 | Perplexity: 399.251453
2025-09-30 02:45:58,239 Stage: Train 0.5 | Epoch: 369 | Iter: 224800 | Total Loss: 0.004573 | Recon Loss: 0.003601 | Commit Loss: 0.001944 | Perplexity: 400.283160
Trainning Epoch:  45%|████▍     | 370/823 [63:36:21<78:08:16, 620.96s/it]Trainning Epoch:  45%|████▍     | 370/823 [63:36:21<78:08:19, 620.97s/it]Trainning Epoch:  45%|████▍     | 370/823 [63:36:21<78:08:20, 620.97s/it]Trainning Epoch:  45%|████▍     | 370/823 [63:36:21<78:08:20, 620.97s/it]2025-09-30 02:49:25,449 Stage: Train 0.5 | Epoch: 370 | Iter: 225000 | Total Loss: 0.004557 | Recon Loss: 0.003584 | Commit Loss: 0.001947 | Perplexity: 400.258966
2025-09-30 02:52:48,373 Stage: Train 0.5 | Epoch: 370 | Iter: 225200 | Total Loss: 0.004594 | Recon Loss: 0.003623 | Commit Loss: 0.001943 | Perplexity: 399.420992
2025-09-30 02:56:11,441 Stage: Train 0.5 | Epoch: 370 | Iter: 225400 | Total Loss: 0.004600 | Recon Loss: 0.003629 | Commit Loss: 0.001942 | Perplexity: 400.029366
Trainning Epoch:  45%|████▌     | 371/823 [63:46:42<77:58:44, 621.07s/it]Trainning Epoch:  45%|████▌     | 371/823 [63:46:42<77:58:47, 621.08s/it]Trainning Epoch:  45%|████▌     | 371/823 [63:46:42<77:58:47, 621.08s/it]Trainning Epoch:  45%|████▌     | 371/823 [63:46:42<77:58:47, 621.08s/it]2025-09-30 02:59:37,578 Stage: Train 0.5 | Epoch: 371 | Iter: 225600 | Total Loss: 0.004578 | Recon Loss: 0.003612 | Commit Loss: 0.001932 | Perplexity: 398.644448
2025-09-30 03:02:58,512 Stage: Train 0.5 | Epoch: 371 | Iter: 225800 | Total Loss: 0.004572 | Recon Loss: 0.003604 | Commit Loss: 0.001936 | Perplexity: 399.527382
2025-09-30 03:06:20,093 Stage: Train 0.5 | Epoch: 371 | Iter: 226000 | Total Loss: 0.004570 | Recon Loss: 0.003601 | Commit Loss: 0.001939 | Perplexity: 398.747095
Trainning Epoch:  45%|████▌     | 372/823 [63:56:57<77:34:18, 619.20s/it]Trainning Epoch:  45%|████▌     | 372/823 [63:56:57<77:34:21, 619.20s/it]Trainning Epoch:  45%|████▌     | 372/823 [63:56:57<77:34:21, 619.20s/it]Trainning Epoch:  45%|████▌     | 372/823 [63:56:57<77:34:21, 619.20s/it]2025-09-30 03:09:44,943 Stage: Train 0.5 | Epoch: 372 | Iter: 226200 | Total Loss: 0.004593 | Recon Loss: 0.003618 | Commit Loss: 0.001949 | Perplexity: 400.264691
2025-09-30 03:13:05,885 Stage: Train 0.5 | Epoch: 372 | Iter: 226400 | Total Loss: 0.004544 | Recon Loss: 0.003575 | Commit Loss: 0.001937 | Perplexity: 399.054288
2025-09-30 03:16:26,901 Stage: Train 0.5 | Epoch: 372 | Iter: 226600 | Total Loss: 0.004552 | Recon Loss: 0.003579 | Commit Loss: 0.001945 | Perplexity: 398.918513
Trainning Epoch:  45%|████▌     | 373/823 [64:07:12<77:14:21, 617.92s/it]Trainning Epoch:  45%|████▌     | 373/823 [64:07:12<77:14:19, 617.91s/it]Trainning Epoch:  45%|████▌     | 373/823 [64:07:12<77:14:20, 617.91s/it]Trainning Epoch:  45%|████▌     | 373/823 [64:07:12<77:14:20, 617.91s/it]2025-09-30 03:19:51,962 Stage: Train 0.5 | Epoch: 373 | Iter: 226800 | Total Loss: 0.004573 | Recon Loss: 0.003604 | Commit Loss: 0.001938 | Perplexity: 398.418004
2025-09-30 03:23:15,271 Stage: Train 0.5 | Epoch: 373 | Iter: 227000 | Total Loss: 0.004553 | Recon Loss: 0.003584 | Commit Loss: 0.001938 | Perplexity: 399.627433
2025-09-30 03:26:38,479 Stage: Train 0.5 | Epoch: 373 | Iter: 227200 | Total Loss: 0.004555 | Recon Loss: 0.003588 | Commit Loss: 0.001934 | Perplexity: 399.145343
Trainning Epoch:  45%|████▌     | 374/823 [64:17:34<77:12:25, 619.03s/it]Trainning Epoch:  45%|████▌     | 374/823 [64:17:34<77:12:23, 619.03s/it]Trainning Epoch:  45%|████▌     | 374/823 [64:17:34<77:12:23, 619.03s/it]Trainning Epoch:  45%|████▌     | 374/823 [64:17:34<77:12:24, 619.03s/it]2025-09-30 03:30:05,189 Stage: Train 0.5 | Epoch: 374 | Iter: 227400 | Total Loss: 0.004569 | Recon Loss: 0.003598 | Commit Loss: 0.001942 | Perplexity: 399.576899
2025-09-30 03:33:28,405 Stage: Train 0.5 | Epoch: 374 | Iter: 227600 | Total Loss: 0.004544 | Recon Loss: 0.003574 | Commit Loss: 0.001941 | Perplexity: 399.662316
2025-09-30 03:36:51,553 Stage: Train 0.5 | Epoch: 374 | Iter: 227800 | Total Loss: 0.004566 | Recon Loss: 0.003595 | Commit Loss: 0.001941 | Perplexity: 399.592731
2025-09-30 03:40:15,164 Stage: Train 0.5 | Epoch: 374 | Iter: 228000 | Total Loss: 0.004601 | Recon Loss: 0.003625 | Commit Loss: 0.001951 | Perplexity: 401.023650
Trainning Epoch:  46%|████▌     | 375/823 [64:27:55<77:08:03, 619.83s/it]Trainning Epoch:  46%|████▌     | 375/823 [64:27:55<77:08:06, 619.84s/it]Trainning Epoch:  46%|████▌     | 375/823 [64:27:55<77:08:04, 619.83s/it]Trainning Epoch:  46%|████▌     | 375/823 [64:27:55<77:08:04, 619.83s/it]2025-09-30 03:43:38,966 Stage: Train 0.5 | Epoch: 375 | Iter: 228200 | Total Loss: 0.004570 | Recon Loss: 0.003596 | Commit Loss: 0.001949 | Perplexity: 399.686807
2025-09-30 03:46:59,606 Stage: Train 0.5 | Epoch: 375 | Iter: 228400 | Total Loss: 0.004590 | Recon Loss: 0.003615 | Commit Loss: 0.001950 | Perplexity: 400.852207
2025-09-30 03:50:20,240 Stage: Train 0.5 | Epoch: 375 | Iter: 228600 | Total Loss: 0.004562 | Recon Loss: 0.003595 | Commit Loss: 0.001935 | Perplexity: 399.186839
Trainning Epoch:  46%|████▌     | 376/823 [64:38:09<76:42:47, 617.82s/it]Trainning Epoch:  46%|████▌     | 376/823 [64:38:09<76:42:46, 617.82s/it]Trainning Epoch:  46%|████▌     | 376/823 [64:38:09<76:42:47, 617.82s/it]Trainning Epoch:  46%|████▌     | 376/823 [64:38:09<76:42:47, 617.82s/it]2025-09-30 03:53:45,804 Stage: Train 0.5 | Epoch: 376 | Iter: 228800 | Total Loss: 0.004530 | Recon Loss: 0.003563 | Commit Loss: 0.001935 | Perplexity: 399.266433
2025-09-30 03:57:09,077 Stage: Train 0.5 | Epoch: 376 | Iter: 229000 | Total Loss: 0.004566 | Recon Loss: 0.003597 | Commit Loss: 0.001938 | Perplexity: 399.857116
2025-09-30 04:00:31,635 Stage: Train 0.5 | Epoch: 376 | Iter: 229200 | Total Loss: 0.004565 | Recon Loss: 0.003586 | Commit Loss: 0.001957 | Perplexity: 399.463485
Trainning Epoch:  46%|████▌     | 377/823 [64:48:28<76:36:11, 618.32s/it]Trainning Epoch:  46%|████▌     | 377/823 [64:48:28<76:36:12, 618.32s/it]Trainning Epoch:  46%|████▌     | 377/823 [64:48:28<76:36:13, 618.33s/it]Trainning Epoch:  46%|████▌     | 377/823 [64:48:28<76:36:14, 618.33s/it]2025-09-30 04:03:57,624 Stage: Train 0.5 | Epoch: 377 | Iter: 229400 | Total Loss: 0.004558 | Recon Loss: 0.003594 | Commit Loss: 0.001927 | Perplexity: 399.767227
2025-09-30 04:07:20,713 Stage: Train 0.5 | Epoch: 377 | Iter: 229600 | Total Loss: 0.004575 | Recon Loss: 0.003603 | Commit Loss: 0.001943 | Perplexity: 399.605510
2025-09-30 04:10:43,939 Stage: Train 0.5 | Epoch: 377 | Iter: 229800 | Total Loss: 0.004549 | Recon Loss: 0.003578 | Commit Loss: 0.001941 | Perplexity: 400.064180
Trainning Epoch:  46%|████▌     | 378/823 [64:58:49<76:30:30, 618.95s/it]Trainning Epoch:  46%|████▌     | 378/823 [64:58:49<76:30:31, 618.95s/it]Trainning Epoch:  46%|████▌     | 378/823 [64:58:49<76:30:32, 618.95s/it]Trainning Epoch:  46%|████▌     | 378/823 [64:58:48<76:30:31, 618.95s/it]2025-09-30 04:14:09,585 Stage: Train 0.5 | Epoch: 378 | Iter: 230000 | Total Loss: 0.004547 | Recon Loss: 0.003584 | Commit Loss: 0.001928 | Perplexity: 398.770439
2025-09-30 04:17:30,999 Stage: Train 0.5 | Epoch: 378 | Iter: 230200 | Total Loss: 0.004509 | Recon Loss: 0.003545 | Commit Loss: 0.001928 | Perplexity: 399.174875
2025-09-30 04:20:52,777 Stage: Train 0.5 | Epoch: 378 | Iter: 230400 | Total Loss: 0.004558 | Recon Loss: 0.003584 | Commit Loss: 0.001949 | Perplexity: 399.338200
Trainning Epoch:  46%|████▌     | 379/823 [65:09:05<76:15:18, 618.28s/it]Trainning Epoch:  46%|████▌     | 379/823 [65:09:05<76:15:20, 618.29s/it]Trainning Epoch:  46%|████▌     | 379/823 [65:09:05<76:15:20, 618.29s/it]Trainning Epoch:  46%|████▌     | 379/823 [65:09:05<76:15:19, 618.29s/it]2025-09-30 04:24:17,813 Stage: Train 0.5 | Epoch: 379 | Iter: 230600 | Total Loss: 0.004513 | Recon Loss: 0.003554 | Commit Loss: 0.001919 | Perplexity: 399.671563
2025-09-30 04:27:40,239 Stage: Train 0.5 | Epoch: 379 | Iter: 230800 | Total Loss: 0.004541 | Recon Loss: 0.003572 | Commit Loss: 0.001939 | Perplexity: 398.649149
2025-09-30 04:31:02,841 Stage: Train 0.5 | Epoch: 379 | Iter: 231000 | Total Loss: 0.004576 | Recon Loss: 0.003603 | Commit Loss: 0.001945 | Perplexity: 399.357920
Trainning Epoch:  46%|████▌     | 380/823 [65:19:24<76:05:00, 618.29s/it]Trainning Epoch:  46%|████▌     | 380/823 [65:19:24<76:05:03, 618.29s/it]Trainning Epoch:  46%|████▌     | 380/823 [65:19:24<76:05:04, 618.29s/it]Trainning Epoch:  46%|████▌     | 380/823 [65:19:24<76:05:03, 618.29s/it]2025-09-30 04:34:29,401 Stage: Train 0.5 | Epoch: 380 | Iter: 231200 | Total Loss: 0.004569 | Recon Loss: 0.003594 | Commit Loss: 0.001949 | Perplexity: 399.840918
2025-09-30 04:37:52,588 Stage: Train 0.5 | Epoch: 380 | Iter: 231400 | Total Loss: 0.004545 | Recon Loss: 0.003576 | Commit Loss: 0.001939 | Perplexity: 399.772867
2025-09-30 04:41:16,642 Stage: Train 0.5 | Epoch: 380 | Iter: 231600 | Total Loss: 0.004564 | Recon Loss: 0.003592 | Commit Loss: 0.001943 | Perplexity: 398.982077
Trainning Epoch:  46%|████▋     | 381/823 [65:29:46<76:03:15, 619.45s/it]Trainning Epoch:  46%|████▋     | 381/823 [65:29:46<76:03:16, 619.45s/it]Trainning Epoch:  46%|████▋     | 381/823 [65:29:46<76:03:16, 619.45s/it]Trainning Epoch:  46%|████▋     | 381/823 [65:29:46<76:03:16, 619.45s/it]2025-09-30 04:44:41,664 Stage: Train 0.5 | Epoch: 381 | Iter: 231800 | Total Loss: 0.004550 | Recon Loss: 0.003582 | Commit Loss: 0.001937 | Perplexity: 399.186290
2025-09-30 04:48:02,453 Stage: Train 0.5 | Epoch: 381 | Iter: 232000 | Total Loss: 0.004540 | Recon Loss: 0.003570 | Commit Loss: 0.001940 | Perplexity: 399.071895
2025-09-30 04:51:23,376 Stage: Train 0.5 | Epoch: 381 | Iter: 232200 | Total Loss: 0.004578 | Recon Loss: 0.003609 | Commit Loss: 0.001938 | Perplexity: 400.494525
Trainning Epoch:  46%|████▋     | 382/823 [65:40:00<75:41:32, 617.90s/it]Trainning Epoch:  46%|████▋     | 382/823 [65:40:00<75:41:31, 617.89s/it]Trainning Epoch:  46%|████▋     | 382/823 [65:40:00<75:41:32, 617.90s/it]Trainning Epoch:  46%|████▋     | 382/823 [65:40:00<75:41:33, 617.90s/it]2025-09-30 04:54:47,684 Stage: Train 0.5 | Epoch: 382 | Iter: 232400 | Total Loss: 0.004524 | Recon Loss: 0.003557 | Commit Loss: 0.001933 | Perplexity: 399.982966
2025-09-30 04:58:07,906 Stage: Train 0.5 | Epoch: 382 | Iter: 232600 | Total Loss: 0.004519 | Recon Loss: 0.003556 | Commit Loss: 0.001927 | Perplexity: 398.227420
2025-09-30 05:01:28,745 Stage: Train 0.5 | Epoch: 382 | Iter: 232800 | Total Loss: 0.004546 | Recon Loss: 0.003581 | Commit Loss: 0.001930 | Perplexity: 399.666666
Trainning Epoch:  47%|████▋     | 383/823 [65:50:13<75:21:32, 616.57s/it]Trainning Epoch:  47%|████▋     | 383/823 [65:50:13<75:21:31, 616.57s/it]Trainning Epoch:  47%|████▋     | 383/823 [65:50:13<75:21:31, 616.57s/it]Trainning Epoch:  47%|████▋     | 383/823 [65:50:13<75:21:32, 616.57s/it]2025-09-30 05:04:53,831 Stage: Train 0.5 | Epoch: 383 | Iter: 233000 | Total Loss: 0.004541 | Recon Loss: 0.003575 | Commit Loss: 0.001932 | Perplexity: 400.113818
2025-09-30 05:08:15,396 Stage: Train 0.5 | Epoch: 383 | Iter: 233200 | Total Loss: 0.004551 | Recon Loss: 0.003584 | Commit Loss: 0.001933 | Perplexity: 400.053252
2025-09-30 05:11:37,372 Stage: Train 0.5 | Epoch: 383 | Iter: 233400 | Total Loss: 0.004526 | Recon Loss: 0.003561 | Commit Loss: 0.001930 | Perplexity: 399.477383
Trainning Epoch:  47%|████▋     | 384/823 [66:00:30<75:12:00, 616.68s/it]Trainning Epoch:  47%|████▋     | 384/823 [66:00:30<75:12:00, 616.68s/it]Trainning Epoch:  47%|████▋     | 384/823 [66:00:30<75:12:00, 616.68s/it]Trainning Epoch:  47%|████▋     | 384/823 [66:00:30<75:12:01, 616.68s/it]2025-09-30 05:15:01,712 Stage: Train 0.5 | Epoch: 384 | Iter: 233600 | Total Loss: 0.004525 | Recon Loss: 0.003560 | Commit Loss: 0.001930 | Perplexity: 399.858714
2025-09-30 05:18:22,106 Stage: Train 0.5 | Epoch: 384 | Iter: 233800 | Total Loss: 0.004560 | Recon Loss: 0.003581 | Commit Loss: 0.001959 | Perplexity: 400.338695
2025-09-30 05:21:42,318 Stage: Train 0.5 | Epoch: 384 | Iter: 234000 | Total Loss: 0.004578 | Recon Loss: 0.003604 | Commit Loss: 0.001947 | Perplexity: 400.405338
Trainning Epoch:  47%|████▋     | 385/823 [66:10:43<74:53:05, 615.49s/it]Trainning Epoch:  47%|████▋     | 385/823 [66:10:43<74:53:06, 615.49s/it]Trainning Epoch:  47%|████▋     | 385/823 [66:10:43<74:53:08, 615.50s/it]Trainning Epoch:  47%|████▋     | 385/823 [66:10:43<74:53:07, 615.50s/it]2025-09-30 05:25:07,274 Stage: Train 0.5 | Epoch: 385 | Iter: 234200 | Total Loss: 0.004519 | Recon Loss: 0.003555 | Commit Loss: 0.001927 | Perplexity: 399.324361
2025-09-30 05:28:28,437 Stage: Train 0.5 | Epoch: 385 | Iter: 234400 | Total Loss: 0.004538 | Recon Loss: 0.003571 | Commit Loss: 0.001934 | Perplexity: 399.425369
2025-09-30 05:31:49,493 Stage: Train 0.5 | Epoch: 385 | Iter: 234600 | Total Loss: 0.004550 | Recon Loss: 0.003573 | Commit Loss: 0.001954 | Perplexity: 399.761380
Trainning Epoch:  47%|████▋     | 386/823 [66:20:58<74:42:01, 615.38s/it]Trainning Epoch:  47%|████▋     | 386/823 [66:20:58<74:42:00, 615.38s/it]Trainning Epoch:  47%|████▋     | 386/823 [66:20:58<74:42:02, 615.38s/it]Trainning Epoch:  47%|████▋     | 386/823 [66:20:58<74:42:01, 615.38s/it]2025-09-30 05:35:15,265 Stage: Train 0.5 | Epoch: 386 | Iter: 234800 | Total Loss: 0.004537 | Recon Loss: 0.003573 | Commit Loss: 0.001927 | Perplexity: 399.554924
2025-09-30 05:38:38,731 Stage: Train 0.5 | Epoch: 386 | Iter: 235000 | Total Loss: 0.004493 | Recon Loss: 0.003530 | Commit Loss: 0.001925 | Perplexity: 399.382319
2025-09-30 05:42:02,136 Stage: Train 0.5 | Epoch: 386 | Iter: 235200 | Total Loss: 0.004544 | Recon Loss: 0.003570 | Commit Loss: 0.001949 | Perplexity: 399.760580
Trainning Epoch:  47%|████▋     | 387/823 [66:31:20<74:45:38, 617.29s/it]Trainning Epoch:  47%|████▋     | 387/823 [66:31:20<74:45:38, 617.29s/it]Trainning Epoch:  47%|████▋     | 387/823 [66:31:20<74:45:39, 617.29s/it]Trainning Epoch:  47%|████▋     | 387/823 [66:31:20<74:45:39, 617.29s/it]2025-09-30 05:45:28,874 Stage: Train 0.5 | Epoch: 387 | Iter: 235400 | Total Loss: 0.004561 | Recon Loss: 0.003589 | Commit Loss: 0.001945 | Perplexity: 400.874381
2025-09-30 05:48:51,468 Stage: Train 0.5 | Epoch: 387 | Iter: 235600 | Total Loss: 0.004524 | Recon Loss: 0.003557 | Commit Loss: 0.001935 | Perplexity: 400.930127
2025-09-30 05:52:14,523 Stage: Train 0.5 | Epoch: 387 | Iter: 235800 | Total Loss: 0.004551 | Recon Loss: 0.003579 | Commit Loss: 0.001945 | Perplexity: 400.730444
Trainning Epoch:  47%|████▋     | 388/823 [66:41:40<74:41:43, 618.17s/it]Trainning Epoch:  47%|████▋     | 388/823 [66:41:40<74:41:44, 618.17s/it]Trainning Epoch:  47%|████▋     | 388/823 [66:41:40<74:41:45, 618.17s/it]Trainning Epoch:  47%|████▋     | 388/823 [66:41:40<74:41:45, 618.17s/it]2025-09-30 05:55:40,497 Stage: Train 0.5 | Epoch: 388 | Iter: 236000 | Total Loss: 0.004487 | Recon Loss: 0.003525 | Commit Loss: 0.001925 | Perplexity: 399.489808
2025-09-30 05:59:02,587 Stage: Train 0.5 | Epoch: 388 | Iter: 236200 | Total Loss: 0.004543 | Recon Loss: 0.003579 | Commit Loss: 0.001929 | Perplexity: 400.663713
2025-09-30 06:02:25,182 Stage: Train 0.5 | Epoch: 388 | Iter: 236400 | Total Loss: 0.004507 | Recon Loss: 0.003545 | Commit Loss: 0.001924 | Perplexity: 400.493916
Trainning Epoch:  47%|████▋     | 389/823 [66:51:59<74:32:17, 618.29s/it]Trainning Epoch:  47%|████▋     | 389/823 [66:51:59<74:32:21, 618.30s/it]Trainning Epoch:  47%|████▋     | 389/823 [66:51:59<74:32:20, 618.30s/it]Trainning Epoch:  47%|████▋     | 389/823 [66:51:59<74:32:21, 618.30s/it]2025-09-30 06:05:50,554 Stage: Train 0.5 | Epoch: 389 | Iter: 236600 | Total Loss: 0.004547 | Recon Loss: 0.003579 | Commit Loss: 0.001935 | Perplexity: 400.097159
2025-09-30 06:09:12,297 Stage: Train 0.5 | Epoch: 389 | Iter: 236800 | Total Loss: 0.004483 | Recon Loss: 0.003528 | Commit Loss: 0.001910 | Perplexity: 399.408234
2025-09-30 06:12:34,211 Stage: Train 0.5 | Epoch: 389 | Iter: 237000 | Total Loss: 0.004531 | Recon Loss: 0.003562 | Commit Loss: 0.001938 | Perplexity: 400.220132
Trainning Epoch:  47%|████▋     | 390/823 [67:02:16<74:19:29, 617.94s/it]Trainning Epoch:  47%|████▋     | 390/823 [67:02:16<74:19:32, 617.95s/it]Trainning Epoch:  47%|████▋     | 390/823 [67:02:16<74:19:32, 617.95s/it]Trainning Epoch:  47%|████▋     | 390/823 [67:02:16<74:19:32, 617.95s/it]2025-09-30 06:16:00,346 Stage: Train 0.5 | Epoch: 390 | Iter: 237200 | Total Loss: 0.004535 | Recon Loss: 0.003572 | Commit Loss: 0.001926 | Perplexity: 400.265580
2025-09-30 06:19:23,211 Stage: Train 0.5 | Epoch: 390 | Iter: 237400 | Total Loss: 0.004511 | Recon Loss: 0.003547 | Commit Loss: 0.001926 | Perplexity: 399.398638
2025-09-30 06:22:46,126 Stage: Train 0.5 | Epoch: 390 | Iter: 237600 | Total Loss: 0.004537 | Recon Loss: 0.003572 | Commit Loss: 0.001930 | Perplexity: 400.804633
Trainning Epoch:  48%|████▊     | 391/823 [67:12:37<74:15:44, 618.85s/it]Trainning Epoch:  48%|████▊     | 391/823 [67:12:37<74:15:46, 618.86s/it]Trainning Epoch:  48%|████▊     | 391/823 [67:12:37<74:15:46, 618.86s/it]Trainning Epoch:  48%|████▊     | 391/823 [67:12:37<74:15:46, 618.86s/it]2025-09-30 06:26:12,470 Stage: Train 0.5 | Epoch: 391 | Iter: 237800 | Total Loss: 0.004517 | Recon Loss: 0.003556 | Commit Loss: 0.001923 | Perplexity: 401.312158
2025-09-30 06:29:33,984 Stage: Train 0.5 | Epoch: 391 | Iter: 238000 | Total Loss: 0.004510 | Recon Loss: 0.003537 | Commit Loss: 0.001947 | Perplexity: 402.045142
2025-09-30 06:32:55,902 Stage: Train 0.5 | Epoch: 391 | Iter: 238200 | Total Loss: 0.004524 | Recon Loss: 0.003559 | Commit Loss: 0.001931 | Perplexity: 400.679490
Trainning Epoch:  48%|████▊     | 392/823 [67:22:54<74:00:45, 618.20s/it]Trainning Epoch:  48%|████▊     | 392/823 [67:22:54<74:00:45, 618.20s/it]Trainning Epoch:  48%|████▊     | 392/823 [67:22:54<74:00:45, 618.20s/it]Trainning Epoch:  48%|████▊     | 392/823 [67:22:54<74:00:45, 618.20s/it]2025-09-30 06:36:22,187 Stage: Train 0.5 | Epoch: 392 | Iter: 238400 | Total Loss: 0.004546 | Recon Loss: 0.003578 | Commit Loss: 0.001936 | Perplexity: 400.773443
2025-09-30 06:39:45,712 Stage: Train 0.5 | Epoch: 392 | Iter: 238600 | Total Loss: 0.004509 | Recon Loss: 0.003541 | Commit Loss: 0.001936 | Perplexity: 400.227627
2025-09-30 06:43:09,575 Stage: Train 0.5 | Epoch: 392 | Iter: 238800 | Total Loss: 0.004534 | Recon Loss: 0.003567 | Commit Loss: 0.001934 | Perplexity: 400.500598
Trainning Epoch:  48%|████▊     | 393/823 [67:33:17<74:01:12, 619.70s/it]Trainning Epoch:  48%|████▊     | 393/823 [67:33:17<74:01:09, 619.70s/it]Trainning Epoch:  48%|████▊     | 393/823 [67:33:17<74:01:10, 619.70s/it]Trainning Epoch:  48%|████▊     | 393/823 [67:33:17<74:01:10, 619.70s/it]2025-09-30 06:46:36,888 Stage: Train 0.5 | Epoch: 393 | Iter: 239000 | Total Loss: 0.004524 | Recon Loss: 0.003560 | Commit Loss: 0.001928 | Perplexity: 400.677505
2025-09-30 06:49:59,350 Stage: Train 0.5 | Epoch: 393 | Iter: 239200 | Total Loss: 0.004492 | Recon Loss: 0.003533 | Commit Loss: 0.001919 | Perplexity: 400.406944
2025-09-30 06:53:22,544 Stage: Train 0.5 | Epoch: 393 | Iter: 239400 | Total Loss: 0.004500 | Recon Loss: 0.003539 | Commit Loss: 0.001923 | Perplexity: 400.580669
Trainning Epoch:  48%|████▊     | 394/823 [67:43:38<73:53:27, 620.06s/it]Trainning Epoch:  48%|████▊     | 394/823 [67:43:38<73:53:29, 620.07s/it]Trainning Epoch:  48%|████▊     | 394/823 [67:43:38<73:53:29, 620.07s/it]Trainning Epoch:  48%|████▊     | 394/823 [67:43:38<73:53:29, 620.07s/it]2025-09-30 06:56:49,803 Stage: Train 0.5 | Epoch: 394 | Iter: 239600 | Total Loss: 0.004526 | Recon Loss: 0.003559 | Commit Loss: 0.001934 | Perplexity: 400.267444
2025-09-30 07:00:13,234 Stage: Train 0.5 | Epoch: 394 | Iter: 239800 | Total Loss: 0.004511 | Recon Loss: 0.003552 | Commit Loss: 0.001917 | Perplexity: 400.687522
2025-09-30 07:03:36,555 Stage: Train 0.5 | Epoch: 394 | Iter: 240000 | Total Loss: 0.004517 | Recon Loss: 0.003551 | Commit Loss: 0.001933 | Perplexity: 401.145577
2025-09-30 07:03:36,556 Saving model at iteration 240000
2025-09-30 07:03:37,268 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_395_step_240000
2025-09-30 07:03:37,851 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_395_step_240000/model.safetensors
2025-09-30 07:03:38,403 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_395_step_240000/optimizer.bin
2025-09-30 07:03:38,404 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_395_step_240000/scheduler.bin
2025-09-30 07:03:38,404 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_395_step_240000/sampler.bin
2025-09-30 07:03:38,405 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_395_step_240000/random_states_0.pkl
Trainning Epoch:  48%|████▊     | 395/823 [67:54:01<73:50:49, 621.14s/it]Trainning Epoch:  48%|████▊     | 395/823 [67:54:01<73:50:46, 621.14s/it]Trainning Epoch:  48%|████▊     | 395/823 [67:54:01<73:50:46, 621.14s/it]Trainning Epoch:  48%|████▊     | 395/823 [67:54:01<73:50:47, 621.14s/it]2025-09-30 07:07:05,183 Stage: Train 0.5 | Epoch: 395 | Iter: 240200 | Total Loss: 0.004498 | Recon Loss: 0.003542 | Commit Loss: 0.001911 | Perplexity: 399.870513
2025-09-30 07:10:28,179 Stage: Train 0.5 | Epoch: 395 | Iter: 240400 | Total Loss: 0.004475 | Recon Loss: 0.003514 | Commit Loss: 0.001922 | Perplexity: 400.466066
2025-09-30 07:13:51,547 Stage: Train 0.5 | Epoch: 395 | Iter: 240600 | Total Loss: 0.004508 | Recon Loss: 0.003554 | Commit Loss: 0.001909 | Perplexity: 399.889253
Trainning Epoch:  48%|████▊     | 396/823 [68:04:23<73:40:29, 621.15s/it]Trainning Epoch:  48%|████▊     | 396/823 [68:04:23<73:40:32, 621.15s/it]Trainning Epoch:  48%|████▊     | 396/823 [68:04:23<73:40:31, 621.15s/it]Trainning Epoch:  48%|████▊     | 396/823 [68:04:23<73:40:31, 621.15s/it]2025-09-30 07:17:18,543 Stage: Train 0.5 | Epoch: 396 | Iter: 240800 | Total Loss: 0.004533 | Recon Loss: 0.003570 | Commit Loss: 0.001926 | Perplexity: 400.837806
2025-09-30 07:20:41,098 Stage: Train 0.5 | Epoch: 396 | Iter: 241000 | Total Loss: 0.004463 | Recon Loss: 0.003504 | Commit Loss: 0.001918 | Perplexity: 400.757739
2025-09-30 07:24:04,202 Stage: Train 0.5 | Epoch: 396 | Iter: 241200 | Total Loss: 0.004496 | Recon Loss: 0.003538 | Commit Loss: 0.001916 | Perplexity: 401.054356
Trainning Epoch:  48%|████▊     | 397/823 [68:14:44<73:29:50, 621.11s/it]Trainning Epoch:  48%|████▊     | 397/823 [68:14:44<73:29:54, 621.11s/it]Trainning Epoch:  48%|████▊     | 397/823 [68:14:44<73:29:51, 621.11s/it]Trainning Epoch:  48%|████▊     | 397/823 [68:14:44<73:29:52, 621.11s/it]2025-09-30 07:27:30,793 Stage: Train 0.5 | Epoch: 397 | Iter: 241400 | Total Loss: 0.004496 | Recon Loss: 0.003530 | Commit Loss: 0.001932 | Perplexity: 400.470411
2025-09-30 07:30:52,198 Stage: Train 0.5 | Epoch: 397 | Iter: 241600 | Total Loss: 0.004465 | Recon Loss: 0.003507 | Commit Loss: 0.001914 | Perplexity: 400.316319
2025-09-30 07:34:13,144 Stage: Train 0.5 | Epoch: 397 | Iter: 241800 | Total Loss: 0.004520 | Recon Loss: 0.003551 | Commit Loss: 0.001937 | Perplexity: 400.665469
Trainning Epoch:  48%|████▊     | 398/823 [68:24:58<73:06:00, 619.20s/it]Trainning Epoch:  48%|████▊     | 398/823 [68:24:58<73:05:58, 619.20s/it]Trainning Epoch:  48%|████▊     | 398/823 [68:24:58<73:06:00, 619.20s/it]Trainning Epoch:  48%|████▊     | 398/823 [68:24:58<73:06:01, 619.20s/it]2025-09-30 07:37:37,876 Stage: Train 0.5 | Epoch: 398 | Iter: 242000 | Total Loss: 0.004529 | Recon Loss: 0.003569 | Commit Loss: 0.001919 | Perplexity: 400.814995
2025-09-30 07:40:58,581 Stage: Train 0.5 | Epoch: 398 | Iter: 242200 | Total Loss: 0.004484 | Recon Loss: 0.003526 | Commit Loss: 0.001916 | Perplexity: 400.628897
2025-09-30 07:44:19,251 Stage: Train 0.5 | Epoch: 398 | Iter: 242400 | Total Loss: 0.004516 | Recon Loss: 0.003554 | Commit Loss: 0.001923 | Perplexity: 400.149853
Trainning Epoch:  48%|████▊     | 399/823 [68:35:12<72:44:05, 617.56s/it]Trainning Epoch:  48%|████▊     | 399/823 [68:35:12<72:44:04, 617.56s/it]Trainning Epoch:  48%|████▊     | 399/823 [68:35:12<72:44:05, 617.56s/it]Trainning Epoch:  48%|████▊     | 399/823 [68:35:12<72:44:06, 617.56s/it]2025-09-30 07:47:43,577 Stage: Train 0.5 | Epoch: 399 | Iter: 242600 | Total Loss: 0.004500 | Recon Loss: 0.003534 | Commit Loss: 0.001933 | Perplexity: 401.225789
2025-09-30 07:51:07,225 Stage: Train 0.5 | Epoch: 399 | Iter: 242800 | Total Loss: 0.004474 | Recon Loss: 0.003515 | Commit Loss: 0.001917 | Perplexity: 400.004713
2025-09-30 07:54:30,601 Stage: Train 0.5 | Epoch: 399 | Iter: 243000 | Total Loss: 0.004523 | Recon Loss: 0.003555 | Commit Loss: 0.001934 | Perplexity: 401.916214
2025-09-30 07:57:54,266 Stage: Train 0.5 | Epoch: 399 | Iter: 243200 | Total Loss: 0.004500 | Recon Loss: 0.003539 | Commit Loss: 0.001921 | Perplexity: 400.797382
Trainning Epoch:  49%|████▊     | 400/823 [68:45:35<72:44:22, 619.06s/it]Trainning Epoch:  49%|████▊     | 400/823 [68:45:35<72:44:23, 619.06s/it]Trainning Epoch:  49%|████▊     | 400/823 [68:45:35<72:44:23, 619.06s/it]Trainning Epoch:  49%|████▊     | 400/823 [68:45:35<72:44:22, 619.06s/it]2025-09-30 08:01:18,388 Stage: Train 0.5 | Epoch: 400 | Iter: 243400 | Total Loss: 0.004502 | Recon Loss: 0.003535 | Commit Loss: 0.001934 | Perplexity: 401.144996
2025-09-30 08:04:39,524 Stage: Train 0.5 | Epoch: 400 | Iter: 243600 | Total Loss: 0.004472 | Recon Loss: 0.003513 | Commit Loss: 0.001920 | Perplexity: 400.800376
2025-09-30 08:08:00,916 Stage: Train 0.5 | Epoch: 400 | Iter: 243800 | Total Loss: 0.004489 | Recon Loss: 0.003528 | Commit Loss: 0.001923 | Perplexity: 400.377329
Trainning Epoch:  49%|████▊     | 401/823 [68:55:49<72:24:53, 617.76s/it]Trainning Epoch:  49%|████▊     | 401/823 [68:55:49<72:24:56, 617.76s/it]Trainning Epoch:  49%|████▊     | 401/823 [68:55:49<72:24:56, 617.76s/it]Trainning Epoch:  49%|████▊     | 401/823 [68:55:49<72:24:56, 617.76s/it]2025-09-30 08:11:27,223 Stage: Train 0.5 | Epoch: 401 | Iter: 244000 | Total Loss: 0.004492 | Recon Loss: 0.003530 | Commit Loss: 0.001923 | Perplexity: 400.701886
2025-09-30 08:14:48,677 Stage: Train 0.5 | Epoch: 401 | Iter: 244200 | Total Loss: 0.004512 | Recon Loss: 0.003554 | Commit Loss: 0.001916 | Perplexity: 400.602932
2025-09-30 08:18:10,639 Stage: Train 0.5 | Epoch: 401 | Iter: 244400 | Total Loss: 0.004489 | Recon Loss: 0.003528 | Commit Loss: 0.001923 | Perplexity: 400.516206
Trainning Epoch:  49%|████▉     | 402/823 [69:06:07<72:14:30, 617.74s/it]Trainning Epoch:  49%|████▉     | 402/823 [69:06:07<72:14:32, 617.75s/it]Trainning Epoch:  49%|████▉     | 402/823 [69:06:07<72:14:32, 617.75s/it]Trainning Epoch:  49%|████▉     | 402/823 [69:06:07<72:14:32, 617.75s/it]2025-09-30 08:21:36,809 Stage: Train 0.5 | Epoch: 402 | Iter: 244600 | Total Loss: 0.004510 | Recon Loss: 0.003550 | Commit Loss: 0.001921 | Perplexity: 400.587556
2025-09-30 08:24:59,813 Stage: Train 0.5 | Epoch: 402 | Iter: 244800 | Total Loss: 0.004496 | Recon Loss: 0.003533 | Commit Loss: 0.001927 | Perplexity: 400.884851
2025-09-30 08:28:23,007 Stage: Train 0.5 | Epoch: 402 | Iter: 245000 | Total Loss: 0.004483 | Recon Loss: 0.003514 | Commit Loss: 0.001938 | Perplexity: 400.950784
Trainning Epoch:  49%|████▉     | 403/823 [69:16:28<72:10:15, 618.61s/it]Trainning Epoch:  49%|████▉     | 403/823 [69:16:28<72:10:16, 618.61s/it]Trainning Epoch:  49%|████▉     | 403/823 [69:16:28<72:10:19, 618.62s/it]Trainning Epoch:  49%|████▉     | 403/823 [69:16:28<72:10:16, 618.61s/it]2025-09-30 08:31:49,820 Stage: Train 0.5 | Epoch: 403 | Iter: 245200 | Total Loss: 0.004489 | Recon Loss: 0.003538 | Commit Loss: 0.001902 | Perplexity: 400.296783
2025-09-30 08:35:13,251 Stage: Train 0.5 | Epoch: 403 | Iter: 245400 | Total Loss: 0.004475 | Recon Loss: 0.003510 | Commit Loss: 0.001930 | Perplexity: 401.586752
2025-09-30 08:38:36,001 Stage: Train 0.5 | Epoch: 403 | Iter: 245600 | Total Loss: 0.004528 | Recon Loss: 0.003562 | Commit Loss: 0.001931 | Perplexity: 400.899155
Trainning Epoch:  49%|████▉     | 404/823 [69:26:49<72:05:03, 619.34s/it]Trainning Epoch:  49%|████▉     | 404/823 [69:26:49<72:05:02, 619.34s/it]Trainning Epoch:  49%|████▉     | 404/823 [69:26:49<72:05:04, 619.34s/it]Trainning Epoch:  49%|████▉     | 404/823 [69:26:49<72:05:04, 619.34s/it]2025-09-30 08:42:01,905 Stage: Train 0.5 | Epoch: 404 | Iter: 245800 | Total Loss: 0.004494 | Recon Loss: 0.003534 | Commit Loss: 0.001919 | Perplexity: 400.615151
2025-09-30 08:45:25,085 Stage: Train 0.5 | Epoch: 404 | Iter: 246000 | Total Loss: 0.004484 | Recon Loss: 0.003524 | Commit Loss: 0.001921 | Perplexity: 401.263689
2025-09-30 08:48:47,908 Stage: Train 0.5 | Epoch: 404 | Iter: 246200 | Total Loss: 0.004469 | Recon Loss: 0.003506 | Commit Loss: 0.001925 | Perplexity: 400.823789
Trainning Epoch:  49%|████▉     | 405/823 [69:37:09<71:56:33, 619.60s/it]Trainning Epoch:  49%|████▉     | 405/823 [69:37:09<71:56:36, 619.61s/it]Trainning Epoch:  49%|████▉     | 405/823 [69:37:09<71:56:35, 619.61s/it]Trainning Epoch:  49%|████▉     | 405/823 [69:37:09<71:56:37, 619.61s/it]2025-09-30 08:52:14,187 Stage: Train 0.5 | Epoch: 405 | Iter: 246400 | Total Loss: 0.004493 | Recon Loss: 0.003530 | Commit Loss: 0.001927 | Perplexity: 400.692953
2025-09-30 08:55:36,568 Stage: Train 0.5 | Epoch: 405 | Iter: 246600 | Total Loss: 0.004465 | Recon Loss: 0.003513 | Commit Loss: 0.001904 | Perplexity: 399.919813
2025-09-30 08:58:59,530 Stage: Train 0.5 | Epoch: 405 | Iter: 246800 | Total Loss: 0.004474 | Recon Loss: 0.003516 | Commit Loss: 0.001914 | Perplexity: 400.500151
Trainning Epoch:  49%|████▉     | 406/823 [69:47:29<71:46:12, 619.60s/it]Trainning Epoch:  49%|████▉     | 406/823 [69:47:29<71:46:18, 619.61s/it]Trainning Epoch:  49%|████▉     | 406/823 [69:47:29<71:46:17, 619.61s/it]Trainning Epoch:  49%|████▉     | 406/823 [69:47:29<71:46:18, 619.61s/it]2025-09-30 09:02:24,902 Stage: Train 0.5 | Epoch: 406 | Iter: 247000 | Total Loss: 0.004514 | Recon Loss: 0.003550 | Commit Loss: 0.001929 | Perplexity: 400.952812
2025-09-30 09:05:46,318 Stage: Train 0.5 | Epoch: 406 | Iter: 247200 | Total Loss: 0.004467 | Recon Loss: 0.003509 | Commit Loss: 0.001916 | Perplexity: 400.713734
2025-09-30 09:09:08,185 Stage: Train 0.5 | Epoch: 406 | Iter: 247400 | Total Loss: 0.004488 | Recon Loss: 0.003524 | Commit Loss: 0.001929 | Perplexity: 400.726638
Trainning Epoch:  49%|████▉     | 407/823 [69:57:45<71:28:55, 618.60s/it]Trainning Epoch:  49%|████▉     | 407/823 [69:57:45<71:28:53, 618.59s/it]Trainning Epoch:  49%|████▉     | 407/823 [69:57:45<71:28:53, 618.59s/it]Trainning Epoch:  49%|████▉     | 407/823 [69:57:45<71:28:53, 618.59s/it]2025-09-30 09:12:34,492 Stage: Train 0.5 | Epoch: 407 | Iter: 247600 | Total Loss: 0.004515 | Recon Loss: 0.003556 | Commit Loss: 0.001919 | Perplexity: 400.032090
2025-09-30 09:15:57,184 Stage: Train 0.5 | Epoch: 407 | Iter: 247800 | Total Loss: 0.004444 | Recon Loss: 0.003487 | Commit Loss: 0.001912 | Perplexity: 400.070316
2025-09-30 09:19:19,913 Stage: Train 0.5 | Epoch: 407 | Iter: 248000 | Total Loss: 0.004490 | Recon Loss: 0.003520 | Commit Loss: 0.001941 | Perplexity: 400.935081
Trainning Epoch:  50%|████▉     | 408/823 [70:08:05<71:22:30, 619.16s/it]Trainning Epoch:  50%|████▉     | 408/823 [70:08:05<71:22:29, 619.15s/it]Trainning Epoch:  50%|████▉     | 408/823 [70:08:05<71:22:29, 619.16s/it]Trainning Epoch:  50%|████▉     | 408/823 [70:08:05<71:22:30, 619.16s/it]2025-09-30 09:22:45,616 Stage: Train 0.5 | Epoch: 408 | Iter: 248200 | Total Loss: 0.004487 | Recon Loss: 0.003529 | Commit Loss: 0.001917 | Perplexity: 401.220647
2025-09-30 09:26:07,799 Stage: Train 0.5 | Epoch: 408 | Iter: 248400 | Total Loss: 0.004449 | Recon Loss: 0.003492 | Commit Loss: 0.001915 | Perplexity: 400.402834
2025-09-30 09:29:29,873 Stage: Train 0.5 | Epoch: 408 | Iter: 248600 | Total Loss: 0.004490 | Recon Loss: 0.003531 | Commit Loss: 0.001918 | Perplexity: 400.308206
Trainning Epoch:  50%|████▉     | 409/823 [70:18:23<71:09:23, 618.75s/it]Trainning Epoch:  50%|████▉     | 409/823 [70:18:23<71:09:25, 618.76s/it]Trainning Epoch:  50%|████▉     | 409/823 [70:18:23<71:09:24, 618.76s/it]Trainning Epoch:  50%|████▉     | 409/823 [70:18:23<71:09:25, 618.76s/it]2025-09-30 09:32:55,802 Stage: Train 0.5 | Epoch: 409 | Iter: 248800 | Total Loss: 0.004466 | Recon Loss: 0.003508 | Commit Loss: 0.001917 | Perplexity: 400.375596
2025-09-30 09:36:18,820 Stage: Train 0.5 | Epoch: 409 | Iter: 249000 | Total Loss: 0.004464 | Recon Loss: 0.003506 | Commit Loss: 0.001916 | Perplexity: 400.176055
2025-09-30 09:39:41,738 Stage: Train 0.5 | Epoch: 409 | Iter: 249200 | Total Loss: 0.004450 | Recon Loss: 0.003495 | Commit Loss: 0.001911 | Perplexity: 399.796071
Trainning Epoch:  50%|████▉     | 410/823 [70:28:43<71:01:42, 619.13s/it]Trainning Epoch:  50%|████▉     | 410/823 [70:28:43<71:01:40, 619.13s/it]Trainning Epoch:  50%|████▉     | 410/823 [70:28:43<71:01:41, 619.13s/it]Trainning Epoch:  50%|████▉     | 410/823 [70:28:43<71:01:42, 619.14s/it]2025-09-30 09:43:06,522 Stage: Train 0.5 | Epoch: 410 | Iter: 249400 | Total Loss: 0.004449 | Recon Loss: 0.003490 | Commit Loss: 0.001918 | Perplexity: 400.573435
2025-09-30 09:46:28,633 Stage: Train 0.5 | Epoch: 410 | Iter: 249600 | Total Loss: 0.004510 | Recon Loss: 0.003548 | Commit Loss: 0.001923 | Perplexity: 401.881084
2025-09-30 09:49:51,224 Stage: Train 0.5 | Epoch: 410 | Iter: 249800 | Total Loss: 0.004446 | Recon Loss: 0.003485 | Commit Loss: 0.001923 | Perplexity: 400.553609
Trainning Epoch:  50%|████▉     | 411/823 [70:39:01<70:48:20, 618.69s/it]Trainning Epoch:  50%|████▉     | 411/823 [70:39:01<70:48:22, 618.70s/it]Trainning Epoch:  50%|████▉     | 411/823 [70:39:01<70:48:24, 618.70s/it]Trainning Epoch:  50%|████▉     | 411/823 [70:39:01<70:48:22, 618.70s/it]2025-09-30 09:53:18,616 Stage: Train 0.5 | Epoch: 411 | Iter: 250000 | Total Loss: 0.004432 | Recon Loss: 0.003480 | Commit Loss: 0.001903 | Perplexity: 399.704351
2025-09-30 09:56:43,857 Stage: Train 0.5 | Epoch: 411 | Iter: 250200 | Total Loss: 0.004446 | Recon Loss: 0.003493 | Commit Loss: 0.001907 | Perplexity: 400.144435
2025-09-30 10:00:08,489 Stage: Train 0.5 | Epoch: 411 | Iter: 250400 | Total Loss: 0.004485 | Recon Loss: 0.003518 | Commit Loss: 0.001935 | Perplexity: 400.709006
Trainning Epoch:  50%|█████     | 412/823 [70:49:27<70:52:44, 620.84s/it]Trainning Epoch:  50%|█████     | 412/823 [70:49:27<70:52:50, 620.85s/it]Trainning Epoch:  50%|█████     | 412/823 [70:49:27<70:52:51, 620.86s/it]Trainning Epoch:  50%|█████     | 412/823 [70:49:27<70:52:51, 620.86s/it]2025-09-30 10:03:34,225 Stage: Train 0.5 | Epoch: 412 | Iter: 250600 | Total Loss: 0.004499 | Recon Loss: 0.003538 | Commit Loss: 0.001921 | Perplexity: 400.867397
2025-09-30 10:06:56,150 Stage: Train 0.5 | Epoch: 412 | Iter: 250800 | Total Loss: 0.004456 | Recon Loss: 0.003491 | Commit Loss: 0.001929 | Perplexity: 400.917405
2025-09-30 10:10:18,347 Stage: Train 0.5 | Epoch: 412 | Iter: 251000 | Total Loss: 0.004489 | Recon Loss: 0.003525 | Commit Loss: 0.001927 | Perplexity: 400.393676
Trainning Epoch:  50%|█████     | 413/823 [70:59:44<70:34:34, 619.69s/it]Trainning Epoch:  50%|█████     | 413/823 [70:59:44<70:34:36, 619.70s/it]Trainning Epoch:  50%|█████     | 413/823 [70:59:44<70:34:38, 619.70s/it]Trainning Epoch:  50%|█████     | 413/823 [70:59:44<70:34:37, 619.70s/it]2025-09-30 10:13:43,492 Stage: Train 0.5 | Epoch: 413 | Iter: 251200 | Total Loss: 0.004458 | Recon Loss: 0.003499 | Commit Loss: 0.001920 | Perplexity: 401.312361
2025-09-30 10:17:04,524 Stage: Train 0.5 | Epoch: 413 | Iter: 251400 | Total Loss: 0.004459 | Recon Loss: 0.003508 | Commit Loss: 0.001902 | Perplexity: 400.560929
2025-09-30 10:20:25,702 Stage: Train 0.5 | Epoch: 413 | Iter: 251600 | Total Loss: 0.004482 | Recon Loss: 0.003518 | Commit Loss: 0.001928 | Perplexity: 401.460244
Trainning Epoch:  50%|█████     | 414/823 [71:09:59<70:15:04, 618.35s/it]Trainning Epoch:  50%|█████     | 414/823 [71:09:59<70:15:05, 618.35s/it]Trainning Epoch:  50%|█████     | 414/823 [71:09:59<70:15:05, 618.35s/it]Trainning Epoch:  50%|█████     | 414/823 [71:09:59<70:15:06, 618.35s/it]2025-09-30 10:23:51,299 Stage: Train 0.5 | Epoch: 414 | Iter: 251800 | Total Loss: 0.004486 | Recon Loss: 0.003525 | Commit Loss: 0.001923 | Perplexity: 400.747846
2025-09-30 10:27:13,329 Stage: Train 0.5 | Epoch: 414 | Iter: 252000 | Total Loss: 0.004447 | Recon Loss: 0.003490 | Commit Loss: 0.001913 | Perplexity: 400.931547
2025-09-30 10:30:36,306 Stage: Train 0.5 | Epoch: 414 | Iter: 252200 | Total Loss: 0.004464 | Recon Loss: 0.003502 | Commit Loss: 0.001925 | Perplexity: 400.640358
Trainning Epoch:  50%|█████     | 415/823 [71:20:18<70:06:17, 618.57s/it]Trainning Epoch:  50%|█████     | 415/823 [71:20:18<70:06:17, 618.57s/it]Trainning Epoch:  50%|█████     | 415/823 [71:20:18<70:06:17, 618.57s/it]Trainning Epoch:  50%|█████     | 415/823 [71:20:18<70:06:17, 618.57s/it]2025-09-30 10:34:02,127 Stage: Train 0.5 | Epoch: 415 | Iter: 252400 | Total Loss: 0.004444 | Recon Loss: 0.003488 | Commit Loss: 0.001912 | Perplexity: 400.920398
2025-09-30 10:37:24,581 Stage: Train 0.5 | Epoch: 415 | Iter: 252600 | Total Loss: 0.004435 | Recon Loss: 0.003478 | Commit Loss: 0.001913 | Perplexity: 400.265849
2025-09-30 10:40:47,398 Stage: Train 0.5 | Epoch: 415 | Iter: 252800 | Total Loss: 0.004443 | Recon Loss: 0.003484 | Commit Loss: 0.001918 | Perplexity: 400.047745
Trainning Epoch:  51%|█████     | 416/823 [71:30:38<69:58:04, 618.88s/it]Trainning Epoch:  51%|█████     | 416/823 [71:30:38<69:58:03, 618.88s/it]Trainning Epoch:  51%|█████     | 416/823 [71:30:38<69:58:04, 618.88s/it]Trainning Epoch:  51%|█████     | 416/823 [71:30:38<69:58:07, 618.89s/it]2025-09-30 10:44:14,291 Stage: Train 0.5 | Epoch: 416 | Iter: 253000 | Total Loss: 0.004448 | Recon Loss: 0.003490 | Commit Loss: 0.001917 | Perplexity: 400.965895
2025-09-30 10:47:37,778 Stage: Train 0.5 | Epoch: 416 | Iter: 253200 | Total Loss: 0.004471 | Recon Loss: 0.003508 | Commit Loss: 0.001926 | Perplexity: 400.830477
2025-09-30 10:51:01,159 Stage: Train 0.5 | Epoch: 416 | Iter: 253400 | Total Loss: 0.004433 | Recon Loss: 0.003466 | Commit Loss: 0.001933 | Perplexity: 401.063496
Trainning Epoch:  51%|█████     | 417/823 [71:41:00<69:54:59, 619.95s/it]Trainning Epoch:  51%|█████     | 417/823 [71:41:00<69:55:06, 619.97s/it]Trainning Epoch:  51%|█████     | 417/823 [71:41:00<69:55:07, 619.97s/it]Trainning Epoch:  51%|█████     | 417/823 [71:41:00<69:55:06, 619.97s/it]2025-09-30 10:54:27,659 Stage: Train 0.5 | Epoch: 417 | Iter: 253600 | Total Loss: 0.004457 | Recon Loss: 0.003497 | Commit Loss: 0.001920 | Perplexity: 400.932444
2025-09-30 10:57:48,912 Stage: Train 0.5 | Epoch: 417 | Iter: 253800 | Total Loss: 0.004444 | Recon Loss: 0.003485 | Commit Loss: 0.001918 | Perplexity: 400.940116
2025-09-30 11:01:11,206 Stage: Train 0.5 | Epoch: 417 | Iter: 254000 | Total Loss: 0.004413 | Recon Loss: 0.003460 | Commit Loss: 0.001905 | Perplexity: 399.971465
Trainning Epoch:  51%|█████     | 418/823 [71:51:17<69:38:48, 619.08s/it]Trainning Epoch:  51%|█████     | 418/823 [71:51:17<69:38:47, 619.08s/it]Trainning Epoch:  51%|█████     | 418/823 [71:51:17<69:38:47, 619.08s/it]Trainning Epoch:  51%|█████     | 418/823 [71:51:17<69:38:48, 619.08s/it]2025-09-30 11:04:37,841 Stage: Train 0.5 | Epoch: 418 | Iter: 254200 | Total Loss: 0.004482 | Recon Loss: 0.003513 | Commit Loss: 0.001938 | Perplexity: 401.548894
2025-09-30 11:08:01,500 Stage: Train 0.5 | Epoch: 418 | Iter: 254400 | Total Loss: 0.004474 | Recon Loss: 0.003515 | Commit Loss: 0.001919 | Perplexity: 400.694523
2025-09-30 11:11:25,038 Stage: Train 0.5 | Epoch: 418 | Iter: 254600 | Total Loss: 0.004463 | Recon Loss: 0.003501 | Commit Loss: 0.001924 | Perplexity: 400.874155
Trainning Epoch:  51%|█████     | 419/823 [72:01:40<69:36:48, 620.32s/it]Trainning Epoch:  51%|█████     | 419/823 [72:01:40<69:36:50, 620.32s/it]Trainning Epoch:  51%|█████     | 419/823 [72:01:40<69:36:52, 620.33s/it]Trainning Epoch:  51%|█████     | 419/823 [72:01:40<69:36:50, 620.32s/it]2025-09-30 11:14:52,308 Stage: Train 0.5 | Epoch: 419 | Iter: 254800 | Total Loss: 0.004471 | Recon Loss: 0.003507 | Commit Loss: 0.001928 | Perplexity: 400.802803
2025-09-30 11:18:14,937 Stage: Train 0.5 | Epoch: 419 | Iter: 255000 | Total Loss: 0.004438 | Recon Loss: 0.003482 | Commit Loss: 0.001911 | Perplexity: 401.167705
2025-09-30 11:21:37,658 Stage: Train 0.5 | Epoch: 419 | Iter: 255200 | Total Loss: 0.004421 | Recon Loss: 0.003459 | Commit Loss: 0.001924 | Perplexity: 400.613214
Trainning Epoch:  51%|█████     | 420/823 [72:12:00<69:25:20, 620.15s/it]Trainning Epoch:  51%|█████     | 420/823 [72:12:00<69:25:24, 620.16s/it]Trainning Epoch:  51%|█████     | 420/823 [72:12:00<69:25:22, 620.16s/it]Trainning Epoch:  51%|█████     | 420/823 [72:12:00<69:25:22, 620.16s/it]2025-09-30 11:25:03,465 Stage: Train 0.5 | Epoch: 420 | Iter: 255400 | Total Loss: 0.004460 | Recon Loss: 0.003501 | Commit Loss: 0.001918 | Perplexity: 400.779769
2025-09-30 11:28:24,665 Stage: Train 0.5 | Epoch: 420 | Iter: 255600 | Total Loss: 0.004410 | Recon Loss: 0.003457 | Commit Loss: 0.001906 | Perplexity: 400.838181
2025-09-30 11:31:45,997 Stage: Train 0.5 | Epoch: 420 | Iter: 255800 | Total Loss: 0.004441 | Recon Loss: 0.003482 | Commit Loss: 0.001918 | Perplexity: 401.192985
Trainning Epoch:  51%|█████     | 421/823 [72:22:16<69:06:24, 618.87s/it]Trainning Epoch:  51%|█████     | 421/823 [72:22:16<69:06:26, 618.87s/it]Trainning Epoch:  51%|█████     | 421/823 [72:22:16<69:06:25, 618.87s/it]Trainning Epoch:  51%|█████     | 421/823 [72:22:16<69:06:25, 618.87s/it]2025-09-30 11:35:11,461 Stage: Train 0.5 | Epoch: 421 | Iter: 256000 | Total Loss: 0.004470 | Recon Loss: 0.003501 | Commit Loss: 0.001939 | Perplexity: 400.764803
2025-09-30 11:38:32,222 Stage: Train 0.5 | Epoch: 421 | Iter: 256200 | Total Loss: 0.004457 | Recon Loss: 0.003500 | Commit Loss: 0.001914 | Perplexity: 400.733528
2025-09-30 11:41:54,254 Stage: Train 0.5 | Epoch: 421 | Iter: 256400 | Total Loss: 0.004435 | Recon Loss: 0.003478 | Commit Loss: 0.001915 | Perplexity: 400.139501
Trainning Epoch:  51%|█████▏    | 422/823 [72:32:32<68:50:49, 618.08s/it]Trainning Epoch:  51%|█████▏    | 422/823 [72:32:32<68:50:49, 618.08s/it]Trainning Epoch:  51%|█████▏    | 422/823 [72:32:32<68:50:53, 618.09s/it]Trainning Epoch:  51%|█████▏    | 422/823 [72:32:32<68:50:51, 618.08s/it]2025-09-30 11:45:19,495 Stage: Train 0.5 | Epoch: 422 | Iter: 256600 | Total Loss: 0.004429 | Recon Loss: 0.003475 | Commit Loss: 0.001907 | Perplexity: 401.484861
2025-09-30 11:48:40,348 Stage: Train 0.5 | Epoch: 422 | Iter: 256800 | Total Loss: 0.004419 | Recon Loss: 0.003464 | Commit Loss: 0.001910 | Perplexity: 400.424892
2025-09-30 11:52:01,958 Stage: Train 0.5 | Epoch: 422 | Iter: 257000 | Total Loss: 0.004461 | Recon Loss: 0.003506 | Commit Loss: 0.001910 | Perplexity: 400.503031
Trainning Epoch:  51%|█████▏    | 423/823 [72:42:47<68:34:40, 617.20s/it]Trainning Epoch:  51%|█████▏    | 423/823 [72:42:47<68:34:38, 617.20s/it]Trainning Epoch:  51%|█████▏    | 423/823 [72:42:47<68:34:39, 617.20s/it]Trainning Epoch:  51%|█████▏    | 423/823 [72:42:47<68:34:41, 617.20s/it]2025-09-30 11:55:27,050 Stage: Train 0.5 | Epoch: 423 | Iter: 257200 | Total Loss: 0.004416 | Recon Loss: 0.003460 | Commit Loss: 0.001912 | Perplexity: 400.672173
2025-09-30 11:58:49,065 Stage: Train 0.5 | Epoch: 423 | Iter: 257400 | Total Loss: 0.004475 | Recon Loss: 0.003513 | Commit Loss: 0.001923 | Perplexity: 401.770265
2025-09-30 12:02:11,745 Stage: Train 0.5 | Epoch: 423 | Iter: 257600 | Total Loss: 0.004437 | Recon Loss: 0.003484 | Commit Loss: 0.001908 | Perplexity: 400.261456
Trainning Epoch:  52%|█████▏    | 424/823 [72:53:07<68:28:53, 617.88s/it]Trainning Epoch:  52%|█████▏    | 424/823 [72:53:07<68:28:56, 617.89s/it]Trainning Epoch:  52%|█████▏    | 424/823 [72:53:07<68:28:56, 617.89s/it]Trainning Epoch:  52%|█████▏    | 424/823 [72:53:07<68:28:56, 617.89s/it]2025-09-30 12:05:38,285 Stage: Train 0.5 | Epoch: 424 | Iter: 257800 | Total Loss: 0.004459 | Recon Loss: 0.003500 | Commit Loss: 0.001917 | Perplexity: 400.384862
2025-09-30 12:09:00,053 Stage: Train 0.5 | Epoch: 424 | Iter: 258000 | Total Loss: 0.004417 | Recon Loss: 0.003463 | Commit Loss: 0.001907 | Perplexity: 399.776318
2025-09-30 12:12:22,334 Stage: Train 0.5 | Epoch: 424 | Iter: 258200 | Total Loss: 0.004429 | Recon Loss: 0.003469 | Commit Loss: 0.001921 | Perplexity: 400.773238
2025-09-30 12:15:45,040 Stage: Train 0.5 | Epoch: 424 | Iter: 258400 | Total Loss: 0.004462 | Recon Loss: 0.003496 | Commit Loss: 0.001931 | Perplexity: 400.768218
Trainning Epoch:  52%|█████▏    | 425/823 [73:03:25<68:20:01, 618.09s/it]Trainning Epoch:  52%|█████▏    | 425/823 [73:03:25<68:20:03, 618.10s/it]Trainning Epoch:  52%|█████▏    | 425/823 [73:03:25<68:20:04, 618.10s/it]Trainning Epoch:  52%|█████▏    | 425/823 [73:03:25<68:20:03, 618.10s/it]2025-09-30 12:19:09,415 Stage: Train 0.5 | Epoch: 425 | Iter: 258600 | Total Loss: 0.004412 | Recon Loss: 0.003458 | Commit Loss: 0.001909 | Perplexity: 400.222802
2025-09-30 12:22:30,411 Stage: Train 0.5 | Epoch: 425 | Iter: 258800 | Total Loss: 0.004416 | Recon Loss: 0.003462 | Commit Loss: 0.001909 | Perplexity: 400.792319
2025-09-30 12:25:52,525 Stage: Train 0.5 | Epoch: 425 | Iter: 259000 | Total Loss: 0.004458 | Recon Loss: 0.003495 | Commit Loss: 0.001925 | Perplexity: 400.829032
Trainning Epoch:  52%|█████▏    | 426/823 [73:13:41<68:04:40, 617.33s/it]Trainning Epoch:  52%|█████▏    | 426/823 [73:13:41<68:04:44, 617.34s/it]Trainning Epoch:  52%|█████▏    | 426/823 [73:13:41<68:04:44, 617.34s/it]Trainning Epoch:  52%|█████▏    | 426/823 [73:13:41<68:04:47, 617.35s/it]2025-09-30 12:29:18,546 Stage: Train 0.5 | Epoch: 426 | Iter: 259200 | Total Loss: 0.004413 | Recon Loss: 0.003452 | Commit Loss: 0.001921 | Perplexity: 401.401416
2025-09-30 12:32:41,079 Stage: Train 0.5 | Epoch: 426 | Iter: 259400 | Total Loss: 0.004441 | Recon Loss: 0.003483 | Commit Loss: 0.001917 | Perplexity: 400.616597
2025-09-30 12:36:03,640 Stage: Train 0.5 | Epoch: 426 | Iter: 259600 | Total Loss: 0.004404 | Recon Loss: 0.003450 | Commit Loss: 0.001909 | Perplexity: 400.768709
Trainning Epoch:  52%|█████▏    | 427/823 [73:24:00<67:58:10, 617.90s/it]Trainning Epoch:  52%|█████▏    | 427/823 [73:24:00<67:58:09, 617.90s/it]Trainning Epoch:  52%|█████▏    | 427/823 [73:24:00<67:58:09, 617.90s/it]Trainning Epoch:  52%|█████▏    | 427/823 [73:24:00<67:58:10, 617.90s/it]2025-09-30 12:39:28,492 Stage: Train 0.5 | Epoch: 427 | Iter: 259800 | Total Loss: 0.004413 | Recon Loss: 0.003458 | Commit Loss: 0.001909 | Perplexity: 400.926374
2025-09-30 12:42:50,610 Stage: Train 0.5 | Epoch: 427 | Iter: 260000 | Total Loss: 0.004454 | Recon Loss: 0.003489 | Commit Loss: 0.001930 | Perplexity: 401.386938
2025-09-30 12:42:50,610 Saving model at iteration 260000
2025-09-30 12:42:50,920 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_428_step_260000
2025-09-30 12:42:51,585 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_428_step_260000/model.safetensors
2025-09-30 12:42:52,182 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_428_step_260000/optimizer.bin
2025-09-30 12:42:52,183 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_428_step_260000/scheduler.bin
2025-09-30 12:42:52,183 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_428_step_260000/sampler.bin
2025-09-30 12:42:52,184 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_428_step_260000/random_states_0.pkl
2025-09-30 12:46:21,744 Stage: Train 0.5 | Epoch: 427 | Iter: 260200 | Total Loss: 0.004435 | Recon Loss: 0.003480 | Commit Loss: 0.001911 | Perplexity: 400.415236
Trainning Epoch:  52%|█████▏    | 428/823 [73:34:27<68:04:54, 620.49s/it]Trainning Epoch:  52%|█████▏    | 428/823 [73:34:27<68:04:59, 620.51s/it]Trainning Epoch:  52%|█████▏    | 428/823 [73:34:27<68:05:00, 620.51s/it]Trainning Epoch:  52%|█████▏    | 428/823 [73:34:27<68:05:01, 620.51s/it]2025-09-30 12:49:53,773 Stage: Train 0.5 | Epoch: 428 | Iter: 260400 | Total Loss: 0.004421 | Recon Loss: 0.003465 | Commit Loss: 0.001912 | Perplexity: 401.362470
2025-09-30 12:53:30,765 Stage: Train 0.5 | Epoch: 428 | Iter: 260600 | Total Loss: 0.004431 | Recon Loss: 0.003467 | Commit Loss: 0.001928 | Perplexity: 401.198949
2025-09-30 12:57:07,156 Stage: Train 0.5 | Epoch: 428 | Iter: 260800 | Total Loss: 0.004431 | Recon Loss: 0.003477 | Commit Loss: 0.001907 | Perplexity: 401.063468
Trainning Epoch:  52%|█████▏    | 429/823 [73:45:22<69:02:47, 630.88s/it]Trainning Epoch:  52%|█████▏    | 429/823 [73:45:22<69:02:47, 630.88s/it]Trainning Epoch:  52%|█████▏    | 429/823 [73:45:22<69:02:47, 630.88s/it]Trainning Epoch:  52%|█████▏    | 429/823 [73:45:22<69:02:47, 630.88s/it]2025-09-30 13:00:43,688 Stage: Train 0.5 | Epoch: 429 | Iter: 261000 | Total Loss: 0.004399 | Recon Loss: 0.003449 | Commit Loss: 0.001900 | Perplexity: 400.336241
2025-09-30 13:04:17,063 Stage: Train 0.5 | Epoch: 429 | Iter: 261200 | Total Loss: 0.004427 | Recon Loss: 0.003466 | Commit Loss: 0.001921 | Perplexity: 401.139888
2025-09-30 13:07:51,503 Stage: Train 0.5 | Epoch: 429 | Iter: 261400 | Total Loss: 0.004429 | Recon Loss: 0.003470 | Commit Loss: 0.001919 | Perplexity: 400.206477
Trainning Epoch:  52%|█████▏    | 430/823 [73:56:14<69:34:15, 637.29s/it]Trainning Epoch:  52%|█████▏    | 430/823 [73:56:14<69:34:19, 637.30s/it]Trainning Epoch:  52%|█████▏    | 430/823 [73:56:14<69:34:17, 637.30s/it]Trainning Epoch:  52%|█████▏    | 430/823 [73:56:14<69:34:16, 637.29s/it]2025-09-30 13:11:26,411 Stage: Train 0.5 | Epoch: 430 | Iter: 261600 | Total Loss: 0.004389 | Recon Loss: 0.003436 | Commit Loss: 0.001905 | Perplexity: 400.439547
2025-09-30 13:14:58,776 Stage: Train 0.5 | Epoch: 430 | Iter: 261800 | Total Loss: 0.004418 | Recon Loss: 0.003466 | Commit Loss: 0.001903 | Perplexity: 400.203758
2025-09-30 13:18:32,129 Stage: Train 0.5 | Epoch: 430 | Iter: 262000 | Total Loss: 0.004421 | Recon Loss: 0.003460 | Commit Loss: 0.001923 | Perplexity: 401.450414
Trainning Epoch:  52%|█████▏    | 431/823 [74:07:03<69:47:19, 640.92s/it]Trainning Epoch:  52%|█████▏    | 431/823 [74:07:03<69:47:22, 640.92s/it]Trainning Epoch:  52%|█████▏    | 431/823 [74:07:03<69:47:20, 640.92s/it]Trainning Epoch:  52%|█████▏    | 431/823 [74:07:03<69:47:22, 640.92s/it]2025-09-30 13:22:06,461 Stage: Train 0.5 | Epoch: 431 | Iter: 262200 | Total Loss: 0.004414 | Recon Loss: 0.003456 | Commit Loss: 0.001918 | Perplexity: 400.598040
2025-09-30 13:25:38,935 Stage: Train 0.5 | Epoch: 431 | Iter: 262400 | Total Loss: 0.004420 | Recon Loss: 0.003466 | Commit Loss: 0.001908 | Perplexity: 400.413386
2025-09-30 13:29:12,227 Stage: Train 0.5 | Epoch: 431 | Iter: 262600 | Total Loss: 0.004423 | Recon Loss: 0.003468 | Commit Loss: 0.001912 | Perplexity: 401.288527
Trainning Epoch:  52%|█████▏    | 432/823 [74:17:51<69:49:10, 642.84s/it]Trainning Epoch:  52%|█████▏    | 432/823 [74:17:51<69:49:12, 642.84s/it]Trainning Epoch:  52%|█████▏    | 432/823 [74:17:51<69:49:13, 642.85s/it]Trainning Epoch:  52%|█████▏    | 432/823 [74:17:51<69:49:13, 642.85s/it]2025-09-30 13:32:43,050 Stage: Train 0.5 | Epoch: 432 | Iter: 262800 | Total Loss: 0.004432 | Recon Loss: 0.003474 | Commit Loss: 0.001917 | Perplexity: 400.701701
2025-09-30 13:36:10,290 Stage: Train 0.5 | Epoch: 432 | Iter: 263000 | Total Loss: 0.004425 | Recon Loss: 0.003465 | Commit Loss: 0.001919 | Perplexity: 400.951222
2025-09-30 13:39:38,836 Stage: Train 0.5 | Epoch: 432 | Iter: 263200 | Total Loss: 0.004408 | Recon Loss: 0.003449 | Commit Loss: 0.001918 | Perplexity: 400.866503
Trainning Epoch:  53%|█████▎    | 433/823 [74:28:26<69:23:31, 640.54s/it]Trainning Epoch:  53%|█████▎    | 433/823 [74:28:26<69:23:31, 640.54s/it]Trainning Epoch:  53%|█████▎    | 433/823 [74:28:26<69:23:32, 640.55s/it]Trainning Epoch:  53%|█████▎    | 433/823 [74:28:26<69:23:32, 640.55s/it]2025-09-30 13:43:08,905 Stage: Train 0.5 | Epoch: 433 | Iter: 263400 | Total Loss: 0.004388 | Recon Loss: 0.003439 | Commit Loss: 0.001899 | Perplexity: 400.460856
2025-09-30 13:46:36,865 Stage: Train 0.5 | Epoch: 433 | Iter: 263600 | Total Loss: 0.004422 | Recon Loss: 0.003459 | Commit Loss: 0.001926 | Perplexity: 401.135647
2025-09-30 13:50:06,509 Stage: Train 0.5 | Epoch: 433 | Iter: 263800 | Total Loss: 0.004419 | Recon Loss: 0.003460 | Commit Loss: 0.001918 | Perplexity: 401.196821
Trainning Epoch:  53%|█████▎    | 434/823 [74:39:02<69:03:35, 639.11s/it]Trainning Epoch:  53%|█████▎    | 434/823 [74:39:02<69:03:34, 639.11s/it]Trainning Epoch:  53%|█████▎    | 434/823 [74:39:02<69:03:33, 639.11s/it]Trainning Epoch:  53%|█████▎    | 434/823 [74:39:02<69:03:33, 639.11s/it]2025-09-30 13:53:36,727 Stage: Train 0.5 | Epoch: 434 | Iter: 264000 | Total Loss: 0.004415 | Recon Loss: 0.003458 | Commit Loss: 0.001914 | Perplexity: 400.503009
2025-09-30 13:57:02,598 Stage: Train 0.5 | Epoch: 434 | Iter: 264200 | Total Loss: 0.004401 | Recon Loss: 0.003442 | Commit Loss: 0.001918 | Perplexity: 400.570312
2025-09-30 14:00:29,083 Stage: Train 0.5 | Epoch: 434 | Iter: 264400 | Total Loss: 0.004414 | Recon Loss: 0.003457 | Commit Loss: 0.001915 | Perplexity: 400.579368
Trainning Epoch:  53%|█████▎    | 435/823 [74:49:32<68:34:54, 636.33s/it]Trainning Epoch:  53%|█████▎    | 435/823 [74:49:32<68:34:57, 636.33s/it]Trainning Epoch:  53%|█████▎    | 435/823 [74:49:32<68:34:56, 636.33s/it]Trainning Epoch:  53%|█████▎    | 435/823 [74:49:32<68:34:57, 636.33s/it]2025-09-30 14:03:59,708 Stage: Train 0.5 | Epoch: 435 | Iter: 264600 | Total Loss: 0.004387 | Recon Loss: 0.003431 | Commit Loss: 0.001912 | Perplexity: 401.047630
2025-09-30 14:07:27,913 Stage: Train 0.5 | Epoch: 435 | Iter: 264800 | Total Loss: 0.004444 | Recon Loss: 0.003477 | Commit Loss: 0.001934 | Perplexity: 401.860317
2025-09-30 14:10:55,552 Stage: Train 0.5 | Epoch: 435 | Iter: 265000 | Total Loss: 0.004449 | Recon Loss: 0.003488 | Commit Loss: 0.001923 | Perplexity: 400.994591
Trainning Epoch:  53%|█████▎    | 436/823 [75:00:07<68:22:57, 636.12s/it]Trainning Epoch:  53%|█████▎    | 436/823 [75:00:07<68:22:57, 636.12s/it]Trainning Epoch:  53%|█████▎    | 436/823 [75:00:07<68:22:59, 636.12s/it]Trainning Epoch:  53%|█████▎    | 436/823 [75:00:07<68:22:56, 636.12s/it]2025-09-30 14:14:27,137 Stage: Train 0.5 | Epoch: 436 | Iter: 265200 | Total Loss: 0.004402 | Recon Loss: 0.003447 | Commit Loss: 0.001911 | Perplexity: 400.884389
2025-09-30 14:17:55,460 Stage: Train 0.5 | Epoch: 436 | Iter: 265400 | Total Loss: 0.004401 | Recon Loss: 0.003438 | Commit Loss: 0.001926 | Perplexity: 400.879829
2025-09-30 14:21:22,630 Stage: Train 0.5 | Epoch: 436 | Iter: 265600 | Total Loss: 0.004423 | Recon Loss: 0.003464 | Commit Loss: 0.001917 | Perplexity: 400.988827
Trainning Epoch:  53%|█████▎    | 437/823 [75:10:41<68:08:45, 635.56s/it]Trainning Epoch:  53%|█████▎    | 437/823 [75:10:41<68:08:45, 635.56s/it]Trainning Epoch:  53%|█████▎    | 437/823 [75:10:41<68:08:47, 635.56s/it]Trainning Epoch:  53%|█████▎    | 437/823 [75:10:41<68:08:45, 635.56s/it]2025-09-30 14:24:53,345 Stage: Train 0.5 | Epoch: 437 | Iter: 265800 | Total Loss: 0.004416 | Recon Loss: 0.003458 | Commit Loss: 0.001916 | Perplexity: 401.167130
2025-09-30 14:28:20,359 Stage: Train 0.5 | Epoch: 437 | Iter: 266000 | Total Loss: 0.004381 | Recon Loss: 0.003428 | Commit Loss: 0.001906 | Perplexity: 401.190468
2025-09-30 14:31:50,191 Stage: Train 0.5 | Epoch: 437 | Iter: 266200 | Total Loss: 0.004424 | Recon Loss: 0.003467 | Commit Loss: 0.001913 | Perplexity: 400.531080
Trainning Epoch:  53%|█████▎    | 438/823 [75:21:18<67:59:39, 635.79s/it]Trainning Epoch:  53%|█████▎    | 438/823 [75:21:18<67:59:40, 635.79s/it]Trainning Epoch:  53%|█████▎    | 438/823 [75:21:18<67:59:39, 635.79s/it]Trainning Epoch:  53%|█████▎    | 438/823 [75:21:18<67:59:40, 635.79s/it]2025-09-30 14:35:21,480 Stage: Train 0.5 | Epoch: 438 | Iter: 266400 | Total Loss: 0.004407 | Recon Loss: 0.003450 | Commit Loss: 0.001913 | Perplexity: 400.294203
2025-09-30 14:38:49,154 Stage: Train 0.5 | Epoch: 438 | Iter: 266600 | Total Loss: 0.004407 | Recon Loss: 0.003452 | Commit Loss: 0.001910 | Perplexity: 401.263381
2025-09-30 14:42:19,506 Stage: Train 0.5 | Epoch: 438 | Iter: 266800 | Total Loss: 0.004404 | Recon Loss: 0.003443 | Commit Loss: 0.001924 | Perplexity: 402.047569
Trainning Epoch:  53%|█████▎    | 439/823 [75:31:58<67:56:56, 637.02s/it]Trainning Epoch:  53%|█████▎    | 439/823 [75:31:58<67:56:55, 637.02s/it]Trainning Epoch:  53%|█████▎    | 439/823 [75:31:58<67:56:58, 637.03s/it]Trainning Epoch:  53%|█████▎    | 439/823 [75:31:58<67:56:59, 637.03s/it]2025-09-30 14:45:52,112 Stage: Train 0.5 | Epoch: 439 | Iter: 267000 | Total Loss: 0.004426 | Recon Loss: 0.003464 | Commit Loss: 0.001924 | Perplexity: 401.388821
2025-09-30 14:49:21,939 Stage: Train 0.5 | Epoch: 439 | Iter: 267200 | Total Loss: 0.004400 | Recon Loss: 0.003452 | Commit Loss: 0.001896 | Perplexity: 400.443525
2025-09-30 14:52:51,891 Stage: Train 0.5 | Epoch: 439 | Iter: 267400 | Total Loss: 0.004393 | Recon Loss: 0.003441 | Commit Loss: 0.001905 | Perplexity: 400.641150
Trainning Epoch:  53%|█████▎    | 440/823 [75:42:37<67:51:18, 637.80s/it]Trainning Epoch:  53%|█████▎    | 440/823 [75:42:37<67:51:22, 637.81s/it]Trainning Epoch:  53%|█████▎    | 440/823 [75:42:37<67:51:21, 637.81s/it]Trainning Epoch:  53%|█████▎    | 440/823 [75:42:37<67:51:23, 637.82s/it]2025-09-30 14:56:23,494 Stage: Train 0.5 | Epoch: 440 | Iter: 267600 | Total Loss: 0.004394 | Recon Loss: 0.003433 | Commit Loss: 0.001923 | Perplexity: 400.901049
2025-09-30 14:59:52,025 Stage: Train 0.5 | Epoch: 440 | Iter: 267800 | Total Loss: 0.004407 | Recon Loss: 0.003448 | Commit Loss: 0.001918 | Perplexity: 400.596431
2025-09-30 15:03:22,355 Stage: Train 0.5 | Epoch: 440 | Iter: 268000 | Total Loss: 0.004395 | Recon Loss: 0.003442 | Commit Loss: 0.001906 | Perplexity: 400.394854
Trainning Epoch:  54%|█████▎    | 441/823 [75:53:17<67:43:40, 638.27s/it]Trainning Epoch:  54%|█████▎    | 441/823 [75:53:17<67:43:39, 638.27s/it]Trainning Epoch:  54%|█████▎    | 441/823 [75:53:17<67:43:42, 638.28s/it]Trainning Epoch:  54%|█████▎    | 441/823 [75:53:17<67:43:42, 638.28s/it]2025-09-30 15:06:54,033 Stage: Train 0.5 | Epoch: 441 | Iter: 268200 | Total Loss: 0.004385 | Recon Loss: 0.003435 | Commit Loss: 0.001900 | Perplexity: 399.893737
2025-09-30 15:10:19,884 Stage: Train 0.5 | Epoch: 441 | Iter: 268400 | Total Loss: 0.004381 | Recon Loss: 0.003427 | Commit Loss: 0.001908 | Perplexity: 400.971826
2025-09-30 15:13:47,149 Stage: Train 0.5 | Epoch: 441 | Iter: 268600 | Total Loss: 0.004392 | Recon Loss: 0.003437 | Commit Loss: 0.001910 | Perplexity: 400.197702
Trainning Epoch:  54%|█████▎    | 442/823 [76:03:48<67:20:30, 636.30s/it]Trainning Epoch:  54%|█████▎    | 442/823 [76:03:48<67:20:29, 636.30s/it]Trainning Epoch:  54%|█████▎    | 442/823 [76:03:48<67:20:30, 636.30s/it]Trainning Epoch:  54%|█████▎    | 442/823 [76:03:48<67:20:30, 636.30s/it]2025-09-30 15:17:18,258 Stage: Train 0.5 | Epoch: 442 | Iter: 268800 | Total Loss: 0.004403 | Recon Loss: 0.003445 | Commit Loss: 0.001916 | Perplexity: 401.046295
2025-09-30 15:20:44,583 Stage: Train 0.5 | Epoch: 442 | Iter: 269000 | Total Loss: 0.004394 | Recon Loss: 0.003429 | Commit Loss: 0.001929 | Perplexity: 401.338858
2025-09-30 15:24:11,177 Stage: Train 0.5 | Epoch: 442 | Iter: 269200 | Total Loss: 0.004401 | Recon Loss: 0.003446 | Commit Loss: 0.001911 | Perplexity: 400.527276
Trainning Epoch:  54%|█████▍    | 443/823 [76:14:20<67:01:29, 634.97s/it]Trainning Epoch:  54%|█████▍    | 443/823 [76:14:20<67:01:26, 634.96s/it]Trainning Epoch:  54%|█████▍    | 443/823 [76:14:20<67:01:27, 634.97s/it]Trainning Epoch:  54%|█████▍    | 443/823 [76:14:20<67:01:30, 634.97s/it]2025-09-30 15:27:42,454 Stage: Train 0.5 | Epoch: 443 | Iter: 269400 | Total Loss: 0.004404 | Recon Loss: 0.003449 | Commit Loss: 0.001912 | Perplexity: 400.192332
2025-09-30 15:31:09,852 Stage: Train 0.5 | Epoch: 443 | Iter: 269600 | Total Loss: 0.004365 | Recon Loss: 0.003408 | Commit Loss: 0.001915 | Perplexity: 400.526821
2025-09-30 15:34:38,317 Stage: Train 0.5 | Epoch: 443 | Iter: 269800 | Total Loss: 0.004399 | Recon Loss: 0.003448 | Commit Loss: 0.001901 | Perplexity: 400.686194
Trainning Epoch:  54%|█████▍    | 444/823 [76:24:56<66:52:55, 635.29s/it]Trainning Epoch:  54%|█████▍    | 444/823 [76:24:56<66:52:52, 635.28s/it]Trainning Epoch:  54%|█████▍    | 444/823 [76:24:56<66:52:52, 635.28s/it]Trainning Epoch:  54%|█████▍    | 444/823 [76:24:56<66:52:54, 635.29s/it]2025-09-30 15:38:10,032 Stage: Train 0.5 | Epoch: 444 | Iter: 270000 | Total Loss: 0.004390 | Recon Loss: 0.003435 | Commit Loss: 0.001909 | Perplexity: 401.494935
2025-09-30 15:41:38,424 Stage: Train 0.5 | Epoch: 444 | Iter: 270200 | Total Loss: 0.004379 | Recon Loss: 0.003419 | Commit Loss: 0.001920 | Perplexity: 400.326171
2025-09-30 15:45:06,731 Stage: Train 0.5 | Epoch: 444 | Iter: 270400 | Total Loss: 0.004404 | Recon Loss: 0.003448 | Commit Loss: 0.001912 | Perplexity: 400.543904
Trainning Epoch:  54%|█████▍    | 445/823 [76:35:34<66:46:06, 635.89s/it]Trainning Epoch:  54%|█████▍    | 445/823 [76:35:34<66:46:05, 635.89s/it]Trainning Epoch:  54%|█████▍    | 445/823 [76:35:34<66:46:09, 635.90s/it]Trainning Epoch:  54%|█████▍    | 445/823 [76:35:34<66:46:09, 635.90s/it]2025-09-30 15:48:38,994 Stage: Train 0.5 | Epoch: 445 | Iter: 270600 | Total Loss: 0.004408 | Recon Loss: 0.003449 | Commit Loss: 0.001919 | Perplexity: 400.927772
2025-09-30 15:52:08,496 Stage: Train 0.5 | Epoch: 445 | Iter: 270800 | Total Loss: 0.004389 | Recon Loss: 0.003427 | Commit Loss: 0.001923 | Perplexity: 401.603424
2025-09-30 15:55:38,621 Stage: Train 0.5 | Epoch: 445 | Iter: 271000 | Total Loss: 0.004401 | Recon Loss: 0.003442 | Commit Loss: 0.001919 | Perplexity: 401.633927
Trainning Epoch:  54%|█████▍    | 446/823 [76:46:14<66:44:44, 637.36s/it]Trainning Epoch:  54%|█████▍    | 446/823 [76:46:14<66:44:43, 637.36s/it]Trainning Epoch:  54%|█████▍    | 446/823 [76:46:14<66:44:43, 637.36s/it]Trainning Epoch:  54%|█████▍    | 446/823 [76:46:14<66:44:43, 637.36s/it]2025-09-30 15:59:10,926 Stage: Train 0.5 | Epoch: 446 | Iter: 271200 | Total Loss: 0.004393 | Recon Loss: 0.003440 | Commit Loss: 0.001907 | Perplexity: 401.101203
2025-09-30 16:02:37,406 Stage: Train 0.5 | Epoch: 446 | Iter: 271400 | Total Loss: 0.004378 | Recon Loss: 0.003426 | Commit Loss: 0.001905 | Perplexity: 401.359204
2025-09-30 16:06:04,938 Stage: Train 0.5 | Epoch: 446 | Iter: 271600 | Total Loss: 0.004349 | Recon Loss: 0.003399 | Commit Loss: 0.001900 | Perplexity: 399.253835
Trainning Epoch:  54%|█████▍    | 447/823 [76:56:47<66:26:01, 636.07s/it]Trainning Epoch:  54%|█████▍    | 447/823 [76:56:47<66:26:03, 636.07s/it]Trainning Epoch:  54%|█████▍    | 447/823 [76:56:47<66:26:05, 636.08s/it]Trainning Epoch:  54%|█████▍    | 447/823 [76:56:47<66:26:08, 636.09s/it]2025-09-30 16:09:35,513 Stage: Train 0.5 | Epoch: 447 | Iter: 271800 | Total Loss: 0.004415 | Recon Loss: 0.003452 | Commit Loss: 0.001925 | Perplexity: 401.455784
2025-09-30 16:13:02,664 Stage: Train 0.5 | Epoch: 447 | Iter: 272000 | Total Loss: 0.004376 | Recon Loss: 0.003418 | Commit Loss: 0.001917 | Perplexity: 401.106591
2025-09-30 16:16:30,000 Stage: Train 0.5 | Epoch: 447 | Iter: 272200 | Total Loss: 0.004399 | Recon Loss: 0.003443 | Commit Loss: 0.001913 | Perplexity: 400.218634
Trainning Epoch:  54%|█████▍    | 448/823 [77:07:22<66:12:10, 635.55s/it]Trainning Epoch:  54%|█████▍    | 448/823 [77:07:22<66:12:13, 635.56s/it]Trainning Epoch:  54%|█████▍    | 448/823 [77:07:22<66:12:11, 635.55s/it]Trainning Epoch:  54%|█████▍    | 448/823 [77:07:22<66:12:13, 635.56s/it]2025-09-30 16:20:01,911 Stage: Train 0.5 | Epoch: 448 | Iter: 272400 | Total Loss: 0.004392 | Recon Loss: 0.003434 | Commit Loss: 0.001916 | Perplexity: 400.462517
2025-09-30 16:23:29,393 Stage: Train 0.5 | Epoch: 448 | Iter: 272600 | Total Loss: 0.004415 | Recon Loss: 0.003459 | Commit Loss: 0.001912 | Perplexity: 401.802815
2025-09-30 16:26:58,198 Stage: Train 0.5 | Epoch: 448 | Iter: 272800 | Total Loss: 0.004355 | Recon Loss: 0.003404 | Commit Loss: 0.001903 | Perplexity: 400.182045
Trainning Epoch:  55%|█████▍    | 449/823 [77:17:59<66:04:30, 636.02s/it]Trainning Epoch:  55%|█████▍    | 449/823 [77:17:59<66:04:27, 636.01s/it]Trainning Epoch:  55%|█████▍    | 449/823 [77:17:59<66:04:30, 636.02s/it]Trainning Epoch:  55%|█████▍    | 449/823 [77:17:59<66:04:29, 636.01s/it]2025-09-30 16:30:31,258 Stage: Train 0.5 | Epoch: 449 | Iter: 273000 | Total Loss: 0.004434 | Recon Loss: 0.003472 | Commit Loss: 0.001924 | Perplexity: 401.741409
2025-09-30 16:33:59,145 Stage: Train 0.5 | Epoch: 449 | Iter: 273200 | Total Loss: 0.004345 | Recon Loss: 0.003394 | Commit Loss: 0.001902 | Perplexity: 400.426867
2025-09-30 16:37:28,818 Stage: Train 0.5 | Epoch: 449 | Iter: 273400 | Total Loss: 0.004412 | Recon Loss: 0.003453 | Commit Loss: 0.001919 | Perplexity: 402.020101
2025-09-30 16:40:56,711 Stage: Train 0.5 | Epoch: 449 | Iter: 273600 | Total Loss: 0.004404 | Recon Loss: 0.003444 | Commit Loss: 0.001920 | Perplexity: 401.599395
Trainning Epoch:  55%|█████▍    | 450/823 [77:28:37<65:57:53, 636.66s/it]Trainning Epoch:  55%|█████▍    | 450/823 [77:28:37<65:57:55, 636.66s/it]Trainning Epoch:  55%|█████▍    | 450/823 [77:28:37<65:57:56, 636.67s/it]Trainning Epoch:  55%|█████▍    | 450/823 [77:28:37<65:57:56, 636.67s/it]2025-09-30 16:44:27,225 Stage: Train 0.5 | Epoch: 450 | Iter: 273800 | Total Loss: 0.004398 | Recon Loss: 0.003436 | Commit Loss: 0.001924 | Perplexity: 400.428503
2025-09-30 16:47:56,340 Stage: Train 0.5 | Epoch: 450 | Iter: 274000 | Total Loss: 0.004386 | Recon Loss: 0.003434 | Commit Loss: 0.001904 | Perplexity: 400.285594
2025-09-30 16:51:23,445 Stage: Train 0.5 | Epoch: 450 | Iter: 274200 | Total Loss: 0.004377 | Recon Loss: 0.003423 | Commit Loss: 0.001906 | Perplexity: 400.297595
Trainning Epoch:  55%|█████▍    | 451/823 [77:39:12<65:44:04, 636.14s/it]Trainning Epoch:  55%|█████▍    | 451/823 [77:39:12<65:44:02, 636.13s/it]Trainning Epoch:  55%|█████▍    | 451/823 [77:39:12<65:44:03, 636.14s/it]Trainning Epoch:  55%|█████▍    | 451/823 [77:39:12<65:44:03, 636.14s/it]2025-09-30 16:54:52,951 Stage: Train 0.5 | Epoch: 451 | Iter: 274400 | Total Loss: 0.004358 | Recon Loss: 0.003405 | Commit Loss: 0.001907 | Perplexity: 400.338419
2025-09-30 16:58:19,116 Stage: Train 0.5 | Epoch: 451 | Iter: 274600 | Total Loss: 0.004411 | Recon Loss: 0.003449 | Commit Loss: 0.001924 | Perplexity: 401.226484
2025-09-30 17:01:46,851 Stage: Train 0.5 | Epoch: 451 | Iter: 274800 | Total Loss: 0.004420 | Recon Loss: 0.003452 | Commit Loss: 0.001936 | Perplexity: 402.183667
Trainning Epoch:  55%|█████▍    | 452/823 [77:49:44<65:25:08, 634.79s/it]Trainning Epoch:  55%|█████▍    | 452/823 [77:49:44<65:25:05, 634.79s/it]Trainning Epoch:  55%|█████▍    | 452/823 [77:49:44<65:25:09, 634.80s/it]Trainning Epoch:  55%|█████▍    | 452/823 [77:49:44<65:25:10, 634.80s/it]2025-09-30 17:05:26,223 Stage: Train 0.5 | Epoch: 452 | Iter: 275000 | Total Loss: 0.004365 | Recon Loss: 0.003414 | Commit Loss: 0.001902 | Perplexity: 400.497407
2025-09-30 17:09:02,379 Stage: Train 0.5 | Epoch: 452 | Iter: 275200 | Total Loss: 0.004376 | Recon Loss: 0.003413 | Commit Loss: 0.001925 | Perplexity: 402.053502
2025-09-30 17:12:37,300 Stage: Train 0.5 | Epoch: 452 | Iter: 275400 | Total Loss: 0.004392 | Recon Loss: 0.003429 | Commit Loss: 0.001927 | Perplexity: 401.904859
Trainning Epoch:  55%|█████▌    | 453/823 [78:00:43<65:59:37, 642.10s/it]Trainning Epoch:  55%|█████▌    | 453/823 [78:00:43<65:59:39, 642.11s/it]Trainning Epoch:  55%|█████▌    | 453/823 [78:00:43<65:59:37, 642.10s/it]Trainning Epoch:  55%|█████▌    | 453/823 [78:00:43<65:59:38, 642.11s/it]2025-09-30 17:16:07,539 Stage: Train 0.5 | Epoch: 453 | Iter: 275600 | Total Loss: 0.004365 | Recon Loss: 0.003416 | Commit Loss: 0.001898 | Perplexity: 400.547809
2025-09-30 17:19:33,661 Stage: Train 0.5 | Epoch: 453 | Iter: 275800 | Total Loss: 0.004367 | Recon Loss: 0.003413 | Commit Loss: 0.001907 | Perplexity: 400.605231
2025-09-30 17:23:01,208 Stage: Train 0.5 | Epoch: 453 | Iter: 276000 | Total Loss: 0.004395 | Recon Loss: 0.003436 | Commit Loss: 0.001917 | Perplexity: 401.106073
Trainning Epoch:  55%|█████▌    | 454/823 [78:11:14<65:29:34, 638.96s/it]Trainning Epoch:  55%|█████▌    | 454/823 [78:11:14<65:29:33, 638.95s/it]Trainning Epoch:  55%|█████▌    | 454/823 [78:11:14<65:29:35, 638.96s/it]Trainning Epoch:  55%|█████▌    | 454/823 [78:11:14<65:29:34, 638.96s/it]2025-09-30 17:26:32,480 Stage: Train 0.5 | Epoch: 454 | Iter: 276200 | Total Loss: 0.004356 | Recon Loss: 0.003401 | Commit Loss: 0.001910 | Perplexity: 401.674855
2025-09-30 17:30:01,062 Stage: Train 0.5 | Epoch: 454 | Iter: 276400 | Total Loss: 0.004386 | Recon Loss: 0.003426 | Commit Loss: 0.001921 | Perplexity: 400.486130
2025-09-30 17:33:30,694 Stage: Train 0.5 | Epoch: 454 | Iter: 276600 | Total Loss: 0.004383 | Recon Loss: 0.003428 | Commit Loss: 0.001910 | Perplexity: 400.510835
Trainning Epoch:  55%|█████▌    | 455/823 [78:21:53<65:17:57, 638.80s/it]Trainning Epoch:  55%|█████▌    | 455/823 [78:21:53<65:17:56, 638.79s/it]Trainning Epoch:  55%|█████▌    | 455/823 [78:21:53<65:17:59, 638.80s/it]Trainning Epoch:  55%|█████▌    | 455/823 [78:21:53<65:18:01, 638.81s/it]2025-09-30 17:37:03,898 Stage: Train 0.5 | Epoch: 455 | Iter: 276800 | Total Loss: 0.004332 | Recon Loss: 0.003382 | Commit Loss: 0.001900 | Perplexity: 399.920183
2025-09-30 17:40:32,121 Stage: Train 0.5 | Epoch: 455 | Iter: 277000 | Total Loss: 0.004360 | Recon Loss: 0.003409 | Commit Loss: 0.001902 | Perplexity: 400.672084
2025-09-30 17:44:02,539 Stage: Train 0.5 | Epoch: 455 | Iter: 277200 | Total Loss: 0.004395 | Recon Loss: 0.003439 | Commit Loss: 0.001912 | Perplexity: 402.367998
Trainning Epoch:  55%|█████▌    | 456/823 [78:32:33<65:09:37, 639.18s/it]Trainning Epoch:  55%|█████▌    | 456/823 [78:32:33<65:09:37, 639.17s/it]Trainning Epoch:  55%|█████▌    | 456/823 [78:32:33<65:09:37, 639.17s/it]Trainning Epoch:  55%|█████▌    | 456/823 [78:32:33<65:09:37, 639.17s/it]2025-09-30 17:47:34,670 Stage: Train 0.5 | Epoch: 456 | Iter: 277400 | Total Loss: 0.004374 | Recon Loss: 0.003419 | Commit Loss: 0.001909 | Perplexity: 402.612776
2025-09-30 17:51:03,309 Stage: Train 0.5 | Epoch: 456 | Iter: 277600 | Total Loss: 0.004354 | Recon Loss: 0.003395 | Commit Loss: 0.001919 | Perplexity: 401.201866
2025-09-30 17:54:32,859 Stage: Train 0.5 | Epoch: 456 | Iter: 277800 | Total Loss: 0.004370 | Recon Loss: 0.003418 | Commit Loss: 0.001904 | Perplexity: 401.371554
Trainning Epoch:  56%|█████▌    | 457/823 [78:43:11<64:57:02, 638.86s/it]Trainning Epoch:  56%|█████▌    | 457/823 [78:43:11<64:57:02, 638.86s/it]Trainning Epoch:  56%|█████▌    | 457/823 [78:43:11<64:57:05, 638.87s/it]Trainning Epoch:  56%|█████▌    | 457/823 [78:43:11<64:57:06, 638.87s/it]2025-09-30 17:58:02,788 Stage: Train 0.5 | Epoch: 457 | Iter: 278000 | Total Loss: 0.004354 | Recon Loss: 0.003405 | Commit Loss: 0.001897 | Perplexity: 401.368479
2025-09-30 18:01:28,619 Stage: Train 0.5 | Epoch: 457 | Iter: 278200 | Total Loss: 0.004341 | Recon Loss: 0.003385 | Commit Loss: 0.001912 | Perplexity: 401.437592
2025-09-30 18:04:55,539 Stage: Train 0.5 | Epoch: 457 | Iter: 278400 | Total Loss: 0.004393 | Recon Loss: 0.003433 | Commit Loss: 0.001919 | Perplexity: 401.777497
Trainning Epoch:  56%|█████▌    | 458/823 [78:53:42<64:31:39, 636.44s/it]Trainning Epoch:  56%|█████▌    | 458/823 [78:53:42<64:31:39, 636.44s/it]Trainning Epoch:  56%|█████▌    | 458/823 [78:53:42<64:31:41, 636.44s/it]Trainning Epoch:  56%|█████▌    | 458/823 [78:53:42<64:31:41, 636.44s/it]2025-09-30 18:08:25,263 Stage: Train 0.5 | Epoch: 458 | Iter: 278600 | Total Loss: 0.004354 | Recon Loss: 0.003398 | Commit Loss: 0.001913 | Perplexity: 401.273755
2025-09-30 18:11:50,488 Stage: Train 0.5 | Epoch: 458 | Iter: 278800 | Total Loss: 0.004364 | Recon Loss: 0.003412 | Commit Loss: 0.001904 | Perplexity: 401.983825
2025-09-30 18:15:16,619 Stage: Train 0.5 | Epoch: 458 | Iter: 279000 | Total Loss: 0.004363 | Recon Loss: 0.003407 | Commit Loss: 0.001912 | Perplexity: 401.115507
Trainning Epoch:  56%|█████▌    | 459/823 [79:04:11<64:07:59, 634.29s/it]Trainning Epoch:  56%|█████▌    | 459/823 [79:04:11<64:08:01, 634.29s/it]Trainning Epoch:  56%|█████▌    | 459/823 [79:04:11<64:08:01, 634.29s/it]Trainning Epoch:  56%|█████▌    | 459/823 [79:04:11<64:08:02, 634.29s/it]2025-09-30 18:18:47,660 Stage: Train 0.5 | Epoch: 459 | Iter: 279200 | Total Loss: 0.004349 | Recon Loss: 0.003402 | Commit Loss: 0.001893 | Perplexity: 401.630684
2025-09-30 18:22:16,721 Stage: Train 0.5 | Epoch: 459 | Iter: 279400 | Total Loss: 0.004369 | Recon Loss: 0.003411 | Commit Loss: 0.001916 | Perplexity: 401.640171
2025-09-30 18:25:46,102 Stage: Train 0.5 | Epoch: 459 | Iter: 279600 | Total Loss: 0.004373 | Recon Loss: 0.003418 | Commit Loss: 0.001909 | Perplexity: 401.820606
Trainning Epoch:  56%|█████▌    | 460/823 [79:14:50<64:05:29, 635.62s/it]Trainning Epoch:  56%|█████▌    | 460/823 [79:14:50<64:05:29, 635.62s/it]Trainning Epoch:  56%|█████▌    | 460/823 [79:14:50<64:05:32, 635.63s/it]Trainning Epoch:  56%|█████▌    | 460/823 [79:14:50<64:05:31, 635.62s/it]2025-09-30 18:29:16,508 Stage: Train 0.5 | Epoch: 460 | Iter: 279800 | Total Loss: 0.004347 | Recon Loss: 0.003393 | Commit Loss: 0.001909 | Perplexity: 401.147039
2025-09-30 18:32:41,915 Stage: Train 0.5 | Epoch: 460 | Iter: 280000 | Total Loss: 0.004359 | Recon Loss: 0.003410 | Commit Loss: 0.001898 | Perplexity: 401.817544
2025-09-30 18:32:41,915 Saving model at iteration 280000
2025-09-30 18:32:42,225 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_461_step_280000
2025-09-30 18:32:42,849 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_461_step_280000/model.safetensors
2025-09-30 18:32:43,430 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_461_step_280000/optimizer.bin
2025-09-30 18:32:43,430 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_461_step_280000/scheduler.bin
2025-09-30 18:32:43,431 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_461_step_280000/sampler.bin
2025-09-30 18:32:43,431 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_461_step_280000/random_states_0.pkl
2025-09-30 18:36:09,164 Stage: Train 0.5 | Epoch: 460 | Iter: 280200 | Total Loss: 0.004351 | Recon Loss: 0.003398 | Commit Loss: 0.001905 | Perplexity: 401.352846
Trainning Epoch:  56%|█████▌    | 461/823 [79:25:20<63:45:08, 634.00s/it]Trainning Epoch:  56%|█████▌    | 461/823 [79:25:20<63:45:06, 634.00s/it]Trainning Epoch:  56%|█████▌    | 461/823 [79:25:20<63:45:08, 634.00s/it]Trainning Epoch:  56%|█████▌    | 461/823 [79:25:20<63:45:08, 634.00s/it]2025-09-30 18:39:39,136 Stage: Train 0.5 | Epoch: 461 | Iter: 280400 | Total Loss: 0.004381 | Recon Loss: 0.003430 | Commit Loss: 0.001901 | Perplexity: 401.726151
2025-09-30 18:43:06,889 Stage: Train 0.5 | Epoch: 461 | Iter: 280600 | Total Loss: 0.004342 | Recon Loss: 0.003389 | Commit Loss: 0.001907 | Perplexity: 401.724497
2025-09-30 18:46:34,852 Stage: Train 0.5 | Epoch: 461 | Iter: 280800 | Total Loss: 0.004388 | Recon Loss: 0.003431 | Commit Loss: 0.001914 | Perplexity: 402.176515
Trainning Epoch:  56%|█████▌    | 462/823 [79:35:54<63:35:15, 634.11s/it]Trainning Epoch:  56%|█████▌    | 462/823 [79:35:54<63:35:15, 634.11s/it]Trainning Epoch:  56%|█████▌    | 462/823 [79:35:54<63:35:15, 634.12s/it]Trainning Epoch:  56%|█████▌    | 462/823 [79:35:54<63:35:15, 634.11s/it]2025-09-30 18:50:04,814 Stage: Train 0.5 | Epoch: 462 | Iter: 281000 | Total Loss: 0.004334 | Recon Loss: 0.003382 | Commit Loss: 0.001904 | Perplexity: 401.640893
2025-09-30 18:53:31,931 Stage: Train 0.5 | Epoch: 462 | Iter: 281200 | Total Loss: 0.004377 | Recon Loss: 0.003417 | Commit Loss: 0.001921 | Perplexity: 402.433458
2025-09-30 18:56:58,764 Stage: Train 0.5 | Epoch: 462 | Iter: 281400 | Total Loss: 0.004347 | Recon Loss: 0.003390 | Commit Loss: 0.001913 | Perplexity: 401.371363
Trainning Epoch:  56%|█████▋    | 463/823 [79:46:27<63:21:37, 633.60s/it]Trainning Epoch:  56%|█████▋    | 463/823 [79:46:27<63:21:37, 633.60s/it]Trainning Epoch:  56%|█████▋    | 463/823 [79:46:27<63:21:39, 633.61s/it]Trainning Epoch:  56%|█████▋    | 463/823 [79:46:27<63:21:38, 633.61s/it]2025-09-30 19:00:28,507 Stage: Train 0.5 | Epoch: 463 | Iter: 281600 | Total Loss: 0.004370 | Recon Loss: 0.003408 | Commit Loss: 0.001923 | Perplexity: 401.751083
2025-09-30 19:03:53,402 Stage: Train 0.5 | Epoch: 463 | Iter: 281800 | Total Loss: 0.004334 | Recon Loss: 0.003385 | Commit Loss: 0.001898 | Perplexity: 402.207032
2025-09-30 19:07:18,871 Stage: Train 0.5 | Epoch: 463 | Iter: 282000 | Total Loss: 0.004370 | Recon Loss: 0.003406 | Commit Loss: 0.001927 | Perplexity: 403.273893
Trainning Epoch:  56%|█████▋    | 464/823 [79:56:54<62:59:55, 631.74s/it]Trainning Epoch:  56%|█████▋    | 464/823 [79:56:54<62:59:57, 631.75s/it]Trainning Epoch:  56%|█████▋    | 464/823 [79:56:54<62:59:57, 631.75s/it]Trainning Epoch:  56%|█████▋    | 464/823 [79:56:54<62:59:54, 631.74s/it]2025-09-30 19:10:48,401 Stage: Train 0.5 | Epoch: 464 | Iter: 282200 | Total Loss: 0.004359 | Recon Loss: 0.003409 | Commit Loss: 0.001900 | Perplexity: 402.478900
2025-09-30 19:14:15,769 Stage: Train 0.5 | Epoch: 464 | Iter: 282400 | Total Loss: 0.004353 | Recon Loss: 0.003397 | Commit Loss: 0.001913 | Perplexity: 403.436535
2025-09-30 19:17:44,760 Stage: Train 0.5 | Epoch: 464 | Iter: 282600 | Total Loss: 0.004351 | Recon Loss: 0.003394 | Commit Loss: 0.001915 | Perplexity: 403.511848
Trainning Epoch:  57%|█████▋    | 465/823 [80:07:31<62:57:49, 633.15s/it]Trainning Epoch:  57%|█████▋    | 465/823 [80:07:31<62:57:51, 633.16s/it]Trainning Epoch:  57%|█████▋    | 465/823 [80:07:31<62:57:52, 633.16s/it]Trainning Epoch:  57%|█████▋    | 465/823 [80:07:31<62:57:54, 633.17s/it]2025-09-30 19:21:15,206 Stage: Train 0.5 | Epoch: 465 | Iter: 282800 | Total Loss: 0.004358 | Recon Loss: 0.003404 | Commit Loss: 0.001908 | Perplexity: 402.012585
2025-09-30 19:24:39,830 Stage: Train 0.5 | Epoch: 465 | Iter: 283000 | Total Loss: 0.004315 | Recon Loss: 0.003365 | Commit Loss: 0.001899 | Perplexity: 402.642514
2025-09-30 19:28:04,856 Stage: Train 0.5 | Epoch: 465 | Iter: 283200 | Total Loss: 0.004375 | Recon Loss: 0.003419 | Commit Loss: 0.001911 | Perplexity: 403.419588
Trainning Epoch:  57%|█████▋    | 466/823 [80:17:56<62:33:28, 630.84s/it]Trainning Epoch:  57%|█████▋    | 466/823 [80:17:56<62:33:31, 630.84s/it]Trainning Epoch:  57%|█████▋    | 466/823 [80:17:56<62:33:31, 630.84s/it]Trainning Epoch:  57%|█████▋    | 466/823 [80:17:56<62:33:30, 630.84s/it]2025-09-30 19:31:34,906 Stage: Train 0.5 | Epoch: 466 | Iter: 283400 | Total Loss: 0.004324 | Recon Loss: 0.003373 | Commit Loss: 0.001902 | Perplexity: 402.588181
2025-09-30 19:35:02,509 Stage: Train 0.5 | Epoch: 466 | Iter: 283600 | Total Loss: 0.004349 | Recon Loss: 0.003398 | Commit Loss: 0.001903 | Perplexity: 402.659176
2025-09-30 19:38:29,899 Stage: Train 0.5 | Epoch: 466 | Iter: 283800 | Total Loss: 0.004347 | Recon Loss: 0.003397 | Commit Loss: 0.001900 | Perplexity: 401.950869
Trainning Epoch:  57%|█████▋    | 467/823 [80:28:32<62:31:27, 632.27s/it]Trainning Epoch:  57%|█████▋    | 467/823 [80:28:32<62:31:31, 632.28s/it]Trainning Epoch:  57%|█████▋    | 467/823 [80:28:32<62:31:30, 632.28s/it]Trainning Epoch:  57%|█████▋    | 467/823 [80:28:32<62:31:31, 632.28s/it]2025-09-30 19:42:00,939 Stage: Train 0.5 | Epoch: 467 | Iter: 284000 | Total Loss: 0.004352 | Recon Loss: 0.003399 | Commit Loss: 0.001906 | Perplexity: 402.883961
2025-09-30 19:45:27,405 Stage: Train 0.5 | Epoch: 467 | Iter: 284200 | Total Loss: 0.004319 | Recon Loss: 0.003370 | Commit Loss: 0.001898 | Perplexity: 402.462038
2025-09-30 19:48:55,637 Stage: Train 0.5 | Epoch: 467 | Iter: 284400 | Total Loss: 0.004349 | Recon Loss: 0.003395 | Commit Loss: 0.001909 | Perplexity: 402.858912
Trainning Epoch:  57%|█████▋    | 468/823 [80:39:05<62:22:49, 632.59s/it]Trainning Epoch:  57%|█████▋    | 468/823 [80:39:05<62:22:46, 632.58s/it]Trainning Epoch:  57%|█████▋    | 468/823 [80:39:05<62:22:48, 632.59s/it]Trainning Epoch:  57%|█████▋    | 468/823 [80:39:05<62:22:48, 632.59s/it]2025-09-30 19:52:26,168 Stage: Train 0.5 | Epoch: 468 | Iter: 284600 | Total Loss: 0.004349 | Recon Loss: 0.003389 | Commit Loss: 0.001919 | Perplexity: 403.647599
2025-09-30 19:55:51,077 Stage: Train 0.5 | Epoch: 468 | Iter: 284800 | Total Loss: 0.004344 | Recon Loss: 0.003392 | Commit Loss: 0.001905 | Perplexity: 402.794843
2025-09-30 19:59:17,497 Stage: Train 0.5 | Epoch: 468 | Iter: 285000 | Total Loss: 0.004344 | Recon Loss: 0.003388 | Commit Loss: 0.001913 | Perplexity: 402.228489
Trainning Epoch:  57%|█████▋    | 469/823 [80:49:34<62:06:29, 631.61s/it]Trainning Epoch:  57%|█████▋    | 469/823 [80:49:34<62:06:28, 631.60s/it]Trainning Epoch:  57%|█████▋    | 469/823 [80:49:34<62:06:31, 631.61s/it]Trainning Epoch:  57%|█████▋    | 469/823 [80:49:34<62:06:29, 631.61s/it]2025-09-30 20:02:47,536 Stage: Train 0.5 | Epoch: 469 | Iter: 285200 | Total Loss: 0.004345 | Recon Loss: 0.003397 | Commit Loss: 0.001897 | Perplexity: 403.127150
2025-09-30 20:06:15,068 Stage: Train 0.5 | Epoch: 469 | Iter: 285400 | Total Loss: 0.004335 | Recon Loss: 0.003382 | Commit Loss: 0.001906 | Perplexity: 402.990807
2025-09-30 20:09:42,915 Stage: Train 0.5 | Epoch: 469 | Iter: 285600 | Total Loss: 0.004325 | Recon Loss: 0.003375 | Commit Loss: 0.001900 | Perplexity: 403.204915
Trainning Epoch:  57%|█████▋    | 470/823 [81:00:09<62:00:27, 632.37s/it]Trainning Epoch:  57%|█████▋    | 470/823 [81:00:09<62:00:29, 632.38s/it]Trainning Epoch:  57%|█████▋    | 470/823 [81:00:09<62:00:28, 632.38s/it]Trainning Epoch:  57%|█████▋    | 470/823 [81:00:09<62:00:29, 632.38s/it]2025-09-30 20:13:13,496 Stage: Train 0.5 | Epoch: 470 | Iter: 285800 | Total Loss: 0.004341 | Recon Loss: 0.003391 | Commit Loss: 0.001900 | Perplexity: 402.293928
2025-09-30 20:16:38,305 Stage: Train 0.5 | Epoch: 470 | Iter: 286000 | Total Loss: 0.004343 | Recon Loss: 0.003391 | Commit Loss: 0.001904 | Perplexity: 403.014303
2025-09-30 20:20:05,161 Stage: Train 0.5 | Epoch: 470 | Iter: 286200 | Total Loss: 0.004341 | Recon Loss: 0.003387 | Commit Loss: 0.001909 | Perplexity: 402.889718
Trainning Epoch:  57%|█████▋    | 471/823 [81:10:39<61:46:46, 631.84s/it]Trainning Epoch:  57%|█████▋    | 471/823 [81:10:39<61:46:44, 631.83s/it]Trainning Epoch:  57%|█████▋    | 471/823 [81:10:39<61:46:45, 631.83s/it]Trainning Epoch:  57%|█████▋    | 471/823 [81:10:39<61:46:44, 631.83s/it]2025-09-30 20:23:35,512 Stage: Train 0.5 | Epoch: 471 | Iter: 286400 | Total Loss: 0.004336 | Recon Loss: 0.003382 | Commit Loss: 0.001908 | Perplexity: 402.375894
2025-09-30 20:27:01,049 Stage: Train 0.5 | Epoch: 471 | Iter: 286600 | Total Loss: 0.004319 | Recon Loss: 0.003376 | Commit Loss: 0.001886 | Perplexity: 402.213956
2025-09-30 20:30:26,026 Stage: Train 0.5 | Epoch: 471 | Iter: 286800 | Total Loss: 0.004336 | Recon Loss: 0.003387 | Commit Loss: 0.001898 | Perplexity: 402.321990
Trainning Epoch:  57%|█████▋    | 472/823 [81:21:07<61:29:14, 630.64s/it]Trainning Epoch:  57%|█████▋    | 472/823 [81:21:07<61:29:13, 630.64s/it]Trainning Epoch:  57%|█████▋    | 472/823 [81:21:07<61:29:16, 630.65s/it]Trainning Epoch:  57%|█████▋    | 472/823 [81:21:07<61:29:17, 630.65s/it]2025-09-30 20:33:55,023 Stage: Train 0.5 | Epoch: 472 | Iter: 287000 | Total Loss: 0.004333 | Recon Loss: 0.003386 | Commit Loss: 0.001893 | Perplexity: 401.309469
2025-09-30 20:37:18,300 Stage: Train 0.5 | Epoch: 472 | Iter: 287200 | Total Loss: 0.004307 | Recon Loss: 0.003359 | Commit Loss: 0.001896 | Perplexity: 402.112022
2025-09-30 20:40:42,728 Stage: Train 0.5 | Epoch: 472 | Iter: 287400 | Total Loss: 0.004359 | Recon Loss: 0.003407 | Commit Loss: 0.001905 | Perplexity: 402.827330
Trainning Epoch:  57%|█████▋    | 473/823 [81:31:31<61:07:51, 628.77s/it]Trainning Epoch:  57%|█████▋    | 473/823 [81:31:31<61:07:50, 628.77s/it]Trainning Epoch:  57%|█████▋    | 473/823 [81:31:31<61:07:52, 628.78s/it]Trainning Epoch:  57%|█████▋    | 473/823 [81:31:31<61:07:52, 628.78s/it]2025-09-30 20:44:11,465 Stage: Train 0.5 | Epoch: 473 | Iter: 287600 | Total Loss: 0.004364 | Recon Loss: 0.003408 | Commit Loss: 0.001912 | Perplexity: 402.987978
2025-09-30 20:47:38,651 Stage: Train 0.5 | Epoch: 473 | Iter: 287800 | Total Loss: 0.004309 | Recon Loss: 0.003359 | Commit Loss: 0.001899 | Perplexity: 402.814963
2025-09-30 20:51:05,786 Stage: Train 0.5 | Epoch: 473 | Iter: 288000 | Total Loss: 0.004348 | Recon Loss: 0.003397 | Commit Loss: 0.001902 | Perplexity: 403.182241
Trainning Epoch:  58%|█████▊    | 474/823 [81:42:05<61:05:26, 630.16s/it]Trainning Epoch:  58%|█████▊    | 474/823 [81:42:05<61:05:26, 630.16s/it]Trainning Epoch:  58%|█████▊    | 474/823 [81:42:05<61:05:27, 630.16s/it]Trainning Epoch:  58%|█████▊    | 474/823 [81:42:05<61:05:27, 630.16s/it]2025-09-30 20:54:36,832 Stage: Train 0.5 | Epoch: 474 | Iter: 288200 | Total Loss: 0.004327 | Recon Loss: 0.003380 | Commit Loss: 0.001894 | Perplexity: 402.096154
2025-09-30 20:58:03,170 Stage: Train 0.5 | Epoch: 474 | Iter: 288400 | Total Loss: 0.004330 | Recon Loss: 0.003380 | Commit Loss: 0.001899 | Perplexity: 403.003274
2025-09-30 21:01:30,701 Stage: Train 0.5 | Epoch: 474 | Iter: 288600 | Total Loss: 0.004326 | Recon Loss: 0.003373 | Commit Loss: 0.001906 | Perplexity: 402.681156
2025-09-30 21:04:58,939 Stage: Train 0.5 | Epoch: 474 | Iter: 288800 | Total Loss: 0.004341 | Recon Loss: 0.003383 | Commit Loss: 0.001915 | Perplexity: 402.667856
Trainning Epoch:  58%|█████▊    | 475/823 [81:52:39<61:02:26, 631.45s/it]Trainning Epoch:  58%|█████▊    | 475/823 [81:52:39<61:02:26, 631.45s/it]Trainning Epoch:  58%|█████▊    | 475/823 [81:52:39<61:02:26, 631.46s/it]Trainning Epoch:  58%|█████▊    | 475/823 [81:52:39<61:02:26, 631.46s/it]2025-09-30 21:08:30,253 Stage: Train 0.5 | Epoch: 475 | Iter: 289000 | Total Loss: 0.004313 | Recon Loss: 0.003360 | Commit Loss: 0.001906 | Perplexity: 403.112952
2025-09-30 21:11:58,572 Stage: Train 0.5 | Epoch: 475 | Iter: 289200 | Total Loss: 0.004343 | Recon Loss: 0.003389 | Commit Loss: 0.001909 | Perplexity: 402.355432
2025-09-30 21:15:25,737 Stage: Train 0.5 | Epoch: 475 | Iter: 289400 | Total Loss: 0.004348 | Recon Loss: 0.003390 | Commit Loss: 0.001918 | Perplexity: 403.066325
Trainning Epoch:  58%|█████▊    | 476/823 [82:03:14<60:57:52, 632.49s/it]Trainning Epoch:  58%|█████▊    | 476/823 [82:03:14<60:57:52, 632.49s/it]Trainning Epoch:  58%|█████▊    | 476/823 [82:03:14<60:57:52, 632.49s/it]Trainning Epoch:  58%|█████▊    | 476/823 [82:03:14<60:57:52, 632.48s/it]2025-09-30 21:18:55,757 Stage: Train 0.5 | Epoch: 476 | Iter: 289600 | Total Loss: 0.004319 | Recon Loss: 0.003373 | Commit Loss: 0.001892 | Perplexity: 402.361362
2025-09-30 21:22:23,191 Stage: Train 0.5 | Epoch: 476 | Iter: 289800 | Total Loss: 0.004324 | Recon Loss: 0.003373 | Commit Loss: 0.001901 | Perplexity: 401.466754
2025-09-30 21:25:51,728 Stage: Train 0.5 | Epoch: 476 | Iter: 290000 | Total Loss: 0.004321 | Recon Loss: 0.003372 | Commit Loss: 0.001900 | Perplexity: 402.917451
Trainning Epoch:  58%|█████▊    | 477/823 [82:13:48<60:50:22, 633.01s/it]Trainning Epoch:  58%|█████▊    | 477/823 [82:13:48<60:50:22, 633.01s/it]Trainning Epoch:  58%|█████▊    | 477/823 [82:13:48<60:50:23, 633.02s/it]Trainning Epoch:  58%|█████▊    | 477/823 [82:13:48<60:50:23, 633.02s/it]2025-09-30 21:29:19,149 Stage: Train 0.5 | Epoch: 477 | Iter: 290200 | Total Loss: 0.004351 | Recon Loss: 0.003399 | Commit Loss: 0.001904 | Perplexity: 402.458702
2025-09-30 21:32:44,274 Stage: Train 0.5 | Epoch: 477 | Iter: 290400 | Total Loss: 0.004349 | Recon Loss: 0.003401 | Commit Loss: 0.001896 | Perplexity: 402.709159
2025-09-30 21:36:09,786 Stage: Train 0.5 | Epoch: 477 | Iter: 290600 | Total Loss: 0.004309 | Recon Loss: 0.003356 | Commit Loss: 0.001905 | Perplexity: 401.914438
Trainning Epoch:  58%|█████▊    | 478/823 [82:24:15<60:28:06, 630.98s/it]Trainning Epoch:  58%|█████▊    | 478/823 [82:24:15<60:28:09, 630.98s/it]Trainning Epoch:  58%|█████▊    | 478/823 [82:24:15<60:28:09, 630.98s/it]Trainning Epoch:  58%|█████▊    | 478/823 [82:24:15<60:28:07, 630.98s/it]2025-09-30 21:39:40,168 Stage: Train 0.5 | Epoch: 478 | Iter: 290800 | Total Loss: 0.004350 | Recon Loss: 0.003397 | Commit Loss: 0.001908 | Perplexity: 402.492034
2025-09-30 21:43:06,350 Stage: Train 0.5 | Epoch: 478 | Iter: 291000 | Total Loss: 0.004315 | Recon Loss: 0.003364 | Commit Loss: 0.001902 | Perplexity: 402.817761
2025-09-30 21:46:34,034 Stage: Train 0.5 | Epoch: 478 | Iter: 291200 | Total Loss: 0.004330 | Recon Loss: 0.003383 | Commit Loss: 0.001893 | Perplexity: 402.435165
Trainning Epoch:  58%|█████▊    | 479/823 [82:34:47<60:20:45, 631.53s/it]Trainning Epoch:  58%|█████▊    | 479/823 [82:34:47<60:20:48, 631.54s/it]Trainning Epoch:  58%|█████▊    | 479/823 [82:34:47<60:20:48, 631.54s/it]Trainning Epoch:  58%|█████▊    | 479/823 [82:34:47<60:20:46, 631.53s/it]2025-09-30 21:50:07,485 Stage: Train 0.5 | Epoch: 479 | Iter: 291400 | Total Loss: 0.004279 | Recon Loss: 0.003338 | Commit Loss: 0.001883 | Perplexity: 400.894495
2025-09-30 21:53:36,650 Stage: Train 0.5 | Epoch: 479 | Iter: 291600 | Total Loss: 0.004308 | Recon Loss: 0.003355 | Commit Loss: 0.001908 | Perplexity: 402.668602
2025-09-30 21:57:05,301 Stage: Train 0.5 | Epoch: 479 | Iter: 291800 | Total Loss: 0.004328 | Recon Loss: 0.003379 | Commit Loss: 0.001896 | Perplexity: 402.690122
Trainning Epoch:  58%|█████▊    | 480/823 [82:45:27<60:24:28, 634.02s/it]Trainning Epoch:  58%|█████▊    | 480/823 [82:45:27<60:24:28, 634.02s/it]Trainning Epoch:  58%|█████▊    | 480/823 [82:45:27<60:24:29, 634.02s/it]Trainning Epoch:  58%|█████▊    | 480/823 [82:45:27<60:24:31, 634.03s/it]2025-09-30 22:00:35,355 Stage: Train 0.5 | Epoch: 480 | Iter: 292000 | Total Loss: 0.004288 | Recon Loss: 0.003345 | Commit Loss: 0.001885 | Perplexity: 402.727559
2025-09-30 22:04:01,183 Stage: Train 0.5 | Epoch: 480 | Iter: 292200 | Total Loss: 0.004301 | Recon Loss: 0.003353 | Commit Loss: 0.001895 | Perplexity: 402.332976
2025-09-30 22:07:25,954 Stage: Train 0.5 | Epoch: 480 | Iter: 292400 | Total Loss: 0.004333 | Recon Loss: 0.003384 | Commit Loss: 0.001899 | Perplexity: 402.645867
Trainning Epoch:  58%|█████▊    | 481/823 [82:55:55<60:03:49, 632.25s/it]Trainning Epoch:  58%|█████▊    | 481/823 [82:55:55<60:03:50, 632.25s/it]Trainning Epoch:  58%|█████▊    | 481/823 [82:55:55<60:03:52, 632.26s/it]Trainning Epoch:  58%|█████▊    | 481/823 [82:55:55<60:03:52, 632.26s/it]2025-09-30 22:10:56,813 Stage: Train 0.5 | Epoch: 481 | Iter: 292600 | Total Loss: 0.004300 | Recon Loss: 0.003350 | Commit Loss: 0.001900 | Perplexity: 402.611038
2025-09-30 22:14:25,199 Stage: Train 0.5 | Epoch: 481 | Iter: 292800 | Total Loss: 0.004330 | Recon Loss: 0.003378 | Commit Loss: 0.001905 | Perplexity: 403.218251
2025-09-30 22:17:53,404 Stage: Train 0.5 | Epoch: 481 | Iter: 293000 | Total Loss: 0.004288 | Recon Loss: 0.003347 | Commit Loss: 0.001881 | Perplexity: 402.013769
Trainning Epoch:  59%|█████▊    | 482/823 [83:06:32<60:00:48, 633.57s/it]Trainning Epoch:  59%|█████▊    | 482/823 [83:06:32<60:00:49, 633.58s/it]Trainning Epoch:  59%|█████▊    | 482/823 [83:06:32<60:00:49, 633.58s/it]Trainning Epoch:  59%|█████▊    | 482/823 [83:06:32<60:00:49, 633.58s/it]2025-09-30 22:21:24,456 Stage: Train 0.5 | Epoch: 482 | Iter: 293200 | Total Loss: 0.004304 | Recon Loss: 0.003357 | Commit Loss: 0.001893 | Perplexity: 402.543505
2025-09-30 22:24:51,526 Stage: Train 0.5 | Epoch: 482 | Iter: 293400 | Total Loss: 0.004299 | Recon Loss: 0.003358 | Commit Loss: 0.001884 | Perplexity: 403.028885
2025-09-30 22:28:18,187 Stage: Train 0.5 | Epoch: 482 | Iter: 293600 | Total Loss: 0.004306 | Recon Loss: 0.003360 | Commit Loss: 0.001893 | Perplexity: 402.538592
Trainning Epoch:  59%|█████▊    | 483/823 [83:17:04<59:47:30, 633.09s/it]Trainning Epoch:  59%|█████▊    | 483/823 [83:17:04<59:47:30, 633.09s/it]Trainning Epoch:  59%|█████▊    | 483/823 [83:17:04<59:47:32, 633.09s/it]Trainning Epoch:  59%|█████▊    | 483/823 [83:17:04<59:47:31, 633.09s/it]2025-09-30 22:31:49,746 Stage: Train 0.5 | Epoch: 483 | Iter: 293800 | Total Loss: 0.004299 | Recon Loss: 0.003350 | Commit Loss: 0.001898 | Perplexity: 402.404279
2025-09-30 22:35:18,852 Stage: Train 0.5 | Epoch: 483 | Iter: 294000 | Total Loss: 0.004297 | Recon Loss: 0.003345 | Commit Loss: 0.001904 | Perplexity: 402.759928
2025-09-30 22:38:48,108 Stage: Train 0.5 | Epoch: 483 | Iter: 294200 | Total Loss: 0.004314 | Recon Loss: 0.003366 | Commit Loss: 0.001897 | Perplexity: 402.911013
Trainning Epoch:  59%|█████▉    | 484/823 [83:27:43<59:47:36, 634.98s/it]Trainning Epoch:  59%|█████▉    | 484/823 [83:27:43<59:47:39, 634.98s/it]Trainning Epoch:  59%|█████▉    | 484/823 [83:27:43<59:47:40, 634.99s/it]Trainning Epoch:  59%|█████▉    | 484/823 [83:27:43<59:47:41, 634.99s/it]2025-09-30 22:42:19,313 Stage: Train 0.5 | Epoch: 484 | Iter: 294400 | Total Loss: 0.004319 | Recon Loss: 0.003370 | Commit Loss: 0.001896 | Perplexity: 402.903959
2025-09-30 22:45:47,631 Stage: Train 0.5 | Epoch: 484 | Iter: 294600 | Total Loss: 0.004306 | Recon Loss: 0.003360 | Commit Loss: 0.001893 | Perplexity: 402.582174
2025-09-30 22:49:16,516 Stage: Train 0.5 | Epoch: 484 | Iter: 294800 | Total Loss: 0.004319 | Recon Loss: 0.003368 | Commit Loss: 0.001900 | Perplexity: 402.950499
Trainning Epoch:  59%|█████▉    | 485/823 [83:38:21<59:40:35, 635.61s/it]Trainning Epoch:  59%|█████▉    | 485/823 [83:38:21<59:40:37, 635.61s/it]Trainning Epoch:  59%|█████▉    | 485/823 [83:38:21<59:40:38, 635.62s/it]Trainning Epoch:  59%|█████▉    | 485/823 [83:38:21<59:40:39, 635.62s/it]2025-09-30 22:52:47,303 Stage: Train 0.5 | Epoch: 485 | Iter: 295000 | Total Loss: 0.004299 | Recon Loss: 0.003353 | Commit Loss: 0.001892 | Perplexity: 403.102969
2025-09-30 22:56:12,940 Stage: Train 0.5 | Epoch: 485 | Iter: 295200 | Total Loss: 0.004282 | Recon Loss: 0.003340 | Commit Loss: 0.001884 | Perplexity: 402.110557
2025-09-30 22:59:39,420 Stage: Train 0.5 | Epoch: 485 | Iter: 295400 | Total Loss: 0.004329 | Recon Loss: 0.003376 | Commit Loss: 0.001906 | Perplexity: 402.296822
Trainning Epoch:  59%|█████▉    | 486/823 [83:48:50<59:19:45, 633.78s/it]Trainning Epoch:  59%|█████▉    | 486/823 [83:48:50<59:19:43, 633.78s/it]Trainning Epoch:  59%|█████▉    | 486/823 [83:48:50<59:19:45, 633.79s/it]Trainning Epoch:  59%|█████▉    | 486/823 [83:48:50<59:19:45, 633.79s/it]2025-09-30 23:03:08,779 Stage: Train 0.5 | Epoch: 486 | Iter: 295600 | Total Loss: 0.004304 | Recon Loss: 0.003355 | Commit Loss: 0.001898 | Perplexity: 402.207967
2025-09-30 23:06:35,965 Stage: Train 0.5 | Epoch: 486 | Iter: 295800 | Total Loss: 0.004281 | Recon Loss: 0.003335 | Commit Loss: 0.001893 | Perplexity: 402.315744
2025-09-30 23:10:04,587 Stage: Train 0.5 | Epoch: 486 | Iter: 296000 | Total Loss: 0.004315 | Recon Loss: 0.003362 | Commit Loss: 0.001907 | Perplexity: 402.209647
Trainning Epoch:  59%|█████▉    | 487/823 [83:59:25<59:10:52, 634.09s/it]Trainning Epoch:  59%|█████▉    | 487/823 [83:59:25<59:10:51, 634.08s/it]Trainning Epoch:  59%|█████▉    | 487/823 [83:59:25<59:10:52, 634.09s/it]Trainning Epoch:  59%|█████▉    | 487/823 [83:59:25<59:10:53, 634.09s/it]2025-09-30 23:13:35,277 Stage: Train 0.5 | Epoch: 487 | Iter: 296200 | Total Loss: 0.004282 | Recon Loss: 0.003340 | Commit Loss: 0.001885 | Perplexity: 402.257817
2025-09-30 23:17:00,821 Stage: Train 0.5 | Epoch: 487 | Iter: 296400 | Total Loss: 0.004323 | Recon Loss: 0.003370 | Commit Loss: 0.001906 | Perplexity: 402.846559
2025-09-30 23:20:27,232 Stage: Train 0.5 | Epoch: 487 | Iter: 296600 | Total Loss: 0.004324 | Recon Loss: 0.003372 | Commit Loss: 0.001904 | Perplexity: 402.063801
Trainning Epoch:  59%|█████▉    | 488/823 [84:09:55<58:52:55, 632.76s/it]Trainning Epoch:  59%|█████▉    | 488/823 [84:09:55<58:52:57, 632.77s/it]Trainning Epoch:  59%|█████▉    | 488/823 [84:09:55<58:52:58, 632.77s/it]Trainning Epoch:  59%|█████▉    | 488/823 [84:09:55<58:52:55, 632.76s/it]2025-09-30 23:23:57,824 Stage: Train 0.5 | Epoch: 488 | Iter: 296800 | Total Loss: 0.004294 | Recon Loss: 0.003342 | Commit Loss: 0.001905 | Perplexity: 403.833526
2025-09-30 23:27:25,514 Stage: Train 0.5 | Epoch: 488 | Iter: 297000 | Total Loss: 0.004292 | Recon Loss: 0.003341 | Commit Loss: 0.001901 | Perplexity: 403.304066
2025-09-30 23:30:53,396 Stage: Train 0.5 | Epoch: 488 | Iter: 297200 | Total Loss: 0.004270 | Recon Loss: 0.003323 | Commit Loss: 0.001893 | Perplexity: 401.769687
Trainning Epoch:  59%|█████▉    | 489/823 [84:20:30<58:46:57, 633.59s/it]Trainning Epoch:  59%|█████▉    | 489/823 [84:20:30<58:46:58, 633.59s/it]Trainning Epoch:  59%|█████▉    | 489/823 [84:20:30<58:47:00, 633.59s/it]Trainning Epoch:  59%|█████▉    | 489/823 [84:20:30<58:46:59, 633.59s/it]2025-09-30 23:34:24,973 Stage: Train 0.5 | Epoch: 489 | Iter: 297400 | Total Loss: 0.004304 | Recon Loss: 0.003355 | Commit Loss: 0.001897 | Perplexity: 403.376793
2025-09-30 23:37:55,076 Stage: Train 0.5 | Epoch: 489 | Iter: 297600 | Total Loss: 0.004305 | Recon Loss: 0.003351 | Commit Loss: 0.001908 | Perplexity: 403.050173
2025-09-30 23:41:26,120 Stage: Train 0.5 | Epoch: 489 | Iter: 297800 | Total Loss: 0.004298 | Recon Loss: 0.003346 | Commit Loss: 0.001904 | Perplexity: 402.623546
Trainning Epoch:  60%|█████▉    | 490/823 [84:31:12<58:50:11, 636.07s/it]Trainning Epoch:  60%|█████▉    | 490/823 [84:31:12<58:50:13, 636.08s/it]Trainning Epoch:  60%|█████▉    | 490/823 [84:31:12<58:50:14, 636.08s/it]Trainning Epoch:  60%|█████▉    | 490/823 [84:31:12<58:50:16, 636.09s/it]2025-09-30 23:44:57,892 Stage: Train 0.5 | Epoch: 490 | Iter: 298000 | Total Loss: 0.004297 | Recon Loss: 0.003355 | Commit Loss: 0.001884 | Perplexity: 402.646239
2025-09-30 23:48:23,181 Stage: Train 0.5 | Epoch: 490 | Iter: 298200 | Total Loss: 0.004299 | Recon Loss: 0.003344 | Commit Loss: 0.001911 | Perplexity: 402.914296
2025-09-30 23:51:48,870 Stage: Train 0.5 | Epoch: 490 | Iter: 298400 | Total Loss: 0.004333 | Recon Loss: 0.003380 | Commit Loss: 0.001905 | Perplexity: 402.856870
Trainning Epoch:  60%|█████▉    | 491/823 [84:41:41<58:28:48, 634.12s/it]Trainning Epoch:  60%|█████▉    | 491/823 [84:41:41<58:28:47, 634.12s/it]Trainning Epoch:  60%|█████▉    | 491/823 [84:41:41<58:28:50, 634.13s/it]Trainning Epoch:  60%|█████▉    | 491/823 [84:41:42<58:28:49, 634.12s/it]2025-09-30 23:55:19,089 Stage: Train 0.5 | Epoch: 491 | Iter: 298600 | Total Loss: 0.004274 | Recon Loss: 0.003328 | Commit Loss: 0.001893 | Perplexity: 402.554448
2025-09-30 23:58:45,320 Stage: Train 0.5 | Epoch: 491 | Iter: 298800 | Total Loss: 0.004316 | Recon Loss: 0.003364 | Commit Loss: 0.001904 | Perplexity: 402.698292
2025-10-01 00:02:12,085 Stage: Train 0.5 | Epoch: 491 | Iter: 299000 | Total Loss: 0.004312 | Recon Loss: 0.003358 | Commit Loss: 0.001908 | Perplexity: 402.724336
Trainning Epoch:  60%|█████▉    | 492/823 [84:52:13<58:14:13, 633.39s/it]Trainning Epoch:  60%|█████▉    | 492/823 [84:52:13<58:14:17, 633.41s/it]Trainning Epoch:  60%|█████▉    | 492/823 [84:52:13<58:14:16, 633.40s/it]Trainning Epoch:  60%|█████▉    | 492/823 [84:52:13<58:14:15, 633.40s/it]2025-10-01 00:05:42,567 Stage: Train 0.5 | Epoch: 492 | Iter: 299200 | Total Loss: 0.004271 | Recon Loss: 0.003324 | Commit Loss: 0.001894 | Perplexity: 402.189332
2025-10-01 00:09:08,450 Stage: Train 0.5 | Epoch: 492 | Iter: 299400 | Total Loss: 0.004331 | Recon Loss: 0.003383 | Commit Loss: 0.001897 | Perplexity: 403.658777
2025-10-01 00:12:35,285 Stage: Train 0.5 | Epoch: 492 | Iter: 299600 | Total Loss: 0.004317 | Recon Loss: 0.003361 | Commit Loss: 0.001912 | Perplexity: 403.245958
Trainning Epoch:  60%|█████▉    | 493/823 [85:02:44<57:58:55, 632.53s/it]Trainning Epoch:  60%|█████▉    | 493/823 [85:02:44<57:58:54, 632.53s/it]Trainning Epoch:  60%|█████▉    | 493/823 [85:02:44<57:58:56, 632.54s/it]Trainning Epoch:  60%|█████▉    | 493/823 [85:02:44<57:58:56, 632.54s/it]2025-10-01 00:16:04,741 Stage: Train 0.5 | Epoch: 493 | Iter: 299800 | Total Loss: 0.004282 | Recon Loss: 0.003334 | Commit Loss: 0.001896 | Perplexity: 402.198176
2025-10-01 00:19:32,862 Stage: Train 0.5 | Epoch: 493 | Iter: 300000 | Total Loss: 0.004292 | Recon Loss: 0.003342 | Commit Loss: 0.001901 | Perplexity: 403.227415
2025-10-01 00:19:32,862 Saving model at iteration 300000
2025-10-01 00:19:33,411 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_494_step_300000
2025-10-01 00:19:33,994 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_494_step_300000/model.safetensors
2025-10-01 00:19:34,589 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_494_step_300000/optimizer.bin
2025-10-01 00:19:34,590 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_494_step_300000/scheduler.bin
2025-10-01 00:19:34,590 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_494_step_300000/sampler.bin
2025-10-01 00:19:34,591 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_494_step_300000/random_states_0.pkl
2025-10-01 00:23:02,009 Stage: Train 0.5 | Epoch: 493 | Iter: 300200 | Total Loss: 0.004310 | Recon Loss: 0.003361 | Commit Loss: 0.001897 | Perplexity: 402.494570
Trainning Epoch:  60%|██████    | 494/823 [85:13:19<57:53:09, 633.40s/it]Trainning Epoch:  60%|██████    | 494/823 [85:13:19<57:53:11, 633.41s/it]Trainning Epoch:  60%|██████    | 494/823 [85:13:19<57:53:10, 633.41s/it]Trainning Epoch:  60%|██████    | 494/823 [85:13:19<57:53:10, 633.41s/it]2025-10-01 00:26:32,117 Stage: Train 0.5 | Epoch: 494 | Iter: 300400 | Total Loss: 0.004279 | Recon Loss: 0.003329 | Commit Loss: 0.001899 | Perplexity: 403.223965
2025-10-01 00:29:57,173 Stage: Train 0.5 | Epoch: 494 | Iter: 300600 | Total Loss: 0.004289 | Recon Loss: 0.003342 | Commit Loss: 0.001894 | Perplexity: 403.157283
2025-10-01 00:33:24,156 Stage: Train 0.5 | Epoch: 494 | Iter: 300800 | Total Loss: 0.004325 | Recon Loss: 0.003371 | Commit Loss: 0.001909 | Perplexity: 403.562944
Trainning Epoch:  60%|██████    | 495/823 [85:23:51<57:39:30, 632.84s/it]Trainning Epoch:  60%|██████    | 495/823 [85:23:51<57:39:29, 632.83s/it]Trainning Epoch:  60%|██████    | 495/823 [85:23:51<57:39:32, 632.84s/it]Trainning Epoch:  60%|██████    | 495/823 [85:23:51<57:39:32, 632.84s/it]2025-10-01 00:36:55,700 Stage: Train 0.5 | Epoch: 495 | Iter: 301000 | Total Loss: 0.004296 | Recon Loss: 0.003346 | Commit Loss: 0.001901 | Perplexity: 402.631935
2025-10-01 00:40:20,766 Stage: Train 0.5 | Epoch: 495 | Iter: 301200 | Total Loss: 0.004285 | Recon Loss: 0.003336 | Commit Loss: 0.001896 | Perplexity: 402.811346
2025-10-01 00:43:46,890 Stage: Train 0.5 | Epoch: 495 | Iter: 301400 | Total Loss: 0.004311 | Recon Loss: 0.003358 | Commit Loss: 0.001906 | Perplexity: 402.910467
Trainning Epoch:  60%|██████    | 496/823 [85:34:20<57:23:12, 631.78s/it]Trainning Epoch:  60%|██████    | 496/823 [85:34:20<57:23:13, 631.78s/it]Trainning Epoch:  60%|██████    | 496/823 [85:34:20<57:23:15, 631.79s/it]Trainning Epoch:  60%|██████    | 496/823 [85:34:20<57:23:15, 631.79s/it]2025-10-01 00:47:16,429 Stage: Train 0.5 | Epoch: 496 | Iter: 301600 | Total Loss: 0.004291 | Recon Loss: 0.003337 | Commit Loss: 0.001908 | Perplexity: 402.588333
2025-10-01 00:50:42,440 Stage: Train 0.5 | Epoch: 496 | Iter: 301800 | Total Loss: 0.004274 | Recon Loss: 0.003329 | Commit Loss: 0.001890 | Perplexity: 403.440271
2025-10-01 00:54:09,722 Stage: Train 0.5 | Epoch: 496 | Iter: 302000 | Total Loss: 0.004282 | Recon Loss: 0.003333 | Commit Loss: 0.001898 | Perplexity: 402.229741
Trainning Epoch:  60%|██████    | 497/823 [85:44:53<57:14:02, 632.03s/it]Trainning Epoch:  60%|██████    | 497/823 [85:44:53<57:14:04, 632.04s/it]Trainning Epoch:  60%|██████    | 497/823 [85:44:53<57:14:02, 632.03s/it]Trainning Epoch:  60%|██████    | 497/823 [85:44:53<57:14:04, 632.04s/it]2025-10-01 00:57:40,983 Stage: Train 0.5 | Epoch: 497 | Iter: 302200 | Total Loss: 0.004314 | Recon Loss: 0.003362 | Commit Loss: 0.001903 | Perplexity: 402.525260
2025-10-01 01:01:06,313 Stage: Train 0.5 | Epoch: 497 | Iter: 302400 | Total Loss: 0.004297 | Recon Loss: 0.003347 | Commit Loss: 0.001900 | Perplexity: 403.357476
2025-10-01 01:04:32,673 Stage: Train 0.5 | Epoch: 497 | Iter: 302600 | Total Loss: 0.004292 | Recon Loss: 0.003340 | Commit Loss: 0.001904 | Perplexity: 402.689748
Trainning Epoch:  61%|██████    | 498/823 [85:55:23<57:00:53, 631.55s/it]Trainning Epoch:  61%|██████    | 498/823 [85:55:23<57:00:53, 631.55s/it]Trainning Epoch:  61%|██████    | 498/823 [85:55:23<57:00:54, 631.55s/it]Trainning Epoch:  61%|██████    | 498/823 [85:55:23<57:00:54, 631.55s/it]2025-10-01 01:08:03,073 Stage: Train 0.5 | Epoch: 498 | Iter: 302800 | Total Loss: 0.004298 | Recon Loss: 0.003348 | Commit Loss: 0.001900 | Perplexity: 403.594280
2025-10-01 01:11:27,728 Stage: Train 0.5 | Epoch: 498 | Iter: 303000 | Total Loss: 0.004248 | Recon Loss: 0.003307 | Commit Loss: 0.001881 | Perplexity: 402.774310
2025-10-01 01:14:52,922 Stage: Train 0.5 | Epoch: 498 | Iter: 303200 | Total Loss: 0.004275 | Recon Loss: 0.003325 | Commit Loss: 0.001901 | Perplexity: 403.074596
Trainning Epoch:  61%|██████    | 499/823 [86:05:51<56:45:13, 630.60s/it]Trainning Epoch:  61%|██████    | 499/823 [86:05:51<56:45:13, 630.60s/it]Trainning Epoch:  61%|██████    | 499/823 [86:05:51<56:45:14, 630.60s/it]Trainning Epoch:  61%|██████    | 499/823 [86:05:51<56:45:14, 630.60s/it]2025-10-01 01:18:23,263 Stage: Train 0.5 | Epoch: 499 | Iter: 303400 | Total Loss: 0.004316 | Recon Loss: 0.003365 | Commit Loss: 0.001902 | Perplexity: 402.935036
2025-10-01 01:21:48,393 Stage: Train 0.5 | Epoch: 499 | Iter: 303600 | Total Loss: 0.004290 | Recon Loss: 0.003345 | Commit Loss: 0.001892 | Perplexity: 403.428721
2025-10-01 01:25:15,251 Stage: Train 0.5 | Epoch: 499 | Iter: 303800 | Total Loss: 0.004265 | Recon Loss: 0.003318 | Commit Loss: 0.001894 | Perplexity: 402.658000
2025-10-01 01:28:41,341 Stage: Train 0.5 | Epoch: 499 | Iter: 304000 | Total Loss: 0.004319 | Recon Loss: 0.003360 | Commit Loss: 0.001918 | Perplexity: 403.179575
Trainning Epoch:  61%|██████    | 500/823 [86:16:22<56:34:11, 630.50s/it]Trainning Epoch:  61%|██████    | 500/823 [86:16:22<56:34:11, 630.50s/it]Trainning Epoch:  61%|██████    | 500/823 [86:16:22<56:34:10, 630.50s/it]Trainning Epoch:  61%|██████    | 500/823 [86:16:22<56:34:11, 630.50s/it]2025-10-01 01:32:12,439 Stage: Train 0.5 | Epoch: 500 | Iter: 304200 | Total Loss: 0.004294 | Recon Loss: 0.003346 | Commit Loss: 0.001895 | Perplexity: 402.916048
2025-10-01 01:35:42,435 Stage: Train 0.5 | Epoch: 500 | Iter: 304400 | Total Loss: 0.004290 | Recon Loss: 0.003343 | Commit Loss: 0.001894 | Perplexity: 403.192042
2025-10-01 01:39:09,820 Stage: Train 0.5 | Epoch: 500 | Iter: 304600 | Total Loss: 0.004301 | Recon Loss: 0.003349 | Commit Loss: 0.001904 | Perplexity: 403.308033
Trainning Epoch:  61%|██████    | 501/823 [86:26:58<56:33:41, 632.37s/it]Trainning Epoch:  61%|██████    | 501/823 [86:26:58<56:33:43, 632.37s/it]Trainning Epoch:  61%|██████    | 501/823 [86:26:58<56:33:44, 632.37s/it]Trainning Epoch:  61%|██████    | 501/823 [86:26:58<56:33:45, 632.38s/it]2025-10-01 01:42:40,255 Stage: Train 0.5 | Epoch: 501 | Iter: 304800 | Total Loss: 0.004286 | Recon Loss: 0.003333 | Commit Loss: 0.001907 | Perplexity: 403.682951
2025-10-01 01:46:07,688 Stage: Train 0.5 | Epoch: 501 | Iter: 305000 | Total Loss: 0.004291 | Recon Loss: 0.003338 | Commit Loss: 0.001907 | Perplexity: 403.112889
2025-10-01 01:49:34,733 Stage: Train 0.5 | Epoch: 501 | Iter: 305200 | Total Loss: 0.004277 | Recon Loss: 0.003325 | Commit Loss: 0.001904 | Perplexity: 402.811945
Trainning Epoch:  61%|██████    | 502/823 [86:37:31<56:23:57, 632.52s/it]Trainning Epoch:  61%|██████    | 502/823 [86:37:31<56:23:59, 632.52s/it]Trainning Epoch:  61%|██████    | 502/823 [86:37:31<56:23:59, 632.52s/it]Trainning Epoch:  61%|██████    | 502/823 [86:37:31<56:23:59, 632.52s/it]2025-10-01 01:53:05,723 Stage: Train 0.5 | Epoch: 502 | Iter: 305400 | Total Loss: 0.004298 | Recon Loss: 0.003348 | Commit Loss: 0.001900 | Perplexity: 402.914023
2025-10-01 01:56:36,033 Stage: Train 0.5 | Epoch: 502 | Iter: 305600 | Total Loss: 0.004266 | Recon Loss: 0.003320 | Commit Loss: 0.001891 | Perplexity: 402.478421
2025-10-01 02:00:05,946 Stage: Train 0.5 | Epoch: 502 | Iter: 305800 | Total Loss: 0.004290 | Recon Loss: 0.003337 | Commit Loss: 0.001907 | Perplexity: 403.535054
Trainning Epoch:  61%|██████    | 503/823 [86:48:11<56:25:22, 634.76s/it]Trainning Epoch:  61%|██████    | 503/823 [86:48:11<56:25:21, 634.76s/it]Trainning Epoch:  61%|██████    | 503/823 [86:48:11<56:25:24, 634.76s/it]Trainning Epoch:  61%|██████    | 503/823 [86:48:11<56:25:24, 634.76s/it]2025-10-01 02:03:36,768 Stage: Train 0.5 | Epoch: 503 | Iter: 306000 | Total Loss: 0.004270 | Recon Loss: 0.003322 | Commit Loss: 0.001897 | Perplexity: 403.280571
2025-10-01 02:07:05,551 Stage: Train 0.5 | Epoch: 503 | Iter: 306200 | Total Loss: 0.004279 | Recon Loss: 0.003329 | Commit Loss: 0.001901 | Perplexity: 402.642210
2025-10-01 02:10:34,944 Stage: Train 0.5 | Epoch: 503 | Iter: 306400 | Total Loss: 0.004287 | Recon Loss: 0.003333 | Commit Loss: 0.001908 | Perplexity: 402.193201
Trainning Epoch:  61%|██████    | 504/823 [86:58:49<56:19:01, 635.55s/it]Trainning Epoch:  61%|██████    | 504/823 [86:58:49<56:19:04, 635.56s/it]Trainning Epoch:  61%|██████    | 504/823 [86:58:49<56:19:05, 635.57s/it]Trainning Epoch:  61%|██████    | 504/823 [86:58:49<56:19:06, 635.57s/it]2025-10-01 02:14:05,833 Stage: Train 0.5 | Epoch: 504 | Iter: 306600 | Total Loss: 0.004262 | Recon Loss: 0.003320 | Commit Loss: 0.001886 | Perplexity: 402.318289
2025-10-01 02:17:32,745 Stage: Train 0.5 | Epoch: 504 | Iter: 306800 | Total Loss: 0.004261 | Recon Loss: 0.003312 | Commit Loss: 0.001898 | Perplexity: 402.901631
2025-10-01 02:20:59,502 Stage: Train 0.5 | Epoch: 504 | Iter: 307000 | Total Loss: 0.004307 | Recon Loss: 0.003353 | Commit Loss: 0.001907 | Perplexity: 403.402699
Trainning Epoch:  61%|██████▏   | 505/823 [87:09:21<56:03:06, 634.55s/it]Trainning Epoch:  61%|██████▏   | 505/823 [87:09:21<56:03:07, 634.55s/it]Trainning Epoch:  61%|██████▏   | 505/823 [87:09:21<56:03:07, 634.55s/it]Trainning Epoch:  61%|██████▏   | 505/823 [87:09:21<56:03:07, 634.55s/it]2025-10-01 02:24:30,533 Stage: Train 0.5 | Epoch: 505 | Iter: 307200 | Total Loss: 0.004243 | Recon Loss: 0.003301 | Commit Loss: 0.001884 | Perplexity: 402.860223
2025-10-01 02:27:59,040 Stage: Train 0.5 | Epoch: 505 | Iter: 307400 | Total Loss: 0.004223 | Recon Loss: 0.003278 | Commit Loss: 0.001890 | Perplexity: 402.541118
2025-10-01 02:31:28,265 Stage: Train 0.5 | Epoch: 505 | Iter: 307600 | Total Loss: 0.004313 | Recon Loss: 0.003356 | Commit Loss: 0.001914 | Perplexity: 404.078154
Trainning Epoch:  61%|██████▏   | 506/823 [87:19:59<55:58:27, 635.67s/it]Trainning Epoch:  61%|██████▏   | 506/823 [87:19:59<55:58:28, 635.67s/it]Trainning Epoch:  61%|██████▏   | 506/823 [87:19:59<55:58:29, 635.68s/it]Trainning Epoch:  61%|██████▏   | 506/823 [87:19:59<55:58:29, 635.68s/it]2025-10-01 02:34:58,772 Stage: Train 0.5 | Epoch: 506 | Iter: 307800 | Total Loss: 0.004266 | Recon Loss: 0.003319 | Commit Loss: 0.001893 | Perplexity: 403.203596
2025-10-01 02:38:26,250 Stage: Train 0.5 | Epoch: 506 | Iter: 308000 | Total Loss: 0.004270 | Recon Loss: 0.003320 | Commit Loss: 0.001901 | Perplexity: 402.809206
2025-10-01 02:41:54,716 Stage: Train 0.5 | Epoch: 506 | Iter: 308200 | Total Loss: 0.004245 | Recon Loss: 0.003295 | Commit Loss: 0.001901 | Perplexity: 403.063083
Trainning Epoch:  62%|██████▏   | 507/823 [87:30:33<55:44:59, 635.13s/it]Trainning Epoch:  62%|██████▏   | 507/823 [87:30:33<55:45:02, 635.14s/it]Trainning Epoch:  62%|██████▏   | 507/823 [87:30:33<55:45:00, 635.13s/it]Trainning Epoch:  62%|██████▏   | 507/823 [87:30:33<55:45:01, 635.13s/it]2025-10-01 02:45:22,886 Stage: Train 0.5 | Epoch: 507 | Iter: 308400 | Total Loss: 0.004277 | Recon Loss: 0.003327 | Commit Loss: 0.001901 | Perplexity: 403.589965
2025-10-01 02:48:48,029 Stage: Train 0.5 | Epoch: 507 | Iter: 308600 | Total Loss: 0.004247 | Recon Loss: 0.003300 | Commit Loss: 0.001894 | Perplexity: 402.735991
2025-10-01 02:52:13,706 Stage: Train 0.5 | Epoch: 507 | Iter: 308800 | Total Loss: 0.004281 | Recon Loss: 0.003329 | Commit Loss: 0.001904 | Perplexity: 403.717977
Trainning Epoch:  62%|██████▏   | 508/823 [87:41:00<55:21:06, 632.59s/it]Trainning Epoch:  62%|██████▏   | 508/823 [87:41:00<55:21:04, 632.58s/it]Trainning Epoch:  62%|██████▏   | 508/823 [87:41:00<55:21:05, 632.59s/it]Trainning Epoch:  62%|██████▏   | 508/823 [87:41:00<55:21:04, 632.59s/it]2025-10-01 02:55:47,422 Stage: Train 0.5 | Epoch: 508 | Iter: 309000 | Total Loss: 0.004276 | Recon Loss: 0.003321 | Commit Loss: 0.001910 | Perplexity: 403.891247
2025-10-01 02:59:18,052 Stage: Train 0.5 | Epoch: 508 | Iter: 309200 | Total Loss: 0.004256 | Recon Loss: 0.003317 | Commit Loss: 0.001877 | Perplexity: 402.340463
2025-10-01 03:02:50,332 Stage: Train 0.5 | Epoch: 508 | Iter: 309400 | Total Loss: 0.004259 | Recon Loss: 0.003310 | Commit Loss: 0.001897 | Perplexity: 402.846904
Trainning Epoch:  62%|██████▏   | 509/823 [87:51:47<55:32:54, 636.86s/it]Trainning Epoch:  62%|██████▏   | 509/823 [87:51:47<55:32:52, 636.86s/it]Trainning Epoch:  62%|██████▏   | 509/823 [87:51:47<55:32:55, 636.86s/it]Trainning Epoch:  62%|██████▏   | 509/823 [87:51:47<55:32:54, 636.86s/it]2025-10-01 03:06:22,278 Stage: Train 0.5 | Epoch: 509 | Iter: 309600 | Total Loss: 0.004262 | Recon Loss: 0.003311 | Commit Loss: 0.001902 | Perplexity: 403.183178
2025-10-01 03:09:51,385 Stage: Train 0.5 | Epoch: 509 | Iter: 309800 | Total Loss: 0.004268 | Recon Loss: 0.003322 | Commit Loss: 0.001892 | Perplexity: 403.393576
2025-10-01 03:13:20,198 Stage: Train 0.5 | Epoch: 509 | Iter: 310000 | Total Loss: 0.004285 | Recon Loss: 0.003331 | Commit Loss: 0.001908 | Perplexity: 404.584874
Trainning Epoch:  62%|██████▏   | 510/823 [88:02:24<55:23:19, 637.06s/it]Trainning Epoch:  62%|██████▏   | 510/823 [88:02:24<55:23:18, 637.06s/it]Trainning Epoch:  62%|██████▏   | 510/823 [88:02:24<55:23:19, 637.06s/it]Trainning Epoch:  62%|██████▏   | 510/823 [88:02:24<55:23:19, 637.06s/it]2025-10-01 03:16:53,163 Stage: Train 0.5 | Epoch: 510 | Iter: 310200 | Total Loss: 0.004275 | Recon Loss: 0.003325 | Commit Loss: 0.001902 | Perplexity: 403.190405
2025-10-01 03:20:20,718 Stage: Train 0.5 | Epoch: 510 | Iter: 310400 | Total Loss: 0.004228 | Recon Loss: 0.003287 | Commit Loss: 0.001881 | Perplexity: 403.051113
2025-10-01 03:23:48,053 Stage: Train 0.5 | Epoch: 510 | Iter: 310600 | Total Loss: 0.004282 | Recon Loss: 0.003328 | Commit Loss: 0.001907 | Perplexity: 404.061900
Trainning Epoch:  62%|██████▏   | 511/823 [88:12:59<55:09:55, 636.53s/it]Trainning Epoch:  62%|██████▏   | 511/823 [88:12:59<55:09:58, 636.53s/it]Trainning Epoch:  62%|██████▏   | 511/823 [88:12:59<55:09:57, 636.53s/it]Trainning Epoch:  62%|██████▏   | 511/823 [88:12:59<55:09:56, 636.53s/it]2025-10-01 03:27:18,813 Stage: Train 0.5 | Epoch: 511 | Iter: 310800 | Total Loss: 0.004249 | Recon Loss: 0.003300 | Commit Loss: 0.001898 | Perplexity: 403.666722
2025-10-01 03:30:47,264 Stage: Train 0.5 | Epoch: 511 | Iter: 311000 | Total Loss: 0.004280 | Recon Loss: 0.003328 | Commit Loss: 0.001905 | Perplexity: 402.979033
2025-10-01 03:34:14,381 Stage: Train 0.5 | Epoch: 511 | Iter: 311200 | Total Loss: 0.004269 | Recon Loss: 0.003314 | Commit Loss: 0.001910 | Perplexity: 403.956302
Trainning Epoch:  62%|██████▏   | 512/823 [88:23:34<54:55:55, 635.87s/it]Trainning Epoch:  62%|██████▏   | 512/823 [88:23:34<54:55:57, 635.87s/it]Trainning Epoch:  62%|██████▏   | 512/823 [88:23:34<54:55:57, 635.87s/it]Trainning Epoch:  62%|██████▏   | 512/823 [88:23:34<54:55:58, 635.88s/it]2025-10-01 03:37:45,549 Stage: Train 0.5 | Epoch: 512 | Iter: 311400 | Total Loss: 0.004258 | Recon Loss: 0.003317 | Commit Loss: 0.001882 | Perplexity: 403.360779
2025-10-01 03:41:12,871 Stage: Train 0.5 | Epoch: 512 | Iter: 311600 | Total Loss: 0.004243 | Recon Loss: 0.003295 | Commit Loss: 0.001896 | Perplexity: 402.208316
2025-10-01 03:44:43,106 Stage: Train 0.5 | Epoch: 512 | Iter: 311800 | Total Loss: 0.004258 | Recon Loss: 0.003305 | Commit Loss: 0.001906 | Perplexity: 403.566956
Trainning Epoch:  62%|██████▏   | 513/823 [88:34:12<54:49:46, 636.73s/it]Trainning Epoch:  62%|██████▏   | 513/823 [88:34:12<54:49:47, 636.74s/it]Trainning Epoch:  62%|██████▏   | 513/823 [88:34:12<54:49:48, 636.74s/it]Trainning Epoch:  62%|██████▏   | 513/823 [88:34:12<54:49:48, 636.74s/it]2025-10-01 03:48:15,526 Stage: Train 0.5 | Epoch: 513 | Iter: 312000 | Total Loss: 0.004279 | Recon Loss: 0.003324 | Commit Loss: 0.001910 | Perplexity: 404.320090
2025-10-01 03:51:41,922 Stage: Train 0.5 | Epoch: 513 | Iter: 312200 | Total Loss: 0.004265 | Recon Loss: 0.003313 | Commit Loss: 0.001903 | Perplexity: 403.854085
2025-10-01 03:55:08,417 Stage: Train 0.5 | Epoch: 513 | Iter: 312400 | Total Loss: 0.004270 | Recon Loss: 0.003319 | Commit Loss: 0.001901 | Perplexity: 402.856814
Trainning Epoch:  62%|██████▏   | 514/823 [88:44:44<54:31:26, 635.23s/it]Trainning Epoch:  62%|██████▏   | 514/823 [88:44:44<54:31:26, 635.23s/it]Trainning Epoch:  62%|██████▏   | 514/823 [88:44:44<54:31:26, 635.23s/it]Trainning Epoch:  62%|██████▏   | 514/823 [88:44:44<54:31:26, 635.23s/it]2025-10-01 03:58:38,967 Stage: Train 0.5 | Epoch: 514 | Iter: 312600 | Total Loss: 0.004258 | Recon Loss: 0.003311 | Commit Loss: 0.001895 | Perplexity: 403.530213
2025-10-01 04:02:05,766 Stage: Train 0.5 | Epoch: 514 | Iter: 312800 | Total Loss: 0.004280 | Recon Loss: 0.003326 | Commit Loss: 0.001907 | Perplexity: 404.645270
2025-10-01 04:05:33,479 Stage: Train 0.5 | Epoch: 514 | Iter: 313000 | Total Loss: 0.004283 | Recon Loss: 0.003336 | Commit Loss: 0.001894 | Perplexity: 403.672074
Trainning Epoch:  63%|██████▎   | 515/823 [88:55:19<54:19:53, 635.04s/it]Trainning Epoch:  63%|██████▎   | 515/823 [88:55:19<54:19:53, 635.04s/it]Trainning Epoch:  63%|██████▎   | 515/823 [88:55:19<54:19:55, 635.05s/it]Trainning Epoch:  63%|██████▎   | 515/823 [88:55:19<54:19:53, 635.04s/it]2025-10-01 04:09:04,796 Stage: Train 0.5 | Epoch: 515 | Iter: 313200 | Total Loss: 0.004243 | Recon Loss: 0.003296 | Commit Loss: 0.001895 | Perplexity: 403.345991
2025-10-01 04:12:31,588 Stage: Train 0.5 | Epoch: 515 | Iter: 313400 | Total Loss: 0.004249 | Recon Loss: 0.003304 | Commit Loss: 0.001890 | Perplexity: 403.752941
2025-10-01 04:15:59,520 Stage: Train 0.5 | Epoch: 515 | Iter: 313600 | Total Loss: 0.004298 | Recon Loss: 0.003341 | Commit Loss: 0.001915 | Perplexity: 403.987481
Trainning Epoch:  63%|██████▎   | 516/823 [89:05:52<54:06:49, 634.56s/it]Trainning Epoch:  63%|██████▎   | 516/823 [89:05:52<54:06:53, 634.57s/it]Trainning Epoch:  63%|██████▎   | 516/823 [89:05:52<54:06:53, 634.57s/it]Trainning Epoch:  63%|██████▎   | 516/823 [89:05:52<54:06:53, 634.57s/it]2025-10-01 04:19:29,812 Stage: Train 0.5 | Epoch: 516 | Iter: 313800 | Total Loss: 0.004210 | Recon Loss: 0.003271 | Commit Loss: 0.001877 | Perplexity: 402.510950
2025-10-01 04:22:55,919 Stage: Train 0.5 | Epoch: 516 | Iter: 314000 | Total Loss: 0.004267 | Recon Loss: 0.003319 | Commit Loss: 0.001895 | Perplexity: 403.209063
2025-10-01 04:26:22,191 Stage: Train 0.5 | Epoch: 516 | Iter: 314200 | Total Loss: 0.004245 | Recon Loss: 0.003295 | Commit Loss: 0.001900 | Perplexity: 403.009232
Trainning Epoch:  63%|██████▎   | 517/823 [89:16:22<53:49:38, 633.26s/it]Trainning Epoch:  63%|██████▎   | 517/823 [89:16:22<53:49:35, 633.25s/it]Trainning Epoch:  63%|██████▎   | 517/823 [89:16:22<53:49:36, 633.26s/it]Trainning Epoch:  63%|██████▎   | 517/823 [89:16:22<53:49:38, 633.26s/it]2025-10-01 04:29:51,931 Stage: Train 0.5 | Epoch: 517 | Iter: 314400 | Total Loss: 0.004235 | Recon Loss: 0.003289 | Commit Loss: 0.001892 | Perplexity: 402.979796
2025-10-01 04:33:18,014 Stage: Train 0.5 | Epoch: 517 | Iter: 314600 | Total Loss: 0.004266 | Recon Loss: 0.003319 | Commit Loss: 0.001894 | Perplexity: 404.405314
2025-10-01 04:36:45,366 Stage: Train 0.5 | Epoch: 517 | Iter: 314800 | Total Loss: 0.004260 | Recon Loss: 0.003311 | Commit Loss: 0.001897 | Perplexity: 403.789046
Trainning Epoch:  63%|██████▎   | 518/823 [89:26:55<53:37:24, 632.93s/it]Trainning Epoch:  63%|██████▎   | 518/823 [89:26:55<53:37:27, 632.94s/it]Trainning Epoch:  63%|██████▎   | 518/823 [89:26:55<53:37:25, 632.93s/it]Trainning Epoch:  63%|██████▎   | 518/823 [89:26:55<53:37:26, 632.94s/it]2025-10-01 04:40:15,833 Stage: Train 0.5 | Epoch: 518 | Iter: 315000 | Total Loss: 0.004250 | Recon Loss: 0.003301 | Commit Loss: 0.001898 | Perplexity: 403.339380
2025-10-01 04:43:42,683 Stage: Train 0.5 | Epoch: 518 | Iter: 315200 | Total Loss: 0.004249 | Recon Loss: 0.003306 | Commit Loss: 0.001886 | Perplexity: 403.048879
2025-10-01 04:47:10,022 Stage: Train 0.5 | Epoch: 518 | Iter: 315400 | Total Loss: 0.004264 | Recon Loss: 0.003318 | Commit Loss: 0.001892 | Perplexity: 403.708394
Trainning Epoch:  63%|██████▎   | 519/823 [89:37:28<53:26:49, 632.93s/it]Trainning Epoch:  63%|██████▎   | 519/823 [89:37:27<53:26:48, 632.92s/it]Trainning Epoch:  63%|██████▎   | 519/823 [89:37:28<53:26:49, 632.92s/it]Trainning Epoch:  63%|██████▎   | 519/823 [89:37:28<53:26:50, 632.93s/it]2025-10-01 04:50:41,057 Stage: Train 0.5 | Epoch: 519 | Iter: 315600 | Total Loss: 0.004222 | Recon Loss: 0.003283 | Commit Loss: 0.001878 | Perplexity: 402.366220
2025-10-01 04:54:08,707 Stage: Train 0.5 | Epoch: 519 | Iter: 315800 | Total Loss: 0.004264 | Recon Loss: 0.003311 | Commit Loss: 0.001907 | Perplexity: 403.480869
2025-10-01 04:57:36,649 Stage: Train 0.5 | Epoch: 519 | Iter: 316000 | Total Loss: 0.004210 | Recon Loss: 0.003271 | Commit Loss: 0.001879 | Perplexity: 402.744394
Trainning Epoch:  63%|██████▎   | 520/823 [89:48:03<53:20:04, 633.68s/it]Trainning Epoch:  63%|██████▎   | 520/823 [89:48:03<53:20:03, 633.68s/it]Trainning Epoch:  63%|██████▎   | 520/823 [89:48:03<53:20:05, 633.68s/it]Trainning Epoch:  63%|██████▎   | 520/823 [89:48:03<53:20:04, 633.68s/it]2025-10-01 05:01:07,453 Stage: Train 0.5 | Epoch: 520 | Iter: 316200 | Total Loss: 0.004228 | Recon Loss: 0.003283 | Commit Loss: 0.001890 | Perplexity: 402.794214
2025-10-01 05:04:31,002 Stage: Train 0.5 | Epoch: 520 | Iter: 316400 | Total Loss: 0.004226 | Recon Loss: 0.003285 | Commit Loss: 0.001882 | Perplexity: 403.137374
2025-10-01 05:07:56,365 Stage: Train 0.5 | Epoch: 520 | Iter: 316600 | Total Loss: 0.004227 | Recon Loss: 0.003285 | Commit Loss: 0.001884 | Perplexity: 402.614276
Trainning Epoch:  63%|██████▎   | 521/823 [89:58:29<52:58:30, 631.49s/it]Trainning Epoch:  63%|██████▎   | 521/823 [89:58:29<52:58:31, 631.49s/it]Trainning Epoch:  63%|██████▎   | 521/823 [89:58:29<52:58:32, 631.50s/it]Trainning Epoch:  63%|██████▎   | 521/823 [89:58:29<52:58:32, 631.50s/it]2025-10-01 05:11:25,904 Stage: Train 0.5 | Epoch: 521 | Iter: 316800 | Total Loss: 0.004253 | Recon Loss: 0.003300 | Commit Loss: 0.001905 | Perplexity: 403.818683
2025-10-01 05:14:52,187 Stage: Train 0.5 | Epoch: 521 | Iter: 317000 | Total Loss: 0.004235 | Recon Loss: 0.003295 | Commit Loss: 0.001881 | Perplexity: 402.877977
2025-10-01 05:18:19,004 Stage: Train 0.5 | Epoch: 521 | Iter: 317200 | Total Loss: 0.004252 | Recon Loss: 0.003304 | Commit Loss: 0.001896 | Perplexity: 404.360766
Trainning Epoch:  63%|██████▎   | 522/823 [90:09:01<52:48:02, 631.50s/it]Trainning Epoch:  63%|██████▎   | 522/823 [90:09:01<52:48:03, 631.51s/it]Trainning Epoch:  63%|██████▎   | 522/823 [90:09:01<52:48:03, 631.51s/it]Trainning Epoch:  63%|██████▎   | 522/823 [90:09:01<52:48:03, 631.51s/it]2025-10-01 05:21:49,311 Stage: Train 0.5 | Epoch: 522 | Iter: 317400 | Total Loss: 0.004243 | Recon Loss: 0.003300 | Commit Loss: 0.001886 | Perplexity: 402.085271
2025-10-01 05:25:14,901 Stage: Train 0.5 | Epoch: 522 | Iter: 317600 | Total Loss: 0.004267 | Recon Loss: 0.003322 | Commit Loss: 0.001889 | Perplexity: 402.547882
2025-10-01 05:28:41,221 Stage: Train 0.5 | Epoch: 522 | Iter: 317800 | Total Loss: 0.004252 | Recon Loss: 0.003308 | Commit Loss: 0.001887 | Perplexity: 403.046264
Trainning Epoch:  64%|██████▎   | 523/823 [90:19:32<52:36:18, 631.26s/it]Trainning Epoch:  64%|██████▎   | 523/823 [90:19:32<52:36:19, 631.26s/it]Trainning Epoch:  64%|██████▎   | 523/823 [90:19:32<52:36:18, 631.26s/it]Trainning Epoch:  64%|██████▎   | 523/823 [90:19:32<52:36:19, 631.27s/it]2025-10-01 05:32:11,656 Stage: Train 0.5 | Epoch: 523 | Iter: 318000 | Total Loss: 0.004241 | Recon Loss: 0.003293 | Commit Loss: 0.001896 | Perplexity: 403.230420
2025-10-01 05:35:36,873 Stage: Train 0.5 | Epoch: 523 | Iter: 318200 | Total Loss: 0.004215 | Recon Loss: 0.003276 | Commit Loss: 0.001878 | Perplexity: 403.121279
2025-10-01 05:39:03,031 Stage: Train 0.5 | Epoch: 523 | Iter: 318400 | Total Loss: 0.004252 | Recon Loss: 0.003301 | Commit Loss: 0.001901 | Perplexity: 403.074807
Trainning Epoch:  64%|██████▎   | 524/823 [90:30:02<52:24:35, 631.02s/it]Trainning Epoch:  64%|██████▎   | 524/823 [90:30:02<52:24:36, 631.02s/it]Trainning Epoch:  64%|██████▎   | 524/823 [90:30:02<52:24:37, 631.03s/it]Trainning Epoch:  64%|██████▎   | 524/823 [90:30:02<52:24:38, 631.03s/it]2025-10-01 05:42:34,200 Stage: Train 0.5 | Epoch: 524 | Iter: 318600 | Total Loss: 0.004254 | Recon Loss: 0.003305 | Commit Loss: 0.001898 | Perplexity: 402.428057
2025-10-01 05:46:00,289 Stage: Train 0.5 | Epoch: 524 | Iter: 318800 | Total Loss: 0.004213 | Recon Loss: 0.003270 | Commit Loss: 0.001885 | Perplexity: 403.140461
2025-10-01 05:49:28,375 Stage: Train 0.5 | Epoch: 524 | Iter: 319000 | Total Loss: 0.004202 | Recon Loss: 0.003266 | Commit Loss: 0.001872 | Perplexity: 403.579819
2025-10-01 05:52:58,264 Stage: Train 0.5 | Epoch: 524 | Iter: 319200 | Total Loss: 0.004256 | Recon Loss: 0.003303 | Commit Loss: 0.001907 | Perplexity: 403.865853
Trainning Epoch:  64%|██████▍   | 525/823 [90:40:39<52:22:17, 632.68s/it]Trainning Epoch:  64%|██████▍   | 525/823 [90:40:39<52:22:17, 632.67s/it]Trainning Epoch:  64%|██████▍   | 525/823 [90:40:39<52:22:18, 632.68s/it]Trainning Epoch:  64%|██████▍   | 525/823 [90:40:39<52:22:17, 632.68s/it]2025-10-01 05:56:27,073 Stage: Train 0.5 | Epoch: 525 | Iter: 319400 | Total Loss: 0.004224 | Recon Loss: 0.003288 | Commit Loss: 0.001871 | Perplexity: 403.195918
2025-10-01 05:59:52,788 Stage: Train 0.5 | Epoch: 525 | Iter: 319600 | Total Loss: 0.004226 | Recon Loss: 0.003280 | Commit Loss: 0.001892 | Perplexity: 404.179435
2025-10-01 06:03:18,235 Stage: Train 0.5 | Epoch: 525 | Iter: 319800 | Total Loss: 0.004218 | Recon Loss: 0.003273 | Commit Loss: 0.001889 | Perplexity: 403.183857
Trainning Epoch:  64%|██████▍   | 526/823 [90:51:07<52:04:59, 631.31s/it]Trainning Epoch:  64%|██████▍   | 526/823 [90:51:07<52:04:59, 631.31s/it]Trainning Epoch:  64%|██████▍   | 526/823 [90:51:07<52:05:01, 631.32s/it]Trainning Epoch:  64%|██████▍   | 526/823 [90:51:07<52:05:01, 631.32s/it]2025-10-01 06:06:47,298 Stage: Train 0.5 | Epoch: 526 | Iter: 320000 | Total Loss: 0.004246 | Recon Loss: 0.003303 | Commit Loss: 0.001885 | Perplexity: 403.212407
2025-10-01 06:06:47,299 Saving model at iteration 320000
2025-10-01 06:06:47,618 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_527_step_320000
2025-10-01 06:06:48,241 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_527_step_320000/model.safetensors
2025-10-01 06:06:48,815 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_527_step_320000/optimizer.bin
2025-10-01 06:06:48,815 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_527_step_320000/scheduler.bin
2025-10-01 06:06:48,815 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_527_step_320000/sampler.bin
2025-10-01 06:06:48,816 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_527_step_320000/random_states_0.pkl
2025-10-01 06:10:14,967 Stage: Train 0.5 | Epoch: 526 | Iter: 320200 | Total Loss: 0.004229 | Recon Loss: 0.003285 | Commit Loss: 0.001887 | Perplexity: 403.491657
2025-10-01 06:13:40,388 Stage: Train 0.5 | Epoch: 526 | Iter: 320400 | Total Loss: 0.004251 | Recon Loss: 0.003304 | Commit Loss: 0.001893 | Perplexity: 403.183978
Trainning Epoch:  64%|██████▍   | 527/823 [91:01:37<51:52:50, 630.98s/it]Trainning Epoch:  64%|██████▍   | 527/823 [91:01:37<51:52:51, 630.98s/it]Trainning Epoch:  64%|██████▍   | 527/823 [91:01:37<51:52:50, 630.98s/it]Trainning Epoch:  64%|██████▍   | 527/823 [91:01:37<51:52:50, 630.98s/it]2025-10-01 06:17:08,353 Stage: Train 0.5 | Epoch: 527 | Iter: 320600 | Total Loss: 0.004212 | Recon Loss: 0.003272 | Commit Loss: 0.001881 | Perplexity: 403.306652
2025-10-01 06:20:34,147 Stage: Train 0.5 | Epoch: 527 | Iter: 320800 | Total Loss: 0.004212 | Recon Loss: 0.003267 | Commit Loss: 0.001890 | Perplexity: 403.275626
2025-10-01 06:24:00,966 Stage: Train 0.5 | Epoch: 527 | Iter: 321000 | Total Loss: 0.004262 | Recon Loss: 0.003314 | Commit Loss: 0.001895 | Perplexity: 404.295927
Trainning Epoch:  64%|██████▍   | 528/823 [91:12:06<51:39:18, 630.37s/it]Trainning Epoch:  64%|██████▍   | 528/823 [91:12:06<51:39:18, 630.37s/it]Trainning Epoch:  64%|██████▍   | 528/823 [91:12:06<51:39:19, 630.37s/it]Trainning Epoch:  64%|██████▍   | 528/823 [91:12:06<51:39:20, 630.37s/it]2025-10-01 06:27:31,258 Stage: Train 0.5 | Epoch: 528 | Iter: 321200 | Total Loss: 0.004222 | Recon Loss: 0.003282 | Commit Loss: 0.001879 | Perplexity: 403.226716
2025-10-01 06:30:58,920 Stage: Train 0.5 | Epoch: 528 | Iter: 321400 | Total Loss: 0.004223 | Recon Loss: 0.003284 | Commit Loss: 0.001878 | Perplexity: 403.278198
2025-10-01 06:34:27,044 Stage: Train 0.5 | Epoch: 528 | Iter: 321600 | Total Loss: 0.004224 | Recon Loss: 0.003278 | Commit Loss: 0.001892 | Perplexity: 402.711193
Trainning Epoch:  64%|██████▍   | 529/823 [91:22:40<51:34:56, 631.62s/it]Trainning Epoch:  64%|██████▍   | 529/823 [91:22:40<51:34:58, 631.63s/it]Trainning Epoch:  64%|██████▍   | 529/823 [91:22:40<51:34:58, 631.63s/it]Trainning Epoch:  64%|██████▍   | 529/823 [91:22:40<51:34:59, 631.63s/it]2025-10-01 06:37:56,299 Stage: Train 0.5 | Epoch: 529 | Iter: 321800 | Total Loss: 0.004208 | Recon Loss: 0.003270 | Commit Loss: 0.001877 | Perplexity: 402.847428
2025-10-01 06:41:22,460 Stage: Train 0.5 | Epoch: 529 | Iter: 322000 | Total Loss: 0.004222 | Recon Loss: 0.003279 | Commit Loss: 0.001885 | Perplexity: 403.456883
2025-10-01 06:44:48,955 Stage: Train 0.5 | Epoch: 529 | Iter: 322200 | Total Loss: 0.004243 | Recon Loss: 0.003288 | Commit Loss: 0.001908 | Perplexity: 404.200771
Trainning Epoch:  64%|██████▍   | 530/823 [91:33:10<51:21:46, 631.08s/it]Trainning Epoch:  64%|██████▍   | 530/823 [91:33:10<51:21:49, 631.09s/it]Trainning Epoch:  64%|██████▍   | 530/823 [91:33:10<51:21:51, 631.10s/it]Trainning Epoch:  64%|██████▍   | 530/823 [91:33:10<51:21:50, 631.09s/it]2025-10-01 06:48:20,266 Stage: Train 0.5 | Epoch: 530 | Iter: 322400 | Total Loss: 0.004227 | Recon Loss: 0.003282 | Commit Loss: 0.001889 | Perplexity: 404.291193
2025-10-01 06:51:48,589 Stage: Train 0.5 | Epoch: 530 | Iter: 322600 | Total Loss: 0.004240 | Recon Loss: 0.003291 | Commit Loss: 0.001897 | Perplexity: 403.572060
2025-10-01 06:55:17,690 Stage: Train 0.5 | Epoch: 530 | Iter: 322800 | Total Loss: 0.004257 | Recon Loss: 0.003303 | Commit Loss: 0.001907 | Perplexity: 403.481165
Trainning Epoch:  65%|██████▍   | 531/823 [91:43:48<51:20:27, 632.97s/it]Trainning Epoch:  65%|██████▍   | 531/823 [91:43:48<51:20:27, 632.97s/it]Trainning Epoch:  65%|██████▍   | 531/823 [91:43:48<51:20:27, 632.97s/it]Trainning Epoch:  65%|██████▍   | 531/823 [91:43:48<51:20:28, 632.97s/it]2025-10-01 06:58:47,379 Stage: Train 0.5 | Epoch: 531 | Iter: 323000 | Total Loss: 0.004228 | Recon Loss: 0.003287 | Commit Loss: 0.001881 | Perplexity: 403.764659
2025-10-01 07:02:13,923 Stage: Train 0.5 | Epoch: 531 | Iter: 323200 | Total Loss: 0.004226 | Recon Loss: 0.003283 | Commit Loss: 0.001886 | Perplexity: 403.079302
2025-10-01 07:05:42,176 Stage: Train 0.5 | Epoch: 531 | Iter: 323400 | Total Loss: 0.004208 | Recon Loss: 0.003262 | Commit Loss: 0.001892 | Perplexity: 402.740068
Trainning Epoch:  65%|██████▍   | 532/823 [91:54:21<51:09:47, 632.95s/it]Trainning Epoch:  65%|██████▍   | 532/823 [91:54:20<51:09:48, 632.95s/it]Trainning Epoch:  65%|██████▍   | 532/823 [91:54:21<51:09:48, 632.95s/it]Trainning Epoch:  65%|██████▍   | 532/823 [91:54:21<51:09:48, 632.95s/it]2025-10-01 07:09:12,935 Stage: Train 0.5 | Epoch: 532 | Iter: 323600 | Total Loss: 0.004229 | Recon Loss: 0.003287 | Commit Loss: 0.001883 | Perplexity: 402.810971
2025-10-01 07:12:40,818 Stage: Train 0.5 | Epoch: 532 | Iter: 323800 | Total Loss: 0.004242 | Recon Loss: 0.003292 | Commit Loss: 0.001900 | Perplexity: 403.642225
2025-10-01 07:16:09,634 Stage: Train 0.5 | Epoch: 532 | Iter: 324000 | Total Loss: 0.004219 | Recon Loss: 0.003272 | Commit Loss: 0.001893 | Perplexity: 404.149025
Trainning Epoch:  65%|██████▍   | 533/823 [92:04:56<51:03:11, 633.76s/it]Trainning Epoch:  65%|██████▍   | 533/823 [92:04:56<51:03:11, 633.76s/it]Trainning Epoch:  65%|██████▍   | 533/823 [92:04:56<51:03:11, 633.76s/it]Trainning Epoch:  65%|██████▍   | 533/823 [92:04:56<51:03:13, 633.77s/it]2025-10-01 07:19:41,657 Stage: Train 0.5 | Epoch: 533 | Iter: 324200 | Total Loss: 0.004227 | Recon Loss: 0.003287 | Commit Loss: 0.001880 | Perplexity: 403.564345
2025-10-01 07:23:10,496 Stage: Train 0.5 | Epoch: 533 | Iter: 324400 | Total Loss: 0.004213 | Recon Loss: 0.003265 | Commit Loss: 0.001896 | Perplexity: 403.531824
2025-10-01 07:26:40,165 Stage: Train 0.5 | Epoch: 533 | Iter: 324600 | Total Loss: 0.004217 | Recon Loss: 0.003273 | Commit Loss: 0.001888 | Perplexity: 402.965883
Trainning Epoch:  65%|██████▍   | 534/823 [92:15:36<51:00:48, 635.46s/it]Trainning Epoch:  65%|██████▍   | 534/823 [92:15:36<51:00:48, 635.46s/it]Trainning Epoch:  65%|██████▍   | 534/823 [92:15:36<51:00:48, 635.46s/it]Trainning Epoch:  65%|██████▍   | 534/823 [92:15:36<51:00:48, 635.46s/it]2025-10-01 07:30:12,325 Stage: Train 0.5 | Epoch: 534 | Iter: 324800 | Total Loss: 0.004232 | Recon Loss: 0.003288 | Commit Loss: 0.001889 | Perplexity: 404.031505
2025-10-01 07:33:41,392 Stage: Train 0.5 | Epoch: 534 | Iter: 325000 | Total Loss: 0.004224 | Recon Loss: 0.003279 | Commit Loss: 0.001890 | Perplexity: 403.161127
2025-10-01 07:37:11,298 Stage: Train 0.5 | Epoch: 534 | Iter: 325200 | Total Loss: 0.004242 | Recon Loss: 0.003292 | Commit Loss: 0.001901 | Perplexity: 403.176996
Trainning Epoch:  65%|██████▌   | 535/823 [92:26:15<50:55:42, 636.61s/it]Trainning Epoch:  65%|██████▌   | 535/823 [92:26:15<50:55:42, 636.61s/it]Trainning Epoch:  65%|██████▌   | 535/823 [92:26:15<50:55:42, 636.61s/it]Trainning Epoch:  65%|██████▌   | 535/823 [92:26:15<50:55:42, 636.61s/it]2025-10-01 07:40:43,662 Stage: Train 0.5 | Epoch: 535 | Iter: 325400 | Total Loss: 0.004216 | Recon Loss: 0.003271 | Commit Loss: 0.001889 | Perplexity: 403.291142
2025-10-01 07:44:10,984 Stage: Train 0.5 | Epoch: 535 | Iter: 325600 | Total Loss: 0.004197 | Recon Loss: 0.003254 | Commit Loss: 0.001886 | Perplexity: 403.745559
2025-10-01 07:47:38,574 Stage: Train 0.5 | Epoch: 535 | Iter: 325800 | Total Loss: 0.004236 | Recon Loss: 0.003289 | Commit Loss: 0.001893 | Perplexity: 403.275374
Trainning Epoch:  65%|██████▌   | 536/823 [92:36:50<50:43:17, 636.23s/it]Trainning Epoch:  65%|██████▌   | 536/823 [92:36:50<50:43:18, 636.23s/it]Trainning Epoch:  65%|██████▌   | 536/823 [92:36:50<50:43:17, 636.23s/it]Trainning Epoch:  65%|██████▌   | 536/823 [92:36:50<50:43:18, 636.23s/it]2025-10-01 07:51:09,748 Stage: Train 0.5 | Epoch: 536 | Iter: 326000 | Total Loss: 0.004222 | Recon Loss: 0.003270 | Commit Loss: 0.001903 | Perplexity: 404.323219
2025-10-01 07:54:37,439 Stage: Train 0.5 | Epoch: 536 | Iter: 326200 | Total Loss: 0.004240 | Recon Loss: 0.003292 | Commit Loss: 0.001895 | Perplexity: 402.920500
2025-10-01 07:58:06,043 Stage: Train 0.5 | Epoch: 536 | Iter: 326400 | Total Loss: 0.004217 | Recon Loss: 0.003275 | Commit Loss: 0.001884 | Perplexity: 402.964494
Trainning Epoch:  65%|██████▌   | 537/823 [92:47:26<50:31:33, 635.99s/it]Trainning Epoch:  65%|██████▌   | 537/823 [92:47:26<50:31:35, 636.00s/it]Trainning Epoch:  65%|██████▌   | 537/823 [92:47:26<50:31:37, 636.00s/it]Trainning Epoch:  65%|██████▌   | 537/823 [92:47:26<50:31:35, 636.00s/it]2025-10-01 08:01:37,852 Stage: Train 0.5 | Epoch: 537 | Iter: 326600 | Total Loss: 0.004202 | Recon Loss: 0.003259 | Commit Loss: 0.001886 | Perplexity: 403.967705
2025-10-01 08:05:05,777 Stage: Train 0.5 | Epoch: 537 | Iter: 326800 | Total Loss: 0.004233 | Recon Loss: 0.003285 | Commit Loss: 0.001896 | Perplexity: 402.742998
2025-10-01 08:08:35,619 Stage: Train 0.5 | Epoch: 537 | Iter: 327000 | Total Loss: 0.004192 | Recon Loss: 0.003254 | Commit Loss: 0.001876 | Perplexity: 402.895907
Trainning Epoch:  65%|██████▌   | 538/823 [92:58:05<50:26:03, 637.06s/it]Trainning Epoch:  65%|██████▌   | 538/823 [92:58:05<50:26:04, 637.07s/it]Trainning Epoch:  65%|██████▌   | 538/823 [92:58:05<50:26:05, 637.07s/it]Trainning Epoch:  65%|██████▌   | 538/823 [92:58:05<50:26:04, 637.07s/it]2025-10-01 08:12:07,976 Stage: Train 0.5 | Epoch: 538 | Iter: 327200 | Total Loss: 0.004219 | Recon Loss: 0.003276 | Commit Loss: 0.001885 | Perplexity: 403.839665
2025-10-01 08:15:36,158 Stage: Train 0.5 | Epoch: 538 | Iter: 327400 | Total Loss: 0.004200 | Recon Loss: 0.003258 | Commit Loss: 0.001884 | Perplexity: 403.408666
2025-10-01 08:19:04,804 Stage: Train 0.5 | Epoch: 538 | Iter: 327600 | Total Loss: 0.004201 | Recon Loss: 0.003262 | Commit Loss: 0.001878 | Perplexity: 402.783392
Trainning Epoch:  65%|██████▌   | 539/823 [93:08:42<50:15:33, 637.09s/it]Trainning Epoch:  65%|██████▌   | 539/823 [93:08:42<50:15:31, 637.08s/it]Trainning Epoch:  65%|██████▌   | 539/823 [93:08:42<50:15:33, 637.09s/it]Trainning Epoch:  65%|██████▌   | 539/823 [93:08:42<50:15:33, 637.09s/it]2025-10-01 08:22:37,351 Stage: Train 0.5 | Epoch: 539 | Iter: 327800 | Total Loss: 0.004264 | Recon Loss: 0.003310 | Commit Loss: 0.001907 | Perplexity: 403.778307
2025-10-01 08:26:04,154 Stage: Train 0.5 | Epoch: 539 | Iter: 328000 | Total Loss: 0.004206 | Recon Loss: 0.003257 | Commit Loss: 0.001898 | Perplexity: 403.077365
2025-10-01 08:29:30,375 Stage: Train 0.5 | Epoch: 539 | Iter: 328200 | Total Loss: 0.004221 | Recon Loss: 0.003278 | Commit Loss: 0.001886 | Perplexity: 403.212953
Trainning Epoch:  66%|██████▌   | 540/823 [93:19:14<49:57:17, 635.47s/it]Trainning Epoch:  66%|██████▌   | 540/823 [93:19:14<49:57:17, 635.47s/it]Trainning Epoch:  66%|██████▌   | 540/823 [93:19:14<49:57:17, 635.47s/it]Trainning Epoch:  66%|██████▌   | 540/823 [93:19:14<49:57:18, 635.47s/it]2025-10-01 08:33:00,441 Stage: Train 0.5 | Epoch: 540 | Iter: 328400 | Total Loss: 0.004191 | Recon Loss: 0.003247 | Commit Loss: 0.001887 | Perplexity: 403.528566
2025-10-01 08:36:27,185 Stage: Train 0.5 | Epoch: 540 | Iter: 328600 | Total Loss: 0.004203 | Recon Loss: 0.003260 | Commit Loss: 0.001886 | Perplexity: 402.570006
2025-10-01 08:39:53,462 Stage: Train 0.5 | Epoch: 540 | Iter: 328800 | Total Loss: 0.004223 | Recon Loss: 0.003271 | Commit Loss: 0.001904 | Perplexity: 403.280455
Trainning Epoch:  66%|██████▌   | 541/823 [93:29:46<49:41:13, 634.30s/it]Trainning Epoch:  66%|██████▌   | 541/823 [93:29:46<49:41:13, 634.30s/it]Trainning Epoch:  66%|██████▌   | 541/823 [93:29:46<49:41:14, 634.31s/it]Trainning Epoch:  66%|██████▌   | 541/823 [93:29:46<49:41:14, 634.31s/it]2025-10-01 08:43:24,093 Stage: Train 0.5 | Epoch: 541 | Iter: 329000 | Total Loss: 0.004250 | Recon Loss: 0.003297 | Commit Loss: 0.001904 | Perplexity: 403.206253
2025-10-01 08:46:51,341 Stage: Train 0.5 | Epoch: 541 | Iter: 329200 | Total Loss: 0.004177 | Recon Loss: 0.003242 | Commit Loss: 0.001870 | Perplexity: 402.655632
2025-10-01 08:50:20,099 Stage: Train 0.5 | Epoch: 541 | Iter: 329400 | Total Loss: 0.004214 | Recon Loss: 0.003266 | Commit Loss: 0.001896 | Perplexity: 403.611250
Trainning Epoch:  66%|██████▌   | 542/823 [93:40:22<49:33:18, 634.87s/it]Trainning Epoch:  66%|██████▌   | 542/823 [93:40:22<49:33:18, 634.87s/it]Trainning Epoch:  66%|██████▌   | 542/823 [93:40:22<49:33:18, 634.87s/it]Trainning Epoch:  66%|██████▌   | 542/823 [93:40:22<49:33:18, 634.87s/it]2025-10-01 08:53:52,261 Stage: Train 0.5 | Epoch: 542 | Iter: 329600 | Total Loss: 0.004205 | Recon Loss: 0.003255 | Commit Loss: 0.001899 | Perplexity: 403.388123
2025-10-01 08:57:20,279 Stage: Train 0.5 | Epoch: 542 | Iter: 329800 | Total Loss: 0.004212 | Recon Loss: 0.003265 | Commit Loss: 0.001895 | Perplexity: 403.438754
2025-10-01 09:00:49,601 Stage: Train 0.5 | Epoch: 542 | Iter: 330000 | Total Loss: 0.004248 | Recon Loss: 0.003294 | Commit Loss: 0.001909 | Perplexity: 403.582488
Trainning Epoch:  66%|██████▌   | 543/823 [93:51:00<49:27:24, 635.87s/it]Trainning Epoch:  66%|██████▌   | 543/823 [93:51:00<49:27:25, 635.88s/it]Trainning Epoch:  66%|██████▌   | 543/823 [93:51:00<49:27:25, 635.88s/it]Trainning Epoch:  66%|██████▌   | 543/823 [93:51:00<49:27:25, 635.88s/it]2025-10-01 09:04:22,071 Stage: Train 0.5 | Epoch: 543 | Iter: 330200 | Total Loss: 0.004206 | Recon Loss: 0.003264 | Commit Loss: 0.001884 | Perplexity: 402.770243
2025-10-01 09:07:50,386 Stage: Train 0.5 | Epoch: 543 | Iter: 330400 | Total Loss: 0.004207 | Recon Loss: 0.003264 | Commit Loss: 0.001887 | Perplexity: 404.109208
2025-10-01 09:11:20,207 Stage: Train 0.5 | Epoch: 543 | Iter: 330600 | Total Loss: 0.004217 | Recon Loss: 0.003271 | Commit Loss: 0.001892 | Perplexity: 403.453784
Trainning Epoch:  66%|██████▌   | 544/823 [94:01:39<49:20:52, 636.75s/it]Trainning Epoch:  66%|██████▌   | 544/823 [94:01:39<49:20:52, 636.75s/it]Trainning Epoch:  66%|██████▌   | 544/823 [94:01:39<49:20:54, 636.75s/it]Trainning Epoch:  66%|██████▌   | 544/823 [94:01:39<49:20:55, 636.76s/it]2025-10-01 09:14:52,291 Stage: Train 0.5 | Epoch: 544 | Iter: 330800 | Total Loss: 0.004229 | Recon Loss: 0.003279 | Commit Loss: 0.001900 | Perplexity: 403.813764
2025-10-01 09:18:19,628 Stage: Train 0.5 | Epoch: 544 | Iter: 331000 | Total Loss: 0.004196 | Recon Loss: 0.003255 | Commit Loss: 0.001883 | Perplexity: 402.750763
2025-10-01 09:21:47,766 Stage: Train 0.5 | Epoch: 544 | Iter: 331200 | Total Loss: 0.004238 | Recon Loss: 0.003293 | Commit Loss: 0.001891 | Perplexity: 403.458746
Trainning Epoch:  66%|██████▌   | 545/823 [94:12:14<49:08:02, 636.27s/it]Trainning Epoch:  66%|██████▌   | 545/823 [94:12:14<49:08:03, 636.27s/it]Trainning Epoch:  66%|██████▌   | 545/823 [94:12:14<49:08:04, 636.28s/it]Trainning Epoch:  66%|██████▌   | 545/823 [94:12:14<49:08:04, 636.27s/it]2025-10-01 09:25:19,666 Stage: Train 0.5 | Epoch: 545 | Iter: 331400 | Total Loss: 0.004206 | Recon Loss: 0.003260 | Commit Loss: 0.001894 | Perplexity: 403.971509
2025-10-01 09:28:48,460 Stage: Train 0.5 | Epoch: 545 | Iter: 331600 | Total Loss: 0.004223 | Recon Loss: 0.003272 | Commit Loss: 0.001903 | Perplexity: 404.638151
2025-10-01 09:32:17,767 Stage: Train 0.5 | Epoch: 545 | Iter: 331800 | Total Loss: 0.004213 | Recon Loss: 0.003265 | Commit Loss: 0.001896 | Perplexity: 404.123979
Trainning Epoch:  66%|██████▋   | 546/823 [94:22:53<49:01:44, 637.20s/it]Trainning Epoch:  66%|██████▋   | 546/823 [94:22:53<49:01:49, 637.22s/it]Trainning Epoch:  66%|██████▋   | 546/823 [94:22:53<49:01:50, 637.22s/it]Trainning Epoch:  66%|██████▋   | 546/823 [94:22:53<49:01:50, 637.22s/it]2025-10-01 09:35:50,626 Stage: Train 0.5 | Epoch: 546 | Iter: 332000 | Total Loss: 0.004190 | Recon Loss: 0.003244 | Commit Loss: 0.001892 | Perplexity: 403.138025
2025-10-01 09:39:17,334 Stage: Train 0.5 | Epoch: 546 | Iter: 332200 | Total Loss: 0.004178 | Recon Loss: 0.003238 | Commit Loss: 0.001880 | Perplexity: 403.288859
2025-10-01 09:42:46,053 Stage: Train 0.5 | Epoch: 546 | Iter: 332400 | Total Loss: 0.004238 | Recon Loss: 0.003287 | Commit Loss: 0.001903 | Perplexity: 404.204883
Trainning Epoch:  66%|██████▋   | 547/823 [94:33:31<48:51:03, 637.19s/it]Trainning Epoch:  66%|██████▋   | 547/823 [94:33:31<48:51:06, 637.20s/it]Trainning Epoch:  66%|██████▋   | 547/823 [94:33:31<48:51:04, 637.19s/it]Trainning Epoch:  66%|██████▋   | 547/823 [94:33:31<48:51:04, 637.19s/it]2025-10-01 09:46:19,243 Stage: Train 0.5 | Epoch: 547 | Iter: 332600 | Total Loss: 0.004223 | Recon Loss: 0.003278 | Commit Loss: 0.001891 | Perplexity: 404.000303
2025-10-01 09:49:47,842 Stage: Train 0.5 | Epoch: 547 | Iter: 332800 | Total Loss: 0.004189 | Recon Loss: 0.003251 | Commit Loss: 0.001877 | Perplexity: 402.773398
2025-10-01 09:53:16,644 Stage: Train 0.5 | Epoch: 547 | Iter: 333000 | Total Loss: 0.004218 | Recon Loss: 0.003269 | Commit Loss: 0.001898 | Perplexity: 403.964142
Trainning Epoch:  67%|██████▋   | 548/823 [94:44:09<48:42:28, 637.63s/it]Trainning Epoch:  67%|██████▋   | 548/823 [94:44:09<48:42:30, 637.64s/it]Trainning Epoch:  67%|██████▋   | 548/823 [94:44:09<48:42:28, 637.63s/it]Trainning Epoch:  67%|██████▋   | 548/823 [94:44:09<48:42:29, 637.63s/it]2025-10-01 09:56:49,728 Stage: Train 0.5 | Epoch: 548 | Iter: 333200 | Total Loss: 0.004181 | Recon Loss: 0.003237 | Commit Loss: 0.001887 | Perplexity: 403.493612
2025-10-01 10:00:16,639 Stage: Train 0.5 | Epoch: 548 | Iter: 333400 | Total Loss: 0.004214 | Recon Loss: 0.003273 | Commit Loss: 0.001882 | Perplexity: 403.421732
2025-10-01 10:03:43,845 Stage: Train 0.5 | Epoch: 548 | Iter: 333600 | Total Loss: 0.004200 | Recon Loss: 0.003258 | Commit Loss: 0.001884 | Perplexity: 403.695200
Trainning Epoch:  67%|██████▋   | 549/823 [94:54:42<48:25:38, 636.27s/it]Trainning Epoch:  67%|██████▋   | 549/823 [94:54:42<48:25:40, 636.28s/it]Trainning Epoch:  67%|██████▋   | 549/823 [94:54:42<48:25:39, 636.28s/it]Trainning Epoch:  67%|██████▋   | 549/823 [94:54:42<48:25:40, 636.28s/it]2025-10-01 10:07:14,380 Stage: Train 0.5 | Epoch: 549 | Iter: 333800 | Total Loss: 0.004252 | Recon Loss: 0.003299 | Commit Loss: 0.001907 | Perplexity: 404.005662
2025-10-01 10:10:38,132 Stage: Train 0.5 | Epoch: 549 | Iter: 334000 | Total Loss: 0.004210 | Recon Loss: 0.003266 | Commit Loss: 0.001887 | Perplexity: 403.653073
2025-10-01 10:14:03,857 Stage: Train 0.5 | Epoch: 549 | Iter: 334200 | Total Loss: 0.004217 | Recon Loss: 0.003274 | Commit Loss: 0.001886 | Perplexity: 402.970974
2025-10-01 10:17:30,054 Stage: Train 0.5 | Epoch: 549 | Iter: 334400 | Total Loss: 0.004193 | Recon Loss: 0.003248 | Commit Loss: 0.001891 | Perplexity: 403.035121
Trainning Epoch:  67%|██████▋   | 550/823 [95:05:10<48:03:44, 633.79s/it]Trainning Epoch:  67%|██████▋   | 550/823 [95:05:10<48:03:45, 633.79s/it]Trainning Epoch:  67%|██████▋   | 550/823 [95:05:10<48:03:44, 633.79s/it]Trainning Epoch:  67%|██████▋   | 550/823 [95:05:10<48:03:45, 633.79s/it]2025-10-01 10:20:58,617 Stage: Train 0.5 | Epoch: 550 | Iter: 334600 | Total Loss: 0.004202 | Recon Loss: 0.003256 | Commit Loss: 0.001891 | Perplexity: 403.442342
2025-10-01 10:24:23,046 Stage: Train 0.5 | Epoch: 550 | Iter: 334800 | Total Loss: 0.004207 | Recon Loss: 0.003259 | Commit Loss: 0.001897 | Perplexity: 403.158719
2025-10-01 10:27:48,882 Stage: Train 0.5 | Epoch: 550 | Iter: 335000 | Total Loss: 0.004237 | Recon Loss: 0.003284 | Commit Loss: 0.001905 | Perplexity: 403.974675
Trainning Epoch:  67%|██████▋   | 551/823 [95:15:37<47:44:06, 631.79s/it]Trainning Epoch:  67%|██████▋   | 551/823 [95:15:37<47:44:07, 631.79s/it]Trainning Epoch:  67%|██████▋   | 551/823 [95:15:37<47:44:06, 631.79s/it]Trainning Epoch:  67%|██████▋   | 551/823 [95:15:37<47:44:06, 631.79s/it]2025-10-01 10:31:19,086 Stage: Train 0.5 | Epoch: 551 | Iter: 335200 | Total Loss: 0.004194 | Recon Loss: 0.003249 | Commit Loss: 0.001889 | Perplexity: 403.423616
2025-10-01 10:34:48,339 Stage: Train 0.5 | Epoch: 551 | Iter: 335400 | Total Loss: 0.004178 | Recon Loss: 0.003239 | Commit Loss: 0.001878 | Perplexity: 403.143485
2025-10-01 10:38:16,554 Stage: Train 0.5 | Epoch: 551 | Iter: 335600 | Total Loss: 0.004192 | Recon Loss: 0.003250 | Commit Loss: 0.001885 | Perplexity: 403.307406
Trainning Epoch:  67%|██████▋   | 552/823 [95:26:13<47:38:57, 632.98s/it]Trainning Epoch:  67%|██████▋   | 552/823 [95:26:13<47:38:57, 632.98s/it]Trainning Epoch:  67%|██████▋   | 552/823 [95:26:13<47:38:59, 632.99s/it]Trainning Epoch:  67%|██████▋   | 552/823 [95:26:13<47:38:59, 632.99s/it]2025-10-01 10:41:46,912 Stage: Train 0.5 | Epoch: 552 | Iter: 335800 | Total Loss: 0.004170 | Recon Loss: 0.003232 | Commit Loss: 0.001877 | Perplexity: 402.673167
2025-10-01 10:45:12,921 Stage: Train 0.5 | Epoch: 552 | Iter: 336000 | Total Loss: 0.004212 | Recon Loss: 0.003260 | Commit Loss: 0.001903 | Perplexity: 403.816079
2025-10-01 10:48:39,306 Stage: Train 0.5 | Epoch: 552 | Iter: 336200 | Total Loss: 0.004249 | Recon Loss: 0.003296 | Commit Loss: 0.001905 | Perplexity: 403.989312
Trainning Epoch:  67%|██████▋   | 553/823 [95:36:44<47:25:39, 632.37s/it]Trainning Epoch:  67%|██████▋   | 553/823 [95:36:44<47:25:39, 632.37s/it]Trainning Epoch:  67%|██████▋   | 553/823 [95:36:44<47:25:41, 632.38s/it]Trainning Epoch:  67%|██████▋   | 553/823 [95:36:44<47:25:42, 632.38s/it]2025-10-01 10:52:10,900 Stage: Train 0.5 | Epoch: 553 | Iter: 336400 | Total Loss: 0.004188 | Recon Loss: 0.003241 | Commit Loss: 0.001894 | Perplexity: 403.516100
2025-10-01 10:55:39,007 Stage: Train 0.5 | Epoch: 553 | Iter: 336600 | Total Loss: 0.004202 | Recon Loss: 0.003254 | Commit Loss: 0.001897 | Perplexity: 403.676999
2025-10-01 10:59:07,102 Stage: Train 0.5 | Epoch: 553 | Iter: 336800 | Total Loss: 0.004236 | Recon Loss: 0.003286 | Commit Loss: 0.001899 | Perplexity: 404.651830
Trainning Epoch:  67%|██████▋   | 554/823 [95:47:20<47:20:13, 633.51s/it]Trainning Epoch:  67%|██████▋   | 554/823 [95:47:20<47:20:13, 633.51s/it]Trainning Epoch:  67%|██████▋   | 554/823 [95:47:20<47:20:12, 633.50s/it]Trainning Epoch:  67%|██████▋   | 554/823 [95:47:20<47:20:13, 633.51s/it]2025-10-01 11:02:39,748 Stage: Train 0.5 | Epoch: 554 | Iter: 337000 | Total Loss: 0.004175 | Recon Loss: 0.003236 | Commit Loss: 0.001877 | Perplexity: 403.625321
2025-10-01 11:06:09,672 Stage: Train 0.5 | Epoch: 554 | Iter: 337200 | Total Loss: 0.004154 | Recon Loss: 0.003216 | Commit Loss: 0.001875 | Perplexity: 402.875110
2025-10-01 11:09:40,119 Stage: Train 0.5 | Epoch: 554 | Iter: 337400 | Total Loss: 0.004235 | Recon Loss: 0.003280 | Commit Loss: 0.001911 | Perplexity: 403.979593
Trainning Epoch:  67%|██████▋   | 555/823 [95:58:02<47:20:56, 636.03s/it]Trainning Epoch:  67%|██████▋   | 555/823 [95:58:02<47:20:56, 636.03s/it]Trainning Epoch:  67%|██████▋   | 555/823 [95:58:02<47:20:57, 636.04s/it]Trainning Epoch:  67%|██████▋   | 555/823 [95:58:02<47:20:58, 636.04s/it]2025-10-01 11:13:11,524 Stage: Train 0.5 | Epoch: 555 | Iter: 337600 | Total Loss: 0.004206 | Recon Loss: 0.003260 | Commit Loss: 0.001894 | Perplexity: 403.612202
2025-10-01 11:16:39,882 Stage: Train 0.5 | Epoch: 555 | Iter: 337800 | Total Loss: 0.004180 | Recon Loss: 0.003236 | Commit Loss: 0.001888 | Perplexity: 403.207188
2025-10-01 11:20:09,489 Stage: Train 0.5 | Epoch: 555 | Iter: 338000 | Total Loss: 0.004185 | Recon Loss: 0.003241 | Commit Loss: 0.001887 | Perplexity: 402.780216
Trainning Epoch:  68%|██████▊   | 556/823 [96:08:40<47:12:37, 636.54s/it]Trainning Epoch:  68%|██████▊   | 556/823 [96:08:40<47:12:38, 636.55s/it]Trainning Epoch:  68%|██████▊   | 556/823 [96:08:40<47:12:38, 636.55s/it]Trainning Epoch:  68%|██████▊   | 556/823 [96:08:40<47:12:39, 636.55s/it]2025-10-01 11:23:41,424 Stage: Train 0.5 | Epoch: 556 | Iter: 338200 | Total Loss: 0.004205 | Recon Loss: 0.003258 | Commit Loss: 0.001894 | Perplexity: 403.232270
2025-10-01 11:27:08,195 Stage: Train 0.5 | Epoch: 556 | Iter: 338400 | Total Loss: 0.004168 | Recon Loss: 0.003229 | Commit Loss: 0.001878 | Perplexity: 402.313997
2025-10-01 11:30:36,517 Stage: Train 0.5 | Epoch: 556 | Iter: 338600 | Total Loss: 0.004192 | Recon Loss: 0.003247 | Commit Loss: 0.001890 | Perplexity: 403.005458
Trainning Epoch:  68%|██████▊   | 557/823 [96:19:15<46:59:51, 636.06s/it]Trainning Epoch:  68%|██████▊   | 557/823 [96:19:15<46:59:50, 636.06s/it]Trainning Epoch:  68%|██████▊   | 557/823 [96:19:15<46:59:51, 636.06s/it]Trainning Epoch:  68%|██████▊   | 557/823 [96:19:15<46:59:51, 636.06s/it]2025-10-01 11:34:09,754 Stage: Train 0.5 | Epoch: 557 | Iter: 338800 | Total Loss: 0.004185 | Recon Loss: 0.003242 | Commit Loss: 0.001885 | Perplexity: 403.726454
2025-10-01 11:37:38,878 Stage: Train 0.5 | Epoch: 557 | Iter: 339000 | Total Loss: 0.004191 | Recon Loss: 0.003245 | Commit Loss: 0.001891 | Perplexity: 403.645473
2025-10-01 11:41:09,059 Stage: Train 0.5 | Epoch: 557 | Iter: 339200 | Total Loss: 0.004207 | Recon Loss: 0.003264 | Commit Loss: 0.001886 | Perplexity: 403.714033
Trainning Epoch:  68%|██████▊   | 558/823 [96:29:56<46:55:33, 637.48s/it]Trainning Epoch:  68%|██████▊   | 558/823 [96:29:56<46:55:33, 637.49s/it]Trainning Epoch:  68%|██████▊   | 558/823 [96:29:56<46:55:33, 637.49s/it]Trainning Epoch:  68%|██████▊   | 558/823 [96:29:56<46:55:34, 637.49s/it]2025-10-01 11:44:41,060 Stage: Train 0.5 | Epoch: 558 | Iter: 339400 | Total Loss: 0.004220 | Recon Loss: 0.003264 | Commit Loss: 0.001912 | Perplexity: 404.310407
2025-10-01 11:48:11,082 Stage: Train 0.5 | Epoch: 558 | Iter: 339600 | Total Loss: 0.004164 | Recon Loss: 0.003224 | Commit Loss: 0.001880 | Perplexity: 403.321314
2025-10-01 11:51:40,907 Stage: Train 0.5 | Epoch: 558 | Iter: 339800 | Total Loss: 0.004202 | Recon Loss: 0.003252 | Commit Loss: 0.001900 | Perplexity: 403.843327
Trainning Epoch:  68%|██████▊   | 559/823 [96:40:37<46:49:51, 638.60s/it]Trainning Epoch:  68%|██████▊   | 559/823 [96:40:37<46:49:53, 638.61s/it]Trainning Epoch:  68%|██████▊   | 559/823 [96:40:37<46:49:52, 638.61s/it]Trainning Epoch:  68%|██████▊   | 559/823 [96:40:37<46:49:52, 638.61s/it]2025-10-01 11:55:13,513 Stage: Train 0.5 | Epoch: 559 | Iter: 340000 | Total Loss: 0.004184 | Recon Loss: 0.003236 | Commit Loss: 0.001894 | Perplexity: 403.779932
2025-10-01 11:55:13,513 Saving model at iteration 340000
2025-10-01 11:55:14,023 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_560_step_340000
2025-10-01 11:55:14,590 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_560_step_340000/model.safetensors
2025-10-01 11:55:15,156 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_560_step_340000/optimizer.bin
2025-10-01 11:55:15,157 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_560_step_340000/scheduler.bin
2025-10-01 11:55:15,157 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_560_step_340000/sampler.bin
2025-10-01 11:55:15,158 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_560_step_340000/random_states_0.pkl
2025-10-01 11:58:43,956 Stage: Train 0.5 | Epoch: 559 | Iter: 340200 | Total Loss: 0.004183 | Recon Loss: 0.003245 | Commit Loss: 0.001877 | Perplexity: 403.596687
2025-10-01 12:02:13,040 Stage: Train 0.5 | Epoch: 559 | Iter: 340400 | Total Loss: 0.004207 | Recon Loss: 0.003252 | Commit Loss: 0.001910 | Perplexity: 404.287013
Trainning Epoch:  68%|██████▊   | 560/823 [96:51:17<46:40:58, 639.00s/it]Trainning Epoch:  68%|██████▊   | 560/823 [96:51:17<46:40:56, 639.00s/it]Trainning Epoch:  68%|██████▊   | 560/823 [96:51:17<46:40:57, 639.00s/it]Trainning Epoch:  68%|██████▊   | 560/823 [96:51:17<46:40:58, 639.00s/it]2025-10-01 12:05:46,319 Stage: Train 0.5 | Epoch: 560 | Iter: 340600 | Total Loss: 0.004183 | Recon Loss: 0.003234 | Commit Loss: 0.001897 | Perplexity: 403.728323
2025-10-01 12:09:15,933 Stage: Train 0.5 | Epoch: 560 | Iter: 340800 | Total Loss: 0.004164 | Recon Loss: 0.003219 | Commit Loss: 0.001889 | Perplexity: 403.283429
2025-10-01 12:12:45,611 Stage: Train 0.5 | Epoch: 560 | Iter: 341000 | Total Loss: 0.004200 | Recon Loss: 0.003251 | Commit Loss: 0.001898 | Perplexity: 403.412152
Trainning Epoch:  68%|██████▊   | 561/823 [97:01:58<46:33:18, 639.69s/it]Trainning Epoch:  68%|██████▊   | 561/823 [97:01:58<46:33:17, 639.69s/it]Trainning Epoch:  68%|██████▊   | 561/823 [97:01:58<46:33:18, 639.69s/it]Trainning Epoch:  68%|██████▊   | 561/823 [97:01:58<46:33:18, 639.69s/it]2025-10-01 12:16:17,941 Stage: Train 0.5 | Epoch: 561 | Iter: 341200 | Total Loss: 0.004175 | Recon Loss: 0.003229 | Commit Loss: 0.001893 | Perplexity: 403.024824
2025-10-01 12:19:44,150 Stage: Train 0.5 | Epoch: 561 | Iter: 341400 | Total Loss: 0.004178 | Recon Loss: 0.003229 | Commit Loss: 0.001898 | Perplexity: 403.452789
2025-10-01 12:23:11,624 Stage: Train 0.5 | Epoch: 561 | Iter: 341600 | Total Loss: 0.004198 | Recon Loss: 0.003247 | Commit Loss: 0.001902 | Perplexity: 403.918764
Trainning Epoch:  68%|██████▊   | 562/823 [97:12:32<46:14:44, 637.87s/it]Trainning Epoch:  68%|██████▊   | 562/823 [97:12:32<46:14:43, 637.87s/it]Trainning Epoch:  68%|██████▊   | 562/823 [97:12:32<46:14:42, 637.87s/it]Trainning Epoch:  68%|██████▊   | 562/823 [97:12:32<46:14:45, 637.87s/it]2025-10-01 12:26:42,637 Stage: Train 0.5 | Epoch: 562 | Iter: 341800 | Total Loss: 0.004190 | Recon Loss: 0.003248 | Commit Loss: 0.001882 | Perplexity: 403.478203
2025-10-01 12:30:08,998 Stage: Train 0.5 | Epoch: 562 | Iter: 342000 | Total Loss: 0.004171 | Recon Loss: 0.003228 | Commit Loss: 0.001887 | Perplexity: 402.730796
2025-10-01 12:33:35,392 Stage: Train 0.5 | Epoch: 562 | Iter: 342200 | Total Loss: 0.004179 | Recon Loss: 0.003230 | Commit Loss: 0.001899 | Perplexity: 403.740313
Trainning Epoch:  68%|██████▊   | 563/823 [97:23:03<45:55:03, 635.78s/it]Trainning Epoch:  68%|██████▊   | 563/823 [97:23:03<45:55:03, 635.78s/it]Trainning Epoch:  68%|██████▊   | 563/823 [97:23:03<45:55:05, 635.79s/it]Trainning Epoch:  68%|██████▊   | 563/823 [97:23:03<45:55:04, 635.79s/it]2025-10-01 12:37:05,662 Stage: Train 0.5 | Epoch: 563 | Iter: 342400 | Total Loss: 0.004166 | Recon Loss: 0.003224 | Commit Loss: 0.001884 | Perplexity: 402.642720
2025-10-01 12:40:32,509 Stage: Train 0.5 | Epoch: 563 | Iter: 342600 | Total Loss: 0.004181 | Recon Loss: 0.003243 | Commit Loss: 0.001877 | Perplexity: 403.037188
2025-10-01 12:43:59,618 Stage: Train 0.5 | Epoch: 563 | Iter: 342800 | Total Loss: 0.004170 | Recon Loss: 0.003228 | Commit Loss: 0.001885 | Perplexity: 403.336859
Trainning Epoch:  69%|██████▊   | 564/823 [97:33:36<45:40:57, 634.97s/it]Trainning Epoch:  69%|██████▊   | 564/823 [97:33:36<45:40:57, 634.97s/it]Trainning Epoch:  69%|██████▊   | 564/823 [97:33:36<45:40:56, 634.97s/it]Trainning Epoch:  69%|██████▊   | 564/823 [97:33:36<45:40:57, 634.97s/it]2025-10-01 12:47:31,490 Stage: Train 0.5 | Epoch: 564 | Iter: 343000 | Total Loss: 0.004204 | Recon Loss: 0.003258 | Commit Loss: 0.001894 | Perplexity: 403.606596
2025-10-01 12:50:59,989 Stage: Train 0.5 | Epoch: 564 | Iter: 343200 | Total Loss: 0.004165 | Recon Loss: 0.003226 | Commit Loss: 0.001878 | Perplexity: 402.525995
2025-10-01 12:54:30,229 Stage: Train 0.5 | Epoch: 564 | Iter: 343400 | Total Loss: 0.004195 | Recon Loss: 0.003249 | Commit Loss: 0.001892 | Perplexity: 402.930361
Trainning Epoch:  69%|██████▊   | 565/823 [97:44:16<45:36:54, 636.49s/it]Trainning Epoch:  69%|██████▊   | 565/823 [97:44:16<45:36:54, 636.49s/it]Trainning Epoch:  69%|██████▊   | 565/823 [97:44:16<45:36:56, 636.50s/it]Trainning Epoch:  69%|██████▊   | 565/823 [97:44:16<45:36:56, 636.50s/it]2025-10-01 12:58:02,958 Stage: Train 0.5 | Epoch: 565 | Iter: 343600 | Total Loss: 0.004192 | Recon Loss: 0.003239 | Commit Loss: 0.001905 | Perplexity: 404.012859
2025-10-01 13:01:32,458 Stage: Train 0.5 | Epoch: 565 | Iter: 343800 | Total Loss: 0.004165 | Recon Loss: 0.003222 | Commit Loss: 0.001886 | Perplexity: 403.124314
2025-10-01 13:05:01,129 Stage: Train 0.5 | Epoch: 565 | Iter: 344000 | Total Loss: 0.004190 | Recon Loss: 0.003239 | Commit Loss: 0.001902 | Perplexity: 404.211116
Trainning Epoch:  69%|██████▉   | 566/823 [97:54:55<45:29:37, 637.27s/it]Trainning Epoch:  69%|██████▉   | 566/823 [97:54:55<45:29:40, 637.28s/it]Trainning Epoch:  69%|██████▉   | 566/823 [97:54:55<45:29:40, 637.28s/it]Trainning Epoch:  69%|██████▉   | 566/823 [97:54:55<45:29:38, 637.27s/it]2025-10-01 13:08:34,030 Stage: Train 0.5 | Epoch: 566 | Iter: 344200 | Total Loss: 0.004164 | Recon Loss: 0.003217 | Commit Loss: 0.001895 | Perplexity: 403.265131
2025-10-01 13:12:00,865 Stage: Train 0.5 | Epoch: 566 | Iter: 344400 | Total Loss: 0.004173 | Recon Loss: 0.003229 | Commit Loss: 0.001888 | Perplexity: 404.222033
2025-10-01 13:15:29,458 Stage: Train 0.5 | Epoch: 566 | Iter: 344600 | Total Loss: 0.004187 | Recon Loss: 0.003242 | Commit Loss: 0.001891 | Perplexity: 403.157578
Trainning Epoch:  69%|██████▉   | 567/823 [98:05:31<45:17:49, 636.99s/it]Trainning Epoch:  69%|██████▉   | 567/823 [98:05:31<45:17:54, 637.01s/it]Trainning Epoch:  69%|██████▉   | 567/823 [98:05:31<45:17:53, 637.01s/it]Trainning Epoch:  69%|██████▉   | 567/823 [98:05:31<45:17:53, 637.00s/it]2025-10-01 13:19:01,008 Stage: Train 0.5 | Epoch: 567 | Iter: 344800 | Total Loss: 0.004171 | Recon Loss: 0.003219 | Commit Loss: 0.001904 | Perplexity: 403.739590
2025-10-01 13:22:28,721 Stage: Train 0.5 | Epoch: 567 | Iter: 345000 | Total Loss: 0.004159 | Recon Loss: 0.003219 | Commit Loss: 0.001881 | Perplexity: 403.687714
2025-10-01 13:25:57,877 Stage: Train 0.5 | Epoch: 567 | Iter: 345200 | Total Loss: 0.004189 | Recon Loss: 0.003240 | Commit Loss: 0.001896 | Perplexity: 404.399335
Trainning Epoch:  69%|██████▉   | 568/823 [98:16:09<45:08:26, 637.28s/it]Trainning Epoch:  69%|██████▉   | 568/823 [98:16:09<45:08:24, 637.27s/it]Trainning Epoch:  69%|██████▉   | 568/823 [98:16:09<45:08:25, 637.28s/it]Trainning Epoch:  69%|██████▉   | 568/823 [98:16:09<45:08:25, 637.28s/it]2025-10-01 13:29:31,206 Stage: Train 0.5 | Epoch: 568 | Iter: 345400 | Total Loss: 0.004155 | Recon Loss: 0.003205 | Commit Loss: 0.001899 | Perplexity: 403.458084
2025-10-01 13:32:59,258 Stage: Train 0.5 | Epoch: 568 | Iter: 345600 | Total Loss: 0.004160 | Recon Loss: 0.003217 | Commit Loss: 0.001886 | Perplexity: 403.192742
2025-10-01 13:36:26,728 Stage: Train 0.5 | Epoch: 568 | Iter: 345800 | Total Loss: 0.004192 | Recon Loss: 0.003249 | Commit Loss: 0.001885 | Perplexity: 403.614910
Trainning Epoch:  69%|██████▉   | 569/823 [98:26:46<44:57:02, 637.10s/it]Trainning Epoch:  69%|██████▉   | 569/823 [98:26:46<44:57:05, 637.11s/it]Trainning Epoch:  69%|██████▉   | 569/823 [98:26:46<44:57:04, 637.11s/it]Trainning Epoch:  69%|██████▉   | 569/823 [98:26:46<44:57:06, 637.11s/it]2025-10-01 13:39:58,914 Stage: Train 0.5 | Epoch: 569 | Iter: 346000 | Total Loss: 0.004195 | Recon Loss: 0.003244 | Commit Loss: 0.001901 | Perplexity: 403.509854
2025-10-01 13:43:26,454 Stage: Train 0.5 | Epoch: 569 | Iter: 346200 | Total Loss: 0.004168 | Recon Loss: 0.003226 | Commit Loss: 0.001884 | Perplexity: 403.348091
2025-10-01 13:46:54,741 Stage: Train 0.5 | Epoch: 569 | Iter: 346400 | Total Loss: 0.004171 | Recon Loss: 0.003225 | Commit Loss: 0.001892 | Perplexity: 402.566943
Trainning Epoch:  69%|██████▉   | 570/823 [98:37:22<44:44:57, 636.75s/it]Trainning Epoch:  69%|██████▉   | 570/823 [98:37:22<44:44:56, 636.74s/it]Trainning Epoch:  69%|██████▉   | 570/823 [98:37:22<44:44:57, 636.75s/it]Trainning Epoch:  69%|██████▉   | 570/823 [98:37:22<44:44:56, 636.75s/it]2025-10-01 13:50:28,421 Stage: Train 0.5 | Epoch: 570 | Iter: 346600 | Total Loss: 0.004175 | Recon Loss: 0.003224 | Commit Loss: 0.001903 | Perplexity: 404.186144
2025-10-01 13:53:57,991 Stage: Train 0.5 | Epoch: 570 | Iter: 346800 | Total Loss: 0.004197 | Recon Loss: 0.003250 | Commit Loss: 0.001894 | Perplexity: 404.439711
2025-10-01 13:57:30,159 Stage: Train 0.5 | Epoch: 570 | Iter: 347000 | Total Loss: 0.004166 | Recon Loss: 0.003224 | Commit Loss: 0.001885 | Perplexity: 402.888041
Trainning Epoch:  69%|██████▉   | 571/823 [98:48:10<44:48:28, 640.11s/it]Trainning Epoch:  69%|██████▉   | 571/823 [98:48:10<44:48:27, 640.11s/it]Trainning Epoch:  69%|██████▉   | 571/823 [98:48:10<44:48:28, 640.11s/it]Trainning Epoch:  69%|██████▉   | 571/823 [98:48:10<44:48:29, 640.12s/it]2025-10-01 14:01:06,547 Stage: Train 0.5 | Epoch: 571 | Iter: 347200 | Total Loss: 0.004173 | Recon Loss: 0.003222 | Commit Loss: 0.001903 | Perplexity: 403.728274
2025-10-01 14:04:34,190 Stage: Train 0.5 | Epoch: 571 | Iter: 347400 | Total Loss: 0.004148 | Recon Loss: 0.003206 | Commit Loss: 0.001885 | Perplexity: 403.920846
2025-10-01 14:08:03,745 Stage: Train 0.5 | Epoch: 571 | Iter: 347600 | Total Loss: 0.004180 | Recon Loss: 0.003229 | Commit Loss: 0.001903 | Perplexity: 403.659247
Trainning Epoch:  70%|██████▉   | 572/823 [98:58:52<44:40:17, 640.71s/it]Trainning Epoch:  70%|██████▉   | 572/823 [98:58:52<44:40:19, 640.71s/it]Trainning Epoch:  70%|██████▉   | 572/823 [98:58:52<44:40:21, 640.72s/it]Trainning Epoch:  70%|██████▉   | 572/823 [98:58:52<44:40:20, 640.72s/it]2025-10-01 14:11:41,449 Stage: Train 0.5 | Epoch: 572 | Iter: 347800 | Total Loss: 0.004191 | Recon Loss: 0.003235 | Commit Loss: 0.001912 | Perplexity: 404.177432
2025-10-01 14:15:09,655 Stage: Train 0.5 | Epoch: 572 | Iter: 348000 | Total Loss: 0.004155 | Recon Loss: 0.003210 | Commit Loss: 0.001889 | Perplexity: 404.030718
2025-10-01 14:18:38,035 Stage: Train 0.5 | Epoch: 572 | Iter: 348200 | Total Loss: 0.004165 | Recon Loss: 0.003219 | Commit Loss: 0.001891 | Perplexity: 403.329363
Trainning Epoch:  70%|██████▉   | 573/823 [99:09:30<44:26:55, 640.06s/it]Trainning Epoch:  70%|██████▉   | 573/823 [99:09:30<44:26:55, 640.06s/it]Trainning Epoch:  70%|██████▉   | 573/823 [99:09:31<44:26:56, 640.06s/it]Trainning Epoch:  70%|██████▉   | 573/823 [99:09:31<44:26:55, 640.06s/it]2025-10-01 14:22:10,731 Stage: Train 0.5 | Epoch: 573 | Iter: 348400 | Total Loss: 0.004157 | Recon Loss: 0.003211 | Commit Loss: 0.001892 | Perplexity: 403.341940
2025-10-01 14:25:36,493 Stage: Train 0.5 | Epoch: 573 | Iter: 348600 | Total Loss: 0.004173 | Recon Loss: 0.003223 | Commit Loss: 0.001900 | Perplexity: 404.217140
2025-10-01 14:29:02,044 Stage: Train 0.5 | Epoch: 573 | Iter: 348800 | Total Loss: 0.004170 | Recon Loss: 0.003226 | Commit Loss: 0.001889 | Perplexity: 403.298242
Trainning Epoch:  70%|██████▉   | 574/823 [99:20:02<44:05:22, 637.44s/it]Trainning Epoch:  70%|██████▉   | 574/823 [99:20:02<44:05:20, 637.43s/it]Trainning Epoch:  70%|██████▉   | 574/823 [99:20:02<44:05:22, 637.44s/it]Trainning Epoch:  70%|██████▉   | 574/823 [99:20:02<44:05:21, 637.44s/it]2025-10-01 14:32:34,497 Stage: Train 0.5 | Epoch: 574 | Iter: 349000 | Total Loss: 0.004203 | Recon Loss: 0.003245 | Commit Loss: 0.001915 | Perplexity: 404.032586
2025-10-01 14:36:01,771 Stage: Train 0.5 | Epoch: 574 | Iter: 349200 | Total Loss: 0.004128 | Recon Loss: 0.003186 | Commit Loss: 0.001883 | Perplexity: 403.255524
2025-10-01 14:39:29,790 Stage: Train 0.5 | Epoch: 574 | Iter: 349400 | Total Loss: 0.004180 | Recon Loss: 0.003233 | Commit Loss: 0.001893 | Perplexity: 403.813092
2025-10-01 14:42:56,831 Stage: Train 0.5 | Epoch: 574 | Iter: 349600 | Total Loss: 0.004195 | Recon Loss: 0.003243 | Commit Loss: 0.001905 | Perplexity: 403.899731
Trainning Epoch:  70%|██████▉   | 575/823 [99:30:37<43:52:08, 636.81s/it]Trainning Epoch:  70%|██████▉   | 575/823 [99:30:37<43:52:10, 636.82s/it]Trainning Epoch:  70%|██████▉   | 575/823 [99:30:37<43:52:10, 636.81s/it]Trainning Epoch:  70%|██████▉   | 575/823 [99:30:37<43:52:10, 636.82s/it]2025-10-01 14:46:28,404 Stage: Train 0.5 | Epoch: 575 | Iter: 349800 | Total Loss: 0.004132 | Recon Loss: 0.003190 | Commit Loss: 0.001883 | Perplexity: 402.849737
2025-10-01 14:49:55,702 Stage: Train 0.5 | Epoch: 575 | Iter: 350000 | Total Loss: 0.004168 | Recon Loss: 0.003224 | Commit Loss: 0.001889 | Perplexity: 403.167804
2025-10-01 14:53:24,177 Stage: Train 0.5 | Epoch: 575 | Iter: 350200 | Total Loss: 0.004177 | Recon Loss: 0.003230 | Commit Loss: 0.001895 | Perplexity: 403.599377
Trainning Epoch:  70%|██████▉   | 576/823 [99:41:13<43:39:54, 636.41s/it]Trainning Epoch:  70%|██████▉   | 576/823 [99:41:13<43:39:55, 636.42s/it]Trainning Epoch:  70%|██████▉   | 576/823 [99:41:13<43:39:55, 636.42s/it]Trainning Epoch:  70%|██████▉   | 576/823 [99:41:13<43:39:56, 636.42s/it]2025-10-01 14:56:53,913 Stage: Train 0.5 | Epoch: 576 | Iter: 350400 | Total Loss: 0.004118 | Recon Loss: 0.003184 | Commit Loss: 0.001869 | Perplexity: 402.912047
2025-10-01 15:00:18,985 Stage: Train 0.5 | Epoch: 576 | Iter: 350600 | Total Loss: 0.004143 | Recon Loss: 0.003202 | Commit Loss: 0.001882 | Perplexity: 403.102077
2025-10-01 15:03:45,708 Stage: Train 0.5 | Epoch: 576 | Iter: 350800 | Total Loss: 0.004185 | Recon Loss: 0.003236 | Commit Loss: 0.001897 | Perplexity: 403.169507
Trainning Epoch:  70%|███████   | 577/823 [99:51:42<43:20:56, 634.38s/it]Trainning Epoch:  70%|███████   | 577/823 [99:51:42<43:20:55, 634.37s/it]Trainning Epoch:  70%|███████   | 577/823 [99:51:42<43:20:56, 634.38s/it]Trainning Epoch:  70%|███████   | 577/823 [99:51:42<43:20:56, 634.38s/it]2025-10-01 15:07:13,902 Stage: Train 0.5 | Epoch: 577 | Iter: 351000 | Total Loss: 0.004161 | Recon Loss: 0.003216 | Commit Loss: 0.001890 | Perplexity: 404.293086
2025-10-01 15:10:39,296 Stage: Train 0.5 | Epoch: 577 | Iter: 351200 | Total Loss: 0.004160 | Recon Loss: 0.003213 | Commit Loss: 0.001894 | Perplexity: 403.463111
2025-10-01 15:14:07,120 Stage: Train 0.5 | Epoch: 577 | Iter: 351400 | Total Loss: 0.004175 | Recon Loss: 0.003224 | Commit Loss: 0.001903 | Perplexity: 403.108204
Trainning Epoch:  70%|███████   | 578/823 [100:02:12<43:04:43, 632.99s/it]Trainning Epoch:  70%|███████   | 578/823 [100:02:12<43:04:42, 632.99s/it]Trainning Epoch:  70%|███████   | 578/823 [100:02:12<43:04:43, 632.99s/it]Trainning Epoch:  70%|███████   | 578/823 [100:02:12<43:04:44, 633.00s/it]2025-10-01 15:17:40,102 Stage: Train 0.5 | Epoch: 578 | Iter: 351600 | Total Loss: 0.004148 | Recon Loss: 0.003203 | Commit Loss: 0.001892 | Perplexity: 403.702369
2025-10-01 15:21:09,858 Stage: Train 0.5 | Epoch: 578 | Iter: 351800 | Total Loss: 0.004154 | Recon Loss: 0.003207 | Commit Loss: 0.001893 | Perplexity: 403.674540
2025-10-01 15:24:39,362 Stage: Train 0.5 | Epoch: 578 | Iter: 352000 | Total Loss: 0.004168 | Recon Loss: 0.003219 | Commit Loss: 0.001898 | Perplexity: 402.776726
Trainning Epoch:  70%|███████   | 579/823 [100:12:53<43:03:47, 635.36s/it]Trainning Epoch:  70%|███████   | 579/823 [100:12:53<43:03:47, 635.36s/it]Trainning Epoch:  70%|███████   | 579/823 [100:12:53<43:03:48, 635.36s/it]Trainning Epoch:  70%|███████   | 579/823 [100:12:53<43:03:48, 635.36s/it]2025-10-01 15:28:11,233 Stage: Train 0.5 | Epoch: 579 | Iter: 352200 | Total Loss: 0.004164 | Recon Loss: 0.003215 | Commit Loss: 0.001898 | Perplexity: 404.087510
2025-10-01 15:31:35,222 Stage: Train 0.5 | Epoch: 579 | Iter: 352400 | Total Loss: 0.004135 | Recon Loss: 0.003189 | Commit Loss: 0.001893 | Perplexity: 403.386168
2025-10-01 15:34:57,510 Stage: Train 0.5 | Epoch: 579 | Iter: 352600 | Total Loss: 0.004153 | Recon Loss: 0.003205 | Commit Loss: 0.001896 | Perplexity: 403.265339
Trainning Epoch:  70%|███████   | 580/823 [100:23:18<42:40:54, 632.32s/it]Trainning Epoch:  70%|███████   | 580/823 [100:23:18<42:40:54, 632.32s/it]Trainning Epoch:  70%|███████   | 580/823 [100:23:18<42:40:55, 632.33s/it]Trainning Epoch:  70%|███████   | 580/823 [100:23:18<42:40:55, 632.33s/it]2025-10-01 15:38:24,079 Stage: Train 0.5 | Epoch: 580 | Iter: 352800 | Total Loss: 0.004176 | Recon Loss: 0.003229 | Commit Loss: 0.001892 | Perplexity: 404.067958
2025-10-01 15:41:46,988 Stage: Train 0.5 | Epoch: 580 | Iter: 353000 | Total Loss: 0.004143 | Recon Loss: 0.003202 | Commit Loss: 0.001882 | Perplexity: 403.200247
2025-10-01 15:45:11,117 Stage: Train 0.5 | Epoch: 580 | Iter: 353200 | Total Loss: 0.004173 | Recon Loss: 0.003223 | Commit Loss: 0.001899 | Perplexity: 403.594410
Trainning Epoch:  71%|███████   | 581/823 [100:33:40<42:18:04, 629.28s/it]Trainning Epoch:  71%|███████   | 581/823 [100:33:40<42:18:05, 629.28s/it]Trainning Epoch:  71%|███████   | 581/823 [100:33:40<42:18:04, 629.28s/it]Trainning Epoch:  71%|███████   | 581/823 [100:33:40<42:18:06, 629.28s/it]2025-10-01 15:48:38,464 Stage: Train 0.5 | Epoch: 581 | Iter: 353400 | Total Loss: 0.004151 | Recon Loss: 0.003207 | Commit Loss: 0.001888 | Perplexity: 403.344627
2025-10-01 15:52:01,960 Stage: Train 0.5 | Epoch: 581 | Iter: 353600 | Total Loss: 0.004148 | Recon Loss: 0.003203 | Commit Loss: 0.001889 | Perplexity: 403.572775
2025-10-01 15:55:26,165 Stage: Train 0.5 | Epoch: 581 | Iter: 353800 | Total Loss: 0.004160 | Recon Loss: 0.003215 | Commit Loss: 0.001889 | Perplexity: 403.352462
Trainning Epoch:  71%|███████   | 582/823 [100:44:04<42:00:18, 627.46s/it]Trainning Epoch:  71%|███████   | 582/823 [100:44:04<42:00:18, 627.46s/it]Trainning Epoch:  71%|███████   | 582/823 [100:44:04<42:00:19, 627.47s/it]Trainning Epoch:  71%|███████   | 582/823 [100:44:04<42:00:20, 627.47s/it]2025-10-01 15:58:53,102 Stage: Train 0.5 | Epoch: 582 | Iter: 354000 | Total Loss: 0.004158 | Recon Loss: 0.003212 | Commit Loss: 0.001893 | Perplexity: 404.244087
2025-10-01 16:02:16,717 Stage: Train 0.5 | Epoch: 582 | Iter: 354200 | Total Loss: 0.004148 | Recon Loss: 0.003200 | Commit Loss: 0.001895 | Perplexity: 402.679967
2025-10-01 16:05:40,372 Stage: Train 0.5 | Epoch: 582 | Iter: 354400 | Total Loss: 0.004154 | Recon Loss: 0.003206 | Commit Loss: 0.001895 | Perplexity: 402.655170
Trainning Epoch:  71%|███████   | 583/823 [100:54:26<41:43:27, 625.87s/it]Trainning Epoch:  71%|███████   | 583/823 [100:54:26<41:43:28, 625.87s/it]Trainning Epoch:  71%|███████   | 583/823 [100:54:26<41:43:27, 625.87s/it]Trainning Epoch:  71%|███████   | 583/823 [100:54:26<41:43:27, 625.87s/it]2025-10-01 16:09:06,568 Stage: Train 0.5 | Epoch: 583 | Iter: 354600 | Total Loss: 0.004168 | Recon Loss: 0.003217 | Commit Loss: 0.001903 | Perplexity: 404.306852
2025-10-01 16:12:27,736 Stage: Train 0.5 | Epoch: 583 | Iter: 354800 | Total Loss: 0.004138 | Recon Loss: 0.003196 | Commit Loss: 0.001884 | Perplexity: 403.259106
2025-10-01 16:15:49,659 Stage: Train 0.5 | Epoch: 583 | Iter: 355000 | Total Loss: 0.004175 | Recon Loss: 0.003230 | Commit Loss: 0.001889 | Perplexity: 403.597734
Trainning Epoch:  71%|███████   | 584/823 [101:04:43<41:22:28, 623.22s/it]Trainning Epoch:  71%|███████   | 584/823 [101:04:43<41:22:29, 623.22s/it]Trainning Epoch:  71%|███████   | 584/823 [101:04:43<41:22:29, 623.22s/it]Trainning Epoch:  71%|███████   | 584/823 [101:04:43<41:22:29, 623.22s/it]2025-10-01 16:19:17,224 Stage: Train 0.5 | Epoch: 584 | Iter: 355200 | Total Loss: 0.004140 | Recon Loss: 0.003195 | Commit Loss: 0.001890 | Perplexity: 403.657186
2025-10-01 16:22:42,344 Stage: Train 0.5 | Epoch: 584 | Iter: 355400 | Total Loss: 0.004177 | Recon Loss: 0.003224 | Commit Loss: 0.001907 | Perplexity: 404.417458
2025-10-01 16:26:07,390 Stage: Train 0.5 | Epoch: 584 | Iter: 355600 | Total Loss: 0.004165 | Recon Loss: 0.003219 | Commit Loss: 0.001892 | Perplexity: 403.985480
Trainning Epoch:  71%|███████   | 585/823 [101:15:09<41:16:15, 624.26s/it]Trainning Epoch:  71%|███████   | 585/823 [101:15:09<41:16:16, 624.27s/it]Trainning Epoch:  71%|███████   | 585/823 [101:15:09<41:16:16, 624.27s/it]Trainning Epoch:  71%|███████   | 585/823 [101:15:09<41:16:16, 624.27s/it]2025-10-01 16:29:33,887 Stage: Train 0.5 | Epoch: 585 | Iter: 355800 | Total Loss: 0.004143 | Recon Loss: 0.003204 | Commit Loss: 0.001877 | Perplexity: 403.560749
2025-10-01 16:32:56,293 Stage: Train 0.5 | Epoch: 585 | Iter: 356000 | Total Loss: 0.004159 | Recon Loss: 0.003211 | Commit Loss: 0.001895 | Perplexity: 403.484044
2025-10-01 16:36:18,502 Stage: Train 0.5 | Epoch: 585 | Iter: 356200 | Total Loss: 0.004155 | Recon Loss: 0.003208 | Commit Loss: 0.001893 | Perplexity: 403.677153
Trainning Epoch:  71%|███████   | 586/823 [101:25:28<40:58:57, 622.52s/it]Trainning Epoch:  71%|███████   | 586/823 [101:25:28<40:58:56, 622.52s/it]Trainning Epoch:  71%|███████   | 586/823 [101:25:28<40:58:57, 622.52s/it]Trainning Epoch:  71%|███████   | 586/823 [101:25:28<40:58:57, 622.52s/it]2025-10-01 16:39:44,663 Stage: Train 0.5 | Epoch: 586 | Iter: 356400 | Total Loss: 0.004158 | Recon Loss: 0.003213 | Commit Loss: 0.001890 | Perplexity: 403.776731
2025-10-01 16:43:07,302 Stage: Train 0.5 | Epoch: 586 | Iter: 356600 | Total Loss: 0.004096 | Recon Loss: 0.003155 | Commit Loss: 0.001883 | Perplexity: 402.810294
2025-10-01 16:46:30,167 Stage: Train 0.5 | Epoch: 586 | Iter: 356800 | Total Loss: 0.004165 | Recon Loss: 0.003212 | Commit Loss: 0.001905 | Perplexity: 403.497779
Trainning Epoch:  71%|███████▏  | 587/823 [101:35:48<40:45:39, 621.78s/it]Trainning Epoch:  71%|███████▏  | 587/823 [101:35:48<40:45:38, 621.77s/it]Trainning Epoch:  71%|███████▏  | 587/823 [101:35:48<40:45:39, 621.78s/it]Trainning Epoch:  71%|███████▏  | 587/823 [101:35:48<40:45:39, 621.78s/it]2025-10-01 16:49:56,929 Stage: Train 0.5 | Epoch: 587 | Iter: 357000 | Total Loss: 0.004144 | Recon Loss: 0.003196 | Commit Loss: 0.001895 | Perplexity: 403.818557
2025-10-01 16:53:19,424 Stage: Train 0.5 | Epoch: 587 | Iter: 357200 | Total Loss: 0.004167 | Recon Loss: 0.003209 | Commit Loss: 0.001916 | Perplexity: 404.076303
2025-10-01 16:56:41,037 Stage: Train 0.5 | Epoch: 587 | Iter: 357400 | Total Loss: 0.004141 | Recon Loss: 0.003196 | Commit Loss: 0.001890 | Perplexity: 403.669179
Trainning Epoch:  71%|███████▏  | 588/823 [101:46:06<40:31:27, 620.80s/it]Trainning Epoch:  71%|███████▏  | 588/823 [101:46:06<40:31:28, 620.80s/it]Trainning Epoch:  71%|███████▏  | 588/823 [101:46:06<40:31:27, 620.80s/it]Trainning Epoch:  71%|███████▏  | 588/823 [101:46:06<40:31:27, 620.80s/it]2025-10-01 17:00:07,074 Stage: Train 0.5 | Epoch: 588 | Iter: 357600 | Total Loss: 0.004167 | Recon Loss: 0.003220 | Commit Loss: 0.001895 | Perplexity: 403.712545
2025-10-01 17:03:29,486 Stage: Train 0.5 | Epoch: 588 | Iter: 357800 | Total Loss: 0.004154 | Recon Loss: 0.003209 | Commit Loss: 0.001889 | Perplexity: 403.967862
2025-10-01 17:06:52,448 Stage: Train 0.5 | Epoch: 588 | Iter: 358000 | Total Loss: 0.004132 | Recon Loss: 0.003182 | Commit Loss: 0.001900 | Perplexity: 402.996288
Trainning Epoch:  72%|███████▏  | 589/823 [101:56:26<40:19:40, 620.43s/it]Trainning Epoch:  72%|███████▏  | 589/823 [101:56:26<40:19:40, 620.43s/it]Trainning Epoch:  72%|███████▏  | 589/823 [101:56:26<40:19:41, 620.43s/it]Trainning Epoch:  72%|███████▏  | 589/823 [101:56:26<40:19:42, 620.44s/it]2025-10-01 17:10:19,619 Stage: Train 0.5 | Epoch: 589 | Iter: 358200 | Total Loss: 0.004124 | Recon Loss: 0.003185 | Commit Loss: 0.001878 | Perplexity: 402.771779
2025-10-01 17:13:43,877 Stage: Train 0.5 | Epoch: 589 | Iter: 358400 | Total Loss: 0.004150 | Recon Loss: 0.003203 | Commit Loss: 0.001894 | Perplexity: 403.488564
2025-10-01 17:17:08,924 Stage: Train 0.5 | Epoch: 589 | Iter: 358600 | Total Loss: 0.004157 | Recon Loss: 0.003209 | Commit Loss: 0.001897 | Perplexity: 403.907349
Trainning Epoch:  72%|███████▏  | 590/823 [102:06:52<40:16:09, 622.19s/it]Trainning Epoch:  72%|███████▏  | 590/823 [102:06:52<40:16:10, 622.19s/it]Trainning Epoch:  72%|███████▏  | 590/823 [102:06:52<40:16:11, 622.19s/it]Trainning Epoch:  72%|███████▏  | 590/823 [102:06:52<40:16:10, 622.19s/it]2025-10-01 17:20:37,325 Stage: Train 0.5 | Epoch: 590 | Iter: 358800 | Total Loss: 0.004134 | Recon Loss: 0.003188 | Commit Loss: 0.001893 | Perplexity: 403.298573
2025-10-01 17:24:00,184 Stage: Train 0.5 | Epoch: 590 | Iter: 359000 | Total Loss: 0.004153 | Recon Loss: 0.003209 | Commit Loss: 0.001888 | Perplexity: 403.753194
2025-10-01 17:27:24,170 Stage: Train 0.5 | Epoch: 590 | Iter: 359200 | Total Loss: 0.004163 | Recon Loss: 0.003206 | Commit Loss: 0.001913 | Perplexity: 404.104969
Trainning Epoch:  72%|███████▏  | 591/823 [102:17:15<40:06:03, 622.26s/it]Trainning Epoch:  72%|███████▏  | 591/823 [102:17:15<40:06:04, 622.26s/it]Trainning Epoch:  72%|███████▏  | 591/823 [102:17:15<40:06:03, 622.26s/it]Trainning Epoch:  72%|███████▏  | 591/823 [102:17:15<40:06:04, 622.26s/it]2025-10-01 17:30:50,894 Stage: Train 0.5 | Epoch: 591 | Iter: 359400 | Total Loss: 0.004145 | Recon Loss: 0.003198 | Commit Loss: 0.001893 | Perplexity: 402.856558
2025-10-01 17:34:12,622 Stage: Train 0.5 | Epoch: 591 | Iter: 359600 | Total Loss: 0.004142 | Recon Loss: 0.003196 | Commit Loss: 0.001891 | Perplexity: 403.386555
2025-10-01 17:37:35,356 Stage: Train 0.5 | Epoch: 591 | Iter: 359800 | Total Loss: 0.004144 | Recon Loss: 0.003195 | Commit Loss: 0.001899 | Perplexity: 403.029146
Trainning Epoch:  72%|███████▏  | 592/823 [102:27:34<39:51:40, 621.22s/it]Trainning Epoch:  72%|███████▏  | 592/823 [102:27:34<39:51:42, 621.22s/it]Trainning Epoch:  72%|███████▏  | 592/823 [102:27:34<39:51:41, 621.22s/it]Trainning Epoch:  72%|███████▏  | 592/823 [102:27:34<39:51:41, 621.22s/it]2025-10-01 17:41:02,243 Stage: Train 0.5 | Epoch: 592 | Iter: 360000 | Total Loss: 0.004176 | Recon Loss: 0.003223 | Commit Loss: 0.001907 | Perplexity: 404.246788
2025-10-01 17:41:02,243 Saving model at iteration 360000
2025-10-01 17:41:02,564 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_593_step_360000
2025-10-01 17:41:03,140 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_593_step_360000/model.safetensors
2025-10-01 17:41:03,693 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_593_step_360000/optimizer.bin
2025-10-01 17:41:03,693 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_593_step_360000/scheduler.bin
2025-10-01 17:41:03,693 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_593_step_360000/sampler.bin
2025-10-01 17:41:03,694 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_593_step_360000/random_states_0.pkl
2025-10-01 17:44:27,836 Stage: Train 0.5 | Epoch: 592 | Iter: 360200 | Total Loss: 0.004123 | Recon Loss: 0.003178 | Commit Loss: 0.001890 | Perplexity: 403.750580
2025-10-01 17:47:51,951 Stage: Train 0.5 | Epoch: 592 | Iter: 360400 | Total Loss: 0.004136 | Recon Loss: 0.003193 | Commit Loss: 0.001886 | Perplexity: 402.733864
Trainning Epoch:  72%|███████▏  | 593/823 [102:38:00<39:46:57, 622.68s/it]Trainning Epoch:  72%|███████▏  | 593/823 [102:38:00<39:46:57, 622.69s/it]Trainning Epoch:  72%|███████▏  | 593/823 [102:38:00<39:46:57, 622.69s/it]Trainning Epoch:  72%|███████▏  | 593/823 [102:38:00<39:46:58, 622.69s/it]2025-10-01 17:51:19,744 Stage: Train 0.5 | Epoch: 593 | Iter: 360600 | Total Loss: 0.004143 | Recon Loss: 0.003196 | Commit Loss: 0.001894 | Perplexity: 404.273191
2025-10-01 17:54:42,923 Stage: Train 0.5 | Epoch: 593 | Iter: 360800 | Total Loss: 0.004120 | Recon Loss: 0.003177 | Commit Loss: 0.001886 | Perplexity: 403.636320
2025-10-01 17:58:06,379 Stage: Train 0.5 | Epoch: 593 | Iter: 361000 | Total Loss: 0.004174 | Recon Loss: 0.003225 | Commit Loss: 0.001898 | Perplexity: 404.152084
Trainning Epoch:  72%|███████▏  | 594/823 [102:48:21<39:35:14, 622.33s/it]Trainning Epoch:  72%|███████▏  | 594/823 [102:48:21<39:35:14, 622.33s/it]Trainning Epoch:  72%|███████▏  | 594/823 [102:48:21<39:35:14, 622.33s/it]Trainning Epoch:  72%|███████▏  | 594/823 [102:48:21<39:35:15, 622.34s/it]2025-10-01 18:01:33,307 Stage: Train 0.5 | Epoch: 594 | Iter: 361200 | Total Loss: 0.004135 | Recon Loss: 0.003187 | Commit Loss: 0.001896 | Perplexity: 403.518821
2025-10-01 18:04:56,249 Stage: Train 0.5 | Epoch: 594 | Iter: 361400 | Total Loss: 0.004155 | Recon Loss: 0.003214 | Commit Loss: 0.001883 | Perplexity: 403.159338
2025-10-01 18:08:19,504 Stage: Train 0.5 | Epoch: 594 | Iter: 361600 | Total Loss: 0.004145 | Recon Loss: 0.003200 | Commit Loss: 0.001889 | Perplexity: 403.323643
Trainning Epoch:  72%|███████▏  | 595/823 [102:58:43<39:23:55, 622.09s/it]Trainning Epoch:  72%|███████▏  | 595/823 [102:58:43<39:23:54, 622.08s/it]Trainning Epoch:  72%|███████▏  | 595/823 [102:58:43<39:23:55, 622.08s/it]Trainning Epoch:  72%|███████▏  | 595/823 [102:58:43<39:23:55, 622.09s/it]2025-10-01 18:11:46,801 Stage: Train 0.5 | Epoch: 595 | Iter: 361800 | Total Loss: 0.004157 | Recon Loss: 0.003205 | Commit Loss: 0.001904 | Perplexity: 403.964861
2025-10-01 18:15:07,729 Stage: Train 0.5 | Epoch: 595 | Iter: 362000 | Total Loss: 0.004122 | Recon Loss: 0.003182 | Commit Loss: 0.001879 | Perplexity: 403.169630
2025-10-01 18:18:29,099 Stage: Train 0.5 | Epoch: 595 | Iter: 362200 | Total Loss: 0.004135 | Recon Loss: 0.003188 | Commit Loss: 0.001893 | Perplexity: 403.064740
Trainning Epoch:  72%|███████▏  | 596/823 [103:08:59<39:07:02, 620.37s/it]Trainning Epoch:  72%|███████▏  | 596/823 [103:08:59<39:07:01, 620.36s/it]Trainning Epoch:  72%|███████▏  | 596/823 [103:08:59<39:07:02, 620.36s/it]Trainning Epoch:  72%|███████▏  | 596/823 [103:08:59<39:07:02, 620.37s/it]2025-10-01 18:21:55,255 Stage: Train 0.5 | Epoch: 596 | Iter: 362400 | Total Loss: 0.004118 | Recon Loss: 0.003173 | Commit Loss: 0.001888 | Perplexity: 403.406743
2025-10-01 18:25:19,429 Stage: Train 0.5 | Epoch: 596 | Iter: 362600 | Total Loss: 0.004139 | Recon Loss: 0.003201 | Commit Loss: 0.001875 | Perplexity: 402.776833
2025-10-01 18:28:43,678 Stage: Train 0.5 | Epoch: 596 | Iter: 362800 | Total Loss: 0.004119 | Recon Loss: 0.003170 | Commit Loss: 0.001897 | Perplexity: 403.187750
Trainning Epoch:  73%|███████▎  | 597/823 [103:19:24<39:01:29, 621.64s/it]Trainning Epoch:  73%|███████▎  | 597/823 [103:19:24<39:01:31, 621.64s/it]Trainning Epoch:  73%|███████▎  | 597/823 [103:19:24<39:01:31, 621.64s/it]Trainning Epoch:  73%|███████▎  | 597/823 [103:19:24<39:01:31, 621.65s/it]2025-10-01 18:32:11,442 Stage: Train 0.5 | Epoch: 597 | Iter: 363000 | Total Loss: 0.004176 | Recon Loss: 0.003226 | Commit Loss: 0.001900 | Perplexity: 403.200023
2025-10-01 18:35:35,557 Stage: Train 0.5 | Epoch: 597 | Iter: 363200 | Total Loss: 0.004118 | Recon Loss: 0.003176 | Commit Loss: 0.001884 | Perplexity: 403.642484
2025-10-01 18:39:00,448 Stage: Train 0.5 | Epoch: 597 | Iter: 363400 | Total Loss: 0.004157 | Recon Loss: 0.003208 | Commit Loss: 0.001897 | Perplexity: 404.087062
Trainning Epoch:  73%|███████▎  | 598/823 [103:29:49<38:55:53, 622.90s/it]Trainning Epoch:  73%|███████▎  | 598/823 [103:29:50<38:55:54, 622.91s/it]Trainning Epoch:  73%|███████▎  | 598/823 [103:29:50<38:55:54, 622.91s/it]Trainning Epoch:  73%|███████▎  | 598/823 [103:29:50<38:55:55, 622.91s/it]2025-10-01 18:42:29,676 Stage: Train 0.5 | Epoch: 598 | Iter: 363600 | Total Loss: 0.004137 | Recon Loss: 0.003187 | Commit Loss: 0.001899 | Perplexity: 403.646774
2025-10-01 18:45:52,897 Stage: Train 0.5 | Epoch: 598 | Iter: 363800 | Total Loss: 0.004131 | Recon Loss: 0.003188 | Commit Loss: 0.001886 | Perplexity: 403.397679
2025-10-01 18:49:16,579 Stage: Train 0.5 | Epoch: 598 | Iter: 364000 | Total Loss: 0.004122 | Recon Loss: 0.003174 | Commit Loss: 0.001897 | Perplexity: 404.022245
Trainning Epoch:  73%|███████▎  | 599/823 [103:40:12<38:45:04, 622.79s/it]Trainning Epoch:  73%|███████▎  | 599/823 [103:40:12<38:45:06, 622.80s/it]Trainning Epoch:  73%|███████▎  | 599/823 [103:40:12<38:45:05, 622.79s/it]Trainning Epoch:  73%|███████▎  | 599/823 [103:40:12<38:45:05, 622.79s/it]2025-10-01 18:52:43,886 Stage: Train 0.5 | Epoch: 599 | Iter: 364200 | Total Loss: 0.004142 | Recon Loss: 0.003195 | Commit Loss: 0.001893 | Perplexity: 403.780947
2025-10-01 18:56:05,842 Stage: Train 0.5 | Epoch: 599 | Iter: 364400 | Total Loss: 0.004111 | Recon Loss: 0.003170 | Commit Loss: 0.001883 | Perplexity: 403.717325
2025-10-01 18:59:28,082 Stage: Train 0.5 | Epoch: 599 | Iter: 364600 | Total Loss: 0.004146 | Recon Loss: 0.003194 | Commit Loss: 0.001904 | Perplexity: 403.576768
2025-10-01 19:02:50,987 Stage: Train 0.5 | Epoch: 599 | Iter: 364800 | Total Loss: 0.004148 | Recon Loss: 0.003203 | Commit Loss: 0.001889 | Perplexity: 403.050984
Trainning Epoch:  73%|███████▎  | 600/823 [103:50:31<38:30:47, 621.74s/it]Trainning Epoch:  73%|███████▎  | 600/823 [103:50:31<38:30:46, 621.73s/it]Trainning Epoch:  73%|███████▎  | 600/823 [103:50:31<38:30:48, 621.74s/it]Trainning Epoch:  73%|███████▎  | 600/823 [103:50:31<38:30:48, 621.74s/it]2025-10-01 19:06:17,492 Stage: Train 0.5 | Epoch: 600 | Iter: 365000 | Total Loss: 0.004112 | Recon Loss: 0.003170 | Commit Loss: 0.001883 | Perplexity: 403.175038
2025-10-01 19:09:39,710 Stage: Train 0.5 | Epoch: 600 | Iter: 365200 | Total Loss: 0.004148 | Recon Loss: 0.003191 | Commit Loss: 0.001914 | Perplexity: 403.773075
2025-10-01 19:13:02,626 Stage: Train 0.5 | Epoch: 600 | Iter: 365400 | Total Loss: 0.004127 | Recon Loss: 0.003188 | Commit Loss: 0.001878 | Perplexity: 403.419848
Trainning Epoch:  73%|███████▎  | 601/823 [104:00:51<38:18:16, 621.16s/it]Trainning Epoch:  73%|███████▎  | 601/823 [104:00:51<38:18:16, 621.16s/it]Trainning Epoch:  73%|███████▎  | 601/823 [104:00:51<38:18:17, 621.16s/it]Trainning Epoch:  73%|███████▎  | 601/823 [104:00:51<38:18:18, 621.17s/it]2025-10-01 19:16:28,356 Stage: Train 0.5 | Epoch: 601 | Iter: 365600 | Total Loss: 0.004138 | Recon Loss: 0.003189 | Commit Loss: 0.001898 | Perplexity: 404.410521
2025-10-01 19:19:50,076 Stage: Train 0.5 | Epoch: 601 | Iter: 365800 | Total Loss: 0.004156 | Recon Loss: 0.003215 | Commit Loss: 0.001883 | Perplexity: 403.741042
2025-10-01 19:23:12,827 Stage: Train 0.5 | Epoch: 601 | Iter: 366000 | Total Loss: 0.004151 | Recon Loss: 0.003200 | Commit Loss: 0.001902 | Perplexity: 404.046235
Trainning Epoch:  73%|███████▎  | 602/823 [104:11:09<38:04:31, 620.23s/it]Trainning Epoch:  73%|███████▎  | 602/823 [104:11:09<38:04:33, 620.24s/it]Trainning Epoch:  73%|███████▎  | 602/823 [104:11:09<38:04:32, 620.24s/it]Trainning Epoch:  73%|███████▎  | 602/823 [104:11:09<38:04:32, 620.24s/it]2025-10-01 19:26:39,508 Stage: Train 0.5 | Epoch: 602 | Iter: 366200 | Total Loss: 0.004116 | Recon Loss: 0.003174 | Commit Loss: 0.001882 | Perplexity: 403.595587
2025-10-01 19:30:02,828 Stage: Train 0.5 | Epoch: 602 | Iter: 366400 | Total Loss: 0.004157 | Recon Loss: 0.003206 | Commit Loss: 0.001901 | Perplexity: 403.802256
2025-10-01 19:33:25,710 Stage: Train 0.5 | Epoch: 602 | Iter: 366600 | Total Loss: 0.004131 | Recon Loss: 0.003185 | Commit Loss: 0.001893 | Perplexity: 403.760180
Trainning Epoch:  73%|███████▎  | 603/823 [104:21:30<37:55:07, 620.49s/it]Trainning Epoch:  73%|███████▎  | 603/823 [104:21:30<37:55:09, 620.50s/it]Trainning Epoch:  73%|███████▎  | 603/823 [104:21:30<37:55:09, 620.50s/it]Trainning Epoch:  73%|███████▎  | 603/823 [104:21:30<37:55:10, 620.50s/it]2025-10-01 19:36:51,356 Stage: Train 0.5 | Epoch: 603 | Iter: 366800 | Total Loss: 0.004092 | Recon Loss: 0.003152 | Commit Loss: 0.001880 | Perplexity: 402.553047
2025-10-01 19:40:14,115 Stage: Train 0.5 | Epoch: 603 | Iter: 367000 | Total Loss: 0.004126 | Recon Loss: 0.003178 | Commit Loss: 0.001896 | Perplexity: 404.563189
2025-10-01 19:43:37,305 Stage: Train 0.5 | Epoch: 603 | Iter: 367200 | Total Loss: 0.004125 | Recon Loss: 0.003182 | Commit Loss: 0.001887 | Perplexity: 403.642893
Trainning Epoch:  73%|███████▎  | 604/823 [104:31:50<37:43:54, 620.25s/it]Trainning Epoch:  73%|███████▎  | 604/823 [104:31:50<37:43:52, 620.24s/it]Trainning Epoch:  73%|███████▎  | 604/823 [104:31:50<37:43:53, 620.25s/it]Trainning Epoch:  73%|███████▎  | 604/823 [104:31:50<37:43:53, 620.25s/it]2025-10-01 19:47:04,912 Stage: Train 0.5 | Epoch: 604 | Iter: 367400 | Total Loss: 0.004097 | Recon Loss: 0.003157 | Commit Loss: 0.001880 | Perplexity: 402.644785
2025-10-01 19:50:29,468 Stage: Train 0.5 | Epoch: 604 | Iter: 367600 | Total Loss: 0.004123 | Recon Loss: 0.003180 | Commit Loss: 0.001888 | Perplexity: 403.674273
2025-10-01 19:53:52,756 Stage: Train 0.5 | Epoch: 604 | Iter: 367800 | Total Loss: 0.004126 | Recon Loss: 0.003173 | Commit Loss: 0.001906 | Perplexity: 402.997536
Trainning Epoch:  74%|███████▎  | 605/823 [104:42:14<37:37:16, 621.27s/it]Trainning Epoch:  74%|███████▎  | 605/823 [104:42:14<37:37:16, 621.27s/it]Trainning Epoch:  74%|███████▎  | 605/823 [104:42:14<37:37:16, 621.27s/it]Trainning Epoch:  74%|███████▎  | 605/823 [104:42:14<37:37:17, 621.27s/it]2025-10-01 19:57:20,564 Stage: Train 0.5 | Epoch: 605 | Iter: 368000 | Total Loss: 0.004129 | Recon Loss: 0.003180 | Commit Loss: 0.001899 | Perplexity: 403.974310
2025-10-01 20:00:44,104 Stage: Train 0.5 | Epoch: 605 | Iter: 368200 | Total Loss: 0.004133 | Recon Loss: 0.003190 | Commit Loss: 0.001886 | Perplexity: 403.536136
2025-10-01 20:04:07,689 Stage: Train 0.5 | Epoch: 605 | Iter: 368400 | Total Loss: 0.004126 | Recon Loss: 0.003181 | Commit Loss: 0.001891 | Perplexity: 403.224981
Trainning Epoch:  74%|███████▎  | 606/823 [104:52:37<37:29:02, 621.86s/it]Trainning Epoch:  74%|███████▎  | 606/823 [104:52:37<37:29:00, 621.85s/it]Trainning Epoch:  74%|███████▎  | 606/823 [104:52:37<37:29:01, 621.85s/it]Trainning Epoch:  74%|███████▎  | 606/823 [104:52:37<37:29:01, 621.85s/it]2025-10-01 20:07:34,332 Stage: Train 0.5 | Epoch: 606 | Iter: 368600 | Total Loss: 0.004100 | Recon Loss: 0.003161 | Commit Loss: 0.001879 | Perplexity: 403.118130
2025-10-01 20:10:56,944 Stage: Train 0.5 | Epoch: 606 | Iter: 368800 | Total Loss: 0.004109 | Recon Loss: 0.003166 | Commit Loss: 0.001887 | Perplexity: 404.084961
2025-10-01 20:14:20,491 Stage: Train 0.5 | Epoch: 606 | Iter: 369000 | Total Loss: 0.004144 | Recon Loss: 0.003188 | Commit Loss: 0.001913 | Perplexity: 404.373253
Trainning Epoch:  74%|███████▍  | 607/823 [105:02:58<37:17:40, 621.58s/it]Trainning Epoch:  74%|███████▍  | 607/823 [105:02:58<37:17:42, 621.58s/it]Trainning Epoch:  74%|███████▍  | 607/823 [105:02:58<37:17:41, 621.58s/it]Trainning Epoch:  74%|███████▍  | 607/823 [105:02:58<37:17:41, 621.58s/it]2025-10-01 20:17:46,446 Stage: Train 0.5 | Epoch: 607 | Iter: 369200 | Total Loss: 0.004120 | Recon Loss: 0.003178 | Commit Loss: 0.001883 | Perplexity: 403.003170
2025-10-01 20:21:07,701 Stage: Train 0.5 | Epoch: 607 | Iter: 369400 | Total Loss: 0.004124 | Recon Loss: 0.003180 | Commit Loss: 0.001887 | Perplexity: 403.981777
2025-10-01 20:24:29,261 Stage: Train 0.5 | Epoch: 607 | Iter: 369600 | Total Loss: 0.004135 | Recon Loss: 0.003182 | Commit Loss: 0.001905 | Perplexity: 403.590723
Trainning Epoch:  74%|███████▍  | 608/823 [105:13:14<37:01:30, 619.96s/it]Trainning Epoch:  74%|███████▍  | 608/823 [105:13:14<37:01:30, 619.95s/it]Trainning Epoch:  74%|███████▍  | 608/823 [105:13:14<37:01:30, 619.96s/it]Trainning Epoch:  74%|███████▍  | 608/823 [105:13:14<37:01:30, 619.96s/it]2025-10-01 20:27:55,207 Stage: Train 0.5 | Epoch: 608 | Iter: 369800 | Total Loss: 0.004126 | Recon Loss: 0.003176 | Commit Loss: 0.001899 | Perplexity: 403.420900
2025-10-01 20:31:17,782 Stage: Train 0.5 | Epoch: 608 | Iter: 370000 | Total Loss: 0.004112 | Recon Loss: 0.003168 | Commit Loss: 0.001888 | Perplexity: 403.262386
2025-10-01 20:34:41,041 Stage: Train 0.5 | Epoch: 608 | Iter: 370200 | Total Loss: 0.004113 | Recon Loss: 0.003167 | Commit Loss: 0.001891 | Perplexity: 403.161139
Trainning Epoch:  74%|███████▍  | 609/823 [105:23:34<36:51:30, 620.05s/it]Trainning Epoch:  74%|███████▍  | 609/823 [105:23:34<36:51:31, 620.05s/it]Trainning Epoch:  74%|███████▍  | 609/823 [105:23:34<36:51:31, 620.05s/it]Trainning Epoch:  74%|███████▍  | 609/823 [105:23:34<36:51:32, 620.06s/it]2025-10-01 20:38:07,113 Stage: Train 0.5 | Epoch: 609 | Iter: 370400 | Total Loss: 0.004097 | Recon Loss: 0.003161 | Commit Loss: 0.001871 | Perplexity: 402.921876
2025-10-01 20:41:30,949 Stage: Train 0.5 | Epoch: 609 | Iter: 370600 | Total Loss: 0.004102 | Recon Loss: 0.003161 | Commit Loss: 0.001882 | Perplexity: 403.294686
2025-10-01 20:44:55,207 Stage: Train 0.5 | Epoch: 609 | Iter: 370800 | Total Loss: 0.004101 | Recon Loss: 0.003157 | Commit Loss: 0.001887 | Perplexity: 403.521420
Trainning Epoch:  74%|███████▍  | 610/823 [105:33:57<36:44:10, 620.89s/it]Trainning Epoch:  74%|███████▍  | 610/823 [105:33:57<36:44:09, 620.89s/it]Trainning Epoch:  74%|███████▍  | 610/823 [105:33:57<36:44:09, 620.89s/it]Trainning Epoch:  74%|███████▍  | 610/823 [105:33:57<36:44:10, 620.89s/it]2025-10-01 20:48:21,628 Stage: Train 0.5 | Epoch: 610 | Iter: 371000 | Total Loss: 0.004123 | Recon Loss: 0.003179 | Commit Loss: 0.001889 | Perplexity: 403.291662
2025-10-01 20:51:44,530 Stage: Train 0.5 | Epoch: 610 | Iter: 371200 | Total Loss: 0.004102 | Recon Loss: 0.003161 | Commit Loss: 0.001883 | Perplexity: 402.636365
2025-10-01 20:55:07,660 Stage: Train 0.5 | Epoch: 610 | Iter: 371400 | Total Loss: 0.004123 | Recon Loss: 0.003171 | Commit Loss: 0.001904 | Perplexity: 403.592725
Trainning Epoch:  74%|███████▍  | 611/823 [105:44:17<36:33:10, 620.71s/it]Trainning Epoch:  74%|███████▍  | 611/823 [105:44:17<36:33:12, 620.72s/it]Trainning Epoch:  74%|███████▍  | 611/823 [105:44:17<36:33:13, 620.72s/it]Trainning Epoch:  74%|███████▍  | 611/823 [105:44:17<36:33:13, 620.72s/it]2025-10-01 20:58:34,975 Stage: Train 0.5 | Epoch: 611 | Iter: 371600 | Total Loss: 0.004111 | Recon Loss: 0.003166 | Commit Loss: 0.001890 | Perplexity: 403.133198
2025-10-01 21:01:58,141 Stage: Train 0.5 | Epoch: 611 | Iter: 371800 | Total Loss: 0.004122 | Recon Loss: 0.003172 | Commit Loss: 0.001900 | Perplexity: 403.606389
2025-10-01 21:05:20,597 Stage: Train 0.5 | Epoch: 611 | Iter: 372000 | Total Loss: 0.004118 | Recon Loss: 0.003174 | Commit Loss: 0.001889 | Perplexity: 403.101755
Trainning Epoch:  74%|███████▍  | 612/823 [105:54:38<36:23:08, 620.80s/it]Trainning Epoch:  74%|███████▍  | 612/823 [105:54:38<36:23:07, 620.79s/it]Trainning Epoch:  74%|███████▍  | 612/823 [105:54:38<36:23:08, 620.80s/it]Trainning Epoch:  74%|███████▍  | 612/823 [105:54:38<36:23:09, 620.80s/it]2025-10-01 21:08:47,358 Stage: Train 0.5 | Epoch: 612 | Iter: 372200 | Total Loss: 0.004096 | Recon Loss: 0.003150 | Commit Loss: 0.001893 | Perplexity: 403.716450
2025-10-01 21:12:09,882 Stage: Train 0.5 | Epoch: 612 | Iter: 372400 | Total Loss: 0.004097 | Recon Loss: 0.003154 | Commit Loss: 0.001887 | Perplexity: 403.523587
2025-10-01 21:15:32,928 Stage: Train 0.5 | Epoch: 612 | Iter: 372600 | Total Loss: 0.004110 | Recon Loss: 0.003163 | Commit Loss: 0.001893 | Perplexity: 403.610019
Trainning Epoch:  74%|███████▍  | 613/823 [106:04:59<36:12:31, 620.72s/it]Trainning Epoch:  74%|███████▍  | 613/823 [106:04:59<36:12:30, 620.72s/it]Trainning Epoch:  74%|███████▍  | 613/823 [106:04:59<36:12:31, 620.72s/it]Trainning Epoch:  74%|███████▍  | 613/823 [106:04:59<36:12:31, 620.72s/it]2025-10-01 21:18:59,316 Stage: Train 0.5 | Epoch: 613 | Iter: 372800 | Total Loss: 0.004117 | Recon Loss: 0.003176 | Commit Loss: 0.001883 | Perplexity: 402.593558
2025-10-01 21:22:20,871 Stage: Train 0.5 | Epoch: 613 | Iter: 373000 | Total Loss: 0.004097 | Recon Loss: 0.003155 | Commit Loss: 0.001884 | Perplexity: 403.924761
2025-10-01 21:25:42,206 Stage: Train 0.5 | Epoch: 613 | Iter: 373200 | Total Loss: 0.004097 | Recon Loss: 0.003152 | Commit Loss: 0.001889 | Perplexity: 403.094544
Trainning Epoch:  75%|███████▍  | 614/823 [106:15:15<35:57:39, 619.42s/it]Trainning Epoch:  75%|███████▍  | 614/823 [106:15:15<35:57:39, 619.42s/it]Trainning Epoch:  75%|███████▍  | 614/823 [106:15:15<35:57:40, 619.43s/it]Trainning Epoch:  75%|███████▍  | 614/823 [106:15:15<35:57:40, 619.43s/it]2025-10-01 21:29:07,944 Stage: Train 0.5 | Epoch: 614 | Iter: 373400 | Total Loss: 0.004118 | Recon Loss: 0.003172 | Commit Loss: 0.001891 | Perplexity: 403.768313
2025-10-01 21:32:29,878 Stage: Train 0.5 | Epoch: 614 | Iter: 373600 | Total Loss: 0.004105 | Recon Loss: 0.003160 | Commit Loss: 0.001890 | Perplexity: 403.177323
2025-10-01 21:35:52,068 Stage: Train 0.5 | Epoch: 614 | Iter: 373800 | Total Loss: 0.004122 | Recon Loss: 0.003177 | Commit Loss: 0.001889 | Perplexity: 403.591553
Trainning Epoch:  75%|███████▍  | 615/823 [106:25:34<35:46:11, 619.09s/it]Trainning Epoch:  75%|███████▍  | 615/823 [106:25:34<35:46:11, 619.09s/it]Trainning Epoch:  75%|███████▍  | 615/823 [106:25:34<35:46:10, 619.09s/it]Trainning Epoch:  75%|███████▍  | 615/823 [106:25:34<35:46:11, 619.09s/it]2025-10-01 21:39:18,880 Stage: Train 0.5 | Epoch: 615 | Iter: 374000 | Total Loss: 0.004105 | Recon Loss: 0.003162 | Commit Loss: 0.001885 | Perplexity: 403.258585
2025-10-01 21:42:41,999 Stage: Train 0.5 | Epoch: 615 | Iter: 374200 | Total Loss: 0.004128 | Recon Loss: 0.003177 | Commit Loss: 0.001902 | Perplexity: 404.080121
2025-10-01 21:46:05,583 Stage: Train 0.5 | Epoch: 615 | Iter: 374400 | Total Loss: 0.004117 | Recon Loss: 0.003168 | Commit Loss: 0.001898 | Perplexity: 403.573835
Trainning Epoch:  75%|███████▍  | 616/823 [106:35:56<35:39:08, 620.04s/it]Trainning Epoch:  75%|███████▍  | 616/823 [106:35:56<35:39:08, 620.04s/it]Trainning Epoch:  75%|███████▍  | 616/823 [106:35:56<35:39:08, 620.04s/it]Trainning Epoch:  75%|███████▍  | 616/823 [106:35:56<35:39:08, 620.04s/it]2025-10-01 21:49:32,870 Stage: Train 0.5 | Epoch: 616 | Iter: 374600 | Total Loss: 0.004107 | Recon Loss: 0.003167 | Commit Loss: 0.001880 | Perplexity: 403.221136
2025-10-01 21:52:55,598 Stage: Train 0.5 | Epoch: 616 | Iter: 374800 | Total Loss: 0.004102 | Recon Loss: 0.003158 | Commit Loss: 0.001887 | Perplexity: 403.895556
2025-10-01 21:56:18,378 Stage: Train 0.5 | Epoch: 616 | Iter: 375000 | Total Loss: 0.004132 | Recon Loss: 0.003186 | Commit Loss: 0.001891 | Perplexity: 403.214420
Trainning Epoch:  75%|███████▍  | 617/823 [106:46:17<35:30:20, 620.49s/it]Trainning Epoch:  75%|███████▍  | 617/823 [106:46:17<35:30:21, 620.49s/it]Trainning Epoch:  75%|███████▍  | 617/823 [106:46:17<35:30:22, 620.50s/it]Trainning Epoch:  75%|███████▍  | 617/823 [106:46:17<35:30:21, 620.49s/it]2025-10-01 21:59:45,547 Stage: Train 0.5 | Epoch: 617 | Iter: 375200 | Total Loss: 0.004078 | Recon Loss: 0.003137 | Commit Loss: 0.001881 | Perplexity: 403.921376
2025-10-01 22:03:07,294 Stage: Train 0.5 | Epoch: 617 | Iter: 375400 | Total Loss: 0.004100 | Recon Loss: 0.003160 | Commit Loss: 0.001880 | Perplexity: 403.562108
2025-10-01 22:06:29,792 Stage: Train 0.5 | Epoch: 617 | Iter: 375600 | Total Loss: 0.004121 | Recon Loss: 0.003177 | Commit Loss: 0.001889 | Perplexity: 403.686935
Trainning Epoch:  75%|███████▌  | 618/823 [106:56:36<35:18:14, 619.97s/it]Trainning Epoch:  75%|███████▌  | 618/823 [106:56:36<35:18:15, 619.98s/it]Trainning Epoch:  75%|███████▌  | 618/823 [106:56:36<35:18:15, 619.98s/it]Trainning Epoch:  75%|███████▌  | 618/823 [106:56:36<35:18:16, 619.98s/it]2025-10-01 22:09:56,588 Stage: Train 0.5 | Epoch: 618 | Iter: 375800 | Total Loss: 0.004122 | Recon Loss: 0.003171 | Commit Loss: 0.001902 | Perplexity: 403.933092
2025-10-01 22:13:20,797 Stage: Train 0.5 | Epoch: 618 | Iter: 376000 | Total Loss: 0.004119 | Recon Loss: 0.003174 | Commit Loss: 0.001891 | Perplexity: 404.232835
2025-10-01 22:16:45,640 Stage: Train 0.5 | Epoch: 618 | Iter: 376200 | Total Loss: 0.004114 | Recon Loss: 0.003165 | Commit Loss: 0.001899 | Perplexity: 403.498794
Trainning Epoch:  75%|███████▌  | 619/823 [107:07:02<35:13:37, 621.65s/it]Trainning Epoch:  75%|███████▌  | 619/823 [107:07:02<35:13:39, 621.67s/it]Trainning Epoch:  75%|███████▌  | 619/823 [107:07:02<35:13:40, 621.67s/it]Trainning Epoch:  75%|███████▌  | 619/823 [107:07:02<35:13:40, 621.67s/it]2025-10-01 22:20:14,733 Stage: Train 0.5 | Epoch: 619 | Iter: 376400 | Total Loss: 0.004085 | Recon Loss: 0.003142 | Commit Loss: 0.001886 | Perplexity: 402.781569
2025-10-01 22:23:38,444 Stage: Train 0.5 | Epoch: 619 | Iter: 376600 | Total Loss: 0.004110 | Recon Loss: 0.003162 | Commit Loss: 0.001896 | Perplexity: 404.317890
2025-10-01 22:27:02,040 Stage: Train 0.5 | Epoch: 619 | Iter: 376800 | Total Loss: 0.004086 | Recon Loss: 0.003147 | Commit Loss: 0.001880 | Perplexity: 402.950990
Trainning Epoch:  75%|███████▌  | 620/823 [107:17:25<35:05:17, 622.25s/it]Trainning Epoch:  75%|███████▌  | 620/823 [107:17:25<35:05:19, 622.26s/it]Trainning Epoch:  75%|███████▌  | 620/823 [107:17:25<35:05:18, 622.26s/it]Trainning Epoch:  75%|███████▌  | 620/823 [107:17:25<35:05:18, 622.26s/it]2025-10-01 22:30:29,928 Stage: Train 0.5 | Epoch: 620 | Iter: 377000 | Total Loss: 0.004108 | Recon Loss: 0.003165 | Commit Loss: 0.001887 | Perplexity: 403.363230
2025-10-01 22:33:53,128 Stage: Train 0.5 | Epoch: 620 | Iter: 377200 | Total Loss: 0.004078 | Recon Loss: 0.003138 | Commit Loss: 0.001879 | Perplexity: 403.295077
2025-10-01 22:37:16,908 Stage: Train 0.5 | Epoch: 620 | Iter: 377400 | Total Loss: 0.004095 | Recon Loss: 0.003147 | Commit Loss: 0.001896 | Perplexity: 403.355230
Trainning Epoch:  75%|███████▌  | 621/823 [107:27:49<34:56:04, 622.60s/it]Trainning Epoch:  75%|███████▌  | 621/823 [107:27:49<34:56:05, 622.60s/it]Trainning Epoch:  75%|███████▌  | 621/823 [107:27:49<34:56:05, 622.60s/it]Trainning Epoch:  75%|███████▌  | 621/823 [107:27:49<34:56:05, 622.60s/it]2025-10-01 22:40:44,791 Stage: Train 0.5 | Epoch: 621 | Iter: 377600 | Total Loss: 0.004128 | Recon Loss: 0.003175 | Commit Loss: 0.001907 | Perplexity: 403.716025
2025-10-01 22:44:08,020 Stage: Train 0.5 | Epoch: 621 | Iter: 377800 | Total Loss: 0.004125 | Recon Loss: 0.003181 | Commit Loss: 0.001888 | Perplexity: 403.441455
2025-10-01 22:47:31,134 Stage: Train 0.5 | Epoch: 621 | Iter: 378000 | Total Loss: 0.004110 | Recon Loss: 0.003164 | Commit Loss: 0.001892 | Perplexity: 403.691834
Trainning Epoch:  76%|███████▌  | 622/823 [107:38:10<34:44:33, 622.26s/it]Trainning Epoch:  76%|███████▌  | 622/823 [107:38:10<34:44:35, 622.27s/it]Trainning Epoch:  76%|███████▌  | 622/823 [107:38:10<34:44:35, 622.26s/it]Trainning Epoch:  76%|███████▌  | 622/823 [107:38:10<34:44:35, 622.27s/it]2025-10-01 22:50:57,982 Stage: Train 0.5 | Epoch: 622 | Iter: 378200 | Total Loss: 0.004101 | Recon Loss: 0.003157 | Commit Loss: 0.001889 | Perplexity: 403.636706
2025-10-01 22:54:20,087 Stage: Train 0.5 | Epoch: 622 | Iter: 378400 | Total Loss: 0.004121 | Recon Loss: 0.003173 | Commit Loss: 0.001896 | Perplexity: 404.449351
2025-10-01 22:57:42,538 Stage: Train 0.5 | Epoch: 622 | Iter: 378600 | Total Loss: 0.004091 | Recon Loss: 0.003147 | Commit Loss: 0.001889 | Perplexity: 403.901487
Trainning Epoch:  76%|███████▌  | 623/823 [107:48:29<34:31:00, 621.30s/it]Trainning Epoch:  76%|███████▌  | 623/823 [107:48:29<34:30:59, 621.30s/it]Trainning Epoch:  76%|███████▌  | 623/823 [107:48:29<34:31:00, 621.30s/it]Trainning Epoch:  76%|███████▌  | 623/823 [107:48:29<34:31:00, 621.30s/it]2025-10-01 23:01:09,023 Stage: Train 0.5 | Epoch: 623 | Iter: 378800 | Total Loss: 0.004118 | Recon Loss: 0.003167 | Commit Loss: 0.001902 | Perplexity: 403.432066
2025-10-01 23:04:32,365 Stage: Train 0.5 | Epoch: 623 | Iter: 379000 | Total Loss: 0.004066 | Recon Loss: 0.003132 | Commit Loss: 0.001868 | Perplexity: 402.416436
2025-10-01 23:07:55,356 Stage: Train 0.5 | Epoch: 623 | Iter: 379200 | Total Loss: 0.004115 | Recon Loss: 0.003165 | Commit Loss: 0.001899 | Perplexity: 403.508611
Trainning Epoch:  76%|███████▌  | 624/823 [107:58:50<34:20:13, 621.17s/it]Trainning Epoch:  76%|███████▌  | 624/823 [107:58:50<34:20:14, 621.18s/it]Trainning Epoch:  76%|███████▌  | 624/823 [107:58:50<34:20:14, 621.18s/it]Trainning Epoch:  76%|███████▌  | 624/823 [107:58:50<34:20:14, 621.18s/it]2025-10-01 23:11:22,297 Stage: Train 0.5 | Epoch: 624 | Iter: 379400 | Total Loss: 0.004111 | Recon Loss: 0.003162 | Commit Loss: 0.001897 | Perplexity: 403.282247
2025-10-01 23:14:45,126 Stage: Train 0.5 | Epoch: 624 | Iter: 379600 | Total Loss: 0.004083 | Recon Loss: 0.003142 | Commit Loss: 0.001883 | Perplexity: 403.325065
2025-10-01 23:18:09,072 Stage: Train 0.5 | Epoch: 624 | Iter: 379800 | Total Loss: 0.004083 | Recon Loss: 0.003138 | Commit Loss: 0.001890 | Perplexity: 402.793569
2025-10-01 23:21:33,245 Stage: Train 0.5 | Epoch: 624 | Iter: 380000 | Total Loss: 0.004120 | Recon Loss: 0.003174 | Commit Loss: 0.001893 | Perplexity: 403.415010
2025-10-01 23:21:33,245 Saving model at iteration 380000
2025-10-01 23:21:33,523 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_625_step_380000
Trainning Epoch:  76%|███████▌  | 625/823 [108:09:14<34:12:15, 621.90s/it]Trainning Epoch:  76%|███████▌  | 625/823 [108:09:14<34:12:15, 621.90s/it]Trainning Epoch:  76%|███████▌  | 625/823 [108:09:14<34:12:15, 621.90s/it]2025-10-01 23:21:34,117 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_625_step_380000/model.safetensors
2025-10-01 23:21:34,743 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_625_step_380000/optimizer.bin
2025-10-01 23:21:34,744 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_625_step_380000/scheduler.bin
2025-10-01 23:21:34,744 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_625_step_380000/sampler.bin
2025-10-01 23:21:34,745 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_625_step_380000/random_states_0.pkl
Trainning Epoch:  76%|███████▌  | 625/823 [108:09:15<34:13:26, 622.26s/it]2025-10-01 23:25:02,748 Stage: Train 0.5 | Epoch: 625 | Iter: 380200 | Total Loss: 0.004090 | Recon Loss: 0.003144 | Commit Loss: 0.001891 | Perplexity: 403.119252
2025-10-01 23:28:27,546 Stage: Train 0.5 | Epoch: 625 | Iter: 380400 | Total Loss: 0.004087 | Recon Loss: 0.003138 | Commit Loss: 0.001899 | Perplexity: 403.518662
2025-10-01 23:31:52,273 Stage: Train 0.5 | Epoch: 625 | Iter: 380600 | Total Loss: 0.004118 | Recon Loss: 0.003167 | Commit Loss: 0.001903 | Perplexity: 403.153940
Trainning Epoch:  76%|███████▌  | 626/823 [108:19:41<34:06:49, 623.40s/it]Trainning Epoch:  76%|███████▌  | 626/823 [108:19:41<34:06:27, 623.29s/it]Trainning Epoch:  76%|███████▌  | 626/823 [108:19:41<34:06:49, 623.40s/it]Trainning Epoch:  76%|███████▌  | 626/823 [108:19:41<34:06:49, 623.40s/it]2025-10-01 23:35:18,459 Stage: Train 0.5 | Epoch: 626 | Iter: 380800 | Total Loss: 0.004114 | Recon Loss: 0.003165 | Commit Loss: 0.001898 | Perplexity: 404.515438
2025-10-01 23:38:42,263 Stage: Train 0.5 | Epoch: 626 | Iter: 381000 | Total Loss: 0.004073 | Recon Loss: 0.003129 | Commit Loss: 0.001888 | Perplexity: 403.564772
2025-10-01 23:42:06,426 Stage: Train 0.5 | Epoch: 626 | Iter: 381200 | Total Loss: 0.004143 | Recon Loss: 0.003190 | Commit Loss: 0.001906 | Perplexity: 404.137209
Trainning Epoch:  76%|███████▌  | 627/823 [108:30:03<33:55:15, 623.04s/it]Trainning Epoch:  76%|███████▌  | 627/823 [108:30:03<33:55:00, 622.96s/it]Trainning Epoch:  76%|███████▌  | 627/823 [108:30:03<33:55:15, 623.04s/it]Trainning Epoch:  76%|███████▌  | 627/823 [108:30:03<33:55:15, 623.04s/it]2025-10-01 23:45:34,191 Stage: Train 0.5 | Epoch: 627 | Iter: 381400 | Total Loss: 0.004078 | Recon Loss: 0.003133 | Commit Loss: 0.001891 | Perplexity: 403.316887
2025-10-01 23:48:58,136 Stage: Train 0.5 | Epoch: 627 | Iter: 381600 | Total Loss: 0.004116 | Recon Loss: 0.003169 | Commit Loss: 0.001895 | Perplexity: 404.490698
2025-10-01 23:52:22,702 Stage: Train 0.5 | Epoch: 627 | Iter: 381800 | Total Loss: 0.004105 | Recon Loss: 0.003157 | Commit Loss: 0.001897 | Perplexity: 403.332754
Trainning Epoch:  76%|███████▋  | 628/823 [108:40:28<33:46:22, 623.50s/it]Trainning Epoch:  76%|███████▋  | 628/823 [108:40:28<33:46:11, 623.44s/it]Trainning Epoch:  76%|███████▋  | 628/823 [108:40:28<33:46:22, 623.50s/it]Trainning Epoch:  76%|███████▋  | 628/823 [108:40:28<33:46:22, 623.50s/it]2025-10-01 23:55:49,445 Stage: Train 0.5 | Epoch: 628 | Iter: 382000 | Total Loss: 0.004099 | Recon Loss: 0.003158 | Commit Loss: 0.001882 | Perplexity: 404.396033
2025-10-01 23:59:12,003 Stage: Train 0.5 | Epoch: 628 | Iter: 382200 | Total Loss: 0.004075 | Recon Loss: 0.003127 | Commit Loss: 0.001895 | Perplexity: 404.058108
2025-10-02 00:02:37,959 Stage: Train 0.5 | Epoch: 628 | Iter: 382400 | Total Loss: 0.004133 | Recon Loss: 0.003177 | Commit Loss: 0.001913 | Perplexity: 403.615611
Trainning Epoch:  76%|███████▋  | 629/823 [108:50:51<33:36:05, 623.53s/it]Trainning Epoch:  76%|███████▋  | 629/823 [108:50:51<33:36:05, 623.53s/it]Trainning Epoch:  76%|███████▋  | 629/823 [108:50:51<33:36:05, 623.53s/it]Trainning Epoch:  76%|███████▋  | 629/823 [108:50:51<33:35:59, 623.50s/it]2025-10-02 00:06:04,261 Stage: Train 0.5 | Epoch: 629 | Iter: 382600 | Total Loss: 0.004067 | Recon Loss: 0.003127 | Commit Loss: 0.001879 | Perplexity: 403.119102
2025-10-02 00:09:26,533 Stage: Train 0.5 | Epoch: 629 | Iter: 382800 | Total Loss: 0.004086 | Recon Loss: 0.003143 | Commit Loss: 0.001886 | Perplexity: 403.020324
2025-10-02 00:12:49,609 Stage: Train 0.5 | Epoch: 629 | Iter: 383000 | Total Loss: 0.004108 | Recon Loss: 0.003157 | Commit Loss: 0.001902 | Perplexity: 404.217157
Trainning Epoch:  77%|███████▋  | 630/823 [109:01:11<33:21:44, 622.30s/it]Trainning Epoch:  77%|███████▋  | 630/823 [109:01:11<33:21:38, 622.27s/it]Trainning Epoch:  77%|███████▋  | 630/823 [109:01:11<33:21:43, 622.30s/it]Trainning Epoch:  77%|███████▋  | 630/823 [109:01:11<33:21:43, 622.30s/it]2025-10-02 00:16:15,565 Stage: Train 0.5 | Epoch: 630 | Iter: 383200 | Total Loss: 0.004102 | Recon Loss: 0.003149 | Commit Loss: 0.001906 | Perplexity: 404.329944
2025-10-02 00:19:38,475 Stage: Train 0.5 | Epoch: 630 | Iter: 383400 | Total Loss: 0.004093 | Recon Loss: 0.003149 | Commit Loss: 0.001889 | Perplexity: 402.972277
2025-10-02 00:23:01,648 Stage: Train 0.5 | Epoch: 630 | Iter: 383600 | Total Loss: 0.004115 | Recon Loss: 0.003162 | Commit Loss: 0.001905 | Perplexity: 403.462787
Trainning Epoch:  77%|███████▋  | 631/823 [109:11:31<33:09:19, 621.66s/it]Trainning Epoch:  77%|███████▋  | 631/823 [109:11:31<33:09:15, 621.64s/it]Trainning Epoch:  77%|███████▋  | 631/823 [109:11:31<33:09:18, 621.66s/it]Trainning Epoch:  77%|███████▋  | 631/823 [109:11:31<33:09:18, 621.66s/it]2025-10-02 00:26:28,591 Stage: Train 0.5 | Epoch: 631 | Iter: 383800 | Total Loss: 0.004121 | Recon Loss: 0.003171 | Commit Loss: 0.001901 | Perplexity: 404.548116
2025-10-02 00:29:51,450 Stage: Train 0.5 | Epoch: 631 | Iter: 384000 | Total Loss: 0.004095 | Recon Loss: 0.003145 | Commit Loss: 0.001899 | Perplexity: 403.910267
2025-10-02 00:33:14,324 Stage: Train 0.5 | Epoch: 631 | Iter: 384200 | Total Loss: 0.004096 | Recon Loss: 0.003147 | Commit Loss: 0.001899 | Perplexity: 402.984349
Trainning Epoch:  77%|███████▋  | 632/823 [109:21:51<32:57:49, 621.31s/it]Trainning Epoch:  77%|███████▋  | 632/823 [109:21:51<32:57:46, 621.29s/it]Trainning Epoch:  77%|███████▋  | 632/823 [109:21:51<32:57:49, 621.30s/it]Trainning Epoch:  77%|███████▋  | 632/823 [109:21:51<32:57:49, 621.30s/it]2025-10-02 00:36:41,898 Stage: Train 0.5 | Epoch: 632 | Iter: 384400 | Total Loss: 0.004081 | Recon Loss: 0.003136 | Commit Loss: 0.001891 | Perplexity: 403.564587
2025-10-02 00:40:06,258 Stage: Train 0.5 | Epoch: 632 | Iter: 384600 | Total Loss: 0.004075 | Recon Loss: 0.003135 | Commit Loss: 0.001881 | Perplexity: 402.143047
2025-10-02 00:43:30,606 Stage: Train 0.5 | Epoch: 632 | Iter: 384800 | Total Loss: 0.004086 | Recon Loss: 0.003138 | Commit Loss: 0.001896 | Perplexity: 403.563049
Trainning Epoch:  77%|███████▋  | 633/823 [109:32:17<32:51:20, 622.53s/it]Trainning Epoch:  77%|███████▋  | 633/823 [109:32:17<32:51:21, 622.53s/it]Trainning Epoch:  77%|███████▋  | 633/823 [109:32:17<32:51:21, 622.53s/it]Trainning Epoch:  77%|███████▋  | 633/823 [109:32:17<32:51:20, 622.53s/it]2025-10-02 00:46:58,325 Stage: Train 0.5 | Epoch: 633 | Iter: 385000 | Total Loss: 0.004119 | Recon Loss: 0.003162 | Commit Loss: 0.001915 | Perplexity: 404.259749
2025-10-02 00:50:19,948 Stage: Train 0.5 | Epoch: 633 | Iter: 385200 | Total Loss: 0.004092 | Recon Loss: 0.003146 | Commit Loss: 0.001891 | Perplexity: 403.394592
2025-10-02 00:53:41,529 Stage: Train 0.5 | Epoch: 633 | Iter: 385400 | Total Loss: 0.004089 | Recon Loss: 0.003142 | Commit Loss: 0.001894 | Perplexity: 403.521738
Trainning Epoch:  77%|███████▋  | 634/823 [109:42:35<32:36:40, 621.17s/it]Trainning Epoch:  77%|███████▋  | 634/823 [109:42:35<32:36:38, 621.16s/it]Trainning Epoch:  77%|███████▋  | 634/823 [109:42:35<32:36:39, 621.16s/it]Trainning Epoch:  77%|███████▋  | 634/823 [109:42:35<32:36:39, 621.16s/it]2025-10-02 00:57:07,126 Stage: Train 0.5 | Epoch: 634 | Iter: 385600 | Total Loss: 0.004070 | Recon Loss: 0.003128 | Commit Loss: 0.001885 | Perplexity: 402.726164
2025-10-02 01:00:29,497 Stage: Train 0.5 | Epoch: 634 | Iter: 385800 | Total Loss: 0.004100 | Recon Loss: 0.003156 | Commit Loss: 0.001889 | Perplexity: 403.489442
2025-10-02 01:03:51,772 Stage: Train 0.5 | Epoch: 634 | Iter: 386000 | Total Loss: 0.004097 | Recon Loss: 0.003149 | Commit Loss: 0.001897 | Perplexity: 403.303944
Trainning Epoch:  77%|███████▋  | 635/823 [109:52:53<32:23:35, 620.30s/it]Trainning Epoch:  77%|███████▋  | 635/823 [109:52:53<32:23:34, 620.29s/it]Trainning Epoch:  77%|███████▋  | 635/823 [109:52:53<32:23:35, 620.29s/it]Trainning Epoch:  77%|███████▋  | 635/823 [109:52:53<32:23:35, 620.30s/it]2025-10-02 01:07:19,253 Stage: Train 0.5 | Epoch: 635 | Iter: 386200 | Total Loss: 0.004066 | Recon Loss: 0.003128 | Commit Loss: 0.001875 | Perplexity: 403.544310
2025-10-02 01:10:44,313 Stage: Train 0.5 | Epoch: 635 | Iter: 386400 | Total Loss: 0.004071 | Recon Loss: 0.003127 | Commit Loss: 0.001887 | Perplexity: 403.546179
2025-10-02 01:14:08,832 Stage: Train 0.5 | Epoch: 635 | Iter: 386600 | Total Loss: 0.004092 | Recon Loss: 0.003138 | Commit Loss: 0.001910 | Perplexity: 403.639848
Trainning Epoch:  77%|███████▋  | 636/823 [110:03:19<32:18:44, 622.06s/it]Trainning Epoch:  77%|███████▋  | 636/823 [110:03:19<32:18:43, 622.05s/it]Trainning Epoch:  77%|███████▋  | 636/823 [110:03:19<32:18:45, 622.06s/it]Trainning Epoch:  77%|███████▋  | 636/823 [110:03:19<32:18:45, 622.06s/it]2025-10-02 01:17:35,796 Stage: Train 0.5 | Epoch: 636 | Iter: 386800 | Total Loss: 0.004086 | Recon Loss: 0.003140 | Commit Loss: 0.001891 | Perplexity: 403.394651
2025-10-02 01:20:58,113 Stage: Train 0.5 | Epoch: 636 | Iter: 387000 | Total Loss: 0.004095 | Recon Loss: 0.003148 | Commit Loss: 0.001894 | Perplexity: 403.970770
2025-10-02 01:24:20,094 Stage: Train 0.5 | Epoch: 636 | Iter: 387200 | Total Loss: 0.004092 | Recon Loss: 0.003144 | Commit Loss: 0.001896 | Perplexity: 403.956537
Trainning Epoch:  77%|███████▋  | 637/823 [110:13:38<32:05:03, 620.99s/it]Trainning Epoch:  77%|███████▋  | 637/823 [110:13:38<32:05:04, 620.99s/it]Trainning Epoch:  77%|███████▋  | 637/823 [110:13:38<32:05:04, 620.99s/it]Trainning Epoch:  77%|███████▋  | 637/823 [110:13:38<32:05:04, 620.99s/it]2025-10-02 01:27:46,374 Stage: Train 0.5 | Epoch: 637 | Iter: 387400 | Total Loss: 0.004096 | Recon Loss: 0.003148 | Commit Loss: 0.001897 | Perplexity: 403.741840
2025-10-02 01:31:08,857 Stage: Train 0.5 | Epoch: 637 | Iter: 387600 | Total Loss: 0.004082 | Recon Loss: 0.003141 | Commit Loss: 0.001882 | Perplexity: 402.713363
2025-10-02 01:34:31,985 Stage: Train 0.5 | Epoch: 637 | Iter: 387800 | Total Loss: 0.004078 | Recon Loss: 0.003129 | Commit Loss: 0.001897 | Perplexity: 403.144036
Trainning Epoch:  78%|███████▊  | 638/823 [110:23:58<31:54:22, 620.88s/it]Trainning Epoch:  78%|███████▊  | 638/823 [110:23:58<31:54:21, 620.87s/it]Trainning Epoch:  78%|███████▊  | 638/823 [110:23:58<31:54:21, 620.87s/it]Trainning Epoch:  78%|███████▊  | 638/823 [110:23:58<31:54:21, 620.87s/it]2025-10-02 01:37:58,758 Stage: Train 0.5 | Epoch: 638 | Iter: 388000 | Total Loss: 0.004109 | Recon Loss: 0.003161 | Commit Loss: 0.001896 | Perplexity: 403.883505
2025-10-02 01:41:21,534 Stage: Train 0.5 | Epoch: 638 | Iter: 388200 | Total Loss: 0.004089 | Recon Loss: 0.003140 | Commit Loss: 0.001899 | Perplexity: 404.715605
2025-10-02 01:44:44,627 Stage: Train 0.5 | Epoch: 638 | Iter: 388400 | Total Loss: 0.004079 | Recon Loss: 0.003131 | Commit Loss: 0.001896 | Perplexity: 402.824773
Trainning Epoch:  78%|███████▊  | 639/823 [110:34:19<31:44:05, 620.90s/it]Trainning Epoch:  78%|███████▊  | 639/823 [110:34:19<31:44:05, 620.90s/it]Trainning Epoch:  78%|███████▊  | 639/823 [110:34:19<31:44:05, 620.90s/it]Trainning Epoch:  78%|███████▊  | 639/823 [110:34:19<31:44:06, 620.90s/it]2025-10-02 01:48:11,719 Stage: Train 0.5 | Epoch: 639 | Iter: 388600 | Total Loss: 0.004086 | Recon Loss: 0.003141 | Commit Loss: 0.001890 | Perplexity: 403.330684
2025-10-02 01:51:33,594 Stage: Train 0.5 | Epoch: 639 | Iter: 388800 | Total Loss: 0.004056 | Recon Loss: 0.003112 | Commit Loss: 0.001888 | Perplexity: 403.683676
2025-10-02 01:54:56,483 Stage: Train 0.5 | Epoch: 639 | Iter: 389000 | Total Loss: 0.004086 | Recon Loss: 0.003142 | Commit Loss: 0.001887 | Perplexity: 403.774955
Trainning Epoch:  78%|███████▊  | 640/823 [110:44:38<31:32:13, 620.40s/it]Trainning Epoch:  78%|███████▊  | 640/823 [110:44:38<31:32:14, 620.41s/it]Trainning Epoch:  78%|███████▊  | 640/823 [110:44:38<31:32:13, 620.40s/it]Trainning Epoch:  78%|███████▊  | 640/823 [110:44:38<31:32:13, 620.40s/it]2025-10-02 01:58:22,497 Stage: Train 0.5 | Epoch: 640 | Iter: 389200 | Total Loss: 0.004112 | Recon Loss: 0.003165 | Commit Loss: 0.001894 | Perplexity: 404.118780
2025-10-02 02:01:44,035 Stage: Train 0.5 | Epoch: 640 | Iter: 389400 | Total Loss: 0.004075 | Recon Loss: 0.003126 | Commit Loss: 0.001899 | Perplexity: 404.414855
2025-10-02 02:05:05,656 Stage: Train 0.5 | Epoch: 640 | Iter: 389600 | Total Loss: 0.004113 | Recon Loss: 0.003166 | Commit Loss: 0.001894 | Perplexity: 403.931176
Trainning Epoch:  78%|███████▊  | 641/823 [110:54:55<31:18:24, 619.25s/it]Trainning Epoch:  78%|███████▊  | 641/823 [110:54:55<31:18:23, 619.25s/it]Trainning Epoch:  78%|███████▊  | 641/823 [110:54:55<31:18:25, 619.26s/it]Trainning Epoch:  78%|███████▊  | 641/823 [110:54:55<31:18:25, 619.26s/it]2025-10-02 02:08:31,375 Stage: Train 0.5 | Epoch: 641 | Iter: 389800 | Total Loss: 0.004056 | Recon Loss: 0.003108 | Commit Loss: 0.001896 | Perplexity: 403.435314
2025-10-02 02:11:54,563 Stage: Train 0.5 | Epoch: 641 | Iter: 390000 | Total Loss: 0.004069 | Recon Loss: 0.003128 | Commit Loss: 0.001883 | Perplexity: 402.799588
2025-10-02 02:15:18,872 Stage: Train 0.5 | Epoch: 641 | Iter: 390200 | Total Loss: 0.004098 | Recon Loss: 0.003150 | Commit Loss: 0.001896 | Perplexity: 403.684476
Trainning Epoch:  78%|███████▊  | 642/823 [111:05:18<31:11:21, 620.34s/it]Trainning Epoch:  78%|███████▊  | 642/823 [111:05:18<31:11:21, 620.34s/it]Trainning Epoch:  78%|███████▊  | 642/823 [111:05:18<31:11:21, 620.34s/it]Trainning Epoch:  78%|███████▊  | 642/823 [111:05:18<31:11:21, 620.34s/it]2025-10-02 02:18:46,247 Stage: Train 0.5 | Epoch: 642 | Iter: 390400 | Total Loss: 0.004077 | Recon Loss: 0.003132 | Commit Loss: 0.001890 | Perplexity: 403.374175
2025-10-02 02:22:08,784 Stage: Train 0.5 | Epoch: 642 | Iter: 390600 | Total Loss: 0.004074 | Recon Loss: 0.003127 | Commit Loss: 0.001893 | Perplexity: 403.152461
2025-10-02 02:25:31,008 Stage: Train 0.5 | Epoch: 642 | Iter: 390800 | Total Loss: 0.004085 | Recon Loss: 0.003134 | Commit Loss: 0.001901 | Perplexity: 403.552113
Trainning Epoch:  78%|███████▊  | 643/823 [111:15:37<31:00:08, 620.05s/it]Trainning Epoch:  78%|███████▊  | 643/823 [111:15:37<31:00:08, 620.04s/it]Trainning Epoch:  78%|███████▊  | 643/823 [111:15:37<31:00:08, 620.05s/it]Trainning Epoch:  78%|███████▊  | 643/823 [111:15:37<31:00:08, 620.05s/it]2025-10-02 02:28:57,560 Stage: Train 0.5 | Epoch: 643 | Iter: 391000 | Total Loss: 0.004105 | Recon Loss: 0.003151 | Commit Loss: 0.001907 | Perplexity: 404.032317
2025-10-02 02:32:20,006 Stage: Train 0.5 | Epoch: 643 | Iter: 391200 | Total Loss: 0.004056 | Recon Loss: 0.003116 | Commit Loss: 0.001882 | Perplexity: 403.490135
2025-10-02 02:35:43,951 Stage: Train 0.5 | Epoch: 643 | Iter: 391400 | Total Loss: 0.004121 | Recon Loss: 0.003163 | Commit Loss: 0.001916 | Perplexity: 404.371292
Trainning Epoch:  78%|███████▊  | 644/823 [111:26:00<30:52:10, 620.84s/it]Trainning Epoch:  78%|███████▊  | 644/823 [111:26:00<30:52:10, 620.84s/it]Trainning Epoch:  78%|███████▊  | 644/823 [111:26:00<30:52:11, 620.85s/it]Trainning Epoch:  78%|███████▊  | 644/823 [111:26:00<30:52:10, 620.84s/it]2025-10-02 02:39:12,846 Stage: Train 0.5 | Epoch: 644 | Iter: 391600 | Total Loss: 0.004075 | Recon Loss: 0.003126 | Commit Loss: 0.001899 | Perplexity: 403.670286
2025-10-02 02:42:37,714 Stage: Train 0.5 | Epoch: 644 | Iter: 391800 | Total Loss: 0.004076 | Recon Loss: 0.003134 | Commit Loss: 0.001884 | Perplexity: 403.562526
2025-10-02 02:46:02,140 Stage: Train 0.5 | Epoch: 644 | Iter: 392000 | Total Loss: 0.004090 | Recon Loss: 0.003135 | Commit Loss: 0.001910 | Perplexity: 403.500814
Trainning Epoch:  78%|███████▊  | 645/823 [111:36:26<30:46:45, 622.51s/it]Trainning Epoch:  78%|███████▊  | 645/823 [111:36:26<30:46:47, 622.51s/it]Trainning Epoch:  78%|███████▊  | 645/823 [111:36:26<30:46:47, 622.52s/it]Trainning Epoch:  78%|███████▊  | 645/823 [111:36:26<30:46:48, 622.52s/it]2025-10-02 02:49:30,654 Stage: Train 0.5 | Epoch: 645 | Iter: 392200 | Total Loss: 0.004078 | Recon Loss: 0.003131 | Commit Loss: 0.001893 | Perplexity: 403.510187
2025-10-02 02:52:56,066 Stage: Train 0.5 | Epoch: 645 | Iter: 392400 | Total Loss: 0.004071 | Recon Loss: 0.003129 | Commit Loss: 0.001883 | Perplexity: 404.073350
2025-10-02 02:56:22,540 Stage: Train 0.5 | Epoch: 645 | Iter: 392600 | Total Loss: 0.004079 | Recon Loss: 0.003132 | Commit Loss: 0.001892 | Perplexity: 403.016886
Trainning Epoch:  78%|███████▊  | 646/823 [111:46:55<30:42:11, 624.47s/it]Trainning Epoch:  78%|███████▊  | 646/823 [111:46:55<30:42:11, 624.47s/it]Trainning Epoch:  78%|███████▊  | 646/823 [111:46:55<30:42:12, 624.47s/it]Trainning Epoch:  78%|███████▊  | 646/823 [111:46:55<30:42:12, 624.48s/it]2025-10-02 02:59:51,791 Stage: Train 0.5 | Epoch: 646 | Iter: 392800 | Total Loss: 0.004088 | Recon Loss: 0.003143 | Commit Loss: 0.001890 | Perplexity: 402.495312
2025-10-02 03:03:16,139 Stage: Train 0.5 | Epoch: 646 | Iter: 393000 | Total Loss: 0.004101 | Recon Loss: 0.003149 | Commit Loss: 0.001903 | Perplexity: 404.559803
2025-10-02 03:06:40,765 Stage: Train 0.5 | Epoch: 646 | Iter: 393200 | Total Loss: 0.004067 | Recon Loss: 0.003120 | Commit Loss: 0.001894 | Perplexity: 404.455055
Trainning Epoch:  79%|███████▊  | 647/823 [111:57:21<30:33:02, 624.90s/it]Trainning Epoch:  79%|███████▊  | 647/823 [111:57:21<30:33:03, 624.91s/it]Trainning Epoch:  79%|███████▊  | 647/823 [111:57:21<30:33:03, 624.90s/it]Trainning Epoch:  79%|███████▊  | 647/823 [111:57:21<30:33:03, 624.90s/it]2025-10-02 03:10:09,197 Stage: Train 0.5 | Epoch: 647 | Iter: 393400 | Total Loss: 0.004095 | Recon Loss: 0.003145 | Commit Loss: 0.001901 | Perplexity: 403.435240
2025-10-02 03:13:31,310 Stage: Train 0.5 | Epoch: 647 | Iter: 393600 | Total Loss: 0.004060 | Recon Loss: 0.003112 | Commit Loss: 0.001897 | Perplexity: 404.236497
2025-10-02 03:16:54,044 Stage: Train 0.5 | Epoch: 647 | Iter: 393800 | Total Loss: 0.004089 | Recon Loss: 0.003139 | Commit Loss: 0.001899 | Perplexity: 404.208081
Trainning Epoch:  79%|███████▊  | 648/823 [112:07:41<30:17:49, 623.26s/it]Trainning Epoch:  79%|███████▊  | 648/823 [112:07:41<30:17:50, 623.26s/it]Trainning Epoch:  79%|███████▊  | 648/823 [112:07:41<30:17:49, 623.26s/it]Trainning Epoch:  79%|███████▊  | 648/823 [112:07:41<30:17:49, 623.25s/it]2025-10-02 03:20:20,299 Stage: Train 0.5 | Epoch: 648 | Iter: 394000 | Total Loss: 0.004103 | Recon Loss: 0.003152 | Commit Loss: 0.001903 | Perplexity: 403.142410
2025-10-02 03:23:41,687 Stage: Train 0.5 | Epoch: 648 | Iter: 394200 | Total Loss: 0.004054 | Recon Loss: 0.003110 | Commit Loss: 0.001888 | Perplexity: 403.741810
2025-10-02 03:27:03,505 Stage: Train 0.5 | Epoch: 648 | Iter: 394400 | Total Loss: 0.004083 | Recon Loss: 0.003135 | Commit Loss: 0.001896 | Perplexity: 403.430661
Trainning Epoch:  79%|███████▉  | 649/823 [112:17:57<30:01:48, 621.32s/it]Trainning Epoch:  79%|███████▉  | 649/823 [112:17:57<30:01:48, 621.31s/it]Trainning Epoch:  79%|███████▉  | 649/823 [112:17:57<30:01:49, 621.32s/it]Trainning Epoch:  79%|███████▉  | 649/823 [112:17:57<30:01:50, 621.32s/it]2025-10-02 03:30:29,359 Stage: Train 0.5 | Epoch: 649 | Iter: 394600 | Total Loss: 0.004097 | Recon Loss: 0.003149 | Commit Loss: 0.001896 | Perplexity: 404.078396
2025-10-02 03:33:50,992 Stage: Train 0.5 | Epoch: 649 | Iter: 394800 | Total Loss: 0.004070 | Recon Loss: 0.003122 | Commit Loss: 0.001896 | Perplexity: 403.809930
2025-10-02 03:37:13,194 Stage: Train 0.5 | Epoch: 649 | Iter: 395000 | Total Loss: 0.004058 | Recon Loss: 0.003117 | Commit Loss: 0.001882 | Perplexity: 403.952370
2025-10-02 03:40:35,205 Stage: Train 0.5 | Epoch: 649 | Iter: 395200 | Total Loss: 0.004075 | Recon Loss: 0.003125 | Commit Loss: 0.001902 | Perplexity: 403.146790
Trainning Epoch:  79%|███████▉  | 650/823 [112:28:16<29:48:41, 620.36s/it]Trainning Epoch:  79%|███████▉  | 650/823 [112:28:15<29:48:41, 620.35s/it]Trainning Epoch:  79%|███████▉  | 650/823 [112:28:16<29:48:41, 620.36s/it]Trainning Epoch:  79%|███████▉  | 650/823 [112:28:16<29:48:41, 620.36s/it]2025-10-02 03:44:01,390 Stage: Train 0.5 | Epoch: 650 | Iter: 395400 | Total Loss: 0.004048 | Recon Loss: 0.003100 | Commit Loss: 0.001896 | Perplexity: 403.709438
2025-10-02 03:47:23,393 Stage: Train 0.5 | Epoch: 650 | Iter: 395600 | Total Loss: 0.004113 | Recon Loss: 0.003160 | Commit Loss: 0.001906 | Perplexity: 404.323478
2025-10-02 03:50:45,349 Stage: Train 0.5 | Epoch: 650 | Iter: 395800 | Total Loss: 0.004081 | Recon Loss: 0.003130 | Commit Loss: 0.001903 | Perplexity: 403.780765
Trainning Epoch:  79%|███████▉  | 651/823 [112:38:34<29:36:31, 619.72s/it]Trainning Epoch:  79%|███████▉  | 651/823 [112:38:34<29:36:31, 619.72s/it]Trainning Epoch:  79%|███████▉  | 651/823 [112:38:34<29:36:31, 619.72s/it]Trainning Epoch:  79%|███████▉  | 651/823 [112:38:34<29:36:31, 619.72s/it]2025-10-02 03:54:10,550 Stage: Train 0.5 | Epoch: 651 | Iter: 396000 | Total Loss: 0.004055 | Recon Loss: 0.003112 | Commit Loss: 0.001887 | Perplexity: 403.449848
2025-10-02 03:57:33,186 Stage: Train 0.5 | Epoch: 651 | Iter: 396200 | Total Loss: 0.004097 | Recon Loss: 0.003149 | Commit Loss: 0.001895 | Perplexity: 403.600779
2025-10-02 04:00:56,836 Stage: Train 0.5 | Epoch: 651 | Iter: 396400 | Total Loss: 0.004067 | Recon Loss: 0.003120 | Commit Loss: 0.001893 | Perplexity: 403.669070
Trainning Epoch:  79%|███████▉  | 652/823 [112:48:53<29:26:07, 619.69s/it]Trainning Epoch:  79%|███████▉  | 652/823 [112:48:53<29:26:07, 619.69s/it]Trainning Epoch:  79%|███████▉  | 652/823 [112:48:53<29:26:07, 619.69s/it]Trainning Epoch:  79%|███████▉  | 652/823 [112:48:53<29:26:07, 619.70s/it]2025-10-02 04:04:22,872 Stage: Train 0.5 | Epoch: 652 | Iter: 396600 | Total Loss: 0.004065 | Recon Loss: 0.003115 | Commit Loss: 0.001900 | Perplexity: 403.832705
2025-10-02 04:07:45,055 Stage: Train 0.5 | Epoch: 652 | Iter: 396800 | Total Loss: 0.004055 | Recon Loss: 0.003106 | Commit Loss: 0.001897 | Perplexity: 403.888448
2025-10-02 04:11:07,513 Stage: Train 0.5 | Epoch: 652 | Iter: 397000 | Total Loss: 0.004111 | Recon Loss: 0.003158 | Commit Loss: 0.001907 | Perplexity: 404.462483
Trainning Epoch:  79%|███████▉  | 653/823 [112:59:12<29:14:55, 619.39s/it]Trainning Epoch:  79%|███████▉  | 653/823 [112:59:12<29:14:56, 619.39s/it]Trainning Epoch:  79%|███████▉  | 653/823 [112:59:12<29:14:56, 619.39s/it]Trainning Epoch:  79%|███████▉  | 653/823 [112:59:12<29:14:56, 619.39s/it]2025-10-02 04:14:32,767 Stage: Train 0.5 | Epoch: 653 | Iter: 397200 | Total Loss: 0.004060 | Recon Loss: 0.003114 | Commit Loss: 0.001892 | Perplexity: 403.345759
2025-10-02 04:17:54,109 Stage: Train 0.5 | Epoch: 653 | Iter: 397400 | Total Loss: 0.004077 | Recon Loss: 0.003133 | Commit Loss: 0.001890 | Perplexity: 402.882285
2025-10-02 04:21:16,563 Stage: Train 0.5 | Epoch: 653 | Iter: 397600 | Total Loss: 0.004064 | Recon Loss: 0.003119 | Commit Loss: 0.001890 | Perplexity: 403.391717
Trainning Epoch:  79%|███████▉  | 654/823 [113:09:29<29:02:47, 618.74s/it]Trainning Epoch:  79%|███████▉  | 654/823 [113:09:29<29:02:47, 618.74s/it]Trainning Epoch:  79%|███████▉  | 654/823 [113:09:29<29:02:47, 618.74s/it]Trainning Epoch:  79%|███████▉  | 654/823 [113:09:29<29:02:47, 618.74s/it]2025-10-02 04:24:43,141 Stage: Train 0.5 | Epoch: 654 | Iter: 397800 | Total Loss: 0.004040 | Recon Loss: 0.003095 | Commit Loss: 0.001889 | Perplexity: 402.970487
2025-10-02 04:28:06,081 Stage: Train 0.5 | Epoch: 654 | Iter: 398000 | Total Loss: 0.004077 | Recon Loss: 0.003128 | Commit Loss: 0.001898 | Perplexity: 403.678780
2025-10-02 04:31:28,960 Stage: Train 0.5 | Epoch: 654 | Iter: 398200 | Total Loss: 0.004055 | Recon Loss: 0.003113 | Commit Loss: 0.001883 | Perplexity: 402.796911
Trainning Epoch:  80%|███████▉  | 655/823 [113:19:50<28:53:58, 619.28s/it]Trainning Epoch:  80%|███████▉  | 655/823 [113:19:50<28:53:59, 619.28s/it]Trainning Epoch:  80%|███████▉  | 655/823 [113:19:50<28:53:59, 619.28s/it]Trainning Epoch:  80%|███████▉  | 655/823 [113:19:50<28:53:59, 619.28s/it]2025-10-02 04:34:54,690 Stage: Train 0.5 | Epoch: 655 | Iter: 398400 | Total Loss: 0.004062 | Recon Loss: 0.003120 | Commit Loss: 0.001885 | Perplexity: 403.489550
2025-10-02 04:38:16,587 Stage: Train 0.5 | Epoch: 655 | Iter: 398600 | Total Loss: 0.004073 | Recon Loss: 0.003120 | Commit Loss: 0.001906 | Perplexity: 404.532890
2025-10-02 04:41:39,098 Stage: Train 0.5 | Epoch: 655 | Iter: 398800 | Total Loss: 0.004088 | Recon Loss: 0.003136 | Commit Loss: 0.001905 | Perplexity: 403.657494
Trainning Epoch:  80%|███████▉  | 656/823 [113:30:08<28:42:44, 618.95s/it]Trainning Epoch:  80%|███████▉  | 656/823 [113:30:08<28:42:44, 618.95s/it]Trainning Epoch:  80%|███████▉  | 656/823 [113:30:08<28:42:44, 618.95s/it]Trainning Epoch:  80%|███████▉  | 656/823 [113:30:08<28:42:44, 618.95s/it]2025-10-02 04:45:06,075 Stage: Train 0.5 | Epoch: 656 | Iter: 399000 | Total Loss: 0.004055 | Recon Loss: 0.003106 | Commit Loss: 0.001898 | Perplexity: 404.312873
2025-10-02 04:48:29,546 Stage: Train 0.5 | Epoch: 656 | Iter: 399200 | Total Loss: 0.004062 | Recon Loss: 0.003118 | Commit Loss: 0.001888 | Perplexity: 403.219063
2025-10-02 04:51:52,893 Stage: Train 0.5 | Epoch: 656 | Iter: 399400 | Total Loss: 0.004044 | Recon Loss: 0.003098 | Commit Loss: 0.001891 | Perplexity: 403.853856
Trainning Epoch:  80%|███████▉  | 657/823 [113:40:30<28:35:08, 619.93s/it]Trainning Epoch:  80%|███████▉  | 657/823 [113:40:30<28:35:09, 619.94s/it]Trainning Epoch:  80%|███████▉  | 657/823 [113:40:30<28:35:09, 619.94s/it]Trainning Epoch:  80%|███████▉  | 657/823 [113:40:30<28:35:09, 619.94s/it]2025-10-02 04:55:19,753 Stage: Train 0.5 | Epoch: 657 | Iter: 399600 | Total Loss: 0.004066 | Recon Loss: 0.003118 | Commit Loss: 0.001896 | Perplexity: 403.607415
2025-10-02 04:58:42,675 Stage: Train 0.5 | Epoch: 657 | Iter: 399800 | Total Loss: 0.004052 | Recon Loss: 0.003104 | Commit Loss: 0.001896 | Perplexity: 404.259903
2025-10-02 05:02:05,908 Stage: Train 0.5 | Epoch: 657 | Iter: 400000 | Total Loss: 0.004081 | Recon Loss: 0.003131 | Commit Loss: 0.001901 | Perplexity: 403.583856
2025-10-02 05:02:05,908 Saving model at iteration 400000
2025-10-02 05:02:06,199 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_658_step_400000
2025-10-02 05:02:06,808 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_658_step_400000/model.safetensors
2025-10-02 05:02:07,413 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_658_step_400000/optimizer.bin
2025-10-02 05:02:07,414 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_658_step_400000/scheduler.bin
2025-10-02 05:02:07,414 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_658_step_400000/sampler.bin
2025-10-02 05:02:07,415 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_658_step_400000/random_states_0.pkl
Trainning Epoch:  80%|███████▉  | 658/823 [113:50:53<28:27:10, 620.79s/it]Trainning Epoch:  80%|███████▉  | 658/823 [113:50:53<28:27:10, 620.79s/it]Trainning Epoch:  80%|███████▉  | 658/823 [113:50:53<28:27:11, 620.80s/it]Trainning Epoch:  80%|███████▉  | 658/823 [113:50:53<28:27:11, 620.80s/it]2025-10-02 05:05:33,798 Stage: Train 0.5 | Epoch: 658 | Iter: 400200 | Total Loss: 0.004040 | Recon Loss: 0.003093 | Commit Loss: 0.001892 | Perplexity: 403.132143
2025-10-02 05:08:56,641 Stage: Train 0.5 | Epoch: 658 | Iter: 400400 | Total Loss: 0.004050 | Recon Loss: 0.003102 | Commit Loss: 0.001897 | Perplexity: 403.614263
2025-10-02 05:12:20,058 Stage: Train 0.5 | Epoch: 658 | Iter: 400600 | Total Loss: 0.004094 | Recon Loss: 0.003135 | Commit Loss: 0.001918 | Perplexity: 403.984532
Trainning Epoch:  80%|████████  | 659/823 [114:01:14<28:16:35, 620.71s/it]Trainning Epoch:  80%|████████  | 659/823 [114:01:14<28:16:35, 620.71s/it]Trainning Epoch:  80%|████████  | 659/823 [114:01:14<28:16:36, 620.71s/it]Trainning Epoch:  80%|████████  | 659/823 [114:01:14<28:16:36, 620.71s/it]2025-10-02 05:15:46,800 Stage: Train 0.5 | Epoch: 659 | Iter: 400800 | Total Loss: 0.004084 | Recon Loss: 0.003136 | Commit Loss: 0.001895 | Perplexity: 404.199322
2025-10-02 05:19:09,369 Stage: Train 0.5 | Epoch: 659 | Iter: 401000 | Total Loss: 0.004095 | Recon Loss: 0.003148 | Commit Loss: 0.001894 | Perplexity: 403.896893
2025-10-02 05:22:32,869 Stage: Train 0.5 | Epoch: 659 | Iter: 401200 | Total Loss: 0.004079 | Recon Loss: 0.003125 | Commit Loss: 0.001907 | Perplexity: 404.120964
Trainning Epoch:  80%|████████  | 660/823 [114:11:35<28:06:31, 620.81s/it]Trainning Epoch:  80%|████████  | 660/823 [114:11:35<28:06:32, 620.81s/it]Trainning Epoch:  80%|████████  | 660/823 [114:11:35<28:06:32, 620.81s/it]Trainning Epoch:  80%|████████  | 660/823 [114:11:35<28:06:31, 620.81s/it]2025-10-02 05:25:59,803 Stage: Train 0.5 | Epoch: 660 | Iter: 401400 | Total Loss: 0.004069 | Recon Loss: 0.003123 | Commit Loss: 0.001892 | Perplexity: 403.013912
2025-10-02 05:29:21,529 Stage: Train 0.5 | Epoch: 660 | Iter: 401600 | Total Loss: 0.004053 | Recon Loss: 0.003105 | Commit Loss: 0.001895 | Perplexity: 403.609802
2025-10-02 05:32:43,046 Stage: Train 0.5 | Epoch: 660 | Iter: 401800 | Total Loss: 0.004053 | Recon Loss: 0.003103 | Commit Loss: 0.001899 | Perplexity: 403.555735
Trainning Epoch:  80%|████████  | 661/823 [114:21:52<27:53:37, 619.86s/it]Trainning Epoch:  80%|████████  | 661/823 [114:21:52<27:53:37, 619.86s/it]Trainning Epoch:  80%|████████  | 661/823 [114:21:52<27:53:37, 619.86s/it]Trainning Epoch:  80%|████████  | 661/823 [114:21:52<27:53:37, 619.86s/it]2025-10-02 05:36:09,116 Stage: Train 0.5 | Epoch: 661 | Iter: 402000 | Total Loss: 0.004088 | Recon Loss: 0.003132 | Commit Loss: 0.001912 | Perplexity: 404.231100
2025-10-02 05:39:31,473 Stage: Train 0.5 | Epoch: 661 | Iter: 402200 | Total Loss: 0.004033 | Recon Loss: 0.003088 | Commit Loss: 0.001889 | Perplexity: 402.987498
2025-10-02 05:42:53,889 Stage: Train 0.5 | Epoch: 661 | Iter: 402400 | Total Loss: 0.004064 | Recon Loss: 0.003115 | Commit Loss: 0.001899 | Perplexity: 403.557759
Trainning Epoch:  80%|████████  | 662/823 [114:32:11<27:42:38, 619.62s/it]Trainning Epoch:  80%|████████  | 662/823 [114:32:11<27:42:39, 619.62s/it]Trainning Epoch:  80%|████████  | 662/823 [114:32:11<27:42:40, 619.63s/it]Trainning Epoch:  80%|████████  | 662/823 [114:32:11<27:42:41, 619.64s/it]2025-10-02 05:46:19,956 Stage: Train 0.5 | Epoch: 662 | Iter: 402600 | Total Loss: 0.004035 | Recon Loss: 0.003093 | Commit Loss: 0.001883 | Perplexity: 402.996701
2025-10-02 05:49:42,736 Stage: Train 0.5 | Epoch: 662 | Iter: 402800 | Total Loss: 0.004057 | Recon Loss: 0.003109 | Commit Loss: 0.001896 | Perplexity: 403.316363
2025-10-02 05:53:06,305 Stage: Train 0.5 | Epoch: 662 | Iter: 403000 | Total Loss: 0.004067 | Recon Loss: 0.003114 | Commit Loss: 0.001906 | Perplexity: 403.596753
Trainning Epoch:  81%|████████  | 663/823 [114:42:32<27:33:21, 620.01s/it]Trainning Epoch:  81%|████████  | 663/823 [114:42:32<27:33:21, 620.01s/it]Trainning Epoch:  81%|████████  | 663/823 [114:42:32<27:33:21, 620.01s/it]Trainning Epoch:  81%|████████  | 663/823 [114:42:32<27:33:22, 620.02s/it]2025-10-02 05:56:33,065 Stage: Train 0.5 | Epoch: 663 | Iter: 403200 | Total Loss: 0.004081 | Recon Loss: 0.003132 | Commit Loss: 0.001897 | Perplexity: 403.744438
2025-10-02 05:59:55,553 Stage: Train 0.5 | Epoch: 663 | Iter: 403400 | Total Loss: 0.004035 | Recon Loss: 0.003084 | Commit Loss: 0.001904 | Perplexity: 404.627438
2025-10-02 06:03:18,445 Stage: Train 0.5 | Epoch: 663 | Iter: 403600 | Total Loss: 0.004114 | Recon Loss: 0.003161 | Commit Loss: 0.001906 | Perplexity: 403.778021
Trainning Epoch:  81%|████████  | 664/823 [114:52:52<27:22:57, 619.99s/it]Trainning Epoch:  81%|████████  | 664/823 [114:52:52<27:22:58, 619.99s/it]Trainning Epoch:  81%|████████  | 664/823 [114:52:52<27:22:57, 619.99s/it]Trainning Epoch:  81%|████████  | 664/823 [114:52:52<27:22:58, 619.99s/it]2025-10-02 06:06:44,797 Stage: Train 0.5 | Epoch: 664 | Iter: 403800 | Total Loss: 0.004011 | Recon Loss: 0.003074 | Commit Loss: 0.001875 | Perplexity: 403.610426
2025-10-02 06:10:07,886 Stage: Train 0.5 | Epoch: 664 | Iter: 404000 | Total Loss: 0.004037 | Recon Loss: 0.003088 | Commit Loss: 0.001897 | Perplexity: 403.415793
2025-10-02 06:13:31,372 Stage: Train 0.5 | Epoch: 664 | Iter: 404200 | Total Loss: 0.004070 | Recon Loss: 0.003123 | Commit Loss: 0.001895 | Perplexity: 403.724986
Trainning Epoch:  81%|████████  | 665/823 [115:03:13<27:13:21, 620.26s/it]Trainning Epoch:  81%|████████  | 665/823 [115:03:13<27:13:20, 620.26s/it]Trainning Epoch:  81%|████████  | 665/823 [115:03:13<27:13:21, 620.26s/it]Trainning Epoch:  81%|████████  | 665/823 [115:03:13<27:13:20, 620.26s/it]2025-10-02 06:16:58,025 Stage: Train 0.5 | Epoch: 665 | Iter: 404400 | Total Loss: 0.004076 | Recon Loss: 0.003125 | Commit Loss: 0.001902 | Perplexity: 404.314302
2025-10-02 06:20:20,689 Stage: Train 0.5 | Epoch: 665 | Iter: 404600 | Total Loss: 0.004018 | Recon Loss: 0.003077 | Commit Loss: 0.001883 | Perplexity: 403.281047
2025-10-02 06:23:43,501 Stage: Train 0.5 | Epoch: 665 | Iter: 404800 | Total Loss: 0.004036 | Recon Loss: 0.003092 | Commit Loss: 0.001887 | Perplexity: 402.897505
Trainning Epoch:  81%|████████  | 666/823 [115:13:34<27:03:22, 620.40s/it]Trainning Epoch:  81%|████████  | 666/823 [115:13:34<27:03:21, 620.39s/it]Trainning Epoch:  81%|████████  | 666/823 [115:13:34<27:03:22, 620.40s/it]Trainning Epoch:  81%|████████  | 666/823 [115:13:34<27:03:22, 620.40s/it]2025-10-02 06:27:10,900 Stage: Train 0.5 | Epoch: 666 | Iter: 405000 | Total Loss: 0.004064 | Recon Loss: 0.003115 | Commit Loss: 0.001899 | Perplexity: 404.459139
2025-10-02 06:30:34,751 Stage: Train 0.5 | Epoch: 666 | Iter: 405200 | Total Loss: 0.004044 | Recon Loss: 0.003093 | Commit Loss: 0.001903 | Perplexity: 404.428054
2025-10-02 06:33:58,953 Stage: Train 0.5 | Epoch: 666 | Iter: 405400 | Total Loss: 0.004061 | Recon Loss: 0.003114 | Commit Loss: 0.001893 | Perplexity: 404.006287
Trainning Epoch:  81%|████████  | 667/823 [115:23:58<26:55:55, 621.51s/it]Trainning Epoch:  81%|████████  | 667/823 [115:23:58<26:55:55, 621.51s/it]Trainning Epoch:  81%|████████  | 667/823 [115:23:58<26:55:55, 621.51s/it]Trainning Epoch:  81%|████████  | 667/823 [115:23:58<26:55:55, 621.51s/it]2025-10-02 06:37:26,540 Stage: Train 0.5 | Epoch: 667 | Iter: 405600 | Total Loss: 0.004073 | Recon Loss: 0.003125 | Commit Loss: 0.001897 | Perplexity: 404.022195
2025-10-02 06:40:49,553 Stage: Train 0.5 | Epoch: 667 | Iter: 405800 | Total Loss: 0.004051 | Recon Loss: 0.003102 | Commit Loss: 0.001898 | Perplexity: 404.160295
2025-10-02 06:44:12,304 Stage: Train 0.5 | Epoch: 667 | Iter: 406000 | Total Loss: 0.004064 | Recon Loss: 0.003118 | Commit Loss: 0.001891 | Perplexity: 403.196422
Trainning Epoch:  81%|████████  | 668/823 [115:34:19<26:45:22, 621.44s/it]Trainning Epoch:  81%|████████  | 668/823 [115:34:19<26:45:23, 621.44s/it]Trainning Epoch:  81%|████████  | 668/823 [115:34:19<26:45:24, 621.45s/it]Trainning Epoch:  81%|████████  | 668/823 [115:34:19<26:45:23, 621.44s/it]2025-10-02 06:47:40,668 Stage: Train 0.5 | Epoch: 668 | Iter: 406200 | Total Loss: 0.004040 | Recon Loss: 0.003096 | Commit Loss: 0.001888 | Perplexity: 403.311190
2025-10-02 06:51:05,324 Stage: Train 0.5 | Epoch: 668 | Iter: 406400 | Total Loss: 0.004036 | Recon Loss: 0.003091 | Commit Loss: 0.001890 | Perplexity: 403.186529
2025-10-02 06:54:31,041 Stage: Train 0.5 | Epoch: 668 | Iter: 406600 | Total Loss: 0.004051 | Recon Loss: 0.003101 | Commit Loss: 0.001900 | Perplexity: 404.117311
Trainning Epoch:  81%|████████▏ | 669/823 [115:44:48<26:40:48, 623.69s/it]Trainning Epoch:  81%|████████▏ | 669/823 [115:44:48<26:40:47, 623.69s/it]Trainning Epoch:  81%|████████▏ | 669/823 [115:44:48<26:40:48, 623.69s/it]Trainning Epoch:  81%|████████▏ | 669/823 [115:44:48<26:40:48, 623.69s/it]2025-10-02 06:58:01,339 Stage: Train 0.5 | Epoch: 669 | Iter: 406800 | Total Loss: 0.004064 | Recon Loss: 0.003113 | Commit Loss: 0.001901 | Perplexity: 403.782760
2025-10-02 07:01:27,237 Stage: Train 0.5 | Epoch: 669 | Iter: 407000 | Total Loss: 0.004046 | Recon Loss: 0.003103 | Commit Loss: 0.001886 | Perplexity: 404.131322
2025-10-02 07:04:53,568 Stage: Train 0.5 | Epoch: 669 | Iter: 407200 | Total Loss: 0.004055 | Recon Loss: 0.003104 | Commit Loss: 0.001902 | Perplexity: 403.732890
Trainning Epoch:  81%|████████▏ | 670/823 [115:55:19<26:36:04, 625.91s/it]Trainning Epoch:  81%|████████▏ | 670/823 [115:55:19<26:36:04, 625.91s/it]Trainning Epoch:  81%|████████▏ | 670/823 [115:55:19<26:36:04, 625.91s/it]Trainning Epoch:  81%|████████▏ | 670/823 [115:55:19<26:36:05, 625.92s/it]2025-10-02 07:08:23,627 Stage: Train 0.5 | Epoch: 670 | Iter: 407400 | Total Loss: 0.004071 | Recon Loss: 0.003125 | Commit Loss: 0.001893 | Perplexity: 403.349621
2025-10-02 07:11:46,346 Stage: Train 0.5 | Epoch: 670 | Iter: 407600 | Total Loss: 0.004026 | Recon Loss: 0.003081 | Commit Loss: 0.001890 | Perplexity: 402.981528
2025-10-02 07:15:08,912 Stage: Train 0.5 | Epoch: 670 | Iter: 407800 | Total Loss: 0.004059 | Recon Loss: 0.003105 | Commit Loss: 0.001909 | Perplexity: 403.889651
Trainning Epoch:  82%|████████▏ | 671/823 [116:05:40<26:21:31, 624.28s/it]Trainning Epoch:  82%|████████▏ | 671/823 [116:05:40<26:21:30, 624.28s/it]Trainning Epoch:  82%|████████▏ | 671/823 [116:05:40<26:21:31, 624.28s/it]Trainning Epoch:  82%|████████▏ | 671/823 [116:05:40<26:21:30, 624.28s/it]2025-10-02 07:18:35,886 Stage: Train 0.5 | Epoch: 671 | Iter: 408000 | Total Loss: 0.004041 | Recon Loss: 0.003093 | Commit Loss: 0.001896 | Perplexity: 403.792975
2025-10-02 07:21:58,984 Stage: Train 0.5 | Epoch: 671 | Iter: 408200 | Total Loss: 0.004038 | Recon Loss: 0.003095 | Commit Loss: 0.001886 | Perplexity: 403.784576
2025-10-02 07:25:22,801 Stage: Train 0.5 | Epoch: 671 | Iter: 408400 | Total Loss: 0.004040 | Recon Loss: 0.003095 | Commit Loss: 0.001890 | Perplexity: 403.525496
Trainning Epoch:  82%|████████▏ | 672/823 [116:16:02<26:09:47, 623.76s/it]Trainning Epoch:  82%|████████▏ | 672/823 [116:16:02<26:09:47, 623.76s/it]Trainning Epoch:  82%|████████▏ | 672/823 [116:16:02<26:09:47, 623.76s/it]Trainning Epoch:  82%|████████▏ | 672/823 [116:16:02<26:09:47, 623.76s/it]2025-10-02 07:28:50,113 Stage: Train 0.5 | Epoch: 672 | Iter: 408600 | Total Loss: 0.004047 | Recon Loss: 0.003102 | Commit Loss: 0.001890 | Perplexity: 403.922293
2025-10-02 07:32:12,554 Stage: Train 0.5 | Epoch: 672 | Iter: 408800 | Total Loss: 0.004033 | Recon Loss: 0.003087 | Commit Loss: 0.001891 | Perplexity: 403.651457
2025-10-02 07:35:36,213 Stage: Train 0.5 | Epoch: 672 | Iter: 409000 | Total Loss: 0.004063 | Recon Loss: 0.003112 | Commit Loss: 0.001902 | Perplexity: 404.015032
Trainning Epoch:  82%|████████▏ | 673/823 [116:26:24<25:57:51, 623.14s/it]Trainning Epoch:  82%|████████▏ | 673/823 [116:26:24<25:57:50, 623.14s/it]Trainning Epoch:  82%|████████▏ | 673/823 [116:26:24<25:57:51, 623.14s/it]Trainning Epoch:  82%|████████▏ | 673/823 [116:26:24<25:57:51, 623.14s/it]2025-10-02 07:39:03,996 Stage: Train 0.5 | Epoch: 673 | Iter: 409200 | Total Loss: 0.004063 | Recon Loss: 0.003112 | Commit Loss: 0.001903 | Perplexity: 404.094578
2025-10-02 07:42:27,494 Stage: Train 0.5 | Epoch: 673 | Iter: 409400 | Total Loss: 0.004028 | Recon Loss: 0.003081 | Commit Loss: 0.001894 | Perplexity: 403.994813
2025-10-02 07:45:51,475 Stage: Train 0.5 | Epoch: 673 | Iter: 409600 | Total Loss: 0.004038 | Recon Loss: 0.003092 | Commit Loss: 0.001893 | Perplexity: 403.462755
Trainning Epoch:  82%|████████▏ | 674/823 [116:36:48<25:48:13, 623.45s/it]Trainning Epoch:  82%|████████▏ | 674/823 [116:36:48<25:48:14, 623.45s/it]Trainning Epoch:  82%|████████▏ | 674/823 [116:36:48<25:48:14, 623.45s/it]Trainning Epoch:  82%|████████▏ | 674/823 [116:36:48<25:48:15, 623.46s/it]2025-10-02 07:49:19,831 Stage: Train 0.5 | Epoch: 674 | Iter: 409800 | Total Loss: 0.004064 | Recon Loss: 0.003115 | Commit Loss: 0.001898 | Perplexity: 404.361473
2025-10-02 07:52:42,100 Stage: Train 0.5 | Epoch: 674 | Iter: 410000 | Total Loss: 0.004061 | Recon Loss: 0.003110 | Commit Loss: 0.001903 | Perplexity: 404.662330
2025-10-02 07:56:05,100 Stage: Train 0.5 | Epoch: 674 | Iter: 410200 | Total Loss: 0.004060 | Recon Loss: 0.003110 | Commit Loss: 0.001901 | Perplexity: 403.990978
2025-10-02 07:59:27,656 Stage: Train 0.5 | Epoch: 674 | Iter: 410400 | Total Loss: 0.004062 | Recon Loss: 0.003107 | Commit Loss: 0.001911 | Perplexity: 404.162777
Trainning Epoch:  82%|████████▏ | 675/823 [116:47:08<25:35:10, 622.37s/it]Trainning Epoch:  82%|████████▏ | 675/823 [116:47:08<25:35:11, 622.38s/it]Trainning Epoch:  82%|████████▏ | 675/823 [116:47:08<25:35:11, 622.38s/it]Trainning Epoch:  82%|████████▏ | 675/823 [116:47:08<25:35:12, 622.38s/it]2025-10-02 08:02:53,551 Stage: Train 0.5 | Epoch: 675 | Iter: 410600 | Total Loss: 0.004028 | Recon Loss: 0.003081 | Commit Loss: 0.001893 | Perplexity: 403.464275
2025-10-02 08:06:15,580 Stage: Train 0.5 | Epoch: 675 | Iter: 410800 | Total Loss: 0.004031 | Recon Loss: 0.003087 | Commit Loss: 0.001888 | Perplexity: 403.218366
2025-10-02 08:09:38,327 Stage: Train 0.5 | Epoch: 675 | Iter: 411000 | Total Loss: 0.004053 | Recon Loss: 0.003105 | Commit Loss: 0.001896 | Perplexity: 402.768530
Trainning Epoch:  82%|████████▏ | 676/823 [116:57:27<25:22:11, 621.30s/it]Trainning Epoch:  82%|████████▏ | 676/823 [116:57:27<25:22:10, 621.30s/it]Trainning Epoch:  82%|████████▏ | 676/823 [116:57:27<25:22:12, 621.31s/it]Trainning Epoch:  82%|████████▏ | 676/823 [116:57:27<25:22:12, 621.31s/it]2025-10-02 08:13:04,068 Stage: Train 0.5 | Epoch: 676 | Iter: 411200 | Total Loss: 0.004040 | Recon Loss: 0.003089 | Commit Loss: 0.001901 | Perplexity: 404.303816
2025-10-02 08:16:26,695 Stage: Train 0.5 | Epoch: 676 | Iter: 411400 | Total Loss: 0.004035 | Recon Loss: 0.003090 | Commit Loss: 0.001890 | Perplexity: 402.894040
2025-10-02 08:19:49,498 Stage: Train 0.5 | Epoch: 676 | Iter: 411600 | Total Loss: 0.004058 | Recon Loss: 0.003099 | Commit Loss: 0.001918 | Perplexity: 403.732677
Trainning Epoch:  82%|████████▏ | 677/823 [117:07:46<25:10:22, 620.70s/it]Trainning Epoch:  82%|████████▏ | 677/823 [117:07:46<25:10:23, 620.71s/it]Trainning Epoch:  82%|████████▏ | 677/823 [117:07:46<25:10:22, 620.70s/it]Trainning Epoch:  82%|████████▏ | 677/823 [117:07:46<25:10:23, 620.71s/it]2025-10-02 08:23:16,564 Stage: Train 0.5 | Epoch: 677 | Iter: 411800 | Total Loss: 0.004040 | Recon Loss: 0.003091 | Commit Loss: 0.001898 | Perplexity: 403.758750
2025-10-02 08:26:39,291 Stage: Train 0.5 | Epoch: 677 | Iter: 412000 | Total Loss: 0.004032 | Recon Loss: 0.003086 | Commit Loss: 0.001894 | Perplexity: 403.413203
2025-10-02 08:30:02,866 Stage: Train 0.5 | Epoch: 677 | Iter: 412200 | Total Loss: 0.004083 | Recon Loss: 0.003124 | Commit Loss: 0.001917 | Perplexity: 405.214511
Trainning Epoch:  82%|████████▏ | 678/823 [117:18:08<25:00:43, 620.99s/it]Trainning Epoch:  82%|████████▏ | 678/823 [117:18:08<25:00:43, 620.99s/it]Trainning Epoch:  82%|████████▏ | 678/823 [117:18:08<25:00:43, 620.99s/it]Trainning Epoch:  82%|████████▏ | 678/823 [117:18:08<25:00:44, 621.00s/it]2025-10-02 08:33:28,473 Stage: Train 0.5 | Epoch: 678 | Iter: 412400 | Total Loss: 0.004032 | Recon Loss: 0.003086 | Commit Loss: 0.001892 | Perplexity: 404.247810
2025-10-02 08:36:50,189 Stage: Train 0.5 | Epoch: 678 | Iter: 412600 | Total Loss: 0.004050 | Recon Loss: 0.003101 | Commit Loss: 0.001898 | Perplexity: 404.395000
2025-10-02 08:40:12,283 Stage: Train 0.5 | Epoch: 678 | Iter: 412800 | Total Loss: 0.004053 | Recon Loss: 0.003103 | Commit Loss: 0.001898 | Perplexity: 404.615914
Trainning Epoch:  83%|████████▎ | 679/823 [117:28:25<24:47:48, 619.92s/it]Trainning Epoch:  83%|████████▎ | 679/823 [117:28:25<24:47:47, 619.92s/it]Trainning Epoch:  83%|████████▎ | 679/823 [117:28:25<24:47:47, 619.91s/it]Trainning Epoch:  83%|████████▎ | 679/823 [117:28:25<24:47:47, 619.92s/it]2025-10-02 08:43:38,040 Stage: Train 0.5 | Epoch: 679 | Iter: 413000 | Total Loss: 0.004035 | Recon Loss: 0.003084 | Commit Loss: 0.001900 | Perplexity: 404.367223
2025-10-02 08:46:59,929 Stage: Train 0.5 | Epoch: 679 | Iter: 413200 | Total Loss: 0.004024 | Recon Loss: 0.003081 | Commit Loss: 0.001887 | Perplexity: 404.270260
2025-10-02 08:50:22,557 Stage: Train 0.5 | Epoch: 679 | Iter: 413400 | Total Loss: 0.004048 | Recon Loss: 0.003096 | Commit Loss: 0.001904 | Perplexity: 404.376047
Trainning Epoch:  83%|████████▎ | 680/823 [117:38:43<24:36:12, 619.39s/it]Trainning Epoch:  83%|████████▎ | 680/823 [117:38:43<24:36:13, 619.40s/it]Trainning Epoch:  83%|████████▎ | 680/823 [117:38:43<24:36:13, 619.39s/it]Trainning Epoch:  83%|████████▎ | 680/823 [117:38:43<24:36:13, 619.39s/it]2025-10-02 08:53:49,452 Stage: Train 0.5 | Epoch: 680 | Iter: 413600 | Total Loss: 0.004026 | Recon Loss: 0.003081 | Commit Loss: 0.001891 | Perplexity: 404.218788
2025-10-02 08:57:13,689 Stage: Train 0.5 | Epoch: 680 | Iter: 413800 | Total Loss: 0.004049 | Recon Loss: 0.003097 | Commit Loss: 0.001904 | Perplexity: 404.822814
2025-10-02 09:00:37,631 Stage: Train 0.5 | Epoch: 680 | Iter: 414000 | Total Loss: 0.004050 | Recon Loss: 0.003097 | Commit Loss: 0.001906 | Perplexity: 404.594771
Trainning Epoch:  83%|████████▎ | 681/823 [117:49:07<24:28:52, 620.65s/it]Trainning Epoch:  83%|████████▎ | 681/823 [117:49:07<24:28:56, 620.68s/it]Trainning Epoch:  83%|████████▎ | 681/823 [117:49:07<24:28:55, 620.67s/it]Trainning Epoch:  83%|████████▎ | 681/823 [117:49:07<24:28:55, 620.67s/it]2025-10-02 09:04:03,995 Stage: Train 0.5 | Epoch: 681 | Iter: 414200 | Total Loss: 0.004039 | Recon Loss: 0.003090 | Commit Loss: 0.001898 | Perplexity: 404.313385
2025-10-02 09:07:25,435 Stage: Train 0.5 | Epoch: 681 | Iter: 414400 | Total Loss: 0.004025 | Recon Loss: 0.003078 | Commit Loss: 0.001895 | Perplexity: 404.302293
2025-10-02 09:10:46,991 Stage: Train 0.5 | Epoch: 681 | Iter: 414600 | Total Loss: 0.004090 | Recon Loss: 0.003136 | Commit Loss: 0.001908 | Perplexity: 404.934986
Trainning Epoch:  83%|████████▎ | 682/823 [117:59:24<24:15:51, 619.51s/it]Trainning Epoch:  83%|████████▎ | 682/823 [117:59:24<24:15:52, 619.52s/it]Trainning Epoch:  83%|████████▎ | 682/823 [117:59:24<24:15:51, 619.52s/it]Trainning Epoch:  83%|████████▎ | 682/823 [117:59:24<24:15:52, 619.52s/it]2025-10-02 09:14:13,009 Stage: Train 0.5 | Epoch: 682 | Iter: 414800 | Total Loss: 0.004013 | Recon Loss: 0.003067 | Commit Loss: 0.001892 | Perplexity: 404.165786
2025-10-02 09:17:35,844 Stage: Train 0.5 | Epoch: 682 | Iter: 415000 | Total Loss: 0.004051 | Recon Loss: 0.003096 | Commit Loss: 0.001909 | Perplexity: 404.694417
2025-10-02 09:20:58,563 Stage: Train 0.5 | Epoch: 682 | Iter: 415200 | Total Loss: 0.004052 | Recon Loss: 0.003101 | Commit Loss: 0.001901 | Perplexity: 404.437703
Trainning Epoch:  83%|████████▎ | 683/823 [118:09:44<24:05:44, 619.61s/it]Trainning Epoch:  83%|████████▎ | 683/823 [118:09:44<24:05:43, 619.60s/it]Trainning Epoch:  83%|████████▎ | 683/823 [118:09:44<24:05:44, 619.60s/it]Trainning Epoch:  83%|████████▎ | 683/823 [118:09:44<24:05:44, 619.60s/it]2025-10-02 09:24:24,968 Stage: Train 0.5 | Epoch: 683 | Iter: 415400 | Total Loss: 0.004047 | Recon Loss: 0.003098 | Commit Loss: 0.001898 | Perplexity: 404.728304
2025-10-02 09:27:48,229 Stage: Train 0.5 | Epoch: 683 | Iter: 415600 | Total Loss: 0.004038 | Recon Loss: 0.003094 | Commit Loss: 0.001888 | Perplexity: 404.257635
2025-10-02 09:31:11,375 Stage: Train 0.5 | Epoch: 683 | Iter: 415800 | Total Loss: 0.004041 | Recon Loss: 0.003091 | Commit Loss: 0.001899 | Perplexity: 404.226054
Trainning Epoch:  83%|████████▎ | 684/823 [118:20:05<23:56:36, 620.12s/it]Trainning Epoch:  83%|████████▎ | 684/823 [118:20:05<23:56:35, 620.11s/it]Trainning Epoch:  83%|████████▎ | 684/823 [118:20:05<23:56:36, 620.12s/it]Trainning Epoch:  83%|████████▎ | 684/823 [118:20:05<23:56:36, 620.12s/it]2025-10-02 09:34:38,330 Stage: Train 0.5 | Epoch: 684 | Iter: 416000 | Total Loss: 0.004037 | Recon Loss: 0.003086 | Commit Loss: 0.001902 | Perplexity: 404.312205
2025-10-02 09:38:01,170 Stage: Train 0.5 | Epoch: 684 | Iter: 416200 | Total Loss: 0.004053 | Recon Loss: 0.003104 | Commit Loss: 0.001899 | Perplexity: 404.528029
2025-10-02 09:41:23,299 Stage: Train 0.5 | Epoch: 684 | Iter: 416400 | Total Loss: 0.004036 | Recon Loss: 0.003086 | Commit Loss: 0.001899 | Perplexity: 405.058262
Trainning Epoch:  83%|████████▎ | 685/823 [118:30:25<23:45:57, 619.98s/it]Trainning Epoch:  83%|████████▎ | 685/823 [118:30:25<23:45:58, 619.99s/it]Trainning Epoch:  83%|████████▎ | 685/823 [118:30:25<23:45:58, 619.99s/it]Trainning Epoch:  83%|████████▎ | 685/823 [118:30:25<23:45:58, 619.99s/it]2025-10-02 09:44:50,009 Stage: Train 0.5 | Epoch: 685 | Iter: 416600 | Total Loss: 0.004042 | Recon Loss: 0.003098 | Commit Loss: 0.001887 | Perplexity: 404.885563
2025-10-02 09:48:13,582 Stage: Train 0.5 | Epoch: 685 | Iter: 416800 | Total Loss: 0.004017 | Recon Loss: 0.003066 | Commit Loss: 0.001902 | Perplexity: 404.417266
2025-10-02 09:51:37,488 Stage: Train 0.5 | Epoch: 685 | Iter: 417000 | Total Loss: 0.004046 | Recon Loss: 0.003089 | Commit Loss: 0.001913 | Perplexity: 404.370816
Trainning Epoch:  83%|████████▎ | 686/823 [118:40:48<23:37:46, 620.92s/it]Trainning Epoch:  83%|████████▎ | 686/823 [118:40:48<23:37:45, 620.92s/it]Trainning Epoch:  83%|████████▎ | 686/823 [118:40:48<23:37:45, 620.92s/it]Trainning Epoch:  83%|████████▎ | 686/823 [118:40:48<23:37:45, 620.92s/it]2025-10-02 09:55:04,960 Stage: Train 0.5 | Epoch: 686 | Iter: 417200 | Total Loss: 0.004030 | Recon Loss: 0.003080 | Commit Loss: 0.001901 | Perplexity: 405.410702
2025-10-02 09:58:27,376 Stage: Train 0.5 | Epoch: 686 | Iter: 417400 | Total Loss: 0.004035 | Recon Loss: 0.003085 | Commit Loss: 0.001899 | Perplexity: 405.486428
2025-10-02 10:01:50,158 Stage: Train 0.5 | Epoch: 686 | Iter: 417600 | Total Loss: 0.004032 | Recon Loss: 0.003084 | Commit Loss: 0.001895 | Perplexity: 404.941756
Trainning Epoch:  83%|████████▎ | 687/823 [118:51:08<23:27:06, 620.78s/it]Trainning Epoch:  83%|████████▎ | 687/823 [118:51:08<23:27:05, 620.78s/it]Trainning Epoch:  83%|████████▎ | 687/823 [118:51:08<23:27:06, 620.78s/it]Trainning Epoch:  83%|████████▎ | 687/823 [118:51:08<23:27:07, 620.79s/it]2025-10-02 10:05:17,984 Stage: Train 0.5 | Epoch: 687 | Iter: 417800 | Total Loss: 0.004060 | Recon Loss: 0.003107 | Commit Loss: 0.001906 | Perplexity: 405.860125
2025-10-02 10:08:42,313 Stage: Train 0.5 | Epoch: 687 | Iter: 418000 | Total Loss: 0.004006 | Recon Loss: 0.003060 | Commit Loss: 0.001893 | Perplexity: 404.411826
2025-10-02 10:12:06,520 Stage: Train 0.5 | Epoch: 687 | Iter: 418200 | Total Loss: 0.004042 | Recon Loss: 0.003088 | Commit Loss: 0.001908 | Perplexity: 404.790481
Trainning Epoch:  84%|████████▎ | 688/823 [119:01:33<23:19:33, 622.03s/it]Trainning Epoch:  84%|████████▎ | 688/823 [119:01:33<23:19:34, 622.04s/it]Trainning Epoch:  84%|████████▎ | 688/823 [119:01:33<23:19:34, 622.03s/it]Trainning Epoch:  84%|████████▎ | 688/823 [119:01:33<23:19:34, 622.03s/it]2025-10-02 10:15:34,670 Stage: Train 0.5 | Epoch: 688 | Iter: 418400 | Total Loss: 0.004039 | Recon Loss: 0.003085 | Commit Loss: 0.001908 | Perplexity: 404.688534
2025-10-02 10:18:58,705 Stage: Train 0.5 | Epoch: 688 | Iter: 418600 | Total Loss: 0.004052 | Recon Loss: 0.003098 | Commit Loss: 0.001908 | Perplexity: 405.102338
2025-10-02 10:22:22,832 Stage: Train 0.5 | Epoch: 688 | Iter: 418800 | Total Loss: 0.004069 | Recon Loss: 0.003115 | Commit Loss: 0.001908 | Perplexity: 406.031889
Trainning Epoch:  84%|████████▎ | 689/823 [119:11:58<23:11:19, 622.98s/it]Trainning Epoch:  84%|████████▎ | 689/823 [119:11:58<23:11:19, 622.98s/it]Trainning Epoch:  84%|████████▎ | 689/823 [119:11:58<23:11:19, 622.98s/it]Trainning Epoch:  84%|████████▎ | 689/823 [119:11:58<23:11:18, 622.98s/it]2025-10-02 10:25:50,342 Stage: Train 0.5 | Epoch: 689 | Iter: 419000 | Total Loss: 0.004002 | Recon Loss: 0.003061 | Commit Loss: 0.001882 | Perplexity: 404.620790
2025-10-02 10:29:13,243 Stage: Train 0.5 | Epoch: 689 | Iter: 419200 | Total Loss: 0.004026 | Recon Loss: 0.003081 | Commit Loss: 0.001889 | Perplexity: 404.048344
2025-10-02 10:32:35,916 Stage: Train 0.5 | Epoch: 689 | Iter: 419400 | Total Loss: 0.004057 | Recon Loss: 0.003105 | Commit Loss: 0.001904 | Perplexity: 404.528543
Trainning Epoch:  84%|████████▍ | 690/823 [119:22:18<22:59:04, 622.14s/it]Trainning Epoch:  84%|████████▍ | 690/823 [119:22:18<22:59:03, 622.13s/it]Trainning Epoch:  84%|████████▍ | 690/823 [119:22:18<22:59:04, 622.14s/it]Trainning Epoch:  84%|████████▍ | 690/823 [119:22:18<22:59:05, 622.14s/it]2025-10-02 10:36:02,869 Stage: Train 0.5 | Epoch: 690 | Iter: 419600 | Total Loss: 0.003993 | Recon Loss: 0.003044 | Commit Loss: 0.001900 | Perplexity: 404.148205
2025-10-02 10:39:25,728 Stage: Train 0.5 | Epoch: 690 | Iter: 419800 | Total Loss: 0.004040 | Recon Loss: 0.003092 | Commit Loss: 0.001896 | Perplexity: 404.563154
2025-10-02 10:42:48,562 Stage: Train 0.5 | Epoch: 690 | Iter: 420000 | Total Loss: 0.004066 | Recon Loss: 0.003109 | Commit Loss: 0.001916 | Perplexity: 405.502120
2025-10-02 10:42:48,563 Saving model at iteration 420000
2025-10-02 10:42:49,156 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_691_step_420000
2025-10-02 10:42:49,757 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_691_step_420000/model.safetensors
2025-10-02 10:42:50,353 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_691_step_420000/optimizer.bin
2025-10-02 10:42:50,354 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_691_step_420000/scheduler.bin
2025-10-02 10:42:50,354 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_691_step_420000/sampler.bin
2025-10-02 10:42:50,355 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_691_step_420000/random_states_0.pkl
Trainning Epoch:  84%|████████▍ | 691/823 [119:32:41<22:48:40, 622.12s/it]Trainning Epoch:  84%|████████▍ | 691/823 [119:32:41<22:48:39, 622.12s/it]Trainning Epoch:  84%|████████▍ | 691/823 [119:32:41<22:48:39, 622.12s/it]Trainning Epoch:  84%|████████▍ | 691/823 [119:32:41<22:48:40, 622.12s/it]2025-10-02 10:46:17,006 Stage: Train 0.5 | Epoch: 691 | Iter: 420200 | Total Loss: 0.004028 | Recon Loss: 0.003077 | Commit Loss: 0.001901 | Perplexity: 404.722666
2025-10-02 10:49:40,495 Stage: Train 0.5 | Epoch: 691 | Iter: 420400 | Total Loss: 0.004037 | Recon Loss: 0.003084 | Commit Loss: 0.001907 | Perplexity: 404.683302
2025-10-02 10:53:03,920 Stage: Train 0.5 | Epoch: 691 | Iter: 420600 | Total Loss: 0.004029 | Recon Loss: 0.003076 | Commit Loss: 0.001907 | Perplexity: 404.879826
Trainning Epoch:  84%|████████▍ | 692/823 [119:43:04<22:38:53, 622.39s/it]Trainning Epoch:  84%|████████▍ | 692/823 [119:43:04<22:38:54, 622.40s/it]Trainning Epoch:  84%|████████▍ | 692/823 [119:43:04<22:38:53, 622.40s/it]Trainning Epoch:  84%|████████▍ | 692/823 [119:43:04<22:38:53, 622.40s/it]2025-10-02 10:56:32,091 Stage: Train 0.5 | Epoch: 692 | Iter: 420800 | Total Loss: 0.004036 | Recon Loss: 0.003082 | Commit Loss: 0.001908 | Perplexity: 404.804338
2025-10-02 10:59:54,908 Stage: Train 0.5 | Epoch: 692 | Iter: 421000 | Total Loss: 0.004005 | Recon Loss: 0.003061 | Commit Loss: 0.001888 | Perplexity: 404.149229
2025-10-02 11:03:18,716 Stage: Train 0.5 | Epoch: 692 | Iter: 421200 | Total Loss: 0.004037 | Recon Loss: 0.003085 | Commit Loss: 0.001904 | Perplexity: 405.181319
Trainning Epoch:  84%|████████▍ | 693/823 [119:53:26<22:28:38, 622.45s/it]Trainning Epoch:  84%|████████▍ | 693/823 [119:53:26<22:28:38, 622.45s/it]Trainning Epoch:  84%|████████▍ | 693/823 [119:53:26<22:28:38, 622.45s/it]Trainning Epoch:  84%|████████▍ | 693/823 [119:53:26<22:28:38, 622.45s/it]2025-10-02 11:06:46,501 Stage: Train 0.5 | Epoch: 693 | Iter: 421400 | Total Loss: 0.004036 | Recon Loss: 0.003080 | Commit Loss: 0.001911 | Perplexity: 404.933253
2025-10-02 11:10:09,541 Stage: Train 0.5 | Epoch: 693 | Iter: 421600 | Total Loss: 0.004012 | Recon Loss: 0.003064 | Commit Loss: 0.001896 | Perplexity: 404.258632
2025-10-02 11:13:32,542 Stage: Train 0.5 | Epoch: 693 | Iter: 421800 | Total Loss: 0.004035 | Recon Loss: 0.003090 | Commit Loss: 0.001890 | Perplexity: 405.545681
Trainning Epoch:  84%|████████▍ | 694/823 [120:03:47<22:17:19, 622.01s/it]Trainning Epoch:  84%|████████▍ | 694/823 [120:03:47<22:17:20, 622.02s/it]Trainning Epoch:  84%|████████▍ | 694/823 [120:03:47<22:17:20, 622.02s/it]Trainning Epoch:  84%|████████▍ | 694/823 [120:03:47<22:17:20, 622.02s/it]2025-10-02 11:16:59,409 Stage: Train 0.5 | Epoch: 694 | Iter: 422000 | Total Loss: 0.004048 | Recon Loss: 0.003092 | Commit Loss: 0.001912 | Perplexity: 405.254325
2025-10-02 11:20:22,080 Stage: Train 0.5 | Epoch: 694 | Iter: 422200 | Total Loss: 0.004021 | Recon Loss: 0.003073 | Commit Loss: 0.001896 | Perplexity: 405.118026
2025-10-02 11:23:45,954 Stage: Train 0.5 | Epoch: 694 | Iter: 422400 | Total Loss: 0.004056 | Recon Loss: 0.003101 | Commit Loss: 0.001910 | Perplexity: 404.802626
Trainning Epoch:  84%|████████▍ | 695/823 [120:14:10<22:07:14, 622.15s/it]Trainning Epoch:  84%|████████▍ | 695/823 [120:14:10<22:07:14, 622.14s/it]Trainning Epoch:  84%|████████▍ | 695/823 [120:14:10<22:07:14, 622.14s/it]Trainning Epoch:  84%|████████▍ | 695/823 [120:14:10<22:07:14, 622.14s/it]2025-10-02 11:27:13,997 Stage: Train 0.5 | Epoch: 695 | Iter: 422600 | Total Loss: 0.004019 | Recon Loss: 0.003067 | Commit Loss: 0.001903 | Perplexity: 404.471927
2025-10-02 11:30:36,738 Stage: Train 0.5 | Epoch: 695 | Iter: 422800 | Total Loss: 0.004030 | Recon Loss: 0.003076 | Commit Loss: 0.001908 | Perplexity: 405.331929
2025-10-02 11:33:59,818 Stage: Train 0.5 | Epoch: 695 | Iter: 423000 | Total Loss: 0.004033 | Recon Loss: 0.003084 | Commit Loss: 0.001899 | Perplexity: 404.482785
Trainning Epoch:  85%|████████▍ | 696/823 [120:24:31<21:56:41, 622.06s/it]Trainning Epoch:  85%|████████▍ | 696/823 [120:24:31<21:56:41, 622.06s/it]Trainning Epoch:  85%|████████▍ | 696/823 [120:24:31<21:56:42, 622.06s/it]Trainning Epoch:  85%|████████▍ | 696/823 [120:24:31<21:56:41, 622.06s/it]2025-10-02 11:37:27,375 Stage: Train 0.5 | Epoch: 696 | Iter: 423200 | Total Loss: 0.004026 | Recon Loss: 0.003072 | Commit Loss: 0.001908 | Perplexity: 404.686531
2025-10-02 11:40:49,999 Stage: Train 0.5 | Epoch: 696 | Iter: 423400 | Total Loss: 0.003998 | Recon Loss: 0.003052 | Commit Loss: 0.001890 | Perplexity: 404.458996
2025-10-02 11:44:12,516 Stage: Train 0.5 | Epoch: 696 | Iter: 423600 | Total Loss: 0.004034 | Recon Loss: 0.003084 | Commit Loss: 0.001900 | Perplexity: 404.796078
Trainning Epoch:  85%|████████▍ | 697/823 [120:34:52<21:45:16, 621.56s/it]Trainning Epoch:  85%|████████▍ | 697/823 [120:34:52<21:45:16, 621.56s/it]Trainning Epoch:  85%|████████▍ | 697/823 [120:34:52<21:45:16, 621.56s/it]Trainning Epoch:  85%|████████▍ | 697/823 [120:34:52<21:45:16, 621.56s/it]2025-10-02 11:47:39,779 Stage: Train 0.5 | Epoch: 697 | Iter: 423800 | Total Loss: 0.004046 | Recon Loss: 0.003098 | Commit Loss: 0.001896 | Perplexity: 404.329727
2025-10-02 11:51:02,337 Stage: Train 0.5 | Epoch: 697 | Iter: 424000 | Total Loss: 0.004008 | Recon Loss: 0.003058 | Commit Loss: 0.001899 | Perplexity: 404.346265
2025-10-02 11:54:24,217 Stage: Train 0.5 | Epoch: 697 | Iter: 424200 | Total Loss: 0.004003 | Recon Loss: 0.003054 | Commit Loss: 0.001898 | Perplexity: 404.214404
Trainning Epoch:  85%|████████▍ | 698/823 [120:45:10<21:33:00, 620.64s/it]Trainning Epoch:  85%|████████▍ | 698/823 [120:45:10<21:33:01, 620.65s/it]Trainning Epoch:  85%|████████▍ | 698/823 [120:45:10<21:33:00, 620.64s/it]Trainning Epoch:  85%|████████▍ | 698/823 [120:45:10<21:33:00, 620.64s/it]2025-10-02 11:57:49,941 Stage: Train 0.5 | Epoch: 698 | Iter: 424400 | Total Loss: 0.004048 | Recon Loss: 0.003095 | Commit Loss: 0.001907 | Perplexity: 405.393235
2025-10-02 12:01:11,961 Stage: Train 0.5 | Epoch: 698 | Iter: 424600 | Total Loss: 0.004006 | Recon Loss: 0.003055 | Commit Loss: 0.001903 | Perplexity: 404.703735
2025-10-02 12:04:34,525 Stage: Train 0.5 | Epoch: 698 | Iter: 424800 | Total Loss: 0.004054 | Recon Loss: 0.003100 | Commit Loss: 0.001907 | Perplexity: 405.210994
Trainning Epoch:  85%|████████▍ | 699/823 [120:55:30<21:21:58, 620.31s/it]Trainning Epoch:  85%|████████▍ | 699/823 [120:55:30<21:21:58, 620.31s/it]Trainning Epoch:  85%|████████▍ | 699/823 [120:55:30<21:21:58, 620.31s/it]Trainning Epoch:  85%|████████▍ | 699/823 [120:55:30<21:21:59, 620.32s/it]2025-10-02 12:08:01,707 Stage: Train 0.5 | Epoch: 699 | Iter: 425000 | Total Loss: 0.004026 | Recon Loss: 0.003074 | Commit Loss: 0.001903 | Perplexity: 404.843014
2025-10-02 12:11:24,346 Stage: Train 0.5 | Epoch: 699 | Iter: 425200 | Total Loss: 0.003999 | Recon Loss: 0.003050 | Commit Loss: 0.001899 | Perplexity: 404.759095
2025-10-02 12:14:47,674 Stage: Train 0.5 | Epoch: 699 | Iter: 425400 | Total Loss: 0.004033 | Recon Loss: 0.003084 | Commit Loss: 0.001898 | Perplexity: 405.029245
2025-10-02 12:18:11,481 Stage: Train 0.5 | Epoch: 699 | Iter: 425600 | Total Loss: 0.004024 | Recon Loss: 0.003076 | Commit Loss: 0.001895 | Perplexity: 404.164889
Trainning Epoch:  85%|████████▌ | 700/823 [121:05:52<21:12:36, 620.78s/it]Trainning Epoch:  85%|████████▌ | 700/823 [121:05:52<21:12:36, 620.79s/it]Trainning Epoch:  85%|████████▌ | 700/823 [121:05:52<21:12:36, 620.78s/it]Trainning Epoch:  85%|████████▌ | 700/823 [121:05:52<21:12:36, 620.78s/it]2025-10-02 12:21:37,458 Stage: Train 0.5 | Epoch: 700 | Iter: 425800 | Total Loss: 0.004028 | Recon Loss: 0.003080 | Commit Loss: 0.001897 | Perplexity: 405.231064
2025-10-02 12:24:59,532 Stage: Train 0.5 | Epoch: 700 | Iter: 426000 | Total Loss: 0.004024 | Recon Loss: 0.003072 | Commit Loss: 0.001904 | Perplexity: 404.122887
2025-10-02 12:28:22,087 Stage: Train 0.5 | Epoch: 700 | Iter: 426200 | Total Loss: 0.004041 | Recon Loss: 0.003084 | Commit Loss: 0.001914 | Perplexity: 405.182857
Trainning Epoch:  85%|████████▌ | 701/823 [121:16:10<21:00:59, 620.16s/it]Trainning Epoch:  85%|████████▌ | 701/823 [121:16:11<21:00:59, 620.16s/it]Trainning Epoch:  85%|████████▌ | 701/823 [121:16:11<21:00:59, 620.16s/it]Trainning Epoch:  85%|████████▌ | 701/823 [121:16:11<21:01:00, 620.16s/it]2025-10-02 12:31:48,625 Stage: Train 0.5 | Epoch: 701 | Iter: 426400 | Total Loss: 0.004026 | Recon Loss: 0.003081 | Commit Loss: 0.001889 | Perplexity: 403.722087
2025-10-02 12:35:12,027 Stage: Train 0.5 | Epoch: 701 | Iter: 426600 | Total Loss: 0.004023 | Recon Loss: 0.003074 | Commit Loss: 0.001899 | Perplexity: 404.949799
2025-10-02 12:38:36,052 Stage: Train 0.5 | Epoch: 701 | Iter: 426800 | Total Loss: 0.004043 | Recon Loss: 0.003088 | Commit Loss: 0.001911 | Perplexity: 404.719722
Trainning Epoch:  85%|████████▌ | 702/823 [121:26:33<20:51:49, 620.74s/it]Trainning Epoch:  85%|████████▌ | 702/823 [121:26:33<20:51:48, 620.74s/it]Trainning Epoch:  85%|████████▌ | 702/823 [121:26:33<20:51:48, 620.73s/it]Trainning Epoch:  85%|████████▌ | 702/823 [121:26:33<20:51:48, 620.73s/it]2025-10-02 12:42:03,152 Stage: Train 0.5 | Epoch: 702 | Iter: 427000 | Total Loss: 0.004016 | Recon Loss: 0.003070 | Commit Loss: 0.001892 | Perplexity: 405.279384
2025-10-02 12:45:26,464 Stage: Train 0.5 | Epoch: 702 | Iter: 427200 | Total Loss: 0.004034 | Recon Loss: 0.003086 | Commit Loss: 0.001896 | Perplexity: 404.692641
2025-10-02 12:48:50,464 Stage: Train 0.5 | Epoch: 702 | Iter: 427400 | Total Loss: 0.004017 | Recon Loss: 0.003067 | Commit Loss: 0.001901 | Perplexity: 404.456084
Trainning Epoch:  85%|████████▌ | 703/823 [121:36:55<20:42:41, 621.35s/it]Trainning Epoch:  85%|████████▌ | 703/823 [121:36:55<20:42:40, 621.34s/it]Trainning Epoch:  85%|████████▌ | 703/823 [121:36:55<20:42:41, 621.35s/it]Trainning Epoch:  85%|████████▌ | 703/823 [121:36:55<20:42:41, 621.34s/it]2025-10-02 12:52:16,459 Stage: Train 0.5 | Epoch: 703 | Iter: 427600 | Total Loss: 0.003976 | Recon Loss: 0.003036 | Commit Loss: 0.001881 | Perplexity: 404.266665
2025-10-02 12:55:38,580 Stage: Train 0.5 | Epoch: 703 | Iter: 427800 | Total Loss: 0.004020 | Recon Loss: 0.003071 | Commit Loss: 0.001899 | Perplexity: 404.476730
2025-10-02 12:59:00,603 Stage: Train 0.5 | Epoch: 703 | Iter: 428000 | Total Loss: 0.004014 | Recon Loss: 0.003061 | Commit Loss: 0.001906 | Perplexity: 403.978928
Trainning Epoch:  86%|████████▌ | 704/823 [121:47:13<20:30:13, 620.28s/it]Trainning Epoch:  86%|████████▌ | 704/823 [121:47:13<20:30:12, 620.28s/it]Trainning Epoch:  86%|████████▌ | 704/823 [121:47:13<20:30:12, 620.28s/it]Trainning Epoch:  86%|████████▌ | 704/823 [121:47:13<20:30:13, 620.28s/it]2025-10-02 13:02:25,775 Stage: Train 0.5 | Epoch: 704 | Iter: 428200 | Total Loss: 0.004015 | Recon Loss: 0.003068 | Commit Loss: 0.001894 | Perplexity: 404.392823
2025-10-02 13:05:47,053 Stage: Train 0.5 | Epoch: 704 | Iter: 428400 | Total Loss: 0.004010 | Recon Loss: 0.003059 | Commit Loss: 0.001902 | Perplexity: 405.296321
2025-10-02 13:09:08,846 Stage: Train 0.5 | Epoch: 704 | Iter: 428600 | Total Loss: 0.004036 | Recon Loss: 0.003084 | Commit Loss: 0.001904 | Perplexity: 404.072362
Trainning Epoch:  86%|████████▌ | 705/823 [121:57:30<20:17:36, 619.12s/it]Trainning Epoch:  86%|████████▌ | 705/823 [121:57:30<20:17:36, 619.13s/it]Trainning Epoch:  86%|████████▌ | 705/823 [121:57:30<20:17:36, 619.12s/it]Trainning Epoch:  86%|████████▌ | 705/823 [121:57:30<20:17:36, 619.12s/it]2025-10-02 13:12:34,467 Stage: Train 0.5 | Epoch: 705 | Iter: 428800 | Total Loss: 0.004005 | Recon Loss: 0.003057 | Commit Loss: 0.001896 | Perplexity: 404.935672
2025-10-02 13:15:57,006 Stage: Train 0.5 | Epoch: 705 | Iter: 429000 | Total Loss: 0.004001 | Recon Loss: 0.003056 | Commit Loss: 0.001890 | Perplexity: 403.906606
2025-10-02 13:19:20,153 Stage: Train 0.5 | Epoch: 705 | Iter: 429200 | Total Loss: 0.004055 | Recon Loss: 0.003100 | Commit Loss: 0.001911 | Perplexity: 405.230029
Trainning Epoch:  86%|████████▌ | 706/823 [122:07:49<20:07:39, 619.32s/it]Trainning Epoch:  86%|████████▌ | 706/823 [122:07:49<20:07:40, 619.32s/it]Trainning Epoch:  86%|████████▌ | 706/823 [122:07:49<20:07:40, 619.32s/it]Trainning Epoch:  86%|████████▌ | 706/823 [122:07:49<20:07:39, 619.32s/it]2025-10-02 13:22:46,980 Stage: Train 0.5 | Epoch: 706 | Iter: 429400 | Total Loss: 0.003996 | Recon Loss: 0.003051 | Commit Loss: 0.001890 | Perplexity: 404.972630
2025-10-02 13:26:10,587 Stage: Train 0.5 | Epoch: 706 | Iter: 429600 | Total Loss: 0.004009 | Recon Loss: 0.003057 | Commit Loss: 0.001905 | Perplexity: 405.054563
2025-10-02 13:29:33,965 Stage: Train 0.5 | Epoch: 706 | Iter: 429800 | Total Loss: 0.004040 | Recon Loss: 0.003084 | Commit Loss: 0.001912 | Perplexity: 405.332260
Trainning Epoch:  86%|████████▌ | 707/823 [122:18:11<19:58:53, 620.11s/it]Trainning Epoch:  86%|████████▌ | 707/823 [122:18:11<19:58:54, 620.12s/it]Trainning Epoch:  86%|████████▌ | 707/823 [122:18:11<19:58:54, 620.12s/it]Trainning Epoch:  86%|████████▌ | 707/823 [122:18:11<19:58:54, 620.13s/it]2025-10-02 13:33:00,165 Stage: Train 0.5 | Epoch: 707 | Iter: 430000 | Total Loss: 0.004003 | Recon Loss: 0.003056 | Commit Loss: 0.001893 | Perplexity: 405.311890
2025-10-02 13:36:22,834 Stage: Train 0.5 | Epoch: 707 | Iter: 430200 | Total Loss: 0.004002 | Recon Loss: 0.003055 | Commit Loss: 0.001893 | Perplexity: 404.493444
2025-10-02 13:39:45,050 Stage: Train 0.5 | Epoch: 707 | Iter: 430400 | Total Loss: 0.004060 | Recon Loss: 0.003104 | Commit Loss: 0.001912 | Perplexity: 405.630514
Trainning Epoch:  86%|████████▌ | 708/823 [122:28:30<19:47:54, 619.78s/it]Trainning Epoch:  86%|████████▌ | 708/823 [122:28:30<19:47:54, 619.78s/it]Trainning Epoch:  86%|████████▌ | 708/823 [122:28:30<19:47:54, 619.78s/it]Trainning Epoch:  86%|████████▌ | 708/823 [122:28:30<19:47:54, 619.78s/it]2025-10-02 13:43:11,636 Stage: Train 0.5 | Epoch: 708 | Iter: 430600 | Total Loss: 0.004000 | Recon Loss: 0.003053 | Commit Loss: 0.001894 | Perplexity: 404.622622
2025-10-02 13:46:34,467 Stage: Train 0.5 | Epoch: 708 | Iter: 430800 | Total Loss: 0.004021 | Recon Loss: 0.003070 | Commit Loss: 0.001902 | Perplexity: 404.666026
2025-10-02 13:49:57,706 Stage: Train 0.5 | Epoch: 708 | Iter: 431000 | Total Loss: 0.004034 | Recon Loss: 0.003076 | Commit Loss: 0.001917 | Perplexity: 404.814926
Trainning Epoch:  86%|████████▌ | 709/823 [122:38:51<19:38:03, 620.03s/it]Trainning Epoch:  86%|████████▌ | 709/823 [122:38:51<19:38:03, 620.03s/it]Trainning Epoch:  86%|████████▌ | 709/823 [122:38:51<19:38:03, 620.03s/it]Trainning Epoch:  86%|████████▌ | 709/823 [122:38:51<19:38:03, 620.03s/it]2025-10-02 13:53:22,941 Stage: Train 0.5 | Epoch: 709 | Iter: 431200 | Total Loss: 0.003999 | Recon Loss: 0.003048 | Commit Loss: 0.001901 | Perplexity: 405.649737
2025-10-02 13:56:45,202 Stage: Train 0.5 | Epoch: 709 | Iter: 431400 | Total Loss: 0.004017 | Recon Loss: 0.003063 | Commit Loss: 0.001910 | Perplexity: 404.484040
2025-10-02 14:00:07,645 Stage: Train 0.5 | Epoch: 709 | Iter: 431600 | Total Loss: 0.004004 | Recon Loss: 0.003054 | Commit Loss: 0.001900 | Perplexity: 404.132368
Trainning Epoch:  86%|████████▋ | 710/823 [122:49:09<19:26:37, 619.45s/it]Trainning Epoch:  86%|████████▋ | 710/823 [122:49:09<19:26:38, 619.46s/it]Trainning Epoch:  86%|████████▋ | 710/823 [122:49:09<19:26:37, 619.45s/it]Trainning Epoch:  86%|████████▋ | 710/823 [122:49:09<19:26:37, 619.45s/it]2025-10-02 14:03:34,074 Stage: Train 0.5 | Epoch: 710 | Iter: 431800 | Total Loss: 0.003997 | Recon Loss: 0.003050 | Commit Loss: 0.001893 | Perplexity: 404.147758
2025-10-02 14:06:55,965 Stage: Train 0.5 | Epoch: 710 | Iter: 432000 | Total Loss: 0.004017 | Recon Loss: 0.003063 | Commit Loss: 0.001909 | Perplexity: 405.364626
2025-10-02 14:10:17,977 Stage: Train 0.5 | Epoch: 710 | Iter: 432200 | Total Loss: 0.004025 | Recon Loss: 0.003072 | Commit Loss: 0.001907 | Perplexity: 405.488662
Trainning Epoch:  86%|████████▋ | 711/823 [122:59:27<19:15:38, 619.09s/it]Trainning Epoch:  86%|████████▋ | 711/823 [122:59:27<19:15:39, 619.10s/it]Trainning Epoch:  86%|████████▋ | 711/823 [122:59:27<19:15:38, 619.09s/it]Trainning Epoch:  86%|████████▋ | 711/823 [122:59:27<19:15:39, 619.10s/it]2025-10-02 14:13:44,863 Stage: Train 0.5 | Epoch: 711 | Iter: 432400 | Total Loss: 0.004037 | Recon Loss: 0.003085 | Commit Loss: 0.001905 | Perplexity: 405.861620
2025-10-02 14:17:08,497 Stage: Train 0.5 | Epoch: 711 | Iter: 432600 | Total Loss: 0.004017 | Recon Loss: 0.003070 | Commit Loss: 0.001893 | Perplexity: 404.825198
2025-10-02 14:20:31,906 Stage: Train 0.5 | Epoch: 711 | Iter: 432800 | Total Loss: 0.004032 | Recon Loss: 0.003080 | Commit Loss: 0.001905 | Perplexity: 404.485126
Trainning Epoch:  87%|████████▋ | 712/823 [123:09:50<19:07:14, 620.13s/it]Trainning Epoch:  87%|████████▋ | 712/823 [123:09:50<19:07:14, 620.13s/it]Trainning Epoch:  87%|████████▋ | 712/823 [123:09:50<19:07:14, 620.13s/it]Trainning Epoch:  87%|████████▋ | 712/823 [123:09:50<19:07:14, 620.13s/it]2025-10-02 14:23:59,200 Stage: Train 0.5 | Epoch: 712 | Iter: 433000 | Total Loss: 0.003976 | Recon Loss: 0.003027 | Commit Loss: 0.001897 | Perplexity: 404.169250
2025-10-02 14:27:22,424 Stage: Train 0.5 | Epoch: 712 | Iter: 433200 | Total Loss: 0.004033 | Recon Loss: 0.003084 | Commit Loss: 0.001898 | Perplexity: 405.412792
2025-10-02 14:30:45,884 Stage: Train 0.5 | Epoch: 712 | Iter: 433400 | Total Loss: 0.004021 | Recon Loss: 0.003060 | Commit Loss: 0.001923 | Perplexity: 405.351373
Trainning Epoch:  87%|████████▋ | 713/823 [123:20:12<18:58:07, 620.80s/it]Trainning Epoch:  87%|████████▋ | 713/823 [123:20:12<18:58:08, 620.80s/it]Trainning Epoch:  87%|████████▋ | 713/823 [123:20:12<18:58:08, 620.80s/it]Trainning Epoch:  87%|████████▋ | 713/823 [123:20:12<18:58:08, 620.80s/it]2025-10-02 14:34:13,090 Stage: Train 0.5 | Epoch: 713 | Iter: 433600 | Total Loss: 0.003979 | Recon Loss: 0.003032 | Commit Loss: 0.001893 | Perplexity: 404.308862
2025-10-02 14:37:36,665 Stage: Train 0.5 | Epoch: 713 | Iter: 433800 | Total Loss: 0.004004 | Recon Loss: 0.003054 | Commit Loss: 0.001899 | Perplexity: 405.613356
2025-10-02 14:41:00,728 Stage: Train 0.5 | Epoch: 713 | Iter: 434000 | Total Loss: 0.004005 | Recon Loss: 0.003051 | Commit Loss: 0.001908 | Perplexity: 404.538122
Trainning Epoch:  87%|████████▋ | 714/823 [123:30:35<18:49:08, 621.55s/it]Trainning Epoch:  87%|████████▋ | 714/823 [123:30:36<18:49:09, 621.55s/it]Trainning Epoch:  87%|████████▋ | 714/823 [123:30:36<18:49:09, 621.55s/it]Trainning Epoch:  87%|████████▋ | 714/823 [123:30:36<18:49:09, 621.55s/it]2025-10-02 14:44:28,734 Stage: Train 0.5 | Epoch: 714 | Iter: 434200 | Total Loss: 0.004039 | Recon Loss: 0.003078 | Commit Loss: 0.001922 | Perplexity: 405.776631
2025-10-02 14:47:52,201 Stage: Train 0.5 | Epoch: 714 | Iter: 434400 | Total Loss: 0.004001 | Recon Loss: 0.003048 | Commit Loss: 0.001907 | Perplexity: 405.542796
2025-10-02 14:51:16,004 Stage: Train 0.5 | Epoch: 714 | Iter: 434600 | Total Loss: 0.004012 | Recon Loss: 0.003059 | Commit Loss: 0.001904 | Perplexity: 404.613011
Trainning Epoch:  87%|████████▋ | 715/823 [123:40:59<18:39:37, 622.02s/it]Trainning Epoch:  87%|████████▋ | 715/823 [123:40:59<18:39:38, 622.02s/it]Trainning Epoch:  87%|████████▋ | 715/823 [123:40:59<18:39:37, 622.02s/it]Trainning Epoch:  87%|████████▋ | 715/823 [123:40:59<18:39:38, 622.02s/it]2025-10-02 14:54:43,513 Stage: Train 0.5 | Epoch: 715 | Iter: 434800 | Total Loss: 0.004028 | Recon Loss: 0.003072 | Commit Loss: 0.001911 | Perplexity: 404.762066
2025-10-02 14:58:06,419 Stage: Train 0.5 | Epoch: 715 | Iter: 435000 | Total Loss: 0.004010 | Recon Loss: 0.003057 | Commit Loss: 0.001905 | Perplexity: 404.140443
2025-10-02 15:01:30,079 Stage: Train 0.5 | Epoch: 715 | Iter: 435200 | Total Loss: 0.004042 | Recon Loss: 0.003086 | Commit Loss: 0.001912 | Perplexity: 405.924751
Trainning Epoch:  87%|████████▋ | 716/823 [123:51:21<18:29:15, 622.01s/it]Trainning Epoch:  87%|████████▋ | 716/823 [123:51:21<18:29:15, 622.01s/it]Trainning Epoch:  87%|████████▋ | 716/823 [123:51:21<18:29:15, 622.01s/it]Trainning Epoch:  87%|████████▋ | 716/823 [123:51:21<18:29:15, 622.01s/it]2025-10-02 15:04:57,424 Stage: Train 0.5 | Epoch: 716 | Iter: 435400 | Total Loss: 0.004026 | Recon Loss: 0.003070 | Commit Loss: 0.001912 | Perplexity: 405.513257
2025-10-02 15:08:20,413 Stage: Train 0.5 | Epoch: 716 | Iter: 435600 | Total Loss: 0.004001 | Recon Loss: 0.003048 | Commit Loss: 0.001906 | Perplexity: 405.166554
2025-10-02 15:11:43,818 Stage: Train 0.5 | Epoch: 716 | Iter: 435800 | Total Loss: 0.004018 | Recon Loss: 0.003065 | Commit Loss: 0.001906 | Perplexity: 404.463203
Trainning Epoch:  87%|████████▋ | 717/823 [124:01:42<18:18:38, 621.87s/it]Trainning Epoch:  87%|████████▋ | 717/823 [124:01:42<18:18:37, 621.87s/it]Trainning Epoch:  87%|████████▋ | 717/823 [124:01:42<18:18:38, 621.87s/it]Trainning Epoch:  87%|████████▋ | 717/823 [124:01:42<18:18:38, 621.87s/it]2025-10-02 15:15:10,841 Stage: Train 0.5 | Epoch: 717 | Iter: 436000 | Total Loss: 0.004012 | Recon Loss: 0.003058 | Commit Loss: 0.001908 | Perplexity: 404.508338
2025-10-02 15:18:32,855 Stage: Train 0.5 | Epoch: 717 | Iter: 436200 | Total Loss: 0.004026 | Recon Loss: 0.003071 | Commit Loss: 0.001912 | Perplexity: 404.923066
2025-10-02 15:21:54,874 Stage: Train 0.5 | Epoch: 717 | Iter: 436400 | Total Loss: 0.003980 | Recon Loss: 0.003032 | Commit Loss: 0.001896 | Perplexity: 403.561459
Trainning Epoch:  87%|████████▋ | 718/823 [124:12:01<18:06:37, 620.93s/it]Trainning Epoch:  87%|████████▋ | 718/823 [124:12:01<18:06:38, 620.93s/it]Trainning Epoch:  87%|████████▋ | 718/823 [124:12:01<18:06:38, 620.93s/it]Trainning Epoch:  87%|████████▋ | 718/823 [124:12:01<18:06:38, 620.94s/it]2025-10-02 15:25:21,657 Stage: Train 0.5 | Epoch: 718 | Iter: 436600 | Total Loss: 0.004024 | Recon Loss: 0.003070 | Commit Loss: 0.001907 | Perplexity: 404.279491
2025-10-02 15:28:44,853 Stage: Train 0.5 | Epoch: 718 | Iter: 436800 | Total Loss: 0.004025 | Recon Loss: 0.003068 | Commit Loss: 0.001915 | Perplexity: 405.642505
2025-10-02 15:32:07,977 Stage: Train 0.5 | Epoch: 718 | Iter: 437000 | Total Loss: 0.004000 | Recon Loss: 0.003049 | Commit Loss: 0.001900 | Perplexity: 404.679461
Trainning Epoch:  87%|████████▋ | 719/823 [124:22:23<17:56:55, 621.30s/it]Trainning Epoch:  87%|████████▋ | 719/823 [124:22:23<17:56:55, 621.30s/it]Trainning Epoch:  87%|████████▋ | 719/823 [124:22:23<17:56:55, 621.31s/it]Trainning Epoch:  87%|████████▋ | 719/823 [124:22:23<17:56:55, 621.31s/it]2025-10-02 15:35:35,199 Stage: Train 0.5 | Epoch: 719 | Iter: 437200 | Total Loss: 0.003989 | Recon Loss: 0.003038 | Commit Loss: 0.001902 | Perplexity: 404.362577
2025-10-02 15:38:58,089 Stage: Train 0.5 | Epoch: 719 | Iter: 437400 | Total Loss: 0.004012 | Recon Loss: 0.003060 | Commit Loss: 0.001904 | Perplexity: 404.893573
2025-10-02 15:42:21,597 Stage: Train 0.5 | Epoch: 719 | Iter: 437600 | Total Loss: 0.004017 | Recon Loss: 0.003066 | Commit Loss: 0.001902 | Perplexity: 404.293515
Trainning Epoch:  87%|████████▋ | 720/823 [124:32:45<17:47:01, 621.56s/it]Trainning Epoch:  87%|████████▋ | 720/823 [124:32:45<17:47:01, 621.57s/it]Trainning Epoch:  87%|████████▋ | 720/823 [124:32:45<17:47:01, 621.57s/it]Trainning Epoch:  87%|████████▋ | 720/823 [124:32:45<17:47:01, 621.57s/it]2025-10-02 15:45:49,635 Stage: Train 0.5 | Epoch: 720 | Iter: 437800 | Total Loss: 0.004006 | Recon Loss: 0.003048 | Commit Loss: 0.001915 | Perplexity: 405.575758
2025-10-02 15:49:12,109 Stage: Train 0.5 | Epoch: 720 | Iter: 438000 | Total Loss: 0.003983 | Recon Loss: 0.003037 | Commit Loss: 0.001894 | Perplexity: 405.078299
2025-10-02 15:52:34,866 Stage: Train 0.5 | Epoch: 720 | Iter: 438200 | Total Loss: 0.004029 | Recon Loss: 0.003069 | Commit Loss: 0.001919 | Perplexity: 405.348555
Trainning Epoch:  88%|████████▊ | 721/823 [124:43:05<17:35:45, 621.03s/it]Trainning Epoch:  88%|████████▊ | 721/823 [124:43:05<17:35:44, 621.03s/it]Trainning Epoch:  88%|████████▊ | 721/823 [124:43:05<17:35:45, 621.03s/it]Trainning Epoch:  88%|████████▊ | 721/823 [124:43:05<17:35:44, 621.03s/it]2025-10-02 15:56:01,042 Stage: Train 0.5 | Epoch: 721 | Iter: 438400 | Total Loss: 0.004019 | Recon Loss: 0.003061 | Commit Loss: 0.001917 | Perplexity: 404.948810
2025-10-02 15:59:23,685 Stage: Train 0.5 | Epoch: 721 | Iter: 438600 | Total Loss: 0.003990 | Recon Loss: 0.003041 | Commit Loss: 0.001898 | Perplexity: 404.335499
2025-10-02 16:02:46,809 Stage: Train 0.5 | Epoch: 721 | Iter: 438800 | Total Loss: 0.004009 | Recon Loss: 0.003059 | Commit Loss: 0.001900 | Perplexity: 404.431038
Trainning Epoch:  88%|████████▊ | 722/823 [124:53:26<17:25:22, 621.02s/it]Trainning Epoch:  88%|████████▊ | 722/823 [124:53:26<17:25:22, 621.01s/it]Trainning Epoch:  88%|████████▊ | 722/823 [124:53:26<17:25:22, 621.02s/it]Trainning Epoch:  88%|████████▊ | 722/823 [124:53:26<17:25:22, 621.02s/it]2025-10-02 16:06:13,897 Stage: Train 0.5 | Epoch: 722 | Iter: 439000 | Total Loss: 0.003974 | Recon Loss: 0.003024 | Commit Loss: 0.001899 | Perplexity: 404.823330
2025-10-02 16:09:37,610 Stage: Train 0.5 | Epoch: 722 | Iter: 439200 | Total Loss: 0.004019 | Recon Loss: 0.003070 | Commit Loss: 0.001897 | Perplexity: 404.974919
2025-10-02 16:13:00,850 Stage: Train 0.5 | Epoch: 722 | Iter: 439400 | Total Loss: 0.003989 | Recon Loss: 0.003035 | Commit Loss: 0.001909 | Perplexity: 404.268513
Trainning Epoch:  88%|████████▊ | 723/823 [125:03:48<17:15:39, 621.40s/it]Trainning Epoch:  88%|████████▊ | 723/823 [125:03:48<17:15:40, 621.40s/it]Trainning Epoch:  88%|████████▊ | 723/823 [125:03:48<17:15:40, 621.40s/it]Trainning Epoch:  88%|████████▊ | 723/823 [125:03:48<17:15:41, 621.41s/it]2025-10-02 16:16:28,397 Stage: Train 0.5 | Epoch: 723 | Iter: 439600 | Total Loss: 0.004025 | Recon Loss: 0.003069 | Commit Loss: 0.001911 | Perplexity: 404.747591
2025-10-02 16:19:54,055 Stage: Train 0.5 | Epoch: 723 | Iter: 439800 | Total Loss: 0.004014 | Recon Loss: 0.003058 | Commit Loss: 0.001911 | Perplexity: 404.904100
2025-10-02 16:23:19,771 Stage: Train 0.5 | Epoch: 723 | Iter: 440000 | Total Loss: 0.004022 | Recon Loss: 0.003071 | Commit Loss: 0.001902 | Perplexity: 404.484706
2025-10-02 16:23:19,771 Saving model at iteration 440000
2025-10-02 16:23:20,220 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_724_step_440000
2025-10-02 16:23:20,794 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_724_step_440000/model.safetensors
2025-10-02 16:23:21,341 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_724_step_440000/optimizer.bin
2025-10-02 16:23:21,342 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_724_step_440000/scheduler.bin
2025-10-02 16:23:21,342 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_724_step_440000/sampler.bin
2025-10-02 16:23:21,343 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFixExclStage4.2_lvl3_ratio0.5/models/checkpoint_epoch_724_step_440000/random_states_0.pkl
Trainning Epoch:  88%|████████▊ | 724/823 [125:14:19<17:10:02, 624.27s/it]Trainning Epoch:  88%|████████▊ | 724/823 [125:14:19<17:10:02, 624.27s/it]Trainning Epoch:  88%|████████▊ | 724/823 [125:14:19<17:10:02, 624.27s/it]Trainning Epoch:  88%|████████▊ | 724/823 [125:14:19<17:10:03, 624.28s/it]2025-10-02 16:26:51,184 Stage: Train 0.5 | Epoch: 724 | Iter: 440200 | Total Loss: 0.004032 | Recon Loss: 0.003071 | Commit Loss: 0.001922 | Perplexity: 405.696266
2025-10-02 16:30:14,964 Stage: Train 0.5 | Epoch: 724 | Iter: 440400 | Total Loss: 0.003951 | Recon Loss: 0.003007 | Commit Loss: 0.001888 | Perplexity: 404.095171
2025-10-02 16:33:39,681 Stage: Train 0.5 | Epoch: 724 | Iter: 440600 | Total Loss: 0.004008 | Recon Loss: 0.003057 | Commit Loss: 0.001901 | Perplexity: 405.423806
2025-10-02 16:37:04,454 Stage: Train 0.5 | Epoch: 724 | Iter: 440800 | Total Loss: 0.003994 | Recon Loss: 0.003045 | Commit Loss: 0.001900 | Perplexity: 404.203420
Trainning Epoch:  88%|████████▊ | 725/823 [125:24:45<17:00:14, 624.63s/it]Trainning Epoch:  88%|████████▊ | 725/823 [125:24:45<17:00:13, 624.63s/it]Trainning Epoch:  88%|████████▊ | 725/823 [125:24:45<17:00:14, 624.64s/it]Trainning Epoch:  88%|████████▊ | 725/823 [125:24:45<17:00:14, 624.64s/it]2025-10-02 16:40:31,352 Stage: Train 0.5 | Epoch: 725 | Iter: 441000 | Total Loss: 0.003984 | Recon Loss: 0.003033 | Commit Loss: 0.001903 | Perplexity: 404.438046
2025-10-02 16:43:54,659 Stage: Train 0.5 | Epoch: 725 | Iter: 441200 | Total Loss: 0.004011 | Recon Loss: 0.003050 | Commit Loss: 0.001921 | Perplexity: 405.212713
2025-10-02 16:47:18,488 Stage: Train 0.5 | Epoch: 725 | Iter: 441400 | Total Loss: 0.004012 | Recon Loss: 0.003063 | Commit Loss: 0.001898 | Perplexity: 404.957130
Trainning Epoch:  88%|████████▊ | 726/823 [125:35:07<16:48:40, 623.92s/it]Trainning Epoch:  88%|████████▊ | 726/823 [125:35:07<16:48:41, 623.93s/it]Trainning Epoch:  88%|████████▊ | 726/823 [125:35:07<16:48:40, 623.93s/it]Trainning Epoch:  88%|████████▊ | 726/823 [125:35:07<16:48:41, 623.93s/it]2025-10-02 16:50:46,064 Stage: Train 0.5 | Epoch: 726 | Iter: 441600 | Total Loss: 0.003971 | Recon Loss: 0.003021 | Commit Loss: 0.001901 | Perplexity: 404.748201
2025-10-02 16:54:12,615 Stage: Train 0.5 | Epoch: 726 | Iter: 441800 | Total Loss: 0.004008 | Recon Loss: 0.003055 | Commit Loss: 0.001907 | Perplexity: 405.323701
2025-10-02 16:57:39,196 Stage: Train 0.5 | Epoch: 726 | Iter: 442000 | Total Loss: 0.004021 | Recon Loss: 0.003065 | Commit Loss: 0.001913 | Perplexity: 405.199495
Trainning Epoch:  88%|████████▊ | 727/823 [125:45:36<16:40:34, 625.36s/it]Trainning Epoch:  88%|████████▊ | 727/823 [125:45:36<16:40:35, 625.37s/it]Trainning Epoch:  88%|████████▊ | 727/823 [125:45:36<16:40:34, 625.36s/it]Trainning Epoch:  88%|████████▊ | 727/823 [125:45:36<16:40:34, 625.36s/it]2025-10-02 17:01:08,192 Stage: Train 0.5 | Epoch: 727 | Iter: 442200 | Total Loss: 0.004004 | Recon Loss: 0.003060 | Commit Loss: 0.001888 | Perplexity: 404.070887
2025-10-02 17:04:33,112 Stage: Train 0.5 | Epoch: 727 | Iter: 442400 | Total Loss: 0.004002 | Recon Loss: 0.003052 | Commit Loss: 0.001900 | Perplexity: 404.825889
2025-10-02 17:07:58,114 Stage: Train 0.5 | Epoch: 727 | Iter: 442600 | Total Loss: 0.003995 | Recon Loss: 0.003046 | Commit Loss: 0.001897 | Perplexity: 404.441116
Trainning Epoch:  88%|████████▊ | 728/823 [125:56:03<16:31:01, 625.91s/it]Trainning Epoch:  88%|████████▊ | 728/823 [125:56:03<16:31:01, 625.91s/it]Trainning Epoch:  88%|████████▊ | 728/823 [125:56:03<16:31:00, 625.90s/it]Trainning Epoch:  88%|████████▊ | 728/823 [125:56:03<16:31:00, 625.90s/it]W1002 17:08:43.280000 3272305 /data1/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3272535 closing signal SIGTERM
W1002 17:08:43.281000 3272305 /data1/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3272537 closing signal SIGTERM
E1002 17:08:43.298000 3272305 /data1/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: -9) local_rank: 1 (pid: 3272536) of binary: /home/wxs/anaconda3/envs/llama_factory/bin/python3.10
Traceback (most recent call last):
  File "/home/wxs/anaconda3/envs/llama_factory/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1189, in launch_command
    multi_gpu_launcher(args)
  File "/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
  File "/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
train_vqvae_new.py FAILED
--------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-02_17:08:43
  host      : dbcloud
  rank      : 3 (local_rank: 3)
  exitcode  : -9 (pid: 3272538)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 3272538
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-02_17:08:43
  host      : dbcloud
  rank      : 1 (local_rank: 1)
  exitcode  : -9 (pid: 3272536)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 3272536
========================================================
