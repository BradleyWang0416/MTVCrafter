The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/accelerator.py:498: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-09-26 13:11:35,635 
python train_vqvae_new.py --batch_size 64 --config vqvae_experiment_configs/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/config.yaml --data_mode joint3d --num_frames 16 --sample_stride 1 --data_stride 16 --project_dir vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5 --not_find_unused_parameters --nb_code 4096 --codebook_dim 2048 --loss_type mpjpe --vqvae_type hybrid --hrnet_output_level 3 --vision_guidance_ratio 0.5 --downsample_time [1,2] --frame_upsample_rate [2.0,1.0] --fix_weights --resume_pth vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_160000
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/accelerate/accelerator.py:498: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
2025-09-26 13:13:06,194 Data loaded with 97196 samples
vision backbone weights are fixed
2025-09-26 13:13:06,776 Trainable parameters: 51,288,835
2025-09-26 13:13:06,776 Non-trainable parameters: 28,535,552
vision backbone weights are fixed
2025-09-26 13:13:12,259 Loading checkpoint from vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_160000
2025-09-26 13:13:12,259 Resuming from epoch 211 and iteration 160000
Missing keys: []Missing keys: []

Unexpected keys: []Unexpected keys: []

Trainning Epoch:  32%|███▏      | 211/658 [00:00<?, ?it/s]2025-09-26 13:13:12,421 Number of trainable parameters: 51.288835 M
2025-09-26 13:13:12,422 Args: {'num_frames': 16, 'sample_stride': 1, 'data_stride': 16, 'data_mode': 'joint3d', 'load_data_file': '/data2/wxs/DATASETS/Human3.6M_for_MotionBERT/h36m_sh_conf_cam_source_final_wImgPath_wJ3dCam_wJ2dCpn.pkl', 'load_image_source_file': '/data2/wxs/DATASETS/Human3.6M_for_MotionBERT/images_source.pkl', 'load_bbox_file': '/data2/wxs/DATASETS/Human3.6M_for_MotionBERT/bboxes_xyxy.pkl', 'load_text_source_file': '', 'return_extra': [['image']], 'normalize': 'anisotropic', 'filter_invalid_images': True, 'processed_image_shape': [192, 256], 'backbone': 'hrnet_32', 'get_item_list': ['factor_2_5d', 'video_rgb', 'joint3d_image_affined', 'joint3d_image_affined_normed', 'joint3d_image_affined_scale', 'joint3d_image_affined_transl', 'affine_trans', 'affine_trans_inv', 'joint_2_5d_image'], 'config': 'vqvae_experiment_configs/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/config.yaml', 'resume_pth': 'vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_160000', 'batch_size': 64, 'commit_ratio': 0.5, 'nb_code': 4096, 'codebook_dim': 2048, 'max_epoch': 1000000000.0, 'total_iter': 500000, 'world_size': 1, 'rank': 0, 'save_interval': 20000, 'warm_up_iter': 5000, 'print_iter': 200, 'learning_rate': 0.0002, 'lr_schedule': [300000], 'gamma': 0.05, 'weight_decay': 0.0001, 'device': 'cuda', 'project_config': '', 'allow_tf32': False, 'project_dir': 'vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5', 'seed': 6666, 'not_find_unused_parameters': True, 'loss_type': 'mpjpe', 'vqvae_type': 'hybrid', 'joint_data_type': 'joint3d_image_affined_normed', 'hrnet_output_level': 3, 'fix_weights': True, 'vision_guidance_ratio': 0.5, 'downsample_time': [1, 2], 'frame_upsample_rate': [2.0, 1.0]}
Trainning Epoch:  32%|███▏      | 211/658 [00:00<?, ?it/s]2025-09-26 13:17:24,353 Stage: Train 0.5 | Epoch: 0 | Iter: 160200 | Total Loss: 0.004730 | Recon Loss: 0.003994 | Commit Loss: 0.001472 | Perplexity: 997.511595
2025-09-26 13:21:33,594 Stage: Train 0.5 | Epoch: 0 | Iter: 160400 | Total Loss: 0.004128 | Recon Loss: 0.003376 | Commit Loss: 0.001505 | Perplexity: 1006.922350
2025-09-26 13:25:43,434 Stage: Train 0.5 | Epoch: 0 | Iter: 160600 | Total Loss: 0.004148 | Recon Loss: 0.003409 | Commit Loss: 0.001477 | Perplexity: 1053.420710
Trainning Epoch:  32%|███▏      | 212/658 [15:50<117:46:57, 950.71s/it]Trainning Epoch:  32%|███▏      | 212/658 [15:50<117:47:00, 950.72s/it]2025-09-26 13:29:56,354 Stage: Train 0.5 | Epoch: 1 | Iter: 160800 | Total Loss: 0.003817 | Recon Loss: 0.003208 | Commit Loss: 0.001219 | Perplexity: 1547.399007
2025-09-26 13:34:05,354 Stage: Train 0.5 | Epoch: 1 | Iter: 161000 | Total Loss: 0.003589 | Recon Loss: 0.003058 | Commit Loss: 0.001063 | Perplexity: 1837.135465
2025-09-26 13:38:14,229 Stage: Train 0.5 | Epoch: 1 | Iter: 161200 | Total Loss: 0.003484 | Recon Loss: 0.003000 | Commit Loss: 0.000967 | Perplexity: 1974.163892
2025-09-26 13:42:23,447 Stage: Train 0.5 | Epoch: 1 | Iter: 161400 | Total Loss: 0.003404 | Recon Loss: 0.002966 | Commit Loss: 0.000875 | Perplexity: 2053.692635
Trainning Epoch:  32%|███▏      | 213/658 [31:39<117:24:30, 949.82s/it]Trainning Epoch:  32%|███▏      | 213/658 [31:39<117:24:30, 949.82s/it]2025-09-26 13:46:32,931 Stage: Train 0.5 | Epoch: 2 | Iter: 161600 | Total Loss: 0.003334 | Recon Loss: 0.002921 | Commit Loss: 0.000825 | Perplexity: 2106.721881
2025-09-26 13:50:37,525 Stage: Train 0.5 | Epoch: 2 | Iter: 161800 | Total Loss: 0.003256 | Recon Loss: 0.002871 | Commit Loss: 0.000770 | Perplexity: 2158.322479
2025-09-26 13:54:42,661 Stage: Train 0.5 | Epoch: 2 | Iter: 162000 | Total Loss: 0.003241 | Recon Loss: 0.002872 | Commit Loss: 0.000737 | Perplexity: 2192.456074
2025-09-26 13:58:48,110 Stage: Train 0.5 | Epoch: 2 | Iter: 162200 | Total Loss: 0.003194 | Recon Loss: 0.002841 | Commit Loss: 0.000707 | Perplexity: 2224.739453
Trainning Epoch:  33%|███▎      | 214/658 [47:14<116:16:12, 942.73s/it]Trainning Epoch:  33%|███▎      | 214/658 [47:14<116:16:12, 942.73s/it]2025-09-26 14:02:58,146 Stage: Train 0.5 | Epoch: 3 | Iter: 162400 | Total Loss: 0.003191 | Recon Loss: 0.002845 | Commit Loss: 0.000692 | Perplexity: 2246.758973
2025-09-26 14:07:06,516 Stage: Train 0.5 | Epoch: 3 | Iter: 162600 | Total Loss: 0.003190 | Recon Loss: 0.002853 | Commit Loss: 0.000675 | Perplexity: 2269.331748
2025-09-26 14:11:15,760 Stage: Train 0.5 | Epoch: 3 | Iter: 162800 | Total Loss: 0.003149 | Recon Loss: 0.002814 | Commit Loss: 0.000669 | Perplexity: 2287.861709
2025-09-26 14:15:24,659 Stage: Train 0.5 | Epoch: 3 | Iter: 163000 | Total Loss: 0.003105 | Recon Loss: 0.002786 | Commit Loss: 0.000638 | Perplexity: 2296.367661
Trainning Epoch:  33%|███▎      | 215/658 [1:03:01<116:14:11, 944.58s/it]Trainning Epoch:  33%|███▎      | 215/658 [1:03:01<116:14:12, 944.59s/it]2025-09-26 14:19:35,667 Stage: Train 0.5 | Epoch: 4 | Iter: 163200 | Total Loss: 0.003134 | Recon Loss: 0.002811 | Commit Loss: 0.000645 | Perplexity: 2309.395255
2025-09-26 14:23:44,494 Stage: Train 0.5 | Epoch: 4 | Iter: 163400 | Total Loss: 0.003136 | Recon Loss: 0.002816 | Commit Loss: 0.000641 | Perplexity: 2319.063494
2025-09-26 14:27:54,639 Stage: Train 0.5 | Epoch: 4 | Iter: 163600 | Total Loss: 0.003059 | Recon Loss: 0.002746 | Commit Loss: 0.000626 | Perplexity: 2335.035859
2025-09-26 14:32:05,173 Stage: Train 0.5 | Epoch: 4 | Iter: 163800 | Total Loss: 0.003112 | Recon Loss: 0.002797 | Commit Loss: 0.000629 | Perplexity: 2342.013533
Trainning Epoch:  33%|███▎      | 216/658 [1:18:52<116:16:04, 946.98s/it]Trainning Epoch:  33%|███▎      | 216/658 [1:18:52<116:16:04, 946.98s/it]2025-09-26 14:36:19,173 Stage: Train 0.5 | Epoch: 5 | Iter: 164000 | Total Loss: 0.003055 | Recon Loss: 0.002740 | Commit Loss: 0.000629 | Perplexity: 2347.685349
2025-09-26 14:40:30,245 Stage: Train 0.5 | Epoch: 5 | Iter: 164200 | Total Loss: 0.003109 | Recon Loss: 0.002791 | Commit Loss: 0.000637 | Perplexity: 2360.876790
2025-09-26 14:44:42,213 Stage: Train 0.5 | Epoch: 5 | Iter: 164400 | Total Loss: 0.003032 | Recon Loss: 0.002723 | Commit Loss: 0.000618 | Perplexity: 2367.907391
Trainning Epoch:  33%|███▎      | 217/658 [1:34:51<116:29:07, 950.90s/it]Trainning Epoch:  33%|███▎      | 217/658 [1:34:51<116:29:08, 950.90s/it]2025-09-26 14:48:57,058 Stage: Train 0.5 | Epoch: 6 | Iter: 164600 | Total Loss: 0.003059 | Recon Loss: 0.002748 | Commit Loss: 0.000623 | Perplexity: 2379.956023
2025-09-26 14:53:06,897 Stage: Train 0.5 | Epoch: 6 | Iter: 164800 | Total Loss: 0.002998 | Recon Loss: 0.002690 | Commit Loss: 0.000616 | Perplexity: 2382.002632
2025-09-26 14:57:17,839 Stage: Train 0.5 | Epoch: 6 | Iter: 165000 | Total Loss: 0.003009 | Recon Loss: 0.002700 | Commit Loss: 0.000619 | Perplexity: 2389.851603
2025-09-26 15:01:29,221 Stage: Train 0.5 | Epoch: 6 | Iter: 165200 | Total Loss: 0.003076 | Recon Loss: 0.002763 | Commit Loss: 0.000627 | Perplexity: 2399.510898
Trainning Epoch:  33%|███▎      | 218/658 [1:50:47<116:24:50, 952.48s/it]Trainning Epoch:  33%|███▎      | 218/658 [1:50:47<116:24:51, 952.48s/it]2025-09-26 15:05:42,691 Stage: Train 0.5 | Epoch: 7 | Iter: 165400 | Total Loss: 0.003027 | Recon Loss: 0.002722 | Commit Loss: 0.000611 | Perplexity: 2404.179049
2025-09-26 15:09:51,422 Stage: Train 0.5 | Epoch: 7 | Iter: 165600 | Total Loss: 0.002987 | Recon Loss: 0.002682 | Commit Loss: 0.000610 | Perplexity: 2405.396407
2025-09-26 15:14:01,591 Stage: Train 0.5 | Epoch: 7 | Iter: 165800 | Total Loss: 0.003033 | Recon Loss: 0.002723 | Commit Loss: 0.000620 | Perplexity: 2409.894926
2025-09-26 15:18:12,550 Stage: Train 0.5 | Epoch: 7 | Iter: 166000 | Total Loss: 0.003019 | Recon Loss: 0.002714 | Commit Loss: 0.000610 | Perplexity: 2418.189856
Trainning Epoch:  33%|███▎      | 219/658 [2:06:39<116:09:50, 952.60s/it]Trainning Epoch:  33%|███▎      | 219/658 [2:06:39<116:09:50, 952.60s/it]2025-09-26 15:22:24,678 Stage: Train 0.5 | Epoch: 8 | Iter: 166200 | Total Loss: 0.002984 | Recon Loss: 0.002672 | Commit Loss: 0.000623 | Perplexity: 2419.103932
2025-09-26 15:26:33,852 Stage: Train 0.5 | Epoch: 8 | Iter: 166400 | Total Loss: 0.003018 | Recon Loss: 0.002714 | Commit Loss: 0.000609 | Perplexity: 2421.669758
2025-09-26 15:30:43,249 Stage: Train 0.5 | Epoch: 8 | Iter: 166600 | Total Loss: 0.002996 | Recon Loss: 0.002690 | Commit Loss: 0.000612 | Perplexity: 2422.017861
2025-09-26 15:34:52,925 Stage: Train 0.5 | Epoch: 8 | Iter: 166800 | Total Loss: 0.003006 | Recon Loss: 0.002699 | Commit Loss: 0.000614 | Perplexity: 2420.261704
Trainning Epoch:  33%|███▎      | 220/658 [2:22:29<115:47:49, 951.76s/it]Trainning Epoch:  33%|███▎      | 220/658 [2:22:29<115:47:49, 951.76s/it]2025-09-26 15:39:03,921 Stage: Train 0.5 | Epoch: 9 | Iter: 167000 | Total Loss: 0.003017 | Recon Loss: 0.002710 | Commit Loss: 0.000614 | Perplexity: 2431.891749
2025-09-26 15:43:12,293 Stage: Train 0.5 | Epoch: 9 | Iter: 167200 | Total Loss: 0.002993 | Recon Loss: 0.002690 | Commit Loss: 0.000607 | Perplexity: 2430.807760
2025-09-26 15:47:20,589 Stage: Train 0.5 | Epoch: 9 | Iter: 167400 | Total Loss: 0.002975 | Recon Loss: 0.002670 | Commit Loss: 0.000608 | Perplexity: 2440.099623
2025-09-26 15:51:29,458 Stage: Train 0.5 | Epoch: 9 | Iter: 167600 | Total Loss: 0.003001 | Recon Loss: 0.002691 | Commit Loss: 0.000620 | Perplexity: 2436.165609
Trainning Epoch:  34%|███▎      | 221/658 [2:38:17<115:21:50, 950.37s/it]Trainning Epoch:  34%|███▎      | 221/658 [2:38:17<115:21:50, 950.37s/it]2025-09-26 15:55:43,806 Stage: Train 0.5 | Epoch: 10 | Iter: 167800 | Total Loss: 0.002978 | Recon Loss: 0.002669 | Commit Loss: 0.000618 | Perplexity: 2441.330532
2025-09-26 15:59:54,750 Stage: Train 0.5 | Epoch: 10 | Iter: 168000 | Total Loss: 0.002966 | Recon Loss: 0.002656 | Commit Loss: 0.000620 | Perplexity: 2446.218701
2025-09-26 16:04:05,952 Stage: Train 0.5 | Epoch: 10 | Iter: 168200 | Total Loss: 0.003044 | Recon Loss: 0.002749 | Commit Loss: 0.000591 | Perplexity: 2446.076554
Trainning Epoch:  34%|███▎      | 222/658 [2:54:14<115:21:34, 952.51s/it]Trainning Epoch:  34%|███▎      | 222/658 [2:54:14<115:21:34, 952.51s/it]2025-09-26 16:08:20,561 Stage: Train 0.5 | Epoch: 11 | Iter: 168400 | Total Loss: 0.002966 | Recon Loss: 0.002661 | Commit Loss: 0.000611 | Perplexity: 2448.213065
2025-09-26 16:12:31,354 Stage: Train 0.5 | Epoch: 11 | Iter: 168600 | Total Loss: 0.002968 | Recon Loss: 0.002664 | Commit Loss: 0.000609 | Perplexity: 2453.147075
2025-09-26 16:16:42,600 Stage: Train 0.5 | Epoch: 11 | Iter: 168800 | Total Loss: 0.002974 | Recon Loss: 0.002671 | Commit Loss: 0.000606 | Perplexity: 2456.020509
2025-09-26 16:20:54,100 Stage: Train 0.5 | Epoch: 11 | Iter: 169000 | Total Loss: 0.002956 | Recon Loss: 0.002657 | Commit Loss: 0.000597 | Perplexity: 2462.707909
Trainning Epoch:  34%|███▍      | 223/658 [3:10:12<115:17:31, 954.14s/it]Trainning Epoch:  34%|███▍      | 223/658 [3:10:12<115:17:31, 954.14s/it]2025-09-26 16:25:07,186 Stage: Train 0.5 | Epoch: 12 | Iter: 169200 | Total Loss: 0.002980 | Recon Loss: 0.002681 | Commit Loss: 0.000598 | Perplexity: 2460.795217
2025-09-26 16:29:15,392 Stage: Train 0.5 | Epoch: 12 | Iter: 169400 | Total Loss: 0.002934 | Recon Loss: 0.002640 | Commit Loss: 0.000589 | Perplexity: 2461.794658
2025-09-26 16:33:24,579 Stage: Train 0.5 | Epoch: 12 | Iter: 169600 | Total Loss: 0.002970 | Recon Loss: 0.002667 | Commit Loss: 0.000606 | Perplexity: 2462.251377
2025-09-26 16:37:34,247 Stage: Train 0.5 | Epoch: 12 | Iter: 169800 | Total Loss: 0.002937 | Recon Loss: 0.002631 | Commit Loss: 0.000612 | Perplexity: 2466.004281
Trainning Epoch:  34%|███▍      | 224/658 [3:26:01<114:50:30, 952.60s/it]Trainning Epoch:  34%|███▍      | 224/658 [3:26:01<114:50:32, 952.61s/it]2025-09-26 16:41:47,339 Stage: Train 0.5 | Epoch: 13 | Iter: 170000 | Total Loss: 0.002938 | Recon Loss: 0.002637 | Commit Loss: 0.000603 | Perplexity: 2471.536963
2025-09-26 16:45:57,009 Stage: Train 0.5 | Epoch: 13 | Iter: 170200 | Total Loss: 0.002959 | Recon Loss: 0.002656 | Commit Loss: 0.000606 | Perplexity: 2476.367899
2025-09-26 16:50:07,397 Stage: Train 0.5 | Epoch: 13 | Iter: 170400 | Total Loss: 0.002964 | Recon Loss: 0.002671 | Commit Loss: 0.000585 | Perplexity: 2475.432240
2025-09-26 16:54:18,051 Stage: Train 0.5 | Epoch: 13 | Iter: 170600 | Total Loss: 0.002960 | Recon Loss: 0.002665 | Commit Loss: 0.000590 | Perplexity: 2468.017881
Trainning Epoch:  34%|███▍      | 225/658 [3:41:55<114:37:52, 953.05s/it]Trainning Epoch:  34%|███▍      | 225/658 [3:41:55<114:37:54, 953.06s/it]2025-09-26 16:58:28,406 Stage: Train 0.5 | Epoch: 14 | Iter: 170800 | Total Loss: 0.002926 | Recon Loss: 0.002624 | Commit Loss: 0.000604 | Perplexity: 2474.422802
2025-09-26 17:02:35,701 Stage: Train 0.5 | Epoch: 14 | Iter: 171000 | Total Loss: 0.002944 | Recon Loss: 0.002643 | Commit Loss: 0.000602 | Perplexity: 2476.382056
2025-09-26 17:06:43,727 Stage: Train 0.5 | Epoch: 14 | Iter: 171200 | Total Loss: 0.002905 | Recon Loss: 0.002606 | Commit Loss: 0.000599 | Perplexity: 2478.857659
2025-09-26 17:10:51,985 Stage: Train 0.5 | Epoch: 14 | Iter: 171400 | Total Loss: 0.002921 | Recon Loss: 0.002623 | Commit Loss: 0.000595 | Perplexity: 2477.167449
Trainning Epoch:  34%|███▍      | 226/658 [3:57:39<114:02:38, 950.37s/it]Trainning Epoch:  34%|███▍      | 226/658 [3:57:39<114:02:39, 950.37s/it]2025-09-26 17:15:04,763 Stage: Train 0.5 | Epoch: 15 | Iter: 171600 | Total Loss: 0.002958 | Recon Loss: 0.002658 | Commit Loss: 0.000602 | Perplexity: 2480.499110
2025-09-26 17:19:14,016 Stage: Train 0.5 | Epoch: 15 | Iter: 171800 | Total Loss: 0.002930 | Recon Loss: 0.002628 | Commit Loss: 0.000605 | Perplexity: 2482.803091
2025-09-26 17:23:24,161 Stage: Train 0.5 | Epoch: 15 | Iter: 172000 | Total Loss: 0.002920 | Recon Loss: 0.002620 | Commit Loss: 0.000599 | Perplexity: 2482.560151
Trainning Epoch:  34%|███▍      | 227/658 [4:13:31<113:49:35, 950.76s/it]Trainning Epoch:  34%|███▍      | 227/658 [4:13:31<113:49:36, 950.76s/it]2025-09-26 17:27:37,069 Stage: Train 0.5 | Epoch: 16 | Iter: 172200 | Total Loss: 0.002906 | Recon Loss: 0.002599 | Commit Loss: 0.000614 | Perplexity: 2485.353025
2025-09-26 17:31:47,349 Stage: Train 0.5 | Epoch: 16 | Iter: 172400 | Total Loss: 0.002914 | Recon Loss: 0.002607 | Commit Loss: 0.000615 | Perplexity: 2488.243959
2025-09-26 17:35:58,278 Stage: Train 0.5 | Epoch: 16 | Iter: 172600 | Total Loss: 0.002940 | Recon Loss: 0.002640 | Commit Loss: 0.000601 | Perplexity: 2486.969808
2025-09-26 17:40:09,357 Stage: Train 0.5 | Epoch: 16 | Iter: 172800 | Total Loss: 0.002928 | Recon Loss: 0.002623 | Commit Loss: 0.000609 | Perplexity: 2491.540895
Trainning Epoch:  35%|███▍      | 228/658 [4:29:27<113:45:21, 952.37s/it]Trainning Epoch:  35%|███▍      | 228/658 [4:29:27<113:45:21, 952.38s/it]2025-09-26 17:44:22,850 Stage: Train 0.5 | Epoch: 17 | Iter: 173000 | Total Loss: 0.002896 | Recon Loss: 0.002590 | Commit Loss: 0.000613 | Perplexity: 2486.162599
2025-09-26 17:48:32,479 Stage: Train 0.5 | Epoch: 17 | Iter: 173200 | Total Loss: 0.002909 | Recon Loss: 0.002607 | Commit Loss: 0.000604 | Perplexity: 2492.087888
2025-09-26 17:52:42,276 Stage: Train 0.5 | Epoch: 17 | Iter: 173400 | Total Loss: 0.002913 | Recon Loss: 0.002610 | Commit Loss: 0.000606 | Perplexity: 2490.790065
2025-09-26 17:56:52,117 Stage: Train 0.5 | Epoch: 17 | Iter: 173600 | Total Loss: 0.002894 | Recon Loss: 0.002593 | Commit Loss: 0.000602 | Perplexity: 2495.452922
Trainning Epoch:  35%|███▍      | 229/658 [4:45:19<113:28:12, 952.20s/it]Trainning Epoch:  35%|███▍      | 229/658 [4:45:19<113:28:12, 952.20s/it]2025-09-26 18:01:05,654 Stage: Train 0.5 | Epoch: 18 | Iter: 173800 | Total Loss: 0.002887 | Recon Loss: 0.002582 | Commit Loss: 0.000611 | Perplexity: 2491.942848
2025-09-26 18:05:17,366 Stage: Train 0.5 | Epoch: 18 | Iter: 174000 | Total Loss: 0.002897 | Recon Loss: 0.002595 | Commit Loss: 0.000604 | Perplexity: 2498.189760
2025-09-26 18:09:29,150 Stage: Train 0.5 | Epoch: 18 | Iter: 174200 | Total Loss: 0.002909 | Recon Loss: 0.002605 | Commit Loss: 0.000609 | Perplexity: 2494.659801
2025-09-26 18:13:40,995 Stage: Train 0.5 | Epoch: 18 | Iter: 174400 | Total Loss: 0.002940 | Recon Loss: 0.002644 | Commit Loss: 0.000592 | Perplexity: 2495.257722
Trainning Epoch:  35%|███▍      | 230/658 [5:01:18<113:28:06, 954.41s/it]Trainning Epoch:  35%|███▍      | 230/658 [5:01:18<113:28:06, 954.41s/it]2025-09-26 18:17:52,332 Stage: Train 0.5 | Epoch: 19 | Iter: 174600 | Total Loss: 0.002882 | Recon Loss: 0.002572 | Commit Loss: 0.000618 | Perplexity: 2503.264778
2025-09-26 18:22:01,069 Stage: Train 0.5 | Epoch: 19 | Iter: 174800 | Total Loss: 0.002875 | Recon Loss: 0.002574 | Commit Loss: 0.000602 | Perplexity: 2496.372175
2025-09-26 18:26:09,865 Stage: Train 0.5 | Epoch: 19 | Iter: 175000 | Total Loss: 0.002909 | Recon Loss: 0.002601 | Commit Loss: 0.000615 | Perplexity: 2503.573024
2025-09-26 18:30:18,416 Stage: Train 0.5 | Epoch: 19 | Iter: 175200 | Total Loss: 0.002863 | Recon Loss: 0.002562 | Commit Loss: 0.000602 | Perplexity: 2499.457805
Trainning Epoch:  35%|███▌      | 231/658 [5:17:06<112:56:59, 952.27s/it]Trainning Epoch:  35%|███▌      | 231/658 [5:17:06<112:57:00, 952.27s/it]2025-09-26 18:34:28,149 Stage: Train 0.5 | Epoch: 20 | Iter: 175400 | Total Loss: 0.002904 | Recon Loss: 0.002599 | Commit Loss: 0.000610 | Perplexity: 2501.457341
2025-09-26 18:38:34,923 Stage: Train 0.5 | Epoch: 20 | Iter: 175600 | Total Loss: 0.002864 | Recon Loss: 0.002562 | Commit Loss: 0.000603 | Perplexity: 2509.630381
2025-09-26 18:42:41,862 Stage: Train 0.5 | Epoch: 20 | Iter: 175800 | Total Loss: 0.002895 | Recon Loss: 0.002587 | Commit Loss: 0.000616 | Perplexity: 2506.351379
Trainning Epoch:  35%|███▌      | 232/658 [5:32:46<112:16:40, 948.83s/it]Trainning Epoch:  35%|███▌      | 232/658 [5:32:46<112:16:41, 948.83s/it]2025-09-26 18:46:52,409 Stage: Train 0.5 | Epoch: 21 | Iter: 176000 | Total Loss: 0.002874 | Recon Loss: 0.002574 | Commit Loss: 0.000601 | Perplexity: 2507.691965
2025-09-26 18:51:00,757 Stage: Train 0.5 | Epoch: 21 | Iter: 176200 | Total Loss: 0.002879 | Recon Loss: 0.002579 | Commit Loss: 0.000600 | Perplexity: 2503.741808
2025-09-26 18:55:09,602 Stage: Train 0.5 | Epoch: 21 | Iter: 176400 | Total Loss: 0.002876 | Recon Loss: 0.002571 | Commit Loss: 0.000610 | Perplexity: 2509.008832
2025-09-26 18:59:18,837 Stage: Train 0.5 | Epoch: 21 | Iter: 176600 | Total Loss: 0.002892 | Recon Loss: 0.002583 | Commit Loss: 0.000618 | Perplexity: 2508.843536
Trainning Epoch:  35%|███▌      | 233/658 [5:48:35<112:01:23, 948.90s/it]Trainning Epoch:  35%|███▌      | 233/658 [5:48:35<112:01:23, 948.90s/it]2025-09-26 19:03:30,659 Stage: Train 0.5 | Epoch: 22 | Iter: 176800 | Total Loss: 0.002863 | Recon Loss: 0.002557 | Commit Loss: 0.000611 | Perplexity: 2510.788849
2025-09-26 19:07:38,286 Stage: Train 0.5 | Epoch: 22 | Iter: 177000 | Total Loss: 0.002907 | Recon Loss: 0.002607 | Commit Loss: 0.000599 | Perplexity: 2511.664420
2025-09-26 19:11:46,227 Stage: Train 0.5 | Epoch: 22 | Iter: 177200 | Total Loss: 0.002860 | Recon Loss: 0.002554 | Commit Loss: 0.000612 | Perplexity: 2512.742258
2025-09-26 19:15:54,377 Stage: Train 0.5 | Epoch: 22 | Iter: 177400 | Total Loss: 0.002873 | Recon Loss: 0.002566 | Commit Loss: 0.000612 | Perplexity: 2513.780320
Trainning Epoch:  36%|███▌      | 234/658 [6:04:20<111:37:21, 947.74s/it]Trainning Epoch:  36%|███▌      | 234/658 [6:04:20<111:37:20, 947.74s/it]2025-09-26 19:20:03,755 Stage: Train 0.5 | Epoch: 23 | Iter: 177600 | Total Loss: 0.002842 | Recon Loss: 0.002537 | Commit Loss: 0.000611 | Perplexity: 2511.851608
2025-09-26 19:24:09,424 Stage: Train 0.5 | Epoch: 23 | Iter: 177800 | Total Loss: 0.002942 | Recon Loss: 0.002633 | Commit Loss: 0.000617 | Perplexity: 2516.519657
2025-09-26 19:28:15,622 Stage: Train 0.5 | Epoch: 23 | Iter: 178000 | Total Loss: 0.002847 | Recon Loss: 0.002545 | Commit Loss: 0.000605 | Perplexity: 2515.767648
2025-09-26 19:32:22,719 Stage: Train 0.5 | Epoch: 23 | Iter: 178200 | Total Loss: 0.002864 | Recon Loss: 0.002566 | Commit Loss: 0.000598 | Perplexity: 2511.933586
Trainning Epoch:  36%|███▌      | 235/658 [6:19:59<111:02:03, 944.97s/it]Trainning Epoch:  36%|███▌      | 235/658 [6:19:59<111:02:04, 944.97s/it]2025-09-26 19:36:33,041 Stage: Train 0.5 | Epoch: 24 | Iter: 178400 | Total Loss: 0.002853 | Recon Loss: 0.002547 | Commit Loss: 0.000612 | Perplexity: 2511.753281
2025-09-26 19:40:40,638 Stage: Train 0.5 | Epoch: 24 | Iter: 178600 | Total Loss: 0.002929 | Recon Loss: 0.002616 | Commit Loss: 0.000625 | Perplexity: 2522.564496
2025-09-26 19:44:48,153 Stage: Train 0.5 | Epoch: 24 | Iter: 178800 | Total Loss: 0.002877 | Recon Loss: 0.002572 | Commit Loss: 0.000609 | Perplexity: 2518.214724
2025-09-26 19:48:55,458 Stage: Train 0.5 | Epoch: 24 | Iter: 179000 | Total Loss: 0.002867 | Recon Loss: 0.002560 | Commit Loss: 0.000613 | Perplexity: 2511.847592
Trainning Epoch:  36%|███▌      | 236/658 [6:35:43<110:43:23, 944.56s/it]Trainning Epoch:  36%|███▌      | 236/658 [6:35:43<110:43:24, 944.56s/it]2025-09-26 19:53:07,529 Stage: Train 0.5 | Epoch: 25 | Iter: 179200 | Total Loss: 0.002853 | Recon Loss: 0.002548 | Commit Loss: 0.000610 | Perplexity: 2517.992045
2025-09-26 19:57:16,665 Stage: Train 0.5 | Epoch: 25 | Iter: 179400 | Total Loss: 0.002904 | Recon Loss: 0.002602 | Commit Loss: 0.000604 | Perplexity: 2513.858514
2025-09-26 20:01:25,798 Stage: Train 0.5 | Epoch: 25 | Iter: 179600 | Total Loss: 0.002878 | Recon Loss: 0.002572 | Commit Loss: 0.000612 | Perplexity: 2514.884186
Trainning Epoch:  36%|███▌      | 237/658 [6:51:32<110:38:01, 946.04s/it]Trainning Epoch:  36%|███▌      | 237/658 [6:51:32<110:38:02, 946.04s/it]2025-09-26 20:05:38,759 Stage: Train 0.5 | Epoch: 26 | Iter: 179800 | Total Loss: 0.002863 | Recon Loss: 0.002560 | Commit Loss: 0.000606 | Perplexity: 2522.488669
2025-09-26 20:09:47,211 Stage: Train 0.5 | Epoch: 26 | Iter: 180000 | Total Loss: 0.002878 | Recon Loss: 0.002572 | Commit Loss: 0.000613 | Perplexity: 2522.171888
2025-09-26 20:09:47,211 Saving model at iteration 180000
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/home/wxs/anaconda3/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
2025-09-26 20:09:47,440 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_27_step_180000
2025-09-26 20:09:47,969 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_27_step_180000/model.safetensors
2025-09-26 20:09:48,355 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_27_step_180000/optimizer.bin
2025-09-26 20:09:48,355 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_27_step_180000/scheduler.bin
2025-09-26 20:09:48,355 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_27_step_180000/sampler.bin
2025-09-26 20:09:48,356 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_27_step_180000/random_states_0.pkl
2025-09-26 20:13:57,121 Stage: Train 0.5 | Epoch: 26 | Iter: 180200 | Total Loss: 0.002837 | Recon Loss: 0.002530 | Commit Loss: 0.000615 | Perplexity: 2518.014905
2025-09-26 20:18:06,631 Stage: Train 0.5 | Epoch: 26 | Iter: 180400 | Total Loss: 0.002887 | Recon Loss: 0.002578 | Commit Loss: 0.000619 | Perplexity: 2520.251145
Trainning Epoch:  36%|███▌      | 238/658 [7:07:23<110:32:48, 947.54s/it]Trainning Epoch:  36%|███▌      | 238/658 [7:07:23<110:32:49, 947.55s/it]2025-09-26 20:22:19,430 Stage: Train 0.5 | Epoch: 27 | Iter: 180600 | Total Loss: 0.002888 | Recon Loss: 0.002586 | Commit Loss: 0.000604 | Perplexity: 2522.687375
2025-09-26 20:26:29,155 Stage: Train 0.5 | Epoch: 27 | Iter: 180800 | Total Loss: 0.002835 | Recon Loss: 0.002530 | Commit Loss: 0.000610 | Perplexity: 2524.235918
2025-09-26 20:30:39,174 Stage: Train 0.5 | Epoch: 27 | Iter: 181000 | Total Loss: 0.002892 | Recon Loss: 0.002580 | Commit Loss: 0.000623 | Perplexity: 2523.479944
2025-09-26 20:34:49,573 Stage: Train 0.5 | Epoch: 27 | Iter: 181200 | Total Loss: 0.002900 | Recon Loss: 0.002592 | Commit Loss: 0.000617 | Perplexity: 2524.372307
Trainning Epoch:  36%|███▋      | 239/658 [7:23:16<110:28:50, 949.24s/it]Trainning Epoch:  36%|███▋      | 239/658 [7:23:16<110:28:50, 949.24s/it]2025-09-26 20:39:01,937 Stage: Train 0.5 | Epoch: 28 | Iter: 181400 | Total Loss: 0.002835 | Recon Loss: 0.002529 | Commit Loss: 0.000611 | Perplexity: 2519.864111
2025-09-26 20:43:10,226 Stage: Train 0.5 | Epoch: 28 | Iter: 181600 | Total Loss: 0.002834 | Recon Loss: 0.002528 | Commit Loss: 0.000613 | Perplexity: 2523.917452
2025-09-26 20:47:18,650 Stage: Train 0.5 | Epoch: 28 | Iter: 181800 | Total Loss: 0.002837 | Recon Loss: 0.002534 | Commit Loss: 0.000607 | Perplexity: 2522.636294
2025-09-26 20:51:26,826 Stage: Train 0.5 | Epoch: 28 | Iter: 182000 | Total Loss: 0.002866 | Recon Loss: 0.002556 | Commit Loss: 0.000619 | Perplexity: 2523.746290
Trainning Epoch:  36%|███▋      | 240/658 [7:39:03<110:08:18, 948.56s/it]Trainning Epoch:  36%|███▋      | 240/658 [7:39:03<110:08:20, 948.56s/it]2025-09-26 20:55:38,234 Stage: Train 0.5 | Epoch: 29 | Iter: 182200 | Total Loss: 0.002889 | Recon Loss: 0.002579 | Commit Loss: 0.000622 | Perplexity: 2527.589261
2025-09-26 20:59:46,869 Stage: Train 0.5 | Epoch: 29 | Iter: 182400 | Total Loss: 0.002877 | Recon Loss: 0.002576 | Commit Loss: 0.000602 | Perplexity: 2524.122560
2025-09-26 21:03:55,374 Stage: Train 0.5 | Epoch: 29 | Iter: 182600 | Total Loss: 0.002837 | Recon Loss: 0.002532 | Commit Loss: 0.000611 | Perplexity: 2525.850836
2025-09-26 21:08:04,140 Stage: Train 0.5 | Epoch: 29 | Iter: 182800 | Total Loss: 0.002855 | Recon Loss: 0.002546 | Commit Loss: 0.000619 | Perplexity: 2527.263602
Trainning Epoch:  37%|███▋      | 241/658 [7:54:51<109:51:14, 948.38s/it]Trainning Epoch:  37%|███▋      | 241/658 [7:54:51<109:51:17, 948.39s/it]2025-09-26 21:12:18,046 Stage: Train 0.5 | Epoch: 30 | Iter: 183000 | Total Loss: 0.002880 | Recon Loss: 0.002572 | Commit Loss: 0.000616 | Perplexity: 2530.222220
2025-09-26 21:16:28,234 Stage: Train 0.5 | Epoch: 30 | Iter: 183200 | Total Loss: 0.002861 | Recon Loss: 0.002546 | Commit Loss: 0.000629 | Perplexity: 2529.567017
2025-09-26 21:20:38,770 Stage: Train 0.5 | Epoch: 30 | Iter: 183400 | Total Loss: 0.002852 | Recon Loss: 0.002541 | Commit Loss: 0.000620 | Perplexity: 2528.901681
Trainning Epoch:  37%|███▋      | 242/658 [8:10:46<109:48:31, 950.27s/it]Trainning Epoch:  37%|███▋      | 242/658 [8:10:46<109:48:33, 950.27s/it]2025-09-26 21:24:51,977 Stage: Train 0.5 | Epoch: 31 | Iter: 183600 | Total Loss: 0.002902 | Recon Loss: 0.002593 | Commit Loss: 0.000618 | Perplexity: 2530.531251
2025-09-26 21:28:59,709 Stage: Train 0.5 | Epoch: 31 | Iter: 183800 | Total Loss: 0.002857 | Recon Loss: 0.002538 | Commit Loss: 0.000639 | Perplexity: 2533.460400
2025-09-26 21:33:07,955 Stage: Train 0.5 | Epoch: 31 | Iter: 184000 | Total Loss: 0.002838 | Recon Loss: 0.002532 | Commit Loss: 0.000611 | Perplexity: 2525.162185
2025-09-26 21:37:16,182 Stage: Train 0.5 | Epoch: 31 | Iter: 184200 | Total Loss: 0.002833 | Recon Loss: 0.002523 | Commit Loss: 0.000620 | Perplexity: 2529.254150
Trainning Epoch:  37%|███▋      | 243/658 [8:26:32<109:23:19, 948.92s/it]Trainning Epoch:  37%|███▋      | 243/658 [8:26:32<109:23:20, 948.92s/it]2025-09-26 21:41:27,354 Stage: Train 0.5 | Epoch: 32 | Iter: 184400 | Total Loss: 0.002860 | Recon Loss: 0.002547 | Commit Loss: 0.000626 | Perplexity: 2533.975251
2025-09-26 21:45:35,809 Stage: Train 0.5 | Epoch: 32 | Iter: 184600 | Total Loss: 0.002848 | Recon Loss: 0.002543 | Commit Loss: 0.000609 | Perplexity: 2534.611509
2025-09-26 21:49:45,350 Stage: Train 0.5 | Epoch: 32 | Iter: 184800 | Total Loss: 0.002860 | Recon Loss: 0.002548 | Commit Loss: 0.000623 | Perplexity: 2534.235344
2025-09-26 21:53:55,194 Stage: Train 0.5 | Epoch: 32 | Iter: 185000 | Total Loss: 0.002838 | Recon Loss: 0.002531 | Commit Loss: 0.000614 | Perplexity: 2534.504287
Trainning Epoch:  37%|███▋      | 244/658 [8:42:22<109:10:22, 949.33s/it]Trainning Epoch:  37%|███▋      | 244/658 [8:42:22<109:10:22, 949.33s/it]2025-09-26 21:58:09,311 Stage: Train 0.5 | Epoch: 33 | Iter: 185200 | Total Loss: 0.002839 | Recon Loss: 0.002520 | Commit Loss: 0.000638 | Perplexity: 2536.586024
2025-09-26 22:02:21,012 Stage: Train 0.5 | Epoch: 33 | Iter: 185400 | Total Loss: 0.002833 | Recon Loss: 0.002521 | Commit Loss: 0.000624 | Perplexity: 2534.846566
2025-09-26 22:06:33,205 Stage: Train 0.5 | Epoch: 33 | Iter: 185600 | Total Loss: 0.002856 | Recon Loss: 0.002552 | Commit Loss: 0.000608 | Perplexity: 2533.007106
2025-09-26 22:10:45,136 Stage: Train 0.5 | Epoch: 33 | Iter: 185800 | Total Loss: 0.002854 | Recon Loss: 0.002542 | Commit Loss: 0.000624 | Perplexity: 2533.926407
Trainning Epoch:  37%|███▋      | 245/658 [8:58:22<109:16:59, 952.59s/it]Trainning Epoch:  37%|███▋      | 245/658 [8:58:22<109:17:00, 952.59s/it]2025-09-26 22:14:57,601 Stage: Train 0.5 | Epoch: 34 | Iter: 186000 | Total Loss: 0.002822 | Recon Loss: 0.002512 | Commit Loss: 0.000620 | Perplexity: 2531.366448
2025-09-26 22:19:06,460 Stage: Train 0.5 | Epoch: 34 | Iter: 186200 | Total Loss: 0.002812 | Recon Loss: 0.002504 | Commit Loss: 0.000616 | Perplexity: 2537.163002
2025-09-26 22:23:15,353 Stage: Train 0.5 | Epoch: 34 | Iter: 186400 | Total Loss: 0.002797 | Recon Loss: 0.002482 | Commit Loss: 0.000631 | Perplexity: 2537.261886
2025-09-26 22:27:23,818 Stage: Train 0.5 | Epoch: 34 | Iter: 186600 | Total Loss: 0.002836 | Recon Loss: 0.002523 | Commit Loss: 0.000626 | Perplexity: 2537.027299
Trainning Epoch:  37%|███▋      | 246/658 [9:14:11<108:53:15, 951.45s/it]Trainning Epoch:  37%|███▋      | 246/658 [9:14:11<108:53:15, 951.45s/it]2025-09-26 22:31:38,981 Stage: Train 0.5 | Epoch: 35 | Iter: 186800 | Total Loss: 0.002829 | Recon Loss: 0.002516 | Commit Loss: 0.000625 | Perplexity: 2536.446281
2025-09-26 22:35:50,079 Stage: Train 0.5 | Epoch: 35 | Iter: 187000 | Total Loss: 0.002821 | Recon Loss: 0.002506 | Commit Loss: 0.000629 | Perplexity: 2540.095963
2025-09-26 22:40:01,621 Stage: Train 0.5 | Epoch: 35 | Iter: 187200 | Total Loss: 0.002810 | Recon Loss: 0.002492 | Commit Loss: 0.000636 | Perplexity: 2541.710093
Trainning Epoch:  38%|███▊      | 247/658 [9:30:09<108:51:45, 953.54s/it]Trainning Epoch:  38%|███▊      | 247/658 [9:30:09<108:51:46, 953.54s/it]2025-09-26 22:44:16,984 Stage: Train 0.5 | Epoch: 36 | Iter: 187400 | Total Loss: 0.002874 | Recon Loss: 0.002562 | Commit Loss: 0.000624 | Perplexity: 2534.464604
2025-09-26 22:48:27,577 Stage: Train 0.5 | Epoch: 36 | Iter: 187600 | Total Loss: 0.002877 | Recon Loss: 0.002574 | Commit Loss: 0.000605 | Perplexity: 2541.816694
2025-09-26 22:52:38,971 Stage: Train 0.5 | Epoch: 36 | Iter: 187800 | Total Loss: 0.002811 | Recon Loss: 0.002503 | Commit Loss: 0.000616 | Perplexity: 2534.663915
2025-09-26 22:56:50,699 Stage: Train 0.5 | Epoch: 36 | Iter: 188000 | Total Loss: 0.002823 | Recon Loss: 0.002519 | Commit Loss: 0.000608 | Perplexity: 2534.612042
Trainning Epoch:  38%|███▊      | 248/658 [9:46:08<108:46:29, 955.10s/it]Trainning Epoch:  38%|███▊      | 248/658 [9:46:08<108:46:29, 955.10s/it]2025-09-26 23:01:03,545 Stage: Train 0.5 | Epoch: 37 | Iter: 188200 | Total Loss: 0.002842 | Recon Loss: 0.002532 | Commit Loss: 0.000621 | Perplexity: 2538.194838
2025-09-26 23:05:11,418 Stage: Train 0.5 | Epoch: 37 | Iter: 188400 | Total Loss: 0.002862 | Recon Loss: 0.002550 | Commit Loss: 0.000623 | Perplexity: 2539.957617
2025-09-26 23:09:19,576 Stage: Train 0.5 | Epoch: 37 | Iter: 188600 | Total Loss: 0.002817 | Recon Loss: 0.002506 | Commit Loss: 0.000622 | Perplexity: 2533.862394
2025-09-26 23:13:28,290 Stage: Train 0.5 | Epoch: 37 | Iter: 188800 | Total Loss: 0.002840 | Recon Loss: 0.002522 | Commit Loss: 0.000637 | Perplexity: 2541.410522
Trainning Epoch:  38%|███▊      | 249/658 [10:01:55<108:13:05, 952.53s/it]Trainning Epoch:  38%|███▊      | 249/658 [10:01:55<108:13:05, 952.53s/it]2025-09-26 23:17:40,290 Stage: Train 0.5 | Epoch: 38 | Iter: 189000 | Total Loss: 0.002864 | Recon Loss: 0.002554 | Commit Loss: 0.000621 | Perplexity: 2537.730695
2025-09-26 23:21:48,340 Stage: Train 0.5 | Epoch: 38 | Iter: 189200 | Total Loss: 0.002844 | Recon Loss: 0.002529 | Commit Loss: 0.000629 | Perplexity: 2537.673862
2025-09-26 23:25:56,259 Stage: Train 0.5 | Epoch: 38 | Iter: 189400 | Total Loss: 0.002813 | Recon Loss: 0.002499 | Commit Loss: 0.000628 | Perplexity: 2537.984230
2025-09-26 23:30:04,169 Stage: Train 0.5 | Epoch: 38 | Iter: 189600 | Total Loss: 0.002792 | Recon Loss: 0.002480 | Commit Loss: 0.000624 | Perplexity: 2535.036637
Trainning Epoch:  38%|███▊      | 250/658 [10:17:41<107:43:33, 950.52s/it]Trainning Epoch:  38%|███▊      | 250/658 [10:17:41<107:43:34, 950.53s/it]2025-09-26 23:34:10,657 Stage: Train 0.5 | Epoch: 39 | Iter: 189800 | Total Loss: 0.002804 | Recon Loss: 0.002492 | Commit Loss: 0.000624 | Perplexity: 2539.642948
2025-09-26 23:38:12,945 Stage: Train 0.5 | Epoch: 39 | Iter: 190000 | Total Loss: 0.002844 | Recon Loss: 0.002533 | Commit Loss: 0.000622 | Perplexity: 2544.976295
2025-09-26 23:42:15,689 Stage: Train 0.5 | Epoch: 39 | Iter: 190200 | Total Loss: 0.002817 | Recon Loss: 0.002501 | Commit Loss: 0.000632 | Perplexity: 2537.026290
2025-09-26 23:46:18,719 Stage: Train 0.5 | Epoch: 39 | Iter: 190400 | Total Loss: 0.002798 | Recon Loss: 0.002488 | Commit Loss: 0.000621 | Perplexity: 2537.610376
Trainning Epoch:  38%|███▊      | 251/658 [10:33:06<106:36:25, 942.96s/it]Trainning Epoch:  38%|███▊      | 251/658 [10:33:06<106:36:30, 942.97s/it]2025-09-26 23:50:28,714 Stage: Train 0.5 | Epoch: 40 | Iter: 190600 | Total Loss: 0.002815 | Recon Loss: 0.002498 | Commit Loss: 0.000634 | Perplexity: 2537.964584
2025-09-26 23:54:34,584 Stage: Train 0.5 | Epoch: 40 | Iter: 190800 | Total Loss: 0.002839 | Recon Loss: 0.002528 | Commit Loss: 0.000623 | Perplexity: 2541.974559
2025-09-26 23:58:40,371 Stage: Train 0.5 | Epoch: 40 | Iter: 191000 | Total Loss: 0.002795 | Recon Loss: 0.002484 | Commit Loss: 0.000620 | Perplexity: 2539.442424
Trainning Epoch:  38%|███▊      | 252/658 [10:48:44<106:11:12, 941.56s/it]Trainning Epoch:  38%|███▊      | 252/658 [10:48:44<106:11:11, 941.56s/it]2025-09-27 00:02:50,737 Stage: Train 0.5 | Epoch: 41 | Iter: 191200 | Total Loss: 0.002830 | Recon Loss: 0.002519 | Commit Loss: 0.000621 | Perplexity: 2538.632023
2025-09-27 00:07:00,086 Stage: Train 0.5 | Epoch: 41 | Iter: 191400 | Total Loss: 0.002842 | Recon Loss: 0.002526 | Commit Loss: 0.000631 | Perplexity: 2540.503242
2025-09-27 00:11:09,665 Stage: Train 0.5 | Epoch: 41 | Iter: 191600 | Total Loss: 0.002820 | Recon Loss: 0.002520 | Commit Loss: 0.000600 | Perplexity: 2533.914167
2025-09-27 00:15:19,550 Stage: Train 0.5 | Epoch: 41 | Iter: 191800 | Total Loss: 0.002807 | Recon Loss: 0.002492 | Commit Loss: 0.000630 | Perplexity: 2539.080818
Trainning Epoch:  38%|███▊      | 253/658 [11:04:36<106:16:20, 944.64s/it]Trainning Epoch:  38%|███▊      | 253/658 [11:04:36<106:16:21, 944.65s/it]2025-09-27 00:19:32,782 Stage: Train 0.5 | Epoch: 42 | Iter: 192000 | Total Loss: 0.002824 | Recon Loss: 0.002509 | Commit Loss: 0.000630 | Perplexity: 2540.289625
2025-09-27 00:23:41,675 Stage: Train 0.5 | Epoch: 42 | Iter: 192200 | Total Loss: 0.002807 | Recon Loss: 0.002497 | Commit Loss: 0.000619 | Perplexity: 2541.778490
2025-09-27 00:27:51,008 Stage: Train 0.5 | Epoch: 42 | Iter: 192400 | Total Loss: 0.002769 | Recon Loss: 0.002448 | Commit Loss: 0.000642 | Perplexity: 2542.489698
2025-09-27 00:32:00,247 Stage: Train 0.5 | Epoch: 42 | Iter: 192600 | Total Loss: 0.002830 | Recon Loss: 0.002507 | Commit Loss: 0.000646 | Perplexity: 2540.800298
Trainning Epoch:  39%|███▊      | 254/658 [11:20:27<106:12:34, 946.42s/it]Trainning Epoch:  39%|███▊      | 254/658 [11:20:27<106:12:36, 946.43s/it]2025-09-27 00:36:11,383 Stage: Train 0.5 | Epoch: 43 | Iter: 192800 | Total Loss: 0.002778 | Recon Loss: 0.002467 | Commit Loss: 0.000621 | Perplexity: 2541.210792
2025-09-27 00:40:17,834 Stage: Train 0.5 | Epoch: 43 | Iter: 193000 | Total Loss: 0.002810 | Recon Loss: 0.002499 | Commit Loss: 0.000621 | Perplexity: 2538.903500
2025-09-27 00:44:24,784 Stage: Train 0.5 | Epoch: 43 | Iter: 193200 | Total Loss: 0.002795 | Recon Loss: 0.002485 | Commit Loss: 0.000618 | Perplexity: 2539.466254
2025-09-27 00:48:31,566 Stage: Train 0.5 | Epoch: 43 | Iter: 193400 | Total Loss: 0.002800 | Recon Loss: 0.002480 | Commit Loss: 0.000640 | Perplexity: 2540.127893
Trainning Epoch:  39%|███▉      | 255/658 [11:36:08<105:46:22, 944.87s/it]Trainning Epoch:  39%|███▉      | 255/658 [11:36:08<105:46:26, 944.88s/it]2025-09-27 00:52:43,462 Stage: Train 0.5 | Epoch: 44 | Iter: 193600 | Total Loss: 0.002797 | Recon Loss: 0.002478 | Commit Loss: 0.000637 | Perplexity: 2545.961237
2025-09-27 00:56:52,879 Stage: Train 0.5 | Epoch: 44 | Iter: 193800 | Total Loss: 0.002813 | Recon Loss: 0.002498 | Commit Loss: 0.000631 | Perplexity: 2539.013582
2025-09-27 01:01:02,271 Stage: Train 0.5 | Epoch: 44 | Iter: 194000 | Total Loss: 0.002885 | Recon Loss: 0.002570 | Commit Loss: 0.000631 | Perplexity: 2535.964977
2025-09-27 01:05:10,755 Stage: Train 0.5 | Epoch: 44 | Iter: 194200 | Total Loss: 0.002805 | Recon Loss: 0.002496 | Commit Loss: 0.000618 | Perplexity: 2538.794486
Trainning Epoch:  39%|███▉      | 256/658 [11:51:58<105:41:11, 946.45s/it]Trainning Epoch:  39%|███▉      | 256/658 [11:51:58<105:41:09, 946.44s/it]2025-09-27 01:09:22,845 Stage: Train 0.5 | Epoch: 45 | Iter: 194400 | Total Loss: 0.002833 | Recon Loss: 0.002514 | Commit Loss: 0.000638 | Perplexity: 2535.687690
2025-09-27 01:13:31,034 Stage: Train 0.5 | Epoch: 45 | Iter: 194600 | Total Loss: 0.002812 | Recon Loss: 0.002500 | Commit Loss: 0.000624 | Perplexity: 2539.621064
2025-09-27 01:17:39,621 Stage: Train 0.5 | Epoch: 45 | Iter: 194800 | Total Loss: 0.002788 | Recon Loss: 0.002470 | Commit Loss: 0.000636 | Perplexity: 2542.187484
Trainning Epoch:  39%|███▉      | 257/658 [12:07:46<105:27:44, 946.79s/it]Trainning Epoch:  39%|███▉      | 257/658 [12:07:46<105:27:43, 946.79s/it]2025-09-27 01:21:52,917 Stage: Train 0.5 | Epoch: 46 | Iter: 195000 | Total Loss: 0.002785 | Recon Loss: 0.002472 | Commit Loss: 0.000625 | Perplexity: 2538.545927
2025-09-27 01:26:02,102 Stage: Train 0.5 | Epoch: 46 | Iter: 195200 | Total Loss: 0.002871 | Recon Loss: 0.002563 | Commit Loss: 0.000617 | Perplexity: 2536.784913
2025-09-27 01:30:11,795 Stage: Train 0.5 | Epoch: 46 | Iter: 195400 | Total Loss: 0.002773 | Recon Loss: 0.002449 | Commit Loss: 0.000648 | Perplexity: 2533.361265
2025-09-27 01:34:21,271 Stage: Train 0.5 | Epoch: 46 | Iter: 195600 | Total Loss: 0.002826 | Recon Loss: 0.002518 | Commit Loss: 0.000617 | Perplexity: 2538.263065
Trainning Epoch:  39%|███▉      | 258/658 [12:23:38<105:22:33, 948.38s/it]Trainning Epoch:  39%|███▉      | 258/658 [12:23:38<105:22:33, 948.38s/it]2025-09-27 01:38:32,243 Stage: Train 0.5 | Epoch: 47 | Iter: 195800 | Total Loss: 0.002803 | Recon Loss: 0.002485 | Commit Loss: 0.000635 | Perplexity: 2542.541333
2025-09-27 01:42:39,637 Stage: Train 0.5 | Epoch: 47 | Iter: 196000 | Total Loss: 0.002814 | Recon Loss: 0.002494 | Commit Loss: 0.000640 | Perplexity: 2537.755382
2025-09-27 01:46:47,377 Stage: Train 0.5 | Epoch: 47 | Iter: 196200 | Total Loss: 0.002802 | Recon Loss: 0.002492 | Commit Loss: 0.000620 | Perplexity: 2532.928954
2025-09-27 01:50:55,414 Stage: Train 0.5 | Epoch: 47 | Iter: 196400 | Total Loss: 0.002801 | Recon Loss: 0.002486 | Commit Loss: 0.000630 | Perplexity: 2542.298123
Trainning Epoch:  39%|███▉      | 259/658 [12:39:21<104:57:42, 947.02s/it]Trainning Epoch:  39%|███▉      | 259/658 [12:39:21<104:57:42, 947.02s/it]2025-09-27 01:55:05,098 Stage: Train 0.5 | Epoch: 48 | Iter: 196600 | Total Loss: 0.002761 | Recon Loss: 0.002448 | Commit Loss: 0.000627 | Perplexity: 2540.701753
2025-09-27 01:59:12,167 Stage: Train 0.5 | Epoch: 48 | Iter: 196800 | Total Loss: 0.002814 | Recon Loss: 0.002495 | Commit Loss: 0.000637 | Perplexity: 2540.804283
2025-09-27 02:03:19,740 Stage: Train 0.5 | Epoch: 48 | Iter: 197000 | Total Loss: 0.002808 | Recon Loss: 0.002494 | Commit Loss: 0.000628 | Perplexity: 2540.004137
2025-09-27 02:07:27,202 Stage: Train 0.5 | Epoch: 48 | Iter: 197200 | Total Loss: 0.002761 | Recon Loss: 0.002443 | Commit Loss: 0.000637 | Perplexity: 2540.307700
Trainning Epoch:  40%|███▉      | 260/658 [12:55:04<104:32:38, 945.62s/it]Trainning Epoch:  40%|███▉      | 260/658 [12:55:04<104:32:38, 945.62s/it]2025-09-27 02:11:39,872 Stage: Train 0.5 | Epoch: 49 | Iter: 197400 | Total Loss: 0.002829 | Recon Loss: 0.002505 | Commit Loss: 0.000647 | Perplexity: 2537.741577
2025-09-27 02:15:48,994 Stage: Train 0.5 | Epoch: 49 | Iter: 197600 | Total Loss: 0.002766 | Recon Loss: 0.002455 | Commit Loss: 0.000622 | Perplexity: 2533.713481
2025-09-27 02:19:58,131 Stage: Train 0.5 | Epoch: 49 | Iter: 197800 | Total Loss: 0.002780 | Recon Loss: 0.002466 | Commit Loss: 0.000629 | Perplexity: 2543.016335
2025-09-27 02:24:07,205 Stage: Train 0.5 | Epoch: 49 | Iter: 198000 | Total Loss: 0.002803 | Recon Loss: 0.002496 | Commit Loss: 0.000613 | Perplexity: 2540.384608
Trainning Epoch:  40%|███▉      | 261/658 [13:10:54<104:26:36, 947.09s/it]Trainning Epoch:  40%|███▉      | 261/658 [13:10:54<104:26:36, 947.09s/it]2025-09-27 02:28:19,896 Stage: Train 0.5 | Epoch: 50 | Iter: 198200 | Total Loss: 0.002784 | Recon Loss: 0.002465 | Commit Loss: 0.000639 | Perplexity: 2541.255938
2025-09-27 02:32:29,157 Stage: Train 0.5 | Epoch: 50 | Iter: 198400 | Total Loss: 0.002808 | Recon Loss: 0.002492 | Commit Loss: 0.000632 | Perplexity: 2540.447343
2025-09-27 02:36:38,295 Stage: Train 0.5 | Epoch: 50 | Iter: 198600 | Total Loss: 0.002794 | Recon Loss: 0.002475 | Commit Loss: 0.000638 | Perplexity: 2536.631307
Trainning Epoch:  40%|███▉      | 262/658 [13:26:44<104:16:05, 947.89s/it]Trainning Epoch:  40%|███▉      | 262/658 [13:26:44<104:16:05, 947.89s/it]2025-09-27 02:40:50,608 Stage: Train 0.5 | Epoch: 51 | Iter: 198800 | Total Loss: 0.002795 | Recon Loss: 0.002474 | Commit Loss: 0.000642 | Perplexity: 2539.045619
2025-09-27 02:44:58,847 Stage: Train 0.5 | Epoch: 51 | Iter: 199000 | Total Loss: 0.002791 | Recon Loss: 0.002476 | Commit Loss: 0.000628 | Perplexity: 2542.481497
2025-09-27 02:49:07,464 Stage: Train 0.5 | Epoch: 51 | Iter: 199200 | Total Loss: 0.002806 | Recon Loss: 0.002490 | Commit Loss: 0.000633 | Perplexity: 2538.688599
2025-09-27 02:53:17,095 Stage: Train 0.5 | Epoch: 51 | Iter: 199400 | Total Loss: 0.002778 | Recon Loss: 0.002462 | Commit Loss: 0.000632 | Perplexity: 2539.536685
Trainning Epoch:  40%|███▉      | 263/658 [13:42:33<104:02:47, 948.27s/it]Trainning Epoch:  40%|███▉      | 263/658 [13:42:33<104:02:46, 948.27s/it]2025-09-27 02:57:30,285 Stage: Train 0.5 | Epoch: 52 | Iter: 199600 | Total Loss: 0.002789 | Recon Loss: 0.002466 | Commit Loss: 0.000647 | Perplexity: 2539.061221
2025-09-27 03:01:39,432 Stage: Train 0.5 | Epoch: 52 | Iter: 199800 | Total Loss: 0.002798 | Recon Loss: 0.002475 | Commit Loss: 0.000646 | Perplexity: 2539.347809
2025-09-27 03:05:49,304 Stage: Train 0.5 | Epoch: 52 | Iter: 200000 | Total Loss: 0.002785 | Recon Loss: 0.002466 | Commit Loss: 0.000639 | Perplexity: 2535.131305
2025-09-27 03:05:49,305 Saving model at iteration 200000
2025-09-27 03:05:49,496 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_53_step_200000
2025-09-27 03:05:50,019 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_53_step_200000/model.safetensors
2025-09-27 03:05:50,450 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_53_step_200000/optimizer.bin
2025-09-27 03:05:50,451 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_53_step_200000/scheduler.bin
2025-09-27 03:05:50,451 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_53_step_200000/sampler.bin
2025-09-27 03:05:50,452 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_53_step_200000/random_states_0.pkl
2025-09-27 03:10:00,277 Stage: Train 0.5 | Epoch: 52 | Iter: 200200 | Total Loss: 0.002789 | Recon Loss: 0.002472 | Commit Loss: 0.000635 | Perplexity: 2540.676383
Trainning Epoch:  40%|████      | 264/658 [13:58:27<103:57:50, 949.92s/it]Trainning Epoch:  40%|████      | 264/658 [13:58:27<103:57:50, 949.93s/it]2025-09-27 03:14:08,915 Stage: Train 0.5 | Epoch: 53 | Iter: 200400 | Total Loss: 0.002762 | Recon Loss: 0.002442 | Commit Loss: 0.000640 | Perplexity: 2534.808870
2025-09-27 03:18:14,693 Stage: Train 0.5 | Epoch: 53 | Iter: 200600 | Total Loss: 0.002804 | Recon Loss: 0.002491 | Commit Loss: 0.000627 | Perplexity: 2537.578434
2025-09-27 03:22:21,282 Stage: Train 0.5 | Epoch: 53 | Iter: 200800 | Total Loss: 0.002785 | Recon Loss: 0.002463 | Commit Loss: 0.000644 | Perplexity: 2541.807631
2025-09-27 03:26:27,755 Stage: Train 0.5 | Epoch: 53 | Iter: 201000 | Total Loss: 0.002781 | Recon Loss: 0.002461 | Commit Loss: 0.000639 | Perplexity: 2538.063844
Trainning Epoch:  40%|████      | 265/658 [14:14:04<103:16:51, 946.08s/it]Trainning Epoch:  40%|████      | 265/658 [14:14:04<103:16:50, 946.08s/it]2025-09-27 03:30:39,121 Stage: Train 0.5 | Epoch: 54 | Iter: 201200 | Total Loss: 0.002755 | Recon Loss: 0.002438 | Commit Loss: 0.000633 | Perplexity: 2541.696565
2025-09-27 03:34:48,582 Stage: Train 0.5 | Epoch: 54 | Iter: 201400 | Total Loss: 0.002789 | Recon Loss: 0.002467 | Commit Loss: 0.000644 | Perplexity: 2538.951879
2025-09-27 03:38:57,818 Stage: Train 0.5 | Epoch: 54 | Iter: 201600 | Total Loss: 0.002793 | Recon Loss: 0.002472 | Commit Loss: 0.000643 | Perplexity: 2538.831832
2025-09-27 03:43:06,050 Stage: Train 0.5 | Epoch: 54 | Iter: 201800 | Total Loss: 0.002790 | Recon Loss: 0.002475 | Commit Loss: 0.000630 | Perplexity: 2541.298895
Trainning Epoch:  40%|████      | 266/658 [14:29:53<103:06:52, 946.97s/it]Trainning Epoch:  40%|████      | 266/658 [14:29:53<103:06:54, 946.98s/it]2025-09-27 03:47:18,322 Stage: Train 0.5 | Epoch: 55 | Iter: 202000 | Total Loss: 0.002778 | Recon Loss: 0.002454 | Commit Loss: 0.000648 | Perplexity: 2542.913112
2025-09-27 03:51:26,773 Stage: Train 0.5 | Epoch: 55 | Iter: 202200 | Total Loss: 0.002803 | Recon Loss: 0.002487 | Commit Loss: 0.000633 | Perplexity: 2542.739025
2025-09-27 03:55:35,733 Stage: Train 0.5 | Epoch: 55 | Iter: 202400 | Total Loss: 0.002769 | Recon Loss: 0.002451 | Commit Loss: 0.000635 | Perplexity: 2533.132848
Trainning Epoch:  41%|████      | 267/658 [14:45:41<102:53:24, 947.33s/it]Trainning Epoch:  41%|████      | 267/658 [14:45:41<102:53:26, 947.33s/it]2025-09-27 03:59:48,470 Stage: Train 0.5 | Epoch: 56 | Iter: 202600 | Total Loss: 0.002809 | Recon Loss: 0.002486 | Commit Loss: 0.000647 | Perplexity: 2538.216552
2025-09-27 04:03:56,340 Stage: Train 0.5 | Epoch: 56 | Iter: 202800 | Total Loss: 0.002765 | Recon Loss: 0.002444 | Commit Loss: 0.000642 | Perplexity: 2537.401997
2025-09-27 04:08:04,482 Stage: Train 0.5 | Epoch: 56 | Iter: 203000 | Total Loss: 0.002791 | Recon Loss: 0.002468 | Commit Loss: 0.000645 | Perplexity: 2540.917413
2025-09-27 04:12:13,071 Stage: Train 0.5 | Epoch: 56 | Iter: 203200 | Total Loss: 0.002774 | Recon Loss: 0.002451 | Commit Loss: 0.000646 | Perplexity: 2538.590919
Trainning Epoch:  41%|████      | 268/658 [15:01:29<102:37:20, 947.28s/it]Trainning Epoch:  41%|████      | 268/658 [15:01:29<102:37:19, 947.28s/it]2025-09-27 04:16:20,896 Stage: Train 0.5 | Epoch: 57 | Iter: 203400 | Total Loss: 0.002745 | Recon Loss: 0.002428 | Commit Loss: 0.000632 | Perplexity: 2535.354993
2025-09-27 04:20:21,401 Stage: Train 0.5 | Epoch: 57 | Iter: 203600 | Total Loss: 0.002769 | Recon Loss: 0.002447 | Commit Loss: 0.000644 | Perplexity: 2541.544274
2025-09-27 04:24:21,945 Stage: Train 0.5 | Epoch: 57 | Iter: 203800 | Total Loss: 0.002804 | Recon Loss: 0.002479 | Commit Loss: 0.000650 | Perplexity: 2541.626210
2025-09-27 04:28:22,192 Stage: Train 0.5 | Epoch: 57 | Iter: 204000 | Total Loss: 0.002776 | Recon Loss: 0.002453 | Commit Loss: 0.000646 | Perplexity: 2541.643329
Trainning Epoch:  41%|████      | 269/658 [15:16:46<101:22:38, 938.20s/it]Trainning Epoch:  41%|████      | 269/658 [15:16:46<101:22:39, 938.20s/it]2025-09-27 04:32:30,520 Stage: Train 0.5 | Epoch: 58 | Iter: 204200 | Total Loss: 0.002738 | Recon Loss: 0.002416 | Commit Loss: 0.000644 | Perplexity: 2538.086405
2025-09-27 04:36:37,570 Stage: Train 0.5 | Epoch: 58 | Iter: 204400 | Total Loss: 0.002770 | Recon Loss: 0.002449 | Commit Loss: 0.000643 | Perplexity: 2536.947781
2025-09-27 04:40:45,143 Stage: Train 0.5 | Epoch: 58 | Iter: 204600 | Total Loss: 0.002756 | Recon Loss: 0.002440 | Commit Loss: 0.000632 | Perplexity: 2537.937391
2025-09-27 04:44:52,165 Stage: Train 0.5 | Epoch: 58 | Iter: 204800 | Total Loss: 0.002790 | Recon Loss: 0.002467 | Commit Loss: 0.000646 | Perplexity: 2543.543702
Trainning Epoch:  41%|████      | 270/658 [15:32:28<101:15:26, 939.50s/it]Trainning Epoch:  41%|████      | 270/658 [15:32:28<101:15:25, 939.50s/it]2025-09-27 04:49:02,186 Stage: Train 0.5 | Epoch: 59 | Iter: 205000 | Total Loss: 0.002743 | Recon Loss: 0.002420 | Commit Loss: 0.000647 | Perplexity: 2541.848488
2025-09-27 04:53:09,899 Stage: Train 0.5 | Epoch: 59 | Iter: 205200 | Total Loss: 0.002743 | Recon Loss: 0.002426 | Commit Loss: 0.000635 | Perplexity: 2537.214127
2025-09-27 04:57:18,226 Stage: Train 0.5 | Epoch: 59 | Iter: 205400 | Total Loss: 0.002762 | Recon Loss: 0.002445 | Commit Loss: 0.000634 | Perplexity: 2538.467117
2025-09-27 05:01:26,830 Stage: Train 0.5 | Epoch: 59 | Iter: 205600 | Total Loss: 0.002762 | Recon Loss: 0.002450 | Commit Loss: 0.000624 | Perplexity: 2538.684509
Trainning Epoch:  41%|████      | 271/658 [15:48:14<101:12:09, 941.42s/it]Trainning Epoch:  41%|████      | 271/658 [15:48:14<101:12:09, 941.42s/it]2025-09-27 05:05:31,713 Stage: Train 0.5 | Epoch: 60 | Iter: 205800 | Total Loss: 0.002734 | Recon Loss: 0.002418 | Commit Loss: 0.000632 | Perplexity: 2537.189406
2025-09-27 05:09:33,818 Stage: Train 0.5 | Epoch: 60 | Iter: 206000 | Total Loss: 0.002750 | Recon Loss: 0.002432 | Commit Loss: 0.000637 | Perplexity: 2539.689877
2025-09-27 05:13:38,422 Stage: Train 0.5 | Epoch: 60 | Iter: 206200 | Total Loss: 0.002732 | Recon Loss: 0.002408 | Commit Loss: 0.000648 | Perplexity: 2543.212826
Trainning Epoch:  41%|████▏     | 272/658 [16:03:41<100:29:29, 937.23s/it]Trainning Epoch:  41%|████▏     | 272/658 [16:03:41<100:29:29, 937.23s/it]2025-09-27 05:17:48,045 Stage: Train 0.5 | Epoch: 61 | Iter: 206400 | Total Loss: 0.002784 | Recon Loss: 0.002460 | Commit Loss: 0.000649 | Perplexity: 2541.975419
2025-09-27 05:21:54,554 Stage: Train 0.5 | Epoch: 61 | Iter: 206600 | Total Loss: 0.002769 | Recon Loss: 0.002450 | Commit Loss: 0.000637 | Perplexity: 2539.862136
2025-09-27 05:26:02,105 Stage: Train 0.5 | Epoch: 61 | Iter: 206800 | Total Loss: 0.002761 | Recon Loss: 0.002441 | Commit Loss: 0.000640 | Perplexity: 2537.676592
2025-09-27 05:30:09,976 Stage: Train 0.5 | Epoch: 61 | Iter: 207000 | Total Loss: 0.002754 | Recon Loss: 0.002427 | Commit Loss: 0.000655 | Perplexity: 2539.930964
Trainning Epoch:  41%|████▏     | 273/658 [16:19:25<100:26:19, 939.17s/it]Trainning Epoch:  41%|████▏     | 273/658 [16:19:25<100:26:19, 939.17s/it]2025-09-27 05:34:20,738 Stage: Train 0.5 | Epoch: 62 | Iter: 207200 | Total Loss: 0.002745 | Recon Loss: 0.002417 | Commit Loss: 0.000656 | Perplexity: 2540.213049
2025-09-27 05:38:26,400 Stage: Train 0.5 | Epoch: 62 | Iter: 207400 | Total Loss: 0.002755 | Recon Loss: 0.002432 | Commit Loss: 0.000646 | Perplexity: 2536.122568
2025-09-27 05:42:33,037 Stage: Train 0.5 | Epoch: 62 | Iter: 207600 | Total Loss: 0.002761 | Recon Loss: 0.002432 | Commit Loss: 0.000660 | Perplexity: 2540.941157
2025-09-27 05:46:38,951 Stage: Train 0.5 | Epoch: 62 | Iter: 207800 | Total Loss: 0.002776 | Recon Loss: 0.002454 | Commit Loss: 0.000645 | Perplexity: 2537.229612
Trainning Epoch:  42%|████▏     | 274/658 [16:35:04<100:09:45, 939.02s/it]Trainning Epoch:  42%|████▏     | 274/658 [16:35:04<100:09:45, 939.02s/it]2025-09-27 05:50:45,367 Stage: Train 0.5 | Epoch: 63 | Iter: 208000 | Total Loss: 0.002765 | Recon Loss: 0.002444 | Commit Loss: 0.000642 | Perplexity: 2542.338016
2025-09-27 05:54:48,983 Stage: Train 0.5 | Epoch: 63 | Iter: 208200 | Total Loss: 0.002768 | Recon Loss: 0.002442 | Commit Loss: 0.000652 | Perplexity: 2541.403866
2025-09-27 05:58:54,381 Stage: Train 0.5 | Epoch: 63 | Iter: 208400 | Total Loss: 0.002767 | Recon Loss: 0.002447 | Commit Loss: 0.000640 | Perplexity: 2535.349543
2025-09-27 06:02:59,545 Stage: Train 0.5 | Epoch: 63 | Iter: 208600 | Total Loss: 0.002764 | Recon Loss: 0.002444 | Commit Loss: 0.000641 | Perplexity: 2537.607797
Trainning Epoch:  42%|████▏     | 275/658 [16:50:36<99:40:04, 936.83s/it] Trainning Epoch:  42%|████▏     | 275/658 [16:50:36<99:40:04, 936.83s/it] 2025-09-27 06:07:09,941 Stage: Train 0.5 | Epoch: 64 | Iter: 208800 | Total Loss: 0.002737 | Recon Loss: 0.002413 | Commit Loss: 0.000647 | Perplexity: 2536.911273
2025-09-27 06:11:17,289 Stage: Train 0.5 | Epoch: 64 | Iter: 209000 | Total Loss: 0.002775 | Recon Loss: 0.002446 | Commit Loss: 0.000657 | Perplexity: 2543.157004
2025-09-27 06:15:25,061 Stage: Train 0.5 | Epoch: 64 | Iter: 209200 | Total Loss: 0.002739 | Recon Loss: 0.002417 | Commit Loss: 0.000644 | Perplexity: 2535.360452
2025-09-27 06:19:32,132 Stage: Train 0.5 | Epoch: 64 | Iter: 209400 | Total Loss: 0.002759 | Recon Loss: 0.002430 | Commit Loss: 0.000656 | Perplexity: 2542.026884
Trainning Epoch:  42%|████▏     | 276/658 [17:06:19<99:37:40, 938.90s/it]Trainning Epoch:  42%|████▏     | 276/658 [17:06:19<99:37:43, 938.91s/it]2025-09-27 06:23:42,053 Stage: Train 0.5 | Epoch: 65 | Iter: 209600 | Total Loss: 0.002741 | Recon Loss: 0.002418 | Commit Loss: 0.000646 | Perplexity: 2536.903759
2025-09-27 06:27:48,998 Stage: Train 0.5 | Epoch: 65 | Iter: 209800 | Total Loss: 0.002760 | Recon Loss: 0.002430 | Commit Loss: 0.000661 | Perplexity: 2543.040316
2025-09-27 06:31:56,382 Stage: Train 0.5 | Epoch: 65 | Iter: 210000 | Total Loss: 0.002755 | Recon Loss: 0.002433 | Commit Loss: 0.000644 | Perplexity: 2536.427277
Trainning Epoch:  42%|████▏     | 277/658 [17:22:01<99:26:59, 939.68s/it]Trainning Epoch:  42%|████▏     | 277/658 [17:22:01<99:26:58, 939.68s/it]2025-09-27 06:36:05,817 Stage: Train 0.5 | Epoch: 66 | Iter: 210200 | Total Loss: 0.002759 | Recon Loss: 0.002425 | Commit Loss: 0.000668 | Perplexity: 2538.882773
2025-09-27 06:40:08,576 Stage: Train 0.5 | Epoch: 66 | Iter: 210400 | Total Loss: 0.002734 | Recon Loss: 0.002412 | Commit Loss: 0.000643 | Perplexity: 2540.550645
2025-09-27 06:44:14,293 Stage: Train 0.5 | Epoch: 66 | Iter: 210600 | Total Loss: 0.002766 | Recon Loss: 0.002445 | Commit Loss: 0.000643 | Perplexity: 2536.893793
2025-09-27 06:48:23,894 Stage: Train 0.5 | Epoch: 66 | Iter: 210800 | Total Loss: 0.002754 | Recon Loss: 0.002429 | Commit Loss: 0.000649 | Perplexity: 2532.379886
Trainning Epoch:  42%|████▏     | 278/658 [17:37:40<99:10:26, 939.54s/it]Trainning Epoch:  42%|████▏     | 278/658 [17:37:40<99:10:25, 939.54s/it]2025-09-27 06:52:33,824 Stage: Train 0.5 | Epoch: 67 | Iter: 211000 | Total Loss: 0.002762 | Recon Loss: 0.002439 | Commit Loss: 0.000645 | Perplexity: 2534.169260
2025-09-27 06:56:37,142 Stage: Train 0.5 | Epoch: 67 | Iter: 211200 | Total Loss: 0.002735 | Recon Loss: 0.002405 | Commit Loss: 0.000660 | Perplexity: 2539.672129
2025-09-27 07:00:41,445 Stage: Train 0.5 | Epoch: 67 | Iter: 211400 | Total Loss: 0.002757 | Recon Loss: 0.002438 | Commit Loss: 0.000637 | Perplexity: 2535.394005
2025-09-27 07:04:46,823 Stage: Train 0.5 | Epoch: 67 | Iter: 211600 | Total Loss: 0.002785 | Recon Loss: 0.002455 | Commit Loss: 0.000660 | Perplexity: 2535.024700
Trainning Epoch:  42%|████▏     | 279/658 [17:53:12<98:40:52, 937.34s/it]Trainning Epoch:  42%|████▏     | 279/658 [17:53:12<98:40:52, 937.34s/it]2025-09-27 07:08:56,605 Stage: Train 0.5 | Epoch: 68 | Iter: 211800 | Total Loss: 0.002733 | Recon Loss: 0.002400 | Commit Loss: 0.000667 | Perplexity: 2537.404696
2025-09-27 07:13:03,180 Stage: Train 0.5 | Epoch: 68 | Iter: 212000 | Total Loss: 0.002728 | Recon Loss: 0.002402 | Commit Loss: 0.000652 | Perplexity: 2541.060105
2025-09-27 07:17:09,943 Stage: Train 0.5 | Epoch: 68 | Iter: 212200 | Total Loss: 0.002778 | Recon Loss: 0.002458 | Commit Loss: 0.000640 | Perplexity: 2535.706328
2025-09-27 07:21:16,730 Stage: Train 0.5 | Epoch: 68 | Iter: 212400 | Total Loss: 0.002761 | Recon Loss: 0.002430 | Commit Loss: 0.000663 | Perplexity: 2535.681458
Trainning Epoch:  43%|████▎     | 280/658 [18:08:53<98:31:24, 938.32s/it]Trainning Epoch:  43%|████▎     | 280/658 [18:08:53<98:31:27, 938.33s/it]2025-09-27 07:25:28,464 Stage: Train 0.5 | Epoch: 69 | Iter: 212600 | Total Loss: 0.002752 | Recon Loss: 0.002433 | Commit Loss: 0.000638 | Perplexity: 2536.047314
2025-09-27 07:29:36,301 Stage: Train 0.5 | Epoch: 69 | Iter: 212800 | Total Loss: 0.002705 | Recon Loss: 0.002380 | Commit Loss: 0.000651 | Perplexity: 2537.661356
2025-09-27 07:33:44,223 Stage: Train 0.5 | Epoch: 69 | Iter: 213000 | Total Loss: 0.002774 | Recon Loss: 0.002455 | Commit Loss: 0.000639 | Perplexity: 2531.997399
2025-09-27 07:37:51,162 Stage: Train 0.5 | Epoch: 69 | Iter: 213200 | Total Loss: 0.002724 | Recon Loss: 0.002399 | Commit Loss: 0.000650 | Perplexity: 2537.982854
Trainning Epoch:  43%|████▎     | 281/658 [18:24:38<98:29:18, 940.47s/it]Trainning Epoch:  43%|████▎     | 281/658 [18:24:38<98:29:20, 940.48s/it]2025-09-27 07:41:58,322 Stage: Train 0.5 | Epoch: 70 | Iter: 213400 | Total Loss: 0.002731 | Recon Loss: 0.002407 | Commit Loss: 0.000648 | Perplexity: 2534.061346
2025-09-27 07:46:03,786 Stage: Train 0.5 | Epoch: 70 | Iter: 213600 | Total Loss: 0.002718 | Recon Loss: 0.002388 | Commit Loss: 0.000659 | Perplexity: 2535.088348
2025-09-27 07:50:09,697 Stage: Train 0.5 | Epoch: 70 | Iter: 213800 | Total Loss: 0.002730 | Recon Loss: 0.002406 | Commit Loss: 0.000648 | Perplexity: 2532.148682
Trainning Epoch:  43%|████▎     | 282/658 [18:40:13<98:02:54, 938.76s/it]Trainning Epoch:  43%|████▎     | 282/658 [18:40:13<98:02:54, 938.76s/it]2025-09-27 07:54:19,660 Stage: Train 0.5 | Epoch: 71 | Iter: 214000 | Total Loss: 0.002722 | Recon Loss: 0.002398 | Commit Loss: 0.000647 | Perplexity: 2533.748098
2025-09-27 07:58:28,372 Stage: Train 0.5 | Epoch: 71 | Iter: 214200 | Total Loss: 0.002709 | Recon Loss: 0.002383 | Commit Loss: 0.000653 | Perplexity: 2531.834761
2025-09-27 08:02:37,438 Stage: Train 0.5 | Epoch: 71 | Iter: 214400 | Total Loss: 0.002711 | Recon Loss: 0.002385 | Commit Loss: 0.000653 | Perplexity: 2539.217144
2025-09-27 08:06:46,065 Stage: Train 0.5 | Epoch: 71 | Iter: 214600 | Total Loss: 0.002767 | Recon Loss: 0.002438 | Commit Loss: 0.000657 | Perplexity: 2538.042109
Trainning Epoch:  43%|████▎     | 283/658 [18:56:02<98:05:45, 941.72s/it]Trainning Epoch:  43%|████▎     | 283/658 [18:56:02<98:05:45, 941.72s/it]2025-09-27 08:10:57,757 Stage: Train 0.5 | Epoch: 72 | Iter: 214800 | Total Loss: 0.002763 | Recon Loss: 0.002438 | Commit Loss: 0.000649 | Perplexity: 2537.699430
2025-09-27 08:15:05,786 Stage: Train 0.5 | Epoch: 72 | Iter: 215000 | Total Loss: 0.002734 | Recon Loss: 0.002407 | Commit Loss: 0.000655 | Perplexity: 2540.555348
2025-09-27 08:19:14,216 Stage: Train 0.5 | Epoch: 72 | Iter: 215200 | Total Loss: 0.002761 | Recon Loss: 0.002426 | Commit Loss: 0.000669 | Perplexity: 2535.816554
2025-09-27 08:23:22,595 Stage: Train 0.5 | Epoch: 72 | Iter: 215400 | Total Loss: 0.002715 | Recon Loss: 0.002386 | Commit Loss: 0.000658 | Perplexity: 2535.415245
Trainning Epoch:  43%|████▎     | 284/658 [19:11:48<97:58:45, 943.12s/it]Trainning Epoch:  43%|████▎     | 284/658 [19:11:48<97:58:46, 943.12s/it]2025-09-27 08:27:34,430 Stage: Train 0.5 | Epoch: 73 | Iter: 215600 | Total Loss: 0.002776 | Recon Loss: 0.002447 | Commit Loss: 0.000657 | Perplexity: 2538.578362
2025-09-27 08:31:43,155 Stage: Train 0.5 | Epoch: 73 | Iter: 215800 | Total Loss: 0.002765 | Recon Loss: 0.002438 | Commit Loss: 0.000654 | Perplexity: 2537.259312
2025-09-27 08:35:51,777 Stage: Train 0.5 | Epoch: 73 | Iter: 216000 | Total Loss: 0.002706 | Recon Loss: 0.002381 | Commit Loss: 0.000649 | Perplexity: 2535.089336
2025-09-27 08:39:59,759 Stage: Train 0.5 | Epoch: 73 | Iter: 216200 | Total Loss: 0.002767 | Recon Loss: 0.002439 | Commit Loss: 0.000657 | Perplexity: 2537.051963
Trainning Epoch:  43%|████▎     | 285/658 [19:27:36<97:51:27, 944.47s/it]Trainning Epoch:  43%|████▎     | 285/658 [19:27:36<97:51:28, 944.47s/it]2025-09-27 08:44:08,248 Stage: Train 0.5 | Epoch: 74 | Iter: 216400 | Total Loss: 0.002685 | Recon Loss: 0.002355 | Commit Loss: 0.000661 | Perplexity: 2535.778109
2025-09-27 08:48:15,094 Stage: Train 0.5 | Epoch: 74 | Iter: 216600 | Total Loss: 0.002726 | Recon Loss: 0.002400 | Commit Loss: 0.000652 | Perplexity: 2534.874033
2025-09-27 08:52:22,670 Stage: Train 0.5 | Epoch: 74 | Iter: 216800 | Total Loss: 0.002720 | Recon Loss: 0.002391 | Commit Loss: 0.000658 | Perplexity: 2536.037991
2025-09-27 08:56:30,064 Stage: Train 0.5 | Epoch: 74 | Iter: 217000 | Total Loss: 0.002747 | Recon Loss: 0.002411 | Commit Loss: 0.000673 | Perplexity: 2536.782844
Trainning Epoch:  43%|████▎     | 286/658 [19:43:17<97:30:11, 943.58s/it]Trainning Epoch:  43%|████▎     | 286/658 [19:43:17<97:30:14, 943.59s/it]2025-09-27 09:00:37,285 Stage: Train 0.5 | Epoch: 75 | Iter: 217200 | Total Loss: 0.002739 | Recon Loss: 0.002410 | Commit Loss: 0.000659 | Perplexity: 2538.353076
2025-09-27 09:04:40,499 Stage: Train 0.5 | Epoch: 75 | Iter: 217400 | Total Loss: 0.002741 | Recon Loss: 0.002418 | Commit Loss: 0.000647 | Perplexity: 2535.407379
2025-09-27 09:08:44,826 Stage: Train 0.5 | Epoch: 75 | Iter: 217600 | Total Loss: 0.002768 | Recon Loss: 0.002435 | Commit Loss: 0.000666 | Perplexity: 2532.553276
Trainning Epoch:  44%|████▎     | 287/658 [19:58:48<96:50:38, 939.73s/it]Trainning Epoch:  44%|████▎     | 287/658 [19:58:48<96:50:37, 939.72s/it]2025-09-27 09:12:54,230 Stage: Train 0.5 | Epoch: 76 | Iter: 217800 | Total Loss: 0.002745 | Recon Loss: 0.002413 | Commit Loss: 0.000663 | Perplexity: 2534.503633
2025-09-27 09:17:01,325 Stage: Train 0.5 | Epoch: 76 | Iter: 218000 | Total Loss: 0.002716 | Recon Loss: 0.002381 | Commit Loss: 0.000671 | Perplexity: 2533.599028
2025-09-27 09:21:09,669 Stage: Train 0.5 | Epoch: 76 | Iter: 218200 | Total Loss: 0.002738 | Recon Loss: 0.002415 | Commit Loss: 0.000647 | Perplexity: 2535.680757
2025-09-27 09:25:17,800 Stage: Train 0.5 | Epoch: 76 | Iter: 218400 | Total Loss: 0.002754 | Recon Loss: 0.002430 | Commit Loss: 0.000647 | Perplexity: 2531.833876
Trainning Epoch:  44%|████▍     | 288/658 [20:14:33<96:44:57, 941.34s/it]Trainning Epoch:  44%|████▍     | 288/658 [20:14:33<96:45:02, 941.36s/it]2025-09-27 09:29:28,345 Stage: Train 0.5 | Epoch: 77 | Iter: 218600 | Total Loss: 0.002720 | Recon Loss: 0.002392 | Commit Loss: 0.000656 | Perplexity: 2534.799396
2025-09-27 09:33:35,535 Stage: Train 0.5 | Epoch: 77 | Iter: 218800 | Total Loss: 0.002751 | Recon Loss: 0.002425 | Commit Loss: 0.000651 | Perplexity: 2532.820394
2025-09-27 09:37:43,282 Stage: Train 0.5 | Epoch: 77 | Iter: 219000 | Total Loss: 0.002720 | Recon Loss: 0.002385 | Commit Loss: 0.000671 | Perplexity: 2533.187815
2025-09-27 09:41:51,186 Stage: Train 0.5 | Epoch: 77 | Iter: 219200 | Total Loss: 0.002730 | Recon Loss: 0.002402 | Commit Loss: 0.000655 | Perplexity: 2532.475104
Trainning Epoch:  44%|████▍     | 289/658 [20:30:17<96:33:40, 942.06s/it]Trainning Epoch:  44%|████▍     | 289/658 [20:30:17<96:33:40, 942.06s/it]2025-09-27 09:46:01,718 Stage: Train 0.5 | Epoch: 78 | Iter: 219400 | Total Loss: 0.002740 | Recon Loss: 0.002405 | Commit Loss: 0.000670 | Perplexity: 2533.255941
2025-09-27 09:50:08,921 Stage: Train 0.5 | Epoch: 78 | Iter: 219600 | Total Loss: 0.002694 | Recon Loss: 0.002374 | Commit Loss: 0.000641 | Perplexity: 2540.657891
2025-09-27 09:54:16,926 Stage: Train 0.5 | Epoch: 78 | Iter: 219800 | Total Loss: 0.002717 | Recon Loss: 0.002383 | Commit Loss: 0.000667 | Perplexity: 2540.307383
2025-09-27 09:58:24,752 Stage: Train 0.5 | Epoch: 78 | Iter: 220000 | Total Loss: 0.002726 | Recon Loss: 0.002393 | Commit Loss: 0.000664 | Perplexity: 2537.573054
2025-09-27 09:58:24,753 Saving model at iteration 220000
2025-09-27 09:58:24,904 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_79_step_220000
2025-09-27 09:58:25,378 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_79_step_220000/model.safetensors
2025-09-27 09:58:25,763 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_79_step_220000/optimizer.bin
2025-09-27 09:58:25,764 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_79_step_220000/scheduler.bin
2025-09-27 09:58:25,764 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_79_step_220000/sampler.bin
2025-09-27 09:58:25,765 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_79_step_220000/random_states_0.pkl
Trainning Epoch:  44%|████▍     | 290/658 [20:46:01<96:22:12, 942.75s/it]Trainning Epoch:  44%|████▍     | 290/658 [20:46:01<96:22:12, 942.75s/it]2025-09-27 10:02:30,284 Stage: Train 0.5 | Epoch: 79 | Iter: 220200 | Total Loss: 0.002730 | Recon Loss: 0.002402 | Commit Loss: 0.000656 | Perplexity: 2532.595040
2025-09-27 10:06:31,054 Stage: Train 0.5 | Epoch: 79 | Iter: 220400 | Total Loss: 0.002709 | Recon Loss: 0.002382 | Commit Loss: 0.000655 | Perplexity: 2532.496261
2025-09-27 10:10:32,648 Stage: Train 0.5 | Epoch: 79 | Iter: 220600 | Total Loss: 0.002711 | Recon Loss: 0.002386 | Commit Loss: 0.000651 | Perplexity: 2531.428367
2025-09-27 10:14:34,862 Stage: Train 0.5 | Epoch: 79 | Iter: 220800 | Total Loss: 0.002719 | Recon Loss: 0.002393 | Commit Loss: 0.000652 | Perplexity: 2532.332698
Trainning Epoch:  44%|████▍     | 291/658 [21:01:22<95:26:16, 936.18s/it]Trainning Epoch:  44%|████▍     | 291/658 [21:01:22<95:26:18, 936.18s/it]2025-09-27 10:18:44,267 Stage: Train 0.5 | Epoch: 80 | Iter: 221000 | Total Loss: 0.002710 | Recon Loss: 0.002380 | Commit Loss: 0.000659 | Perplexity: 2538.999598
2025-09-27 10:22:49,687 Stage: Train 0.5 | Epoch: 80 | Iter: 221200 | Total Loss: 0.002733 | Recon Loss: 0.002405 | Commit Loss: 0.000656 | Perplexity: 2531.092805
2025-09-27 10:26:56,722 Stage: Train 0.5 | Epoch: 80 | Iter: 221400 | Total Loss: 0.002707 | Recon Loss: 0.002375 | Commit Loss: 0.000664 | Perplexity: 2538.871975
Trainning Epoch:  44%|████▍     | 292/658 [21:17:02<95:18:00, 937.38s/it]Trainning Epoch:  44%|████▍     | 292/658 [21:17:02<95:18:00, 937.38s/it]2025-09-27 10:31:07,886 Stage: Train 0.5 | Epoch: 81 | Iter: 221600 | Total Loss: 0.002737 | Recon Loss: 0.002409 | Commit Loss: 0.000657 | Perplexity: 2537.848164
2025-09-27 10:35:13,649 Stage: Train 0.5 | Epoch: 81 | Iter: 221800 | Total Loss: 0.002705 | Recon Loss: 0.002374 | Commit Loss: 0.000661 | Perplexity: 2532.948940
2025-09-27 10:39:20,452 Stage: Train 0.5 | Epoch: 81 | Iter: 222000 | Total Loss: 0.002763 | Recon Loss: 0.002429 | Commit Loss: 0.000669 | Perplexity: 2539.174840
2025-09-27 10:43:27,550 Stage: Train 0.5 | Epoch: 81 | Iter: 222200 | Total Loss: 0.002727 | Recon Loss: 0.002394 | Commit Loss: 0.000668 | Perplexity: 2537.271077
Trainning Epoch:  45%|████▍     | 293/658 [21:32:42<95:07:25, 938.21s/it]Trainning Epoch:  45%|████▍     | 293/658 [21:32:42<95:07:25, 938.21s/it]2025-09-27 10:47:37,397 Stage: Train 0.5 | Epoch: 82 | Iter: 222400 | Total Loss: 0.002723 | Recon Loss: 0.002392 | Commit Loss: 0.000661 | Perplexity: 2527.855010
2025-09-27 10:51:43,288 Stage: Train 0.5 | Epoch: 82 | Iter: 222600 | Total Loss: 0.002739 | Recon Loss: 0.002407 | Commit Loss: 0.000664 | Perplexity: 2534.014050
2025-09-27 10:55:49,891 Stage: Train 0.5 | Epoch: 82 | Iter: 222800 | Total Loss: 0.002717 | Recon Loss: 0.002375 | Commit Loss: 0.000683 | Perplexity: 2534.306973
2025-09-27 10:59:56,580 Stage: Train 0.5 | Epoch: 82 | Iter: 223000 | Total Loss: 0.002725 | Recon Loss: 0.002391 | Commit Loss: 0.000669 | Perplexity: 2536.025704
Trainning Epoch:  45%|████▍     | 294/658 [21:48:22<94:54:40, 938.68s/it]Trainning Epoch:  45%|████▍     | 294/658 [21:48:22<94:54:40, 938.68s/it]2025-09-27 11:04:03,086 Stage: Train 0.5 | Epoch: 83 | Iter: 223200 | Total Loss: 0.002706 | Recon Loss: 0.002373 | Commit Loss: 0.000665 | Perplexity: 2534.165945
2025-09-27 11:08:05,126 Stage: Train 0.5 | Epoch: 83 | Iter: 223400 | Total Loss: 0.002732 | Recon Loss: 0.002396 | Commit Loss: 0.000672 | Perplexity: 2540.918442
2025-09-27 11:12:07,570 Stage: Train 0.5 | Epoch: 83 | Iter: 223600 | Total Loss: 0.002726 | Recon Loss: 0.002391 | Commit Loss: 0.000670 | Perplexity: 2535.117080
2025-09-27 11:16:14,807 Stage: Train 0.5 | Epoch: 83 | Iter: 223800 | Total Loss: 0.002711 | Recon Loss: 0.002384 | Commit Loss: 0.000654 | Perplexity: 2530.882540
Trainning Epoch:  45%|████▍     | 295/658 [22:03:52<94:22:11, 935.90s/it]Trainning Epoch:  45%|████▍     | 295/658 [22:03:52<94:22:11, 935.90s/it]2025-09-27 11:20:24,976 Stage: Train 0.5 | Epoch: 84 | Iter: 224000 | Total Loss: 0.002704 | Recon Loss: 0.002374 | Commit Loss: 0.000659 | Perplexity: 2536.868964
2025-09-27 11:24:30,055 Stage: Train 0.5 | Epoch: 84 | Iter: 224200 | Total Loss: 0.002698 | Recon Loss: 0.002368 | Commit Loss: 0.000661 | Perplexity: 2530.844861
2025-09-27 11:28:34,924 Stage: Train 0.5 | Epoch: 84 | Iter: 224400 | Total Loss: 0.002691 | Recon Loss: 0.002359 | Commit Loss: 0.000663 | Perplexity: 2532.572019
2025-09-27 11:32:39,996 Stage: Train 0.5 | Epoch: 84 | Iter: 224600 | Total Loss: 0.002722 | Recon Loss: 0.002387 | Commit Loss: 0.000669 | Perplexity: 2534.064137
Trainning Epoch:  45%|████▍     | 296/658 [22:19:27<94:06:05, 935.82s/it]Trainning Epoch:  45%|████▍     | 296/658 [22:19:27<94:06:06, 935.82s/it]2025-09-27 11:36:58,144 Stage: Train 0.5 | Epoch: 85 | Iter: 224800 | Total Loss: 0.002694 | Recon Loss: 0.002362 | Commit Loss: 0.000663 | Perplexity: 2533.761129
2025-09-27 11:41:12,019 Stage: Train 0.5 | Epoch: 85 | Iter: 225000 | Total Loss: 0.002692 | Recon Loss: 0.002358 | Commit Loss: 0.000667 | Perplexity: 2535.930254
2025-09-27 11:45:26,286 Stage: Train 0.5 | Epoch: 85 | Iter: 225200 | Total Loss: 0.002732 | Recon Loss: 0.002403 | Commit Loss: 0.000658 | Perplexity: 2534.694655
Trainning Epoch:  45%|████▌     | 297/658 [22:35:36<94:50:38, 945.81s/it]Trainning Epoch:  45%|████▌     | 297/658 [22:35:36<94:50:39, 945.82s/it]2025-09-27 11:49:46,026 Stage: Train 0.5 | Epoch: 86 | Iter: 225400 | Total Loss: 0.002722 | Recon Loss: 0.002387 | Commit Loss: 0.000672 | Perplexity: 2527.164824
2025-09-27 11:54:02,810 Stage: Train 0.5 | Epoch: 86 | Iter: 225600 | Total Loss: 0.002730 | Recon Loss: 0.002384 | Commit Loss: 0.000691 | Perplexity: 2530.165509
2025-09-27 11:58:20,334 Stage: Train 0.5 | Epoch: 86 | Iter: 225800 | Total Loss: 0.002726 | Recon Loss: 0.002398 | Commit Loss: 0.000658 | Perplexity: 2528.485901
2025-09-27 12:02:38,193 Stage: Train 0.5 | Epoch: 86 | Iter: 226000 | Total Loss: 0.002698 | Recon Loss: 0.002372 | Commit Loss: 0.000652 | Perplexity: 2530.958655
Trainning Epoch:  45%|████▌     | 298/658 [22:51:59<95:42:03, 957.01s/it]Trainning Epoch:  45%|████▌     | 298/658 [22:51:59<95:42:03, 957.01s/it]2025-09-27 12:06:58,366 Stage: Train 0.5 | Epoch: 87 | Iter: 226200 | Total Loss: 0.002727 | Recon Loss: 0.002396 | Commit Loss: 0.000664 | Perplexity: 2531.853585
2025-09-27 12:11:12,221 Stage: Train 0.5 | Epoch: 87 | Iter: 226400 | Total Loss: 0.002718 | Recon Loss: 0.002392 | Commit Loss: 0.000653 | Perplexity: 2532.922762
2025-09-27 12:15:27,428 Stage: Train 0.5 | Epoch: 87 | Iter: 226600 | Total Loss: 0.002698 | Recon Loss: 0.002365 | Commit Loss: 0.000666 | Perplexity: 2530.606968
2025-09-27 12:19:44,121 Stage: Train 0.5 | Epoch: 87 | Iter: 226800 | Total Loss: 0.002740 | Recon Loss: 0.002402 | Commit Loss: 0.000676 | Perplexity: 2534.255105
Trainning Epoch:  45%|████▌     | 299/658 [23:08:13<95:56:05, 962.02s/it]Trainning Epoch:  45%|████▌     | 299/658 [23:08:13<95:56:06, 962.02s/it]2025-09-27 12:24:00,497 Stage: Train 0.5 | Epoch: 88 | Iter: 227000 | Total Loss: 0.002722 | Recon Loss: 0.002395 | Commit Loss: 0.000655 | Perplexity: 2534.097787
2025-09-27 12:28:13,113 Stage: Train 0.5 | Epoch: 88 | Iter: 227200 | Total Loss: 0.002683 | Recon Loss: 0.002344 | Commit Loss: 0.000678 | Perplexity: 2535.582518
2025-09-27 12:32:25,529 Stage: Train 0.5 | Epoch: 88 | Iter: 227400 | Total Loss: 0.002704 | Recon Loss: 0.002368 | Commit Loss: 0.000671 | Perplexity: 2531.300389
2025-09-27 12:36:39,269 Stage: Train 0.5 | Epoch: 88 | Iter: 227600 | Total Loss: 0.002717 | Recon Loss: 0.002386 | Commit Loss: 0.000663 | Perplexity: 2533.333854
Trainning Epoch:  46%|████▌     | 300/658 [23:24:17<95:42:51, 962.49s/it]Trainning Epoch:  46%|████▌     | 300/658 [23:24:17<95:42:51, 962.49s/it]2025-09-27 12:40:49,886 Stage: Train 0.5 | Epoch: 89 | Iter: 227800 | Total Loss: 0.002713 | Recon Loss: 0.002386 | Commit Loss: 0.000653 | Perplexity: 2528.526504
2025-09-27 12:44:56,047 Stage: Train 0.5 | Epoch: 89 | Iter: 228000 | Total Loss: 0.002716 | Recon Loss: 0.002378 | Commit Loss: 0.000676 | Perplexity: 2535.399955
2025-09-27 12:49:06,977 Stage: Train 0.5 | Epoch: 89 | Iter: 228200 | Total Loss: 0.002675 | Recon Loss: 0.002344 | Commit Loss: 0.000663 | Perplexity: 2529.612938
2025-09-27 12:53:20,752 Stage: Train 0.5 | Epoch: 89 | Iter: 228400 | Total Loss: 0.002760 | Recon Loss: 0.002426 | Commit Loss: 0.000668 | Perplexity: 2534.782321
Trainning Epoch:  46%|████▌     | 301/658 [23:40:08<95:06:38, 959.10s/it]Trainning Epoch:  46%|████▌     | 301/658 [23:40:08<95:06:39, 959.10s/it]2025-09-27 12:57:39,510 Stage: Train 0.5 | Epoch: 90 | Iter: 228600 | Total Loss: 0.002679 | Recon Loss: 0.002342 | Commit Loss: 0.000674 | Perplexity: 2534.307714
2025-09-27 13:01:52,382 Stage: Train 0.5 | Epoch: 90 | Iter: 228800 | Total Loss: 0.002703 | Recon Loss: 0.002368 | Commit Loss: 0.000670 | Perplexity: 2526.032917
2025-09-27 13:06:06,482 Stage: Train 0.5 | Epoch: 90 | Iter: 229000 | Total Loss: 0.002687 | Recon Loss: 0.002346 | Commit Loss: 0.000682 | Perplexity: 2533.254691
Trainning Epoch:  46%|████▌     | 302/658 [23:56:16<95:06:19, 961.74s/it]Trainning Epoch:  46%|████▌     | 302/658 [23:56:16<95:06:20, 961.74s/it]2025-09-27 13:10:24,070 Stage: Train 0.5 | Epoch: 91 | Iter: 229200 | Total Loss: 0.002726 | Recon Loss: 0.002394 | Commit Loss: 0.000664 | Perplexity: 2530.638197
2025-09-27 13:14:41,975 Stage: Train 0.5 | Epoch: 91 | Iter: 229400 | Total Loss: 0.002686 | Recon Loss: 0.002350 | Commit Loss: 0.000670 | Perplexity: 2529.470778
2025-09-27 13:18:58,961 Stage: Train 0.5 | Epoch: 91 | Iter: 229600 | Total Loss: 0.002661 | Recon Loss: 0.002320 | Commit Loss: 0.000683 | Perplexity: 2529.180275
2025-09-27 13:23:15,413 Stage: Train 0.5 | Epoch: 91 | Iter: 229800 | Total Loss: 0.002700 | Recon Loss: 0.002361 | Commit Loss: 0.000677 | Perplexity: 2528.335516
Trainning Epoch:  46%|████▌     | 303/658 [24:12:36<95:22:51, 967.24s/it]Trainning Epoch:  46%|████▌     | 303/658 [24:12:36<95:22:51, 967.24s/it]2025-09-27 13:27:34,560 Stage: Train 0.5 | Epoch: 92 | Iter: 230000 | Total Loss: 0.002688 | Recon Loss: 0.002352 | Commit Loss: 0.000671 | Perplexity: 2530.811952
2025-09-27 13:31:48,421 Stage: Train 0.5 | Epoch: 92 | Iter: 230200 | Total Loss: 0.002712 | Recon Loss: 0.002376 | Commit Loss: 0.000673 | Perplexity: 2531.452004
2025-09-27 13:36:04,307 Stage: Train 0.5 | Epoch: 92 | Iter: 230400 | Total Loss: 0.002733 | Recon Loss: 0.002392 | Commit Loss: 0.000680 | Perplexity: 2529.113606
2025-09-27 13:40:19,637 Stage: Train 0.5 | Epoch: 92 | Iter: 230600 | Total Loss: 0.002668 | Recon Loss: 0.002336 | Commit Loss: 0.000665 | Perplexity: 2529.853759
Trainning Epoch:  46%|████▌     | 304/658 [24:28:48<95:15:17, 968.69s/it]Trainning Epoch:  46%|████▌     | 304/658 [24:28:48<95:15:16, 968.69s/it]2025-09-27 13:44:38,625 Stage: Train 0.5 | Epoch: 93 | Iter: 230800 | Total Loss: 0.002702 | Recon Loss: 0.002364 | Commit Loss: 0.000677 | Perplexity: 2528.751426
2025-09-27 13:48:56,523 Stage: Train 0.5 | Epoch: 93 | Iter: 231000 | Total Loss: 0.002666 | Recon Loss: 0.002331 | Commit Loss: 0.000670 | Perplexity: 2535.026857
2025-09-27 13:53:13,945 Stage: Train 0.5 | Epoch: 93 | Iter: 231200 | Total Loss: 0.002688 | Recon Loss: 0.002353 | Commit Loss: 0.000671 | Perplexity: 2534.533322
2025-09-27 13:57:31,470 Stage: Train 0.5 | Epoch: 93 | Iter: 231400 | Total Loss: 0.002694 | Recon Loss: 0.002354 | Commit Loss: 0.000680 | Perplexity: 2528.474866
Trainning Epoch:  46%|████▋     | 305/658 [24:45:09<95:21:28, 972.49s/it]Trainning Epoch:  46%|████▋     | 305/658 [24:45:09<95:21:27, 972.49s/it]2025-09-27 14:01:43,638 Stage: Train 0.5 | Epoch: 94 | Iter: 231600 | Total Loss: 0.002674 | Recon Loss: 0.002343 | Commit Loss: 0.000663 | Perplexity: 2531.772018
2025-09-27 14:05:51,720 Stage: Train 0.5 | Epoch: 94 | Iter: 231800 | Total Loss: 0.002685 | Recon Loss: 0.002347 | Commit Loss: 0.000675 | Perplexity: 2532.204957
2025-09-27 14:10:01,970 Stage: Train 0.5 | Epoch: 94 | Iter: 232000 | Total Loss: 0.002689 | Recon Loss: 0.002348 | Commit Loss: 0.000683 | Perplexity: 2529.460729
2025-09-27 14:14:12,019 Stage: Train 0.5 | Epoch: 94 | Iter: 232200 | Total Loss: 0.002698 | Recon Loss: 0.002361 | Commit Loss: 0.000675 | Perplexity: 2530.373555
Trainning Epoch:  47%|████▋     | 306/658 [25:00:59<94:25:26, 965.70s/it]Trainning Epoch:  47%|████▋     | 306/658 [25:00:59<94:25:26, 965.70s/it]2025-09-27 14:18:31,326 Stage: Train 0.5 | Epoch: 95 | Iter: 232400 | Total Loss: 0.002679 | Recon Loss: 0.002339 | Commit Loss: 0.000681 | Perplexity: 2534.802266
2025-09-27 14:22:45,890 Stage: Train 0.5 | Epoch: 95 | Iter: 232600 | Total Loss: 0.002675 | Recon Loss: 0.002347 | Commit Loss: 0.000656 | Perplexity: 2523.183372
2025-09-27 14:27:00,911 Stage: Train 0.5 | Epoch: 95 | Iter: 232800 | Total Loss: 0.002707 | Recon Loss: 0.002368 | Commit Loss: 0.000676 | Perplexity: 2530.680223
Trainning Epoch:  47%|████▋     | 307/658 [25:17:12<94:21:09, 967.72s/it]Trainning Epoch:  47%|████▋     | 307/658 [25:17:12<94:21:09, 967.72s/it]2025-09-27 14:31:21,183 Stage: Train 0.5 | Epoch: 96 | Iter: 233000 | Total Loss: 0.002693 | Recon Loss: 0.002358 | Commit Loss: 0.000670 | Perplexity: 2525.916222
2025-09-27 14:35:34,967 Stage: Train 0.5 | Epoch: 96 | Iter: 233200 | Total Loss: 0.002659 | Recon Loss: 0.002331 | Commit Loss: 0.000657 | Perplexity: 2531.474529
2025-09-27 14:39:50,030 Stage: Train 0.5 | Epoch: 96 | Iter: 233400 | Total Loss: 0.002691 | Recon Loss: 0.002351 | Commit Loss: 0.000681 | Perplexity: 2532.041040
2025-09-27 14:44:05,523 Stage: Train 0.5 | Epoch: 96 | Iter: 233600 | Total Loss: 0.002727 | Recon Loss: 0.002384 | Commit Loss: 0.000685 | Perplexity: 2532.922057
Trainning Epoch:  47%|████▋     | 308/658 [25:33:25<94:15:14, 969.47s/it]Trainning Epoch:  47%|████▋     | 308/658 [25:33:25<94:15:15, 969.47s/it]2025-09-27 14:48:21,869 Stage: Train 0.5 | Epoch: 97 | Iter: 233800 | Total Loss: 0.002729 | Recon Loss: 0.002393 | Commit Loss: 0.000672 | Perplexity: 2528.885900
2025-09-27 14:52:33,414 Stage: Train 0.5 | Epoch: 97 | Iter: 234000 | Total Loss: 0.002658 | Recon Loss: 0.002325 | Commit Loss: 0.000666 | Perplexity: 2527.148582
2025-09-27 14:56:45,435 Stage: Train 0.5 | Epoch: 97 | Iter: 234200 | Total Loss: 0.002725 | Recon Loss: 0.002384 | Commit Loss: 0.000682 | Perplexity: 2530.650658
2025-09-27 15:00:57,815 Stage: Train 0.5 | Epoch: 97 | Iter: 234400 | Total Loss: 0.002661 | Recon Loss: 0.002327 | Commit Loss: 0.000669 | Perplexity: 2532.291254
Trainning Epoch:  47%|████▋     | 309/658 [25:49:25<93:42:55, 966.69s/it]Trainning Epoch:  47%|████▋     | 309/658 [25:49:25<93:42:57, 966.70s/it]2025-09-27 15:05:16,854 Stage: Train 0.5 | Epoch: 98 | Iter: 234600 | Total Loss: 0.002667 | Recon Loss: 0.002336 | Commit Loss: 0.000662 | Perplexity: 2527.431199
2025-09-27 15:09:33,004 Stage: Train 0.5 | Epoch: 98 | Iter: 234800 | Total Loss: 0.002670 | Recon Loss: 0.002340 | Commit Loss: 0.000661 | Perplexity: 2528.424135
2025-09-27 15:13:50,827 Stage: Train 0.5 | Epoch: 98 | Iter: 235000 | Total Loss: 0.002675 | Recon Loss: 0.002335 | Commit Loss: 0.000680 | Perplexity: 2524.736074
2025-09-27 15:18:08,374 Stage: Train 0.5 | Epoch: 98 | Iter: 235200 | Total Loss: 0.002705 | Recon Loss: 0.002374 | Commit Loss: 0.000663 | Perplexity: 2531.758447
Trainning Epoch:  47%|████▋     | 310/658 [26:05:46<93:50:54, 970.85s/it]Trainning Epoch:  47%|████▋     | 310/658 [26:05:46<93:50:53, 970.84s/it]2025-09-27 15:22:28,929 Stage: Train 0.5 | Epoch: 99 | Iter: 235400 | Total Loss: 0.002673 | Recon Loss: 0.002330 | Commit Loss: 0.000686 | Perplexity: 2534.369832
2025-09-27 15:26:46,229 Stage: Train 0.5 | Epoch: 99 | Iter: 235600 | Total Loss: 0.002720 | Recon Loss: 0.002379 | Commit Loss: 0.000681 | Perplexity: 2530.847394
2025-09-27 15:31:04,188 Stage: Train 0.5 | Epoch: 99 | Iter: 235800 | Total Loss: 0.002690 | Recon Loss: 0.002356 | Commit Loss: 0.000667 | Perplexity: 2532.786678
2025-09-27 15:35:20,844 Stage: Train 0.5 | Epoch: 99 | Iter: 236000 | Total Loss: 0.002744 | Recon Loss: 0.002399 | Commit Loss: 0.000690 | Perplexity: 2528.421932
Trainning Epoch:  47%|████▋     | 311/658 [26:22:08<93:54:13, 974.22s/it]Trainning Epoch:  47%|████▋     | 311/658 [26:22:08<93:54:12, 974.22s/it]2025-09-27 15:39:40,902 Stage: Train 0.5 | Epoch: 100 | Iter: 236200 | Total Loss: 0.002682 | Recon Loss: 0.002348 | Commit Loss: 0.000669 | Perplexity: 2528.410297
2025-09-27 15:43:56,210 Stage: Train 0.5 | Epoch: 100 | Iter: 236400 | Total Loss: 0.002711 | Recon Loss: 0.002369 | Commit Loss: 0.000683 | Perplexity: 2524.955280
2025-09-27 15:48:11,835 Stage: Train 0.5 | Epoch: 100 | Iter: 236600 | Total Loss: 0.002649 | Recon Loss: 0.002313 | Commit Loss: 0.000673 | Perplexity: 2532.990841
Trainning Epoch:  47%|████▋     | 312/658 [26:38:24<93:40:12, 974.60s/it]Trainning Epoch:  47%|████▋     | 312/658 [26:38:24<93:40:12, 974.60s/it]2025-09-27 15:52:30,812 Stage: Train 0.5 | Epoch: 101 | Iter: 236800 | Total Loss: 0.002719 | Recon Loss: 0.002382 | Commit Loss: 0.000675 | Perplexity: 2527.586300
2025-09-27 15:56:41,515 Stage: Train 0.5 | Epoch: 101 | Iter: 237000 | Total Loss: 0.002696 | Recon Loss: 0.002357 | Commit Loss: 0.000679 | Perplexity: 2527.699652
2025-09-27 16:00:53,729 Stage: Train 0.5 | Epoch: 101 | Iter: 237200 | Total Loss: 0.002676 | Recon Loss: 0.002338 | Commit Loss: 0.000677 | Perplexity: 2528.281277
2025-09-27 16:05:05,901 Stage: Train 0.5 | Epoch: 101 | Iter: 237400 | Total Loss: 0.002715 | Recon Loss: 0.002373 | Commit Loss: 0.000685 | Perplexity: 2526.725831
Trainning Epoch:  48%|████▊     | 313/658 [26:54:24<92:59:18, 970.31s/it]Trainning Epoch:  48%|████▊     | 313/658 [26:54:24<92:59:21, 970.32s/it]2025-09-27 16:09:21,616 Stage: Train 0.5 | Epoch: 102 | Iter: 237600 | Total Loss: 0.002677 | Recon Loss: 0.002335 | Commit Loss: 0.000684 | Perplexity: 2530.561812
2025-09-27 16:13:33,789 Stage: Train 0.5 | Epoch: 102 | Iter: 237800 | Total Loss: 0.002676 | Recon Loss: 0.002336 | Commit Loss: 0.000681 | Perplexity: 2531.786530
2025-09-27 16:17:45,270 Stage: Train 0.5 | Epoch: 102 | Iter: 238000 | Total Loss: 0.002699 | Recon Loss: 0.002359 | Commit Loss: 0.000680 | Perplexity: 2528.922875
2025-09-27 16:21:57,289 Stage: Train 0.5 | Epoch: 102 | Iter: 238200 | Total Loss: 0.002704 | Recon Loss: 0.002367 | Commit Loss: 0.000674 | Perplexity: 2525.933765
Trainning Epoch:  48%|████▊     | 314/658 [27:10:25<92:27:20, 967.56s/it]Trainning Epoch:  48%|████▊     | 314/658 [27:10:25<92:27:23, 967.57s/it]2025-09-27 16:26:14,935 Stage: Train 0.5 | Epoch: 103 | Iter: 238400 | Total Loss: 0.002670 | Recon Loss: 0.002338 | Commit Loss: 0.000664 | Perplexity: 2521.961089
2025-09-27 16:30:30,022 Stage: Train 0.5 | Epoch: 103 | Iter: 238600 | Total Loss: 0.002685 | Recon Loss: 0.002350 | Commit Loss: 0.000668 | Perplexity: 2529.279148
2025-09-27 16:34:46,301 Stage: Train 0.5 | Epoch: 103 | Iter: 238800 | Total Loss: 0.002674 | Recon Loss: 0.002339 | Commit Loss: 0.000670 | Perplexity: 2527.169779
2025-09-27 16:39:02,163 Stage: Train 0.5 | Epoch: 103 | Iter: 239000 | Total Loss: 0.002695 | Recon Loss: 0.002355 | Commit Loss: 0.000680 | Perplexity: 2528.969988
Trainning Epoch:  48%|████▊     | 315/658 [27:26:40<92:23:58, 969.79s/it]Trainning Epoch:  48%|████▊     | 315/658 [27:26:40<92:23:59, 969.79s/it]2025-09-27 16:43:16,050 Stage: Train 0.5 | Epoch: 104 | Iter: 239200 | Total Loss: 0.002705 | Recon Loss: 0.002373 | Commit Loss: 0.000664 | Perplexity: 2528.125072
2025-09-27 16:47:25,018 Stage: Train 0.5 | Epoch: 104 | Iter: 239400 | Total Loss: 0.002674 | Recon Loss: 0.002334 | Commit Loss: 0.000680 | Perplexity: 2524.783737
2025-09-27 16:51:36,106 Stage: Train 0.5 | Epoch: 104 | Iter: 239600 | Total Loss: 0.002654 | Recon Loss: 0.002317 | Commit Loss: 0.000673 | Perplexity: 2533.584888
2025-09-27 16:55:48,260 Stage: Train 0.5 | Epoch: 104 | Iter: 239800 | Total Loss: 0.002706 | Recon Loss: 0.002367 | Commit Loss: 0.000678 | Perplexity: 2522.795879
Trainning Epoch:  48%|████▊     | 316/658 [27:42:35<91:43:21, 965.50s/it]Trainning Epoch:  48%|████▊     | 316/658 [27:42:35<91:43:20, 965.50s/it]2025-09-27 17:00:06,619 Stage: Train 0.5 | Epoch: 105 | Iter: 240000 | Total Loss: 0.002649 | Recon Loss: 0.002314 | Commit Loss: 0.000670 | Perplexity: 2529.846658
2025-09-27 17:00:06,619 Saving model at iteration 240000
2025-09-27 17:00:06,844 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_106_step_240000
2025-09-27 17:00:07,339 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_106_step_240000/model.safetensors
2025-09-27 17:00:07,784 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_106_step_240000/optimizer.bin
2025-09-27 17:00:07,785 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_106_step_240000/scheduler.bin
2025-09-27 17:00:07,785 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_106_step_240000/sampler.bin
2025-09-27 17:00:07,786 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_106_step_240000/random_states_0.pkl
2025-09-27 17:04:21,642 Stage: Train 0.5 | Epoch: 105 | Iter: 240200 | Total Loss: 0.002693 | Recon Loss: 0.002356 | Commit Loss: 0.000675 | Perplexity: 2528.426315
2025-09-27 17:08:34,903 Stage: Train 0.5 | Epoch: 105 | Iter: 240400 | Total Loss: 0.002681 | Recon Loss: 0.002343 | Commit Loss: 0.000676 | Perplexity: 2523.581149
Trainning Epoch:  48%|████▊     | 317/658 [27:58:45<91:34:56, 966.85s/it]Trainning Epoch:  48%|████▊     | 317/658 [27:58:45<91:34:55, 966.85s/it]2025-09-27 17:12:54,114 Stage: Train 0.5 | Epoch: 106 | Iter: 240600 | Total Loss: 0.002711 | Recon Loss: 0.002366 | Commit Loss: 0.000690 | Perplexity: 2529.651388
2025-09-27 17:17:10,422 Stage: Train 0.5 | Epoch: 106 | Iter: 240800 | Total Loss: 0.002660 | Recon Loss: 0.002321 | Commit Loss: 0.000679 | Perplexity: 2529.279329
2025-09-27 17:21:27,230 Stage: Train 0.5 | Epoch: 106 | Iter: 241000 | Total Loss: 0.002653 | Recon Loss: 0.002312 | Commit Loss: 0.000683 | Perplexity: 2525.306381
2025-09-27 17:25:43,957 Stage: Train 0.5 | Epoch: 106 | Iter: 241200 | Total Loss: 0.002705 | Recon Loss: 0.002361 | Commit Loss: 0.000687 | Perplexity: 2529.111902
Trainning Epoch:  48%|████▊     | 318/658 [28:15:04<91:38:43, 970.36s/it]Trainning Epoch:  48%|████▊     | 318/658 [28:15:04<91:38:44, 970.37s/it]2025-09-27 17:29:59,892 Stage: Train 0.5 | Epoch: 107 | Iter: 241400 | Total Loss: 0.002664 | Recon Loss: 0.002327 | Commit Loss: 0.000675 | Perplexity: 2525.484471
2025-09-27 17:34:08,372 Stage: Train 0.5 | Epoch: 107 | Iter: 241600 | Total Loss: 0.002679 | Recon Loss: 0.002336 | Commit Loss: 0.000685 | Perplexity: 2529.037578
2025-09-27 17:38:17,631 Stage: Train 0.5 | Epoch: 107 | Iter: 241800 | Total Loss: 0.002674 | Recon Loss: 0.002328 | Commit Loss: 0.000692 | Perplexity: 2525.713630
2025-09-27 17:42:26,667 Stage: Train 0.5 | Epoch: 107 | Iter: 242000 | Total Loss: 0.002675 | Recon Loss: 0.002333 | Commit Loss: 0.000683 | Perplexity: 2526.737651
Trainning Epoch:  48%|████▊     | 319/658 [28:30:53<90:46:36, 964.00s/it]Trainning Epoch:  48%|████▊     | 319/658 [28:30:53<90:46:37, 964.00s/it]2025-09-27 17:46:37,533 Stage: Train 0.5 | Epoch: 108 | Iter: 242200 | Total Loss: 0.002666 | Recon Loss: 0.002338 | Commit Loss: 0.000657 | Perplexity: 2525.940891
2025-09-27 17:50:43,500 Stage: Train 0.5 | Epoch: 108 | Iter: 242400 | Total Loss: 0.002663 | Recon Loss: 0.002328 | Commit Loss: 0.000671 | Perplexity: 2530.592898
2025-09-27 17:54:52,265 Stage: Train 0.5 | Epoch: 108 | Iter: 242600 | Total Loss: 0.002695 | Recon Loss: 0.002351 | Commit Loss: 0.000688 | Perplexity: 2527.685702
2025-09-27 17:59:04,050 Stage: Train 0.5 | Epoch: 108 | Iter: 242800 | Total Loss: 0.002688 | Recon Loss: 0.002345 | Commit Loss: 0.000687 | Perplexity: 2522.297823
Trainning Epoch:  49%|████▊     | 320/658 [28:46:41<90:03:28, 959.20s/it]Trainning Epoch:  49%|████▊     | 320/658 [28:46:41<90:03:27, 959.19s/it]2025-09-27 18:03:20,786 Stage: Train 0.5 | Epoch: 109 | Iter: 243000 | Total Loss: 0.002670 | Recon Loss: 0.002328 | Commit Loss: 0.000685 | Perplexity: 2527.973231
2025-09-27 18:07:34,241 Stage: Train 0.5 | Epoch: 109 | Iter: 243200 | Total Loss: 0.002679 | Recon Loss: 0.002334 | Commit Loss: 0.000688 | Perplexity: 2525.704803
2025-09-27 18:11:47,645 Stage: Train 0.5 | Epoch: 109 | Iter: 243400 | Total Loss: 0.002691 | Recon Loss: 0.002349 | Commit Loss: 0.000684 | Perplexity: 2528.838113
2025-09-27 18:16:01,097 Stage: Train 0.5 | Epoch: 109 | Iter: 243600 | Total Loss: 0.002648 | Recon Loss: 0.002307 | Commit Loss: 0.000681 | Perplexity: 2525.487865
Trainning Epoch:  49%|████▉     | 321/658 [29:02:48<90:00:52, 961.58s/it]Trainning Epoch:  49%|████▉     | 321/658 [29:02:48<90:00:52, 961.58s/it]2025-09-27 18:20:19,490 Stage: Train 0.5 | Epoch: 110 | Iter: 243800 | Total Loss: 0.002670 | Recon Loss: 0.002331 | Commit Loss: 0.000678 | Perplexity: 2523.032726
2025-09-27 18:24:34,192 Stage: Train 0.5 | Epoch: 110 | Iter: 244000 | Total Loss: 0.002675 | Recon Loss: 0.002334 | Commit Loss: 0.000682 | Perplexity: 2522.168469
2025-09-27 18:28:49,601 Stage: Train 0.5 | Epoch: 110 | Iter: 244200 | Total Loss: 0.002660 | Recon Loss: 0.002318 | Commit Loss: 0.000683 | Perplexity: 2526.889860
Trainning Epoch:  49%|████▉     | 322/658 [29:19:01<90:02:51, 964.80s/it]Trainning Epoch:  49%|████▉     | 322/658 [29:19:01<90:02:52, 964.80s/it]2025-09-27 18:33:09,588 Stage: Train 0.5 | Epoch: 111 | Iter: 244400 | Total Loss: 0.002639 | Recon Loss: 0.002305 | Commit Loss: 0.000669 | Perplexity: 2526.183362
2025-09-27 18:37:27,758 Stage: Train 0.5 | Epoch: 111 | Iter: 244600 | Total Loss: 0.002676 | Recon Loss: 0.002331 | Commit Loss: 0.000689 | Perplexity: 2521.955009
2025-09-27 18:41:45,799 Stage: Train 0.5 | Epoch: 111 | Iter: 244800 | Total Loss: 0.002664 | Recon Loss: 0.002323 | Commit Loss: 0.000682 | Perplexity: 2524.570638
2025-09-27 18:46:03,749 Stage: Train 0.5 | Epoch: 111 | Iter: 245000 | Total Loss: 0.002675 | Recon Loss: 0.002335 | Commit Loss: 0.000680 | Perplexity: 2528.399976
Trainning Epoch:  49%|████▉     | 323/658 [29:35:26<90:20:35, 970.85s/it]Trainning Epoch:  49%|████▉     | 323/658 [29:35:26<90:20:34, 970.85s/it]2025-09-27 18:50:25,009 Stage: Train 0.5 | Epoch: 112 | Iter: 245200 | Total Loss: 0.002725 | Recon Loss: 0.002381 | Commit Loss: 0.000687 | Perplexity: 2528.895157
2025-09-27 18:54:39,015 Stage: Train 0.5 | Epoch: 112 | Iter: 245400 | Total Loss: 0.002651 | Recon Loss: 0.002310 | Commit Loss: 0.000683 | Perplexity: 2524.869580
2025-09-27 18:58:53,638 Stage: Train 0.5 | Epoch: 112 | Iter: 245600 | Total Loss: 0.002650 | Recon Loss: 0.002306 | Commit Loss: 0.000688 | Perplexity: 2528.668926
2025-09-27 19:03:08,277 Stage: Train 0.5 | Epoch: 112 | Iter: 245800 | Total Loss: 0.002679 | Recon Loss: 0.002338 | Commit Loss: 0.000683 | Perplexity: 2521.535143
Trainning Epoch:  49%|████▉     | 324/658 [29:51:37<90:05:33, 971.06s/it]Trainning Epoch:  49%|████▉     | 324/658 [29:51:37<90:05:32, 971.06s/it]2025-09-27 19:07:28,313 Stage: Train 0.5 | Epoch: 113 | Iter: 246000 | Total Loss: 0.002658 | Recon Loss: 0.002315 | Commit Loss: 0.000687 | Perplexity: 2527.228889
2025-09-27 19:11:44,126 Stage: Train 0.5 | Epoch: 113 | Iter: 246200 | Total Loss: 0.002673 | Recon Loss: 0.002333 | Commit Loss: 0.000679 | Perplexity: 2525.084025
2025-09-27 19:16:00,149 Stage: Train 0.5 | Epoch: 113 | Iter: 246400 | Total Loss: 0.002665 | Recon Loss: 0.002326 | Commit Loss: 0.000678 | Perplexity: 2523.258336
2025-09-27 19:20:16,647 Stage: Train 0.5 | Epoch: 113 | Iter: 246600 | Total Loss: 0.002647 | Recon Loss: 0.002304 | Commit Loss: 0.000685 | Perplexity: 2521.106299
Trainning Epoch:  49%|████▉     | 325/658 [30:07:54<89:59:34, 972.90s/it]Trainning Epoch:  49%|████▉     | 325/658 [30:07:54<89:59:34, 972.90s/it]2025-09-27 19:24:31,514 Stage: Train 0.5 | Epoch: 114 | Iter: 246800 | Total Loss: 0.002660 | Recon Loss: 0.002317 | Commit Loss: 0.000686 | Perplexity: 2530.105083
2025-09-27 19:28:42,859 Stage: Train 0.5 | Epoch: 114 | Iter: 247000 | Total Loss: 0.002640 | Recon Loss: 0.002299 | Commit Loss: 0.000682 | Perplexity: 2521.559764
2025-09-27 19:32:53,932 Stage: Train 0.5 | Epoch: 114 | Iter: 247200 | Total Loss: 0.002678 | Recon Loss: 0.002339 | Commit Loss: 0.000679 | Perplexity: 2529.180854
2025-09-27 19:37:04,954 Stage: Train 0.5 | Epoch: 114 | Iter: 247400 | Total Loss: 0.002682 | Recon Loss: 0.002334 | Commit Loss: 0.000696 | Perplexity: 2527.334506
Trainning Epoch:  50%|████▉     | 326/658 [30:23:52<89:18:18, 968.37s/it]Trainning Epoch:  50%|████▉     | 326/658 [30:23:52<89:18:20, 968.37s/it]2025-09-27 19:41:26,347 Stage: Train 0.5 | Epoch: 115 | Iter: 247600 | Total Loss: 0.002639 | Recon Loss: 0.002295 | Commit Loss: 0.000689 | Perplexity: 2529.686001
2025-09-27 19:45:44,494 Stage: Train 0.5 | Epoch: 115 | Iter: 247800 | Total Loss: 0.002688 | Recon Loss: 0.002347 | Commit Loss: 0.000682 | Perplexity: 2524.911392
2025-09-27 19:50:02,266 Stage: Train 0.5 | Epoch: 115 | Iter: 248000 | Total Loss: 0.002652 | Recon Loss: 0.002312 | Commit Loss: 0.000680 | Perplexity: 2524.518517
Trainning Epoch:  50%|████▉     | 327/658 [30:40:15<89:26:07, 972.71s/it]Trainning Epoch:  50%|████▉     | 327/658 [30:40:15<89:26:07, 972.71s/it]2025-09-27 19:54:22,706 Stage: Train 0.5 | Epoch: 116 | Iter: 248200 | Total Loss: 0.002671 | Recon Loss: 0.002330 | Commit Loss: 0.000682 | Perplexity: 2524.842889
2025-09-27 19:58:35,690 Stage: Train 0.5 | Epoch: 116 | Iter: 248400 | Total Loss: 0.002648 | Recon Loss: 0.002302 | Commit Loss: 0.000692 | Perplexity: 2522.178655
2025-09-27 20:02:49,509 Stage: Train 0.5 | Epoch: 116 | Iter: 248600 | Total Loss: 0.002647 | Recon Loss: 0.002308 | Commit Loss: 0.000678 | Perplexity: 2524.353257
2025-09-27 20:07:02,717 Stage: Train 0.5 | Epoch: 116 | Iter: 248800 | Total Loss: 0.002695 | Recon Loss: 0.002343 | Commit Loss: 0.000704 | Perplexity: 2526.368405
Trainning Epoch:  50%|████▉     | 328/658 [30:56:22<89:00:28, 971.00s/it]Trainning Epoch:  50%|████▉     | 328/658 [30:56:22<89:00:29, 971.00s/it]2025-09-27 20:11:21,149 Stage: Train 0.5 | Epoch: 117 | Iter: 249000 | Total Loss: 0.002633 | Recon Loss: 0.002292 | Commit Loss: 0.000681 | Perplexity: 2531.314755
2025-09-27 20:15:35,747 Stage: Train 0.5 | Epoch: 117 | Iter: 249200 | Total Loss: 0.002678 | Recon Loss: 0.002341 | Commit Loss: 0.000673 | Perplexity: 2520.367964
2025-09-27 20:19:51,753 Stage: Train 0.5 | Epoch: 117 | Iter: 249400 | Total Loss: 0.002675 | Recon Loss: 0.002328 | Commit Loss: 0.000694 | Perplexity: 2527.473478
2025-09-27 20:24:07,155 Stage: Train 0.5 | Epoch: 117 | Iter: 249600 | Total Loss: 0.002683 | Recon Loss: 0.002333 | Commit Loss: 0.000700 | Perplexity: 2525.295077
Trainning Epoch:  50%|█████     | 329/658 [31:12:36<88:49:28, 971.94s/it]Trainning Epoch:  50%|█████     | 329/658 [31:12:36<88:49:29, 971.94s/it]2025-09-27 20:28:23,876 Stage: Train 0.5 | Epoch: 118 | Iter: 249800 | Total Loss: 0.002656 | Recon Loss: 0.002307 | Commit Loss: 0.000699 | Perplexity: 2529.393281
2025-09-27 20:32:34,435 Stage: Train 0.5 | Epoch: 118 | Iter: 250000 | Total Loss: 0.002638 | Recon Loss: 0.002299 | Commit Loss: 0.000678 | Perplexity: 2521.545056
2025-09-27 20:36:44,413 Stage: Train 0.5 | Epoch: 118 | Iter: 250200 | Total Loss: 0.002681 | Recon Loss: 0.002331 | Commit Loss: 0.000700 | Perplexity: 2524.165125
2025-09-27 20:40:54,282 Stage: Train 0.5 | Epoch: 118 | Iter: 250400 | Total Loss: 0.002681 | Recon Loss: 0.002333 | Commit Loss: 0.000695 | Perplexity: 2529.787216
Trainning Epoch:  50%|█████     | 330/658 [31:28:31<88:05:43, 966.90s/it]Trainning Epoch:  50%|█████     | 330/658 [31:28:31<88:05:43, 966.90s/it]2025-09-27 20:45:12,027 Stage: Train 0.5 | Epoch: 119 | Iter: 250600 | Total Loss: 0.002644 | Recon Loss: 0.002297 | Commit Loss: 0.000694 | Perplexity: 2527.663295
2025-09-27 20:49:27,694 Stage: Train 0.5 | Epoch: 119 | Iter: 250800 | Total Loss: 0.002688 | Recon Loss: 0.002335 | Commit Loss: 0.000706 | Perplexity: 2533.134497
2025-09-27 20:53:43,864 Stage: Train 0.5 | Epoch: 119 | Iter: 251000 | Total Loss: 0.002614 | Recon Loss: 0.002266 | Commit Loss: 0.000695 | Perplexity: 2522.931694
2025-09-27 20:57:59,593 Stage: Train 0.5 | Epoch: 119 | Iter: 251200 | Total Loss: 0.002666 | Recon Loss: 0.002315 | Commit Loss: 0.000701 | Perplexity: 2519.507227
Trainning Epoch:  50%|█████     | 331/658 [31:44:47<88:03:44, 969.49s/it]Trainning Epoch:  50%|█████     | 331/658 [31:44:47<88:03:44, 969.49s/it]2025-09-27 21:02:21,999 Stage: Train 0.5 | Epoch: 120 | Iter: 251400 | Total Loss: 0.002686 | Recon Loss: 0.002341 | Commit Loss: 0.000690 | Perplexity: 2522.121147
2025-09-27 21:06:39,656 Stage: Train 0.5 | Epoch: 120 | Iter: 251600 | Total Loss: 0.002597 | Recon Loss: 0.002254 | Commit Loss: 0.000685 | Perplexity: 2526.483951
2025-09-27 21:10:56,778 Stage: Train 0.5 | Epoch: 120 | Iter: 251800 | Total Loss: 0.002661 | Recon Loss: 0.002319 | Commit Loss: 0.000684 | Perplexity: 2523.020105
Trainning Epoch:  50%|█████     | 332/658 [32:01:10<88:10:24, 973.70s/it]Trainning Epoch:  50%|█████     | 332/658 [32:01:10<88:10:25, 973.70s/it]2025-09-27 21:15:18,060 Stage: Train 0.5 | Epoch: 121 | Iter: 252000 | Total Loss: 0.002663 | Recon Loss: 0.002310 | Commit Loss: 0.000704 | Perplexity: 2523.106726
2025-09-27 21:19:30,472 Stage: Train 0.5 | Epoch: 121 | Iter: 252200 | Total Loss: 0.002684 | Recon Loss: 0.002336 | Commit Loss: 0.000696 | Perplexity: 2523.111161
2025-09-27 21:23:44,586 Stage: Train 0.5 | Epoch: 121 | Iter: 252400 | Total Loss: 0.002651 | Recon Loss: 0.002303 | Commit Loss: 0.000696 | Perplexity: 2529.003687
2025-09-27 21:27:59,054 Stage: Train 0.5 | Epoch: 121 | Iter: 252600 | Total Loss: 0.002636 | Recon Loss: 0.002291 | Commit Loss: 0.000690 | Perplexity: 2528.614897
Trainning Epoch:  51%|█████     | 333/658 [32:17:18<87:44:38, 971.93s/it]Trainning Epoch:  51%|█████     | 333/658 [32:17:18<87:44:37, 971.93s/it]2025-09-27 21:32:18,146 Stage: Train 0.5 | Epoch: 122 | Iter: 252800 | Total Loss: 0.002655 | Recon Loss: 0.002309 | Commit Loss: 0.000692 | Perplexity: 2526.832742
2025-09-27 21:36:34,108 Stage: Train 0.5 | Epoch: 122 | Iter: 253000 | Total Loss: 0.002635 | Recon Loss: 0.002286 | Commit Loss: 0.000697 | Perplexity: 2525.086674
2025-09-27 21:40:51,273 Stage: Train 0.5 | Epoch: 122 | Iter: 253200 | Total Loss: 0.002656 | Recon Loss: 0.002314 | Commit Loss: 0.000683 | Perplexity: 2520.902195
2025-09-27 21:45:09,292 Stage: Train 0.5 | Epoch: 122 | Iter: 253400 | Total Loss: 0.002651 | Recon Loss: 0.002303 | Commit Loss: 0.000696 | Perplexity: 2526.952501
Trainning Epoch:  51%|█████     | 334/658 [32:33:39<87:42:38, 974.56s/it]Trainning Epoch:  51%|█████     | 334/658 [32:33:39<87:42:38, 974.56s/it]2025-09-27 21:49:24,831 Stage: Train 0.5 | Epoch: 123 | Iter: 253600 | Total Loss: 0.002665 | Recon Loss: 0.002324 | Commit Loss: 0.000682 | Perplexity: 2525.724143
2025-09-27 21:53:34,617 Stage: Train 0.5 | Epoch: 123 | Iter: 253800 | Total Loss: 0.002671 | Recon Loss: 0.002323 | Commit Loss: 0.000696 | Perplexity: 2525.627603
2025-09-27 21:57:45,425 Stage: Train 0.5 | Epoch: 123 | Iter: 254000 | Total Loss: 0.002660 | Recon Loss: 0.002311 | Commit Loss: 0.000699 | Perplexity: 2528.436047
2025-09-27 22:01:56,367 Stage: Train 0.5 | Epoch: 123 | Iter: 254200 | Total Loss: 0.002647 | Recon Loss: 0.002296 | Commit Loss: 0.000701 | Perplexity: 2524.344769
Trainning Epoch:  51%|█████     | 335/658 [32:49:34<86:55:29, 968.82s/it]Trainning Epoch:  51%|█████     | 335/658 [32:49:34<86:55:29, 968.82s/it]2025-09-27 22:06:11,558 Stage: Train 0.5 | Epoch: 124 | Iter: 254400 | Total Loss: 0.002621 | Recon Loss: 0.002279 | Commit Loss: 0.000685 | Perplexity: 2527.455629
2025-09-27 22:10:24,937 Stage: Train 0.5 | Epoch: 124 | Iter: 254600 | Total Loss: 0.002671 | Recon Loss: 0.002325 | Commit Loss: 0.000692 | Perplexity: 2529.621752
2025-09-27 22:14:38,828 Stage: Train 0.5 | Epoch: 124 | Iter: 254800 | Total Loss: 0.002623 | Recon Loss: 0.002268 | Commit Loss: 0.000709 | Perplexity: 2523.692731
2025-09-27 22:18:53,547 Stage: Train 0.5 | Epoch: 124 | Iter: 255000 | Total Loss: 0.002641 | Recon Loss: 0.002296 | Commit Loss: 0.000691 | Perplexity: 2531.313376
Trainning Epoch:  51%|█████     | 336/658 [33:05:41<86:35:34, 968.12s/it]Trainning Epoch:  51%|█████     | 336/658 [33:05:41<86:35:36, 968.13s/it]2025-09-27 22:23:15,705 Stage: Train 0.5 | Epoch: 125 | Iter: 255200 | Total Loss: 0.002645 | Recon Loss: 0.002293 | Commit Loss: 0.000704 | Perplexity: 2520.886003
2025-09-27 22:27:33,588 Stage: Train 0.5 | Epoch: 125 | Iter: 255400 | Total Loss: 0.002650 | Recon Loss: 0.002307 | Commit Loss: 0.000686 | Perplexity: 2521.447490
2025-09-27 22:31:50,785 Stage: Train 0.5 | Epoch: 125 | Iter: 255600 | Total Loss: 0.002663 | Recon Loss: 0.002316 | Commit Loss: 0.000694 | Perplexity: 2524.632683
Trainning Epoch:  51%|█████     | 337/658 [33:22:04<86:44:06, 972.73s/it]Trainning Epoch:  51%|█████     | 337/658 [33:22:04<86:44:06, 972.73s/it]2025-09-27 22:36:12,103 Stage: Train 0.5 | Epoch: 126 | Iter: 255800 | Total Loss: 0.002658 | Recon Loss: 0.002316 | Commit Loss: 0.000684 | Perplexity: 2528.665768
2025-09-27 22:40:29,742 Stage: Train 0.5 | Epoch: 126 | Iter: 256000 | Total Loss: 0.002641 | Recon Loss: 0.002292 | Commit Loss: 0.000698 | Perplexity: 2530.233080
2025-09-27 22:44:49,747 Stage: Train 0.5 | Epoch: 126 | Iter: 256200 | Total Loss: 0.002644 | Recon Loss: 0.002295 | Commit Loss: 0.000699 | Perplexity: 2531.265093
2025-09-27 22:49:10,185 Stage: Train 0.5 | Epoch: 126 | Iter: 256400 | Total Loss: 0.002680 | Recon Loss: 0.002327 | Commit Loss: 0.000706 | Perplexity: 2529.199280
Trainning Epoch:  51%|█████▏    | 338/658 [33:38:33<86:53:43, 977.57s/it]Trainning Epoch:  51%|█████▏    | 338/658 [33:38:33<86:53:43, 977.57s/it]2025-09-27 22:53:30,080 Stage: Train 0.5 | Epoch: 127 | Iter: 256600 | Total Loss: 0.002665 | Recon Loss: 0.002313 | Commit Loss: 0.000703 | Perplexity: 2529.971248
2025-09-27 22:57:43,708 Stage: Train 0.5 | Epoch: 127 | Iter: 256800 | Total Loss: 0.002612 | Recon Loss: 0.002267 | Commit Loss: 0.000689 | Perplexity: 2527.184586
2025-09-27 23:01:58,860 Stage: Train 0.5 | Epoch: 127 | Iter: 257000 | Total Loss: 0.002640 | Recon Loss: 0.002292 | Commit Loss: 0.000695 | Perplexity: 2525.922068
2025-09-27 23:06:16,022 Stage: Train 0.5 | Epoch: 127 | Iter: 257200 | Total Loss: 0.002648 | Recon Loss: 0.002301 | Commit Loss: 0.000694 | Perplexity: 2525.987578
Trainning Epoch:  52%|█████▏    | 339/658 [33:54:46<86:29:54, 976.16s/it]Trainning Epoch:  52%|█████▏    | 339/658 [33:54:46<86:29:56, 976.17s/it]2025-09-27 23:10:39,467 Stage: Train 0.5 | Epoch: 128 | Iter: 257400 | Total Loss: 0.002614 | Recon Loss: 0.002267 | Commit Loss: 0.000694 | Perplexity: 2525.807131
2025-09-27 23:14:59,598 Stage: Train 0.5 | Epoch: 128 | Iter: 257600 | Total Loss: 0.002620 | Recon Loss: 0.002276 | Commit Loss: 0.000688 | Perplexity: 2524.582458
2025-09-27 23:19:19,805 Stage: Train 0.5 | Epoch: 128 | Iter: 257800 | Total Loss: 0.002652 | Recon Loss: 0.002310 | Commit Loss: 0.000682 | Perplexity: 2524.546003
2025-09-27 23:23:39,880 Stage: Train 0.5 | Epoch: 128 | Iter: 258000 | Total Loss: 0.002640 | Recon Loss: 0.002293 | Commit Loss: 0.000694 | Perplexity: 2522.739207
Trainning Epoch:  52%|█████▏    | 340/658 [34:11:19<86:39:55, 981.12s/it]Trainning Epoch:  52%|█████▏    | 340/658 [34:11:19<86:39:58, 981.13s/it]2025-09-27 23:28:03,820 Stage: Train 0.5 | Epoch: 129 | Iter: 258200 | Total Loss: 0.002635 | Recon Loss: 0.002286 | Commit Loss: 0.000696 | Perplexity: 2526.369139
2025-09-27 23:32:23,476 Stage: Train 0.5 | Epoch: 129 | Iter: 258400 | Total Loss: 0.002618 | Recon Loss: 0.002269 | Commit Loss: 0.000699 | Perplexity: 2522.810237
2025-09-27 23:36:43,385 Stage: Train 0.5 | Epoch: 129 | Iter: 258600 | Total Loss: 0.002641 | Recon Loss: 0.002294 | Commit Loss: 0.000693 | Perplexity: 2523.296162
2025-09-27 23:41:02,465 Stage: Train 0.5 | Epoch: 129 | Iter: 258800 | Total Loss: 0.002627 | Recon Loss: 0.002282 | Commit Loss: 0.000692 | Perplexity: 2518.233792
Trainning Epoch:  52%|█████▏    | 341/658 [34:27:50<86:39:14, 984.08s/it]Trainning Epoch:  52%|█████▏    | 341/658 [34:27:50<86:39:14, 984.08s/it]2025-09-27 23:45:26,139 Stage: Train 0.5 | Epoch: 130 | Iter: 259000 | Total Loss: 0.002642 | Recon Loss: 0.002300 | Commit Loss: 0.000683 | Perplexity: 2518.735409
2025-09-27 23:49:46,233 Stage: Train 0.5 | Epoch: 130 | Iter: 259200 | Total Loss: 0.002631 | Recon Loss: 0.002280 | Commit Loss: 0.000701 | Perplexity: 2527.324623
2025-09-27 23:54:06,256 Stage: Train 0.5 | Epoch: 130 | Iter: 259400 | Total Loss: 0.002658 | Recon Loss: 0.002308 | Commit Loss: 0.000701 | Perplexity: 2525.462874
Trainning Epoch:  52%|█████▏    | 342/658 [34:44:21<86:34:08, 986.23s/it]Trainning Epoch:  52%|█████▏    | 342/658 [34:44:21<86:34:08, 986.23s/it]2025-09-27 23:58:29,747 Stage: Train 0.5 | Epoch: 131 | Iter: 259600 | Total Loss: 0.002654 | Recon Loss: 0.002305 | Commit Loss: 0.000698 | Perplexity: 2527.363062
2025-09-28 00:02:49,294 Stage: Train 0.5 | Epoch: 131 | Iter: 259800 | Total Loss: 0.002623 | Recon Loss: 0.002272 | Commit Loss: 0.000701 | Perplexity: 2519.551622
2025-09-28 00:07:09,631 Stage: Train 0.5 | Epoch: 131 | Iter: 260000 | Total Loss: 0.002639 | Recon Loss: 0.002286 | Commit Loss: 0.000706 | Perplexity: 2533.345358
2025-09-28 00:07:09,631 Saving model at iteration 260000
2025-09-28 00:07:09,844 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_132_step_260000
2025-09-28 00:07:10,342 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_132_step_260000/model.safetensors
2025-09-28 00:07:10,750 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_132_step_260000/optimizer.bin
2025-09-28 00:07:10,750 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_132_step_260000/scheduler.bin
2025-09-28 00:07:10,750 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_132_step_260000/sampler.bin
2025-09-28 00:07:10,751 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_132_step_260000/random_states_0.pkl
2025-09-28 00:11:30,912 Stage: Train 0.5 | Epoch: 131 | Iter: 260200 | Total Loss: 0.002666 | Recon Loss: 0.002317 | Commit Loss: 0.000697 | Perplexity: 2522.348529
Trainning Epoch:  52%|█████▏    | 343/658 [35:00:54<86:28:23, 988.27s/it]Trainning Epoch:  52%|█████▏    | 343/658 [35:00:54<86:28:24, 988.27s/it]2025-09-28 00:15:55,426 Stage: Train 0.5 | Epoch: 132 | Iter: 260400 | Total Loss: 0.002591 | Recon Loss: 0.002248 | Commit Loss: 0.000686 | Perplexity: 2516.609940
2025-09-28 00:20:14,181 Stage: Train 0.5 | Epoch: 132 | Iter: 260600 | Total Loss: 0.002653 | Recon Loss: 0.002299 | Commit Loss: 0.000708 | Perplexity: 2527.137538
2025-09-28 00:24:33,146 Stage: Train 0.5 | Epoch: 132 | Iter: 260800 | Total Loss: 0.002620 | Recon Loss: 0.002269 | Commit Loss: 0.000702 | Perplexity: 2521.970900
2025-09-28 00:28:52,414 Stage: Train 0.5 | Epoch: 132 | Iter: 261000 | Total Loss: 0.002661 | Recon Loss: 0.002301 | Commit Loss: 0.000721 | Perplexity: 2522.659525
Trainning Epoch:  52%|█████▏    | 344/658 [35:17:23<86:13:02, 988.48s/it]Trainning Epoch:  52%|█████▏    | 344/658 [35:17:23<86:13:03, 988.48s/it]2025-09-28 00:33:16,478 Stage: Train 0.5 | Epoch: 133 | Iter: 261200 | Total Loss: 0.002647 | Recon Loss: 0.002289 | Commit Loss: 0.000717 | Perplexity: 2531.920175
2025-09-28 00:37:35,986 Stage: Train 0.5 | Epoch: 133 | Iter: 261400 | Total Loss: 0.002626 | Recon Loss: 0.002273 | Commit Loss: 0.000707 | Perplexity: 2527.907040
2025-09-28 00:41:56,042 Stage: Train 0.5 | Epoch: 133 | Iter: 261600 | Total Loss: 0.002629 | Recon Loss: 0.002277 | Commit Loss: 0.000705 | Perplexity: 2526.440554
2025-09-28 00:46:16,162 Stage: Train 0.5 | Epoch: 133 | Iter: 261800 | Total Loss: 0.002632 | Recon Loss: 0.002279 | Commit Loss: 0.000705 | Perplexity: 2520.703087
Trainning Epoch:  52%|█████▏    | 345/658 [35:33:55<86:02:12, 989.56s/it]Trainning Epoch:  52%|█████▏    | 345/658 [35:33:55<86:02:13, 989.56s/it]2025-09-28 00:50:38,631 Stage: Train 0.5 | Epoch: 134 | Iter: 262000 | Total Loss: 0.002654 | Recon Loss: 0.002304 | Commit Loss: 0.000698 | Perplexity: 2527.989110
2025-09-28 00:54:57,066 Stage: Train 0.5 | Epoch: 134 | Iter: 262200 | Total Loss: 0.002642 | Recon Loss: 0.002289 | Commit Loss: 0.000706 | Perplexity: 2528.291422
2025-09-28 00:59:16,058 Stage: Train 0.5 | Epoch: 134 | Iter: 262400 | Total Loss: 0.002656 | Recon Loss: 0.002308 | Commit Loss: 0.000698 | Perplexity: 2523.576259
2025-09-28 01:03:34,300 Stage: Train 0.5 | Epoch: 134 | Iter: 262600 | Total Loss: 0.002610 | Recon Loss: 0.002261 | Commit Loss: 0.000696 | Perplexity: 2516.634556
Trainning Epoch:  53%|█████▎    | 346/658 [35:50:21<85:41:00, 988.65s/it]Trainning Epoch:  53%|█████▎    | 346/658 [35:50:21<85:41:00, 988.65s/it]2025-09-28 01:07:57,082 Stage: Train 0.5 | Epoch: 135 | Iter: 262800 | Total Loss: 0.002611 | Recon Loss: 0.002260 | Commit Loss: 0.000702 | Perplexity: 2526.696954
2025-09-28 01:12:15,942 Stage: Train 0.5 | Epoch: 135 | Iter: 263000 | Total Loss: 0.002646 | Recon Loss: 0.002296 | Commit Loss: 0.000700 | Perplexity: 2520.597438
2025-09-28 01:16:35,315 Stage: Train 0.5 | Epoch: 135 | Iter: 263200 | Total Loss: 0.002608 | Recon Loss: 0.002259 | Commit Loss: 0.000699 | Perplexity: 2521.554199
Trainning Epoch:  53%|█████▎    | 347/658 [36:06:50<85:24:05, 988.57s/it]Trainning Epoch:  53%|█████▎    | 347/658 [36:06:50<85:24:06, 988.57s/it]2025-09-28 01:20:58,986 Stage: Train 0.5 | Epoch: 136 | Iter: 263400 | Total Loss: 0.002620 | Recon Loss: 0.002267 | Commit Loss: 0.000706 | Perplexity: 2523.880499
2025-09-28 01:25:18,963 Stage: Train 0.5 | Epoch: 136 | Iter: 263600 | Total Loss: 0.002630 | Recon Loss: 0.002283 | Commit Loss: 0.000694 | Perplexity: 2523.032283
2025-09-28 01:29:39,536 Stage: Train 0.5 | Epoch: 136 | Iter: 263800 | Total Loss: 0.002606 | Recon Loss: 0.002252 | Commit Loss: 0.000708 | Perplexity: 2525.331750
2025-09-28 01:33:59,453 Stage: Train 0.5 | Epoch: 136 | Iter: 264000 | Total Loss: 0.002653 | Recon Loss: 0.002300 | Commit Loss: 0.000705 | Perplexity: 2522.976677
Trainning Epoch:  53%|█████▎    | 348/658 [36:23:22<85:13:44, 989.75s/it]Trainning Epoch:  53%|█████▎    | 348/658 [36:23:22<85:13:45, 989.76s/it]2025-09-28 01:38:22,174 Stage: Train 0.5 | Epoch: 137 | Iter: 264200 | Total Loss: 0.002610 | Recon Loss: 0.002256 | Commit Loss: 0.000709 | Perplexity: 2516.720063
2025-09-28 01:42:40,165 Stage: Train 0.5 | Epoch: 137 | Iter: 264400 | Total Loss: 0.002645 | Recon Loss: 0.002293 | Commit Loss: 0.000704 | Perplexity: 2522.205937
2025-09-28 01:46:58,638 Stage: Train 0.5 | Epoch: 137 | Iter: 264600 | Total Loss: 0.002632 | Recon Loss: 0.002280 | Commit Loss: 0.000704 | Perplexity: 2526.434402
2025-09-28 01:51:17,324 Stage: Train 0.5 | Epoch: 137 | Iter: 264800 | Total Loss: 0.002604 | Recon Loss: 0.002252 | Commit Loss: 0.000703 | Perplexity: 2520.736572
Trainning Epoch:  53%|█████▎    | 349/658 [36:39:47<84:49:30, 988.25s/it]Trainning Epoch:  53%|█████▎    | 349/658 [36:39:47<84:49:31, 988.26s/it]2025-09-28 01:55:39,713 Stage: Train 0.5 | Epoch: 138 | Iter: 265000 | Total Loss: 0.002644 | Recon Loss: 0.002300 | Commit Loss: 0.000688 | Perplexity: 2524.322771
2025-09-28 01:59:59,416 Stage: Train 0.5 | Epoch: 138 | Iter: 265200 | Total Loss: 0.002648 | Recon Loss: 0.002297 | Commit Loss: 0.000701 | Perplexity: 2522.964642
2025-09-28 02:04:18,482 Stage: Train 0.5 | Epoch: 138 | Iter: 265400 | Total Loss: 0.002636 | Recon Loss: 0.002285 | Commit Loss: 0.000702 | Perplexity: 2523.709662
2025-09-28 02:08:37,759 Stage: Train 0.5 | Epoch: 138 | Iter: 265600 | Total Loss: 0.002620 | Recon Loss: 0.002265 | Commit Loss: 0.000711 | Perplexity: 2524.648307
Trainning Epoch:  53%|█████▎    | 350/658 [36:56:16<84:34:29, 988.54s/it]Trainning Epoch:  53%|█████▎    | 350/658 [36:56:16<84:34:29, 988.54s/it]2025-09-28 02:13:01,141 Stage: Train 0.5 | Epoch: 139 | Iter: 265800 | Total Loss: 0.002584 | Recon Loss: 0.002235 | Commit Loss: 0.000698 | Perplexity: 2526.515956
2025-09-28 02:17:20,204 Stage: Train 0.5 | Epoch: 139 | Iter: 266000 | Total Loss: 0.002635 | Recon Loss: 0.002285 | Commit Loss: 0.000700 | Perplexity: 2525.588610
2025-09-28 02:21:39,881 Stage: Train 0.5 | Epoch: 139 | Iter: 266200 | Total Loss: 0.002637 | Recon Loss: 0.002282 | Commit Loss: 0.000710 | Perplexity: 2527.910328
2025-09-28 02:25:59,041 Stage: Train 0.5 | Epoch: 139 | Iter: 266400 | Total Loss: 0.002609 | Recon Loss: 0.002258 | Commit Loss: 0.000702 | Perplexity: 2522.372268
Trainning Epoch:  53%|█████▎    | 351/658 [37:12:46<84:20:07, 988.95s/it]Trainning Epoch:  53%|█████▎    | 351/658 [37:12:46<84:20:10, 988.96s/it]2025-09-28 02:30:24,760 Stage: Train 0.5 | Epoch: 140 | Iter: 266600 | Total Loss: 0.002639 | Recon Loss: 0.002288 | Commit Loss: 0.000703 | Perplexity: 2522.404653
2025-09-28 02:34:45,789 Stage: Train 0.5 | Epoch: 140 | Iter: 266800 | Total Loss: 0.002618 | Recon Loss: 0.002264 | Commit Loss: 0.000708 | Perplexity: 2524.452012
2025-09-28 02:39:06,237 Stage: Train 0.5 | Epoch: 140 | Iter: 267000 | Total Loss: 0.002639 | Recon Loss: 0.002282 | Commit Loss: 0.000714 | Perplexity: 2525.571008
Trainning Epoch:  53%|█████▎    | 352/658 [37:29:21<84:13:11, 990.82s/it]Trainning Epoch:  53%|█████▎    | 352/658 [37:29:21<84:13:12, 990.83s/it]2025-09-28 02:43:29,821 Stage: Train 0.5 | Epoch: 141 | Iter: 267200 | Total Loss: 0.002597 | Recon Loss: 0.002251 | Commit Loss: 0.000692 | Perplexity: 2521.593586
2025-09-28 02:47:46,840 Stage: Train 0.5 | Epoch: 141 | Iter: 267400 | Total Loss: 0.002609 | Recon Loss: 0.002252 | Commit Loss: 0.000712 | Perplexity: 2525.117903
2025-09-28 02:52:04,514 Stage: Train 0.5 | Epoch: 141 | Iter: 267600 | Total Loss: 0.002669 | Recon Loss: 0.002315 | Commit Loss: 0.000708 | Perplexity: 2527.383927
2025-09-28 02:56:21,766 Stage: Train 0.5 | Epoch: 141 | Iter: 267800 | Total Loss: 0.002613 | Recon Loss: 0.002260 | Commit Loss: 0.000705 | Perplexity: 2528.901884
Trainning Epoch:  54%|█████▎    | 353/658 [37:45:43<83:42:37, 988.06s/it]Trainning Epoch:  54%|█████▎    | 353/658 [37:45:43<83:42:39, 988.06s/it]2025-09-28 03:00:43,687 Stage: Train 0.5 | Epoch: 142 | Iter: 268000 | Total Loss: 0.002594 | Recon Loss: 0.002246 | Commit Loss: 0.000695 | Perplexity: 2523.197532
2025-09-28 03:05:02,965 Stage: Train 0.5 | Epoch: 142 | Iter: 268200 | Total Loss: 0.002612 | Recon Loss: 0.002264 | Commit Loss: 0.000695 | Perplexity: 2528.551893
2025-09-28 03:09:22,631 Stage: Train 0.5 | Epoch: 142 | Iter: 268400 | Total Loss: 0.002606 | Recon Loss: 0.002251 | Commit Loss: 0.000709 | Perplexity: 2528.577627
2025-09-28 03:13:43,613 Stage: Train 0.5 | Epoch: 142 | Iter: 268600 | Total Loss: 0.002623 | Recon Loss: 0.002269 | Commit Loss: 0.000708 | Perplexity: 2526.550824
Trainning Epoch:  54%|█████▍    | 354/658 [38:02:15<83:31:24, 989.10s/it]Trainning Epoch:  54%|█████▍    | 354/658 [38:02:15<83:31:25, 989.10s/it]2025-09-28 03:17:59,948 Stage: Train 0.5 | Epoch: 143 | Iter: 268800 | Total Loss: 0.002623 | Recon Loss: 0.002270 | Commit Loss: 0.000706 | Perplexity: 2522.985258
2025-09-28 03:22:08,600 Stage: Train 0.5 | Epoch: 143 | Iter: 269000 | Total Loss: 0.002600 | Recon Loss: 0.002252 | Commit Loss: 0.000695 | Perplexity: 2521.807789
2025-09-28 03:26:19,325 Stage: Train 0.5 | Epoch: 143 | Iter: 269200 | Total Loss: 0.002605 | Recon Loss: 0.002250 | Commit Loss: 0.000710 | Perplexity: 2523.798700
2025-09-28 03:30:29,593 Stage: Train 0.5 | Epoch: 143 | Iter: 269400 | Total Loss: 0.002589 | Recon Loss: 0.002234 | Commit Loss: 0.000709 | Perplexity: 2522.692681
Trainning Epoch:  54%|█████▍    | 355/658 [38:18:07<82:18:55, 978.01s/it]Trainning Epoch:  54%|█████▍    | 355/658 [38:18:07<82:18:58, 978.01s/it]2025-09-28 03:34:51,150 Stage: Train 0.5 | Epoch: 144 | Iter: 269600 | Total Loss: 0.002613 | Recon Loss: 0.002263 | Commit Loss: 0.000701 | Perplexity: 2528.065222
2025-09-28 03:39:11,298 Stage: Train 0.5 | Epoch: 144 | Iter: 269800 | Total Loss: 0.002631 | Recon Loss: 0.002280 | Commit Loss: 0.000703 | Perplexity: 2524.531091
2025-09-28 03:43:32,477 Stage: Train 0.5 | Epoch: 144 | Iter: 270000 | Total Loss: 0.002618 | Recon Loss: 0.002268 | Commit Loss: 0.000700 | Perplexity: 2521.298436
2025-09-28 03:47:52,162 Stage: Train 0.5 | Epoch: 144 | Iter: 270200 | Total Loss: 0.002637 | Recon Loss: 0.002281 | Commit Loss: 0.000712 | Perplexity: 2524.137568
Trainning Epoch:  54%|█████▍    | 356/658 [38:34:39<82:24:44, 982.40s/it]Trainning Epoch:  54%|█████▍    | 356/658 [38:34:39<82:24:44, 982.40s/it]2025-09-28 03:52:15,641 Stage: Train 0.5 | Epoch: 145 | Iter: 270400 | Total Loss: 0.002584 | Recon Loss: 0.002233 | Commit Loss: 0.000703 | Perplexity: 2521.670088
2025-09-28 03:56:36,074 Stage: Train 0.5 | Epoch: 145 | Iter: 270600 | Total Loss: 0.002612 | Recon Loss: 0.002258 | Commit Loss: 0.000709 | Perplexity: 2521.916543
2025-09-28 04:00:56,392 Stage: Train 0.5 | Epoch: 145 | Iter: 270800 | Total Loss: 0.002609 | Recon Loss: 0.002250 | Commit Loss: 0.000718 | Perplexity: 2523.582238
Trainning Epoch:  54%|█████▍    | 357/658 [38:51:12<82:23:41, 985.45s/it]Trainning Epoch:  54%|█████▍    | 357/658 [38:51:12<82:23:42, 985.46s/it]2025-09-28 04:05:20,172 Stage: Train 0.5 | Epoch: 146 | Iter: 271000 | Total Loss: 0.002604 | Recon Loss: 0.002251 | Commit Loss: 0.000706 | Perplexity: 2524.604963
2025-09-28 04:09:38,031 Stage: Train 0.5 | Epoch: 146 | Iter: 271200 | Total Loss: 0.002645 | Recon Loss: 0.002300 | Commit Loss: 0.000690 | Perplexity: 2521.674514
2025-09-28 04:13:57,088 Stage: Train 0.5 | Epoch: 146 | Iter: 271400 | Total Loss: 0.002574 | Recon Loss: 0.002223 | Commit Loss: 0.000702 | Perplexity: 2522.374828
2025-09-28 04:18:16,325 Stage: Train 0.5 | Epoch: 146 | Iter: 271600 | Total Loss: 0.002608 | Recon Loss: 0.002253 | Commit Loss: 0.000709 | Perplexity: 2526.368573
Trainning Epoch:  54%|█████▍    | 358/658 [39:07:39<82:09:17, 985.86s/it]Trainning Epoch:  54%|█████▍    | 358/658 [39:07:39<82:09:18, 985.86s/it]2025-09-28 04:22:37,430 Stage: Train 0.5 | Epoch: 147 | Iter: 271800 | Total Loss: 0.002633 | Recon Loss: 0.002276 | Commit Loss: 0.000713 | Perplexity: 2519.180101
2025-09-28 04:26:52,898 Stage: Train 0.5 | Epoch: 147 | Iter: 272000 | Total Loss: 0.002625 | Recon Loss: 0.002276 | Commit Loss: 0.000697 | Perplexity: 2524.639026
2025-09-28 04:31:09,177 Stage: Train 0.5 | Epoch: 147 | Iter: 272200 | Total Loss: 0.002590 | Recon Loss: 0.002238 | Commit Loss: 0.000705 | Perplexity: 2519.810873
2025-09-28 04:35:25,209 Stage: Train 0.5 | Epoch: 147 | Iter: 272400 | Total Loss: 0.002602 | Recon Loss: 0.002248 | Commit Loss: 0.000709 | Perplexity: 2524.098876
Trainning Epoch:  55%|█████▍    | 359/658 [39:23:54<81:37:35, 982.79s/it]Trainning Epoch:  55%|█████▍    | 359/658 [39:23:54<81:37:36, 982.80s/it]2025-09-28 04:39:47,058 Stage: Train 0.5 | Epoch: 148 | Iter: 272600 | Total Loss: 0.002607 | Recon Loss: 0.002258 | Commit Loss: 0.000698 | Perplexity: 2526.780870
2025-09-28 04:44:06,940 Stage: Train 0.5 | Epoch: 148 | Iter: 272800 | Total Loss: 0.002608 | Recon Loss: 0.002245 | Commit Loss: 0.000726 | Perplexity: 2523.778390
2025-09-28 04:48:27,718 Stage: Train 0.5 | Epoch: 148 | Iter: 273000 | Total Loss: 0.002602 | Recon Loss: 0.002246 | Commit Loss: 0.000711 | Perplexity: 2526.915625
2025-09-28 04:52:48,440 Stage: Train 0.5 | Epoch: 148 | Iter: 273200 | Total Loss: 0.002608 | Recon Loss: 0.002255 | Commit Loss: 0.000705 | Perplexity: 2515.470643
Trainning Epoch:  55%|█████▍    | 360/658 [39:40:27<81:36:16, 985.83s/it]Trainning Epoch:  55%|█████▍    | 360/658 [39:40:27<81:36:17, 985.83s/it]2025-09-28 04:57:07,791 Stage: Train 0.5 | Epoch: 149 | Iter: 273400 | Total Loss: 0.002599 | Recon Loss: 0.002254 | Commit Loss: 0.000690 | Perplexity: 2519.059291
2025-09-28 05:01:22,645 Stage: Train 0.5 | Epoch: 149 | Iter: 273600 | Total Loss: 0.002598 | Recon Loss: 0.002249 | Commit Loss: 0.000698 | Perplexity: 2523.532516
2025-09-28 05:05:38,751 Stage: Train 0.5 | Epoch: 149 | Iter: 273800 | Total Loss: 0.002592 | Recon Loss: 0.002239 | Commit Loss: 0.000707 | Perplexity: 2525.793275
2025-09-28 05:09:54,017 Stage: Train 0.5 | Epoch: 149 | Iter: 274000 | Total Loss: 0.002588 | Recon Loss: 0.002231 | Commit Loss: 0.000715 | Perplexity: 2520.386232
Trainning Epoch:  55%|█████▍    | 361/658 [39:56:41<81:02:08, 982.25s/it]Trainning Epoch:  55%|█████▍    | 361/658 [39:56:41<81:02:09, 982.25s/it]2025-09-28 05:14:09,934 Stage: Train 0.5 | Epoch: 150 | Iter: 274200 | Total Loss: 0.002585 | Recon Loss: 0.002231 | Commit Loss: 0.000708 | Perplexity: 2518.567557
2025-09-28 05:18:22,925 Stage: Train 0.5 | Epoch: 150 | Iter: 274400 | Total Loss: 0.002644 | Recon Loss: 0.002291 | Commit Loss: 0.000706 | Perplexity: 2523.796974
2025-09-28 05:22:38,264 Stage: Train 0.5 | Epoch: 150 | Iter: 274600 | Total Loss: 0.002581 | Recon Loss: 0.002229 | Commit Loss: 0.000704 | Perplexity: 2519.307638
Trainning Epoch:  55%|█████▌    | 362/658 [40:12:51<80:27:43, 978.59s/it]Trainning Epoch:  55%|█████▌    | 362/658 [40:12:51<80:27:44, 978.60s/it]2025-09-28 05:26:57,579 Stage: Train 0.5 | Epoch: 151 | Iter: 274800 | Total Loss: 0.002604 | Recon Loss: 0.002247 | Commit Loss: 0.000715 | Perplexity: 2524.319546
2025-09-28 05:31:07,000 Stage: Train 0.5 | Epoch: 151 | Iter: 275000 | Total Loss: 0.002560 | Recon Loss: 0.002204 | Commit Loss: 0.000711 | Perplexity: 2515.274076
2025-09-28 05:35:18,000 Stage: Train 0.5 | Epoch: 151 | Iter: 275200 | Total Loss: 0.002610 | Recon Loss: 0.002251 | Commit Loss: 0.000716 | Perplexity: 2529.522439
2025-09-28 05:39:31,413 Stage: Train 0.5 | Epoch: 151 | Iter: 275400 | Total Loss: 0.002639 | Recon Loss: 0.002285 | Commit Loss: 0.000709 | Perplexity: 2521.636547
Trainning Epoch:  55%|█████▌    | 363/658 [40:28:51<79:44:10, 973.05s/it]Trainning Epoch:  55%|█████▌    | 363/658 [40:28:51<79:44:10, 973.05s/it]2025-09-28 05:43:49,951 Stage: Train 0.5 | Epoch: 152 | Iter: 275600 | Total Loss: 0.002574 | Recon Loss: 0.002215 | Commit Loss: 0.000718 | Perplexity: 2526.669852
2025-09-28 05:48:05,406 Stage: Train 0.5 | Epoch: 152 | Iter: 275800 | Total Loss: 0.002606 | Recon Loss: 0.002257 | Commit Loss: 0.000696 | Perplexity: 2519.665900
2025-09-28 05:52:21,534 Stage: Train 0.5 | Epoch: 152 | Iter: 276000 | Total Loss: 0.002602 | Recon Loss: 0.002239 | Commit Loss: 0.000726 | Perplexity: 2524.629443
2025-09-28 05:56:38,029 Stage: Train 0.5 | Epoch: 152 | Iter: 276200 | Total Loss: 0.002608 | Recon Loss: 0.002245 | Commit Loss: 0.000726 | Perplexity: 2523.669674
Trainning Epoch:  55%|█████▌    | 364/658 [40:45:08<79:33:18, 974.14s/it]Trainning Epoch:  55%|█████▌    | 364/658 [40:45:08<79:33:17, 974.14s/it]2025-09-28 06:01:01,095 Stage: Train 0.5 | Epoch: 153 | Iter: 276400 | Total Loss: 0.002579 | Recon Loss: 0.002221 | Commit Loss: 0.000715 | Perplexity: 2519.198573
2025-09-28 06:05:21,689 Stage: Train 0.5 | Epoch: 153 | Iter: 276600 | Total Loss: 0.002600 | Recon Loss: 0.002235 | Commit Loss: 0.000729 | Perplexity: 2526.882017
2025-09-28 06:09:42,489 Stage: Train 0.5 | Epoch: 153 | Iter: 276800 | Total Loss: 0.002620 | Recon Loss: 0.002266 | Commit Loss: 0.000708 | Perplexity: 2517.673617
2025-09-28 06:14:02,937 Stage: Train 0.5 | Epoch: 153 | Iter: 277000 | Total Loss: 0.002605 | Recon Loss: 0.002253 | Commit Loss: 0.000704 | Perplexity: 2522.283632
Trainning Epoch:  55%|█████▌    | 365/658 [41:01:42<79:45:39, 980.00s/it]Trainning Epoch:  55%|█████▌    | 365/658 [41:01:42<79:45:38, 980.00s/it]2025-09-28 06:18:24,679 Stage: Train 0.5 | Epoch: 154 | Iter: 277200 | Total Loss: 0.002595 | Recon Loss: 0.002239 | Commit Loss: 0.000711 | Perplexity: 2518.816888
2025-09-28 06:22:42,943 Stage: Train 0.5 | Epoch: 154 | Iter: 277400 | Total Loss: 0.002596 | Recon Loss: 0.002241 | Commit Loss: 0.000709 | Perplexity: 2522.384722
2025-09-28 06:27:01,845 Stage: Train 0.5 | Epoch: 154 | Iter: 277600 | Total Loss: 0.002581 | Recon Loss: 0.002230 | Commit Loss: 0.000703 | Perplexity: 2522.065629
2025-09-28 06:31:20,609 Stage: Train 0.5 | Epoch: 154 | Iter: 277800 | Total Loss: 0.002590 | Recon Loss: 0.002238 | Commit Loss: 0.000704 | Perplexity: 2523.506934
Trainning Epoch:  56%|█████▌    | 366/658 [41:18:08<79:38:09, 981.81s/it]Trainning Epoch:  56%|█████▌    | 366/658 [41:18:08<79:38:09, 981.81s/it]2025-09-28 06:35:37,090 Stage: Train 0.5 | Epoch: 155 | Iter: 278000 | Total Loss: 0.002581 | Recon Loss: 0.002232 | Commit Loss: 0.000697 | Perplexity: 2522.357159
2025-09-28 06:39:52,906 Stage: Train 0.5 | Epoch: 155 | Iter: 278200 | Total Loss: 0.002609 | Recon Loss: 0.002263 | Commit Loss: 0.000691 | Perplexity: 2517.158910
2025-09-28 06:44:09,223 Stage: Train 0.5 | Epoch: 155 | Iter: 278400 | Total Loss: 0.002594 | Recon Loss: 0.002236 | Commit Loss: 0.000716 | Perplexity: 2521.488710
Trainning Epoch:  56%|█████▌    | 367/658 [41:34:22<79:10:27, 979.47s/it]Trainning Epoch:  56%|█████▌    | 367/658 [41:34:22<79:10:30, 979.49s/it]2025-09-28 06:48:29,367 Stage: Train 0.5 | Epoch: 156 | Iter: 278600 | Total Loss: 0.002631 | Recon Loss: 0.002276 | Commit Loss: 0.000710 | Perplexity: 2522.646409
2025-09-28 06:52:47,355 Stage: Train 0.5 | Epoch: 156 | Iter: 278800 | Total Loss: 0.002597 | Recon Loss: 0.002244 | Commit Loss: 0.000706 | Perplexity: 2519.071853
2025-09-28 06:57:05,960 Stage: Train 0.5 | Epoch: 156 | Iter: 279000 | Total Loss: 0.002602 | Recon Loss: 0.002252 | Commit Loss: 0.000701 | Perplexity: 2519.250280
2025-09-28 07:01:26,077 Stage: Train 0.5 | Epoch: 156 | Iter: 279200 | Total Loss: 0.002617 | Recon Loss: 0.002256 | Commit Loss: 0.000722 | Perplexity: 2521.508536
Trainning Epoch:  56%|█████▌    | 368/658 [41:50:49<79:05:05, 981.74s/it]Trainning Epoch:  56%|█████▌    | 368/658 [41:50:49<79:05:05, 981.74s/it]2025-09-28 07:05:46,585 Stage: Train 0.5 | Epoch: 157 | Iter: 279400 | Total Loss: 0.002590 | Recon Loss: 0.002240 | Commit Loss: 0.000701 | Perplexity: 2520.644733
2025-09-28 07:09:59,681 Stage: Train 0.5 | Epoch: 157 | Iter: 279600 | Total Loss: 0.002631 | Recon Loss: 0.002283 | Commit Loss: 0.000695 | Perplexity: 2518.323817
2025-09-28 07:14:13,009 Stage: Train 0.5 | Epoch: 157 | Iter: 279800 | Total Loss: 0.002596 | Recon Loss: 0.002247 | Commit Loss: 0.000698 | Perplexity: 2514.251809
2025-09-28 07:18:27,705 Stage: Train 0.5 | Epoch: 157 | Iter: 280000 | Total Loss: 0.002572 | Recon Loss: 0.002222 | Commit Loss: 0.000701 | Perplexity: 2521.446223
2025-09-28 07:18:27,705 Saving model at iteration 280000
2025-09-28 07:18:27,912 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_158_step_280000
2025-09-28 07:18:28,471 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_158_step_280000/model.safetensors
2025-09-28 07:18:28,898 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_158_step_280000/optimizer.bin
2025-09-28 07:18:28,898 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_158_step_280000/scheduler.bin
2025-09-28 07:18:28,898 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_158_step_280000/sampler.bin
2025-09-28 07:18:28,899 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_158_step_280000/random_states_0.pkl
Trainning Epoch:  56%|█████▌    | 369/658 [42:06:58<78:29:49, 977.82s/it]Trainning Epoch:  56%|█████▌    | 369/658 [42:06:58<78:29:51, 977.83s/it]2025-09-28 07:22:48,777 Stage: Train 0.5 | Epoch: 158 | Iter: 280200 | Total Loss: 0.002616 | Recon Loss: 0.002265 | Commit Loss: 0.000702 | Perplexity: 2517.938309
2025-09-28 07:27:06,117 Stage: Train 0.5 | Epoch: 158 | Iter: 280400 | Total Loss: 0.002587 | Recon Loss: 0.002233 | Commit Loss: 0.000708 | Perplexity: 2521.662887
2025-09-28 07:31:24,348 Stage: Train 0.5 | Epoch: 158 | Iter: 280600 | Total Loss: 0.002599 | Recon Loss: 0.002241 | Commit Loss: 0.000717 | Perplexity: 2526.526342
2025-09-28 07:35:43,145 Stage: Train 0.5 | Epoch: 158 | Iter: 280800 | Total Loss: 0.002599 | Recon Loss: 0.002243 | Commit Loss: 0.000712 | Perplexity: 2524.419268
Trainning Epoch:  56%|█████▌    | 370/658 [42:23:22<78:22:50, 979.76s/it]Trainning Epoch:  56%|█████▌    | 370/658 [42:23:22<78:22:50, 979.76s/it]2025-09-28 07:40:06,723 Stage: Train 0.5 | Epoch: 159 | Iter: 281000 | Total Loss: 0.002572 | Recon Loss: 0.002218 | Commit Loss: 0.000708 | Perplexity: 2522.957051
2025-09-28 07:44:27,228 Stage: Train 0.5 | Epoch: 159 | Iter: 281200 | Total Loss: 0.002612 | Recon Loss: 0.002253 | Commit Loss: 0.000718 | Perplexity: 2524.724744
2025-09-28 07:48:46,963 Stage: Train 0.5 | Epoch: 159 | Iter: 281400 | Total Loss: 0.002572 | Recon Loss: 0.002217 | Commit Loss: 0.000710 | Perplexity: 2524.341161
2025-09-28 07:53:06,608 Stage: Train 0.5 | Epoch: 159 | Iter: 281600 | Total Loss: 0.002634 | Recon Loss: 0.002277 | Commit Loss: 0.000714 | Perplexity: 2523.177914
Trainning Epoch:  56%|█████▋    | 371/658 [42:39:54<78:24:04, 983.43s/it]Trainning Epoch:  56%|█████▋    | 371/658 [42:39:54<78:24:05, 983.43s/it]2025-09-28 07:57:30,823 Stage: Train 0.5 | Epoch: 160 | Iter: 281800 | Total Loss: 0.002606 | Recon Loss: 0.002255 | Commit Loss: 0.000701 | Perplexity: 2517.106184
2025-09-28 08:01:50,836 Stage: Train 0.5 | Epoch: 160 | Iter: 282000 | Total Loss: 0.002573 | Recon Loss: 0.002223 | Commit Loss: 0.000700 | Perplexity: 2519.061959
2025-09-28 08:06:10,788 Stage: Train 0.5 | Epoch: 160 | Iter: 282200 | Total Loss: 0.002572 | Recon Loss: 0.002215 | Commit Loss: 0.000714 | Perplexity: 2523.473623
Trainning Epoch:  57%|█████▋    | 372/658 [42:56:26<78:19:34, 985.92s/it]Trainning Epoch:  57%|█████▋    | 372/658 [42:56:26<78:19:34, 985.92s/it]2025-09-28 08:10:33,668 Stage: Train 0.5 | Epoch: 161 | Iter: 282400 | Total Loss: 0.002590 | Recon Loss: 0.002240 | Commit Loss: 0.000699 | Perplexity: 2517.939509
2025-09-28 08:14:52,297 Stage: Train 0.5 | Epoch: 161 | Iter: 282600 | Total Loss: 0.002588 | Recon Loss: 0.002233 | Commit Loss: 0.000710 | Perplexity: 2522.311283
2025-09-28 08:19:11,674 Stage: Train 0.5 | Epoch: 161 | Iter: 282800 | Total Loss: 0.002556 | Recon Loss: 0.002203 | Commit Loss: 0.000706 | Perplexity: 2516.608469
2025-09-28 08:23:31,123 Stage: Train 0.5 | Epoch: 161 | Iter: 283000 | Total Loss: 0.002596 | Recon Loss: 0.002240 | Commit Loss: 0.000712 | Perplexity: 2522.762328
Trainning Epoch:  57%|█████▋    | 373/658 [43:12:53<78:05:24, 986.40s/it]Trainning Epoch:  57%|█████▋    | 373/658 [43:12:53<78:05:26, 986.41s/it]2025-09-28 08:27:53,269 Stage: Train 0.5 | Epoch: 162 | Iter: 283200 | Total Loss: 0.002576 | Recon Loss: 0.002219 | Commit Loss: 0.000713 | Perplexity: 2518.786697
2025-09-28 08:32:12,280 Stage: Train 0.5 | Epoch: 162 | Iter: 283400 | Total Loss: 0.002575 | Recon Loss: 0.002228 | Commit Loss: 0.000694 | Perplexity: 2513.996442
2025-09-28 08:36:31,800 Stage: Train 0.5 | Epoch: 162 | Iter: 283600 | Total Loss: 0.002584 | Recon Loss: 0.002226 | Commit Loss: 0.000716 | Perplexity: 2518.260995
2025-09-28 08:40:52,007 Stage: Train 0.5 | Epoch: 162 | Iter: 283800 | Total Loss: 0.002544 | Recon Loss: 0.002195 | Commit Loss: 0.000700 | Perplexity: 2519.938552
Trainning Epoch:  57%|█████▋    | 374/658 [43:29:23<77:53:53, 987.44s/it]Trainning Epoch:  57%|█████▋    | 374/658 [43:29:23<77:53:54, 987.45s/it]2025-09-28 08:45:15,610 Stage: Train 0.5 | Epoch: 163 | Iter: 284000 | Total Loss: 0.002584 | Recon Loss: 0.002220 | Commit Loss: 0.000728 | Perplexity: 2523.848270
2025-09-28 08:49:34,281 Stage: Train 0.5 | Epoch: 163 | Iter: 284200 | Total Loss: 0.002572 | Recon Loss: 0.002219 | Commit Loss: 0.000706 | Perplexity: 2518.492933
2025-09-28 08:53:53,040 Stage: Train 0.5 | Epoch: 163 | Iter: 284400 | Total Loss: 0.002595 | Recon Loss: 0.002236 | Commit Loss: 0.000719 | Perplexity: 2520.559071
2025-09-28 08:58:10,772 Stage: Train 0.5 | Epoch: 163 | Iter: 284600 | Total Loss: 0.002579 | Recon Loss: 0.002224 | Commit Loss: 0.000710 | Perplexity: 2516.146598
Trainning Epoch:  57%|█████▋    | 375/658 [43:45:49<77:35:48, 987.10s/it]Trainning Epoch:  57%|█████▋    | 375/658 [43:45:49<77:35:49, 987.10s/it]2025-09-28 09:02:35,255 Stage: Train 0.5 | Epoch: 164 | Iter: 284800 | Total Loss: 0.002603 | Recon Loss: 0.002243 | Commit Loss: 0.000719 | Perplexity: 2520.069056
2025-09-28 09:06:56,099 Stage: Train 0.5 | Epoch: 164 | Iter: 285000 | Total Loss: 0.002599 | Recon Loss: 0.002242 | Commit Loss: 0.000713 | Perplexity: 2516.865272
2025-09-28 09:11:16,414 Stage: Train 0.5 | Epoch: 164 | Iter: 285200 | Total Loss: 0.002557 | Recon Loss: 0.002201 | Commit Loss: 0.000712 | Perplexity: 2522.274994
2025-09-28 09:15:36,533 Stage: Train 0.5 | Epoch: 164 | Iter: 285400 | Total Loss: 0.002563 | Recon Loss: 0.002206 | Commit Loss: 0.000715 | Perplexity: 2516.132968
Trainning Epoch:  57%|█████▋    | 376/658 [44:02:24<77:29:46, 989.32s/it]Trainning Epoch:  57%|█████▋    | 376/658 [44:02:24<77:29:47, 989.32s/it]2025-09-28 09:20:00,138 Stage: Train 0.5 | Epoch: 165 | Iter: 285600 | Total Loss: 0.002592 | Recon Loss: 0.002230 | Commit Loss: 0.000725 | Perplexity: 2519.127996
2025-09-28 09:24:20,448 Stage: Train 0.5 | Epoch: 165 | Iter: 285800 | Total Loss: 0.002589 | Recon Loss: 0.002228 | Commit Loss: 0.000721 | Perplexity: 2519.908342
2025-09-28 09:28:40,306 Stage: Train 0.5 | Epoch: 165 | Iter: 286000 | Total Loss: 0.002573 | Recon Loss: 0.002214 | Commit Loss: 0.000718 | Perplexity: 2519.257479
Trainning Epoch:  57%|█████▋    | 377/658 [44:18:55<77:15:54, 989.87s/it]Trainning Epoch:  57%|█████▋    | 377/658 [44:18:55<77:15:54, 989.87s/it]2025-09-28 09:33:04,001 Stage: Train 0.5 | Epoch: 166 | Iter: 286200 | Total Loss: 0.002575 | Recon Loss: 0.002221 | Commit Loss: 0.000707 | Perplexity: 2522.977201
2025-09-28 09:37:21,647 Stage: Train 0.5 | Epoch: 166 | Iter: 286400 | Total Loss: 0.002552 | Recon Loss: 0.002193 | Commit Loss: 0.000719 | Perplexity: 2522.542188
2025-09-28 09:41:39,316 Stage: Train 0.5 | Epoch: 166 | Iter: 286600 | Total Loss: 0.002577 | Recon Loss: 0.002220 | Commit Loss: 0.000714 | Perplexity: 2514.941411
2025-09-28 09:45:57,541 Stage: Train 0.5 | Epoch: 166 | Iter: 286800 | Total Loss: 0.002604 | Recon Loss: 0.002240 | Commit Loss: 0.000729 | Perplexity: 2521.205321
Trainning Epoch:  57%|█████▋    | 378/658 [44:35:19<76:50:48, 988.03s/it]Trainning Epoch:  57%|█████▋    | 378/658 [44:35:19<76:50:49, 988.03s/it]2025-09-28 09:50:18,406 Stage: Train 0.5 | Epoch: 167 | Iter: 287000 | Total Loss: 0.002585 | Recon Loss: 0.002231 | Commit Loss: 0.000709 | Perplexity: 2514.363940
2025-09-28 09:54:36,492 Stage: Train 0.5 | Epoch: 167 | Iter: 287200 | Total Loss: 0.002561 | Recon Loss: 0.002211 | Commit Loss: 0.000700 | Perplexity: 2515.213600
2025-09-28 09:58:55,067 Stage: Train 0.5 | Epoch: 167 | Iter: 287400 | Total Loss: 0.002573 | Recon Loss: 0.002217 | Commit Loss: 0.000712 | Perplexity: 2516.971215
2025-09-28 10:03:13,297 Stage: Train 0.5 | Epoch: 167 | Iter: 287600 | Total Loss: 0.002562 | Recon Loss: 0.002207 | Commit Loss: 0.000710 | Perplexity: 2522.198118
Trainning Epoch:  58%|█████▊    | 379/658 [44:51:44<76:30:30, 987.21s/it]Trainning Epoch:  58%|█████▊    | 379/658 [44:51:44<76:30:32, 987.21s/it]2025-09-28 10:07:32,907 Stage: Train 0.5 | Epoch: 168 | Iter: 287800 | Total Loss: 0.002588 | Recon Loss: 0.002232 | Commit Loss: 0.000711 | Perplexity: 2513.881230
2025-09-28 10:11:49,422 Stage: Train 0.5 | Epoch: 168 | Iter: 288000 | Total Loss: 0.002554 | Recon Loss: 0.002192 | Commit Loss: 0.000725 | Perplexity: 2521.808923
2025-09-28 10:16:07,210 Stage: Train 0.5 | Epoch: 168 | Iter: 288200 | Total Loss: 0.002591 | Recon Loss: 0.002228 | Commit Loss: 0.000727 | Perplexity: 2521.209570
2025-09-28 10:20:24,358 Stage: Train 0.5 | Epoch: 168 | Iter: 288400 | Total Loss: 0.002576 | Recon Loss: 0.002220 | Commit Loss: 0.000712 | Perplexity: 2516.714415
Trainning Epoch:  58%|█████▊    | 380/658 [45:08:03<76:02:16, 984.66s/it]Trainning Epoch:  58%|█████▊    | 380/658 [45:08:03<76:02:18, 984.67s/it]2025-09-28 10:24:42,713 Stage: Train 0.5 | Epoch: 169 | Iter: 288600 | Total Loss: 0.002537 | Recon Loss: 0.002185 | Commit Loss: 0.000704 | Perplexity: 2510.274027
2025-09-28 10:28:58,492 Stage: Train 0.5 | Epoch: 169 | Iter: 288800 | Total Loss: 0.002614 | Recon Loss: 0.002259 | Commit Loss: 0.000710 | Perplexity: 2519.649683
2025-09-28 10:33:13,849 Stage: Train 0.5 | Epoch: 169 | Iter: 289000 | Total Loss: 0.002591 | Recon Loss: 0.002235 | Commit Loss: 0.000712 | Perplexity: 2514.967513
2025-09-28 10:37:30,009 Stage: Train 0.5 | Epoch: 169 | Iter: 289200 | Total Loss: 0.002587 | Recon Loss: 0.002225 | Commit Loss: 0.000725 | Perplexity: 2514.161851
Trainning Epoch:  58%|█████▊    | 381/658 [45:24:17<75:31:48, 981.62s/it]Trainning Epoch:  58%|█████▊    | 381/658 [45:24:17<75:31:50, 981.63s/it]2025-09-28 10:41:52,231 Stage: Train 0.5 | Epoch: 170 | Iter: 289400 | Total Loss: 0.002584 | Recon Loss: 0.002228 | Commit Loss: 0.000713 | Perplexity: 2520.081942
2025-09-28 10:46:11,005 Stage: Train 0.5 | Epoch: 170 | Iter: 289600 | Total Loss: 0.002589 | Recon Loss: 0.002236 | Commit Loss: 0.000706 | Perplexity: 2516.291876
2025-09-28 10:50:29,830 Stage: Train 0.5 | Epoch: 170 | Iter: 289800 | Total Loss: 0.002544 | Recon Loss: 0.002191 | Commit Loss: 0.000706 | Perplexity: 2512.776948
Trainning Epoch:  58%|█████▊    | 382/658 [45:40:44<75:22:31, 983.16s/it]Trainning Epoch:  58%|█████▊    | 382/658 [45:40:44<75:22:30, 983.16s/it]2025-09-28 10:54:52,122 Stage: Train 0.5 | Epoch: 171 | Iter: 290000 | Total Loss: 0.002607 | Recon Loss: 0.002245 | Commit Loss: 0.000725 | Perplexity: 2518.110885
2025-09-28 10:59:08,584 Stage: Train 0.5 | Epoch: 171 | Iter: 290200 | Total Loss: 0.002567 | Recon Loss: 0.002210 | Commit Loss: 0.000715 | Perplexity: 2518.002963
2025-09-28 11:03:25,435 Stage: Train 0.5 | Epoch: 171 | Iter: 290400 | Total Loss: 0.002580 | Recon Loss: 0.002222 | Commit Loss: 0.000717 | Perplexity: 2524.154867
2025-09-28 11:07:42,791 Stage: Train 0.5 | Epoch: 171 | Iter: 290600 | Total Loss: 0.002576 | Recon Loss: 0.002218 | Commit Loss: 0.000715 | Perplexity: 2513.822076
Trainning Epoch:  58%|█████▊    | 383/658 [45:57:03<75:01:10, 982.07s/it]Trainning Epoch:  58%|█████▊    | 383/658 [45:57:03<75:01:12, 982.08s/it]2025-09-28 11:12:02,702 Stage: Train 0.5 | Epoch: 172 | Iter: 290800 | Total Loss: 0.002572 | Recon Loss: 0.002213 | Commit Loss: 0.000717 | Perplexity: 2516.002396
2025-09-28 11:16:18,984 Stage: Train 0.5 | Epoch: 172 | Iter: 291000 | Total Loss: 0.002551 | Recon Loss: 0.002199 | Commit Loss: 0.000703 | Perplexity: 2514.662865
2025-09-28 11:20:36,267 Stage: Train 0.5 | Epoch: 172 | Iter: 291200 | Total Loss: 0.002610 | Recon Loss: 0.002246 | Commit Loss: 0.000728 | Perplexity: 2517.029105
2025-09-28 11:24:54,233 Stage: Train 0.5 | Epoch: 172 | Iter: 291400 | Total Loss: 0.002596 | Recon Loss: 0.002235 | Commit Loss: 0.000721 | Perplexity: 2514.860386
Trainning Epoch:  58%|█████▊    | 384/658 [46:13:24<74:42:54, 981.66s/it]Trainning Epoch:  58%|█████▊    | 384/658 [46:13:24<74:42:54, 981.66s/it]2025-09-28 11:29:18,447 Stage: Train 0.5 | Epoch: 173 | Iter: 291600 | Total Loss: 0.002565 | Recon Loss: 0.002210 | Commit Loss: 0.000708 | Perplexity: 2522.391289
2025-09-28 11:33:38,652 Stage: Train 0.5 | Epoch: 173 | Iter: 291800 | Total Loss: 0.002590 | Recon Loss: 0.002233 | Commit Loss: 0.000713 | Perplexity: 2519.706816
2025-09-28 11:37:58,976 Stage: Train 0.5 | Epoch: 173 | Iter: 292000 | Total Loss: 0.002598 | Recon Loss: 0.002236 | Commit Loss: 0.000724 | Perplexity: 2518.139475
2025-09-28 11:42:18,837 Stage: Train 0.5 | Epoch: 173 | Iter: 292200 | Total Loss: 0.002569 | Recon Loss: 0.002213 | Commit Loss: 0.000712 | Perplexity: 2514.917126
Trainning Epoch:  59%|█████▊    | 385/658 [46:29:58<74:42:41, 985.21s/it]Trainning Epoch:  59%|█████▊    | 385/658 [46:29:58<74:42:41, 985.21s/it]2025-09-28 11:46:39,397 Stage: Train 0.5 | Epoch: 174 | Iter: 292400 | Total Loss: 0.002558 | Recon Loss: 0.002204 | Commit Loss: 0.000708 | Perplexity: 2515.635874
2025-09-28 11:50:56,577 Stage: Train 0.5 | Epoch: 174 | Iter: 292600 | Total Loss: 0.002580 | Recon Loss: 0.002225 | Commit Loss: 0.000711 | Perplexity: 2514.932053
2025-09-28 11:55:13,710 Stage: Train 0.5 | Epoch: 174 | Iter: 292800 | Total Loss: 0.002577 | Recon Loss: 0.002217 | Commit Loss: 0.000720 | Perplexity: 2514.319878
2025-09-28 11:59:30,473 Stage: Train 0.5 | Epoch: 174 | Iter: 293000 | Total Loss: 0.002557 | Recon Loss: 0.002199 | Commit Loss: 0.000717 | Perplexity: 2519.688510
Trainning Epoch:  59%|█████▊    | 386/658 [46:46:18<74:19:12, 983.65s/it]Trainning Epoch:  59%|█████▊    | 386/658 [46:46:18<74:19:13, 983.65s/it]2025-09-28 12:03:52,452 Stage: Train 0.5 | Epoch: 175 | Iter: 293200 | Total Loss: 0.002528 | Recon Loss: 0.002173 | Commit Loss: 0.000711 | Perplexity: 2514.666609
2025-09-28 12:08:10,506 Stage: Train 0.5 | Epoch: 175 | Iter: 293400 | Total Loss: 0.002576 | Recon Loss: 0.002227 | Commit Loss: 0.000699 | Perplexity: 2518.089139
2025-09-28 12:12:28,693 Stage: Train 0.5 | Epoch: 175 | Iter: 293600 | Total Loss: 0.002557 | Recon Loss: 0.002196 | Commit Loss: 0.000722 | Perplexity: 2513.469424
Trainning Epoch:  59%|█████▉    | 387/658 [47:02:42<74:03:14, 983.74s/it]Trainning Epoch:  59%|█████▉    | 387/658 [47:02:42<74:03:14, 983.74s/it]2025-09-28 12:16:50,751 Stage: Train 0.5 | Epoch: 176 | Iter: 293800 | Total Loss: 0.002586 | Recon Loss: 0.002218 | Commit Loss: 0.000736 | Perplexity: 2522.417682
2025-09-28 12:21:09,340 Stage: Train 0.5 | Epoch: 176 | Iter: 294000 | Total Loss: 0.002586 | Recon Loss: 0.002233 | Commit Loss: 0.000706 | Perplexity: 2518.124419
2025-09-28 12:25:27,763 Stage: Train 0.5 | Epoch: 176 | Iter: 294200 | Total Loss: 0.002577 | Recon Loss: 0.002223 | Commit Loss: 0.000708 | Perplexity: 2515.063551
2025-09-28 12:29:48,533 Stage: Train 0.5 | Epoch: 176 | Iter: 294400 | Total Loss: 0.002553 | Recon Loss: 0.002194 | Commit Loss: 0.000718 | Perplexity: 2518.090306
Trainning Epoch:  59%|█████▉    | 388/658 [47:19:12<73:55:40, 985.71s/it]Trainning Epoch:  59%|█████▉    | 388/658 [47:19:12<73:55:40, 985.71s/it]2025-09-28 12:34:13,827 Stage: Train 0.5 | Epoch: 177 | Iter: 294600 | Total Loss: 0.002597 | Recon Loss: 0.002242 | Commit Loss: 0.000711 | Perplexity: 2516.732776
2025-09-28 12:38:33,570 Stage: Train 0.5 | Epoch: 177 | Iter: 294800 | Total Loss: 0.002564 | Recon Loss: 0.002209 | Commit Loss: 0.000711 | Perplexity: 2516.438164
2025-09-28 12:42:51,882 Stage: Train 0.5 | Epoch: 177 | Iter: 295000 | Total Loss: 0.002565 | Recon Loss: 0.002210 | Commit Loss: 0.000711 | Perplexity: 2521.526725
2025-09-28 12:47:10,131 Stage: Train 0.5 | Epoch: 177 | Iter: 295200 | Total Loss: 0.002550 | Recon Loss: 0.002192 | Commit Loss: 0.000717 | Perplexity: 2516.519766
Trainning Epoch:  59%|█████▉    | 389/658 [47:35:40<73:42:37, 986.46s/it]Trainning Epoch:  59%|█████▉    | 389/658 [47:35:40<73:42:38, 986.46s/it]2025-09-28 12:51:31,991 Stage: Train 0.5 | Epoch: 178 | Iter: 295400 | Total Loss: 0.002556 | Recon Loss: 0.002199 | Commit Loss: 0.000713 | Perplexity: 2517.808082
2025-09-28 12:55:49,585 Stage: Train 0.5 | Epoch: 178 | Iter: 295600 | Total Loss: 0.002590 | Recon Loss: 0.002232 | Commit Loss: 0.000716 | Perplexity: 2515.384918
2025-09-28 13:00:07,674 Stage: Train 0.5 | Epoch: 178 | Iter: 295800 | Total Loss: 0.002577 | Recon Loss: 0.002218 | Commit Loss: 0.000718 | Perplexity: 2519.711116
2025-09-28 13:04:26,128 Stage: Train 0.5 | Epoch: 178 | Iter: 296000 | Total Loss: 0.002566 | Recon Loss: 0.002205 | Commit Loss: 0.000721 | Perplexity: 2513.699425
Trainning Epoch:  59%|█████▉    | 390/658 [47:52:04<73:23:00, 985.75s/it]Trainning Epoch:  59%|█████▉    | 390/658 [47:52:04<73:23:00, 985.75s/it]2025-09-28 13:08:47,857 Stage: Train 0.5 | Epoch: 179 | Iter: 296200 | Total Loss: 0.002575 | Recon Loss: 0.002225 | Commit Loss: 0.000701 | Perplexity: 2510.033392
2025-09-28 13:13:06,740 Stage: Train 0.5 | Epoch: 179 | Iter: 296400 | Total Loss: 0.002549 | Recon Loss: 0.002190 | Commit Loss: 0.000717 | Perplexity: 2513.854496
2025-09-28 13:17:26,508 Stage: Train 0.5 | Epoch: 179 | Iter: 296600 | Total Loss: 0.002544 | Recon Loss: 0.002189 | Commit Loss: 0.000710 | Perplexity: 2513.012997
2025-09-28 13:21:45,830 Stage: Train 0.5 | Epoch: 179 | Iter: 296800 | Total Loss: 0.002575 | Recon Loss: 0.002212 | Commit Loss: 0.000726 | Perplexity: 2522.315228
Trainning Epoch:  59%|█████▉    | 391/658 [48:08:33<73:10:40, 986.67s/it]Trainning Epoch:  59%|█████▉    | 391/658 [48:08:33<73:10:39, 986.67s/it]2025-09-28 13:26:10,810 Stage: Train 0.5 | Epoch: 180 | Iter: 297000 | Total Loss: 0.002568 | Recon Loss: 0.002209 | Commit Loss: 0.000719 | Perplexity: 2517.578521
2025-09-28 13:30:31,311 Stage: Train 0.5 | Epoch: 180 | Iter: 297200 | Total Loss: 0.002563 | Recon Loss: 0.002200 | Commit Loss: 0.000726 | Perplexity: 2515.188215
2025-09-28 13:34:50,762 Stage: Train 0.5 | Epoch: 180 | Iter: 297400 | Total Loss: 0.002551 | Recon Loss: 0.002192 | Commit Loss: 0.000718 | Perplexity: 2513.307806
Trainning Epoch:  60%|█████▉    | 392/658 [48:25:05<73:01:22, 988.28s/it]Trainning Epoch:  60%|█████▉    | 392/658 [48:25:05<73:01:22, 988.28s/it]2025-09-28 13:39:14,016 Stage: Train 0.5 | Epoch: 181 | Iter: 297600 | Total Loss: 0.002584 | Recon Loss: 0.002223 | Commit Loss: 0.000722 | Perplexity: 2520.946456
2025-09-28 13:43:33,765 Stage: Train 0.5 | Epoch: 181 | Iter: 297800 | Total Loss: 0.002574 | Recon Loss: 0.002211 | Commit Loss: 0.000727 | Perplexity: 2519.549543
2025-09-28 13:47:54,520 Stage: Train 0.5 | Epoch: 181 | Iter: 298000 | Total Loss: 0.002580 | Recon Loss: 0.002223 | Commit Loss: 0.000714 | Perplexity: 2521.036586
2025-09-28 13:52:14,498 Stage: Train 0.5 | Epoch: 181 | Iter: 298200 | Total Loss: 0.002532 | Recon Loss: 0.002183 | Commit Loss: 0.000699 | Perplexity: 2514.608234
Trainning Epoch:  60%|█████▉    | 393/658 [48:41:37<72:49:51, 989.40s/it]Trainning Epoch:  60%|█████▉    | 393/658 [48:41:37<72:49:51, 989.40s/it]2025-09-28 13:56:37,796 Stage: Train 0.5 | Epoch: 182 | Iter: 298400 | Total Loss: 0.002571 | Recon Loss: 0.002214 | Commit Loss: 0.000715 | Perplexity: 2512.944182
2025-09-28 14:00:57,288 Stage: Train 0.5 | Epoch: 182 | Iter: 298600 | Total Loss: 0.002558 | Recon Loss: 0.002203 | Commit Loss: 0.000710 | Perplexity: 2516.873331
2025-09-28 14:05:16,703 Stage: Train 0.5 | Epoch: 182 | Iter: 298800 | Total Loss: 0.002578 | Recon Loss: 0.002224 | Commit Loss: 0.000708 | Perplexity: 2511.214592
2025-09-28 14:09:35,937 Stage: Train 0.5 | Epoch: 182 | Iter: 299000 | Total Loss: 0.002566 | Recon Loss: 0.002202 | Commit Loss: 0.000726 | Perplexity: 2514.825287
Trainning Epoch:  60%|█████▉    | 394/658 [48:58:06<72:32:57, 989.31s/it]Trainning Epoch:  60%|█████▉    | 394/658 [48:58:06<72:32:57, 989.31s/it]2025-09-28 14:13:58,209 Stage: Train 0.5 | Epoch: 183 | Iter: 299200 | Total Loss: 0.002525 | Recon Loss: 0.002172 | Commit Loss: 0.000706 | Perplexity: 2520.670387
2025-09-28 14:18:17,309 Stage: Train 0.5 | Epoch: 183 | Iter: 299400 | Total Loss: 0.002556 | Recon Loss: 0.002196 | Commit Loss: 0.000719 | Perplexity: 2514.743861
2025-09-28 14:22:37,081 Stage: Train 0.5 | Epoch: 183 | Iter: 299600 | Total Loss: 0.002586 | Recon Loss: 0.002226 | Commit Loss: 0.000720 | Perplexity: 2517.625537
2025-09-28 14:26:56,146 Stage: Train 0.5 | Epoch: 183 | Iter: 299800 | Total Loss: 0.002574 | Recon Loss: 0.002216 | Commit Loss: 0.000717 | Perplexity: 2514.851014
Trainning Epoch:  60%|██████    | 395/658 [49:14:34<72:15:05, 989.00s/it]Trainning Epoch:  60%|██████    | 395/658 [49:14:34<72:15:05, 988.99s/it]2025-09-28 14:31:12,400 Stage: Train 0.5 | Epoch: 184 | Iter: 300000 | Total Loss: 0.002577 | Recon Loss: 0.002220 | Commit Loss: 0.000715 | Perplexity: 2517.092396
2025-09-28 14:31:12,401 Saving model at iteration 300000
2025-09-28 14:31:12,815 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_185_step_300000
2025-09-28 14:31:13,322 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_185_step_300000/model.safetensors
2025-09-28 14:31:13,745 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_185_step_300000/optimizer.bin
2025-09-28 14:31:13,745 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_185_step_300000/scheduler.bin
2025-09-28 14:31:13,746 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_185_step_300000/sampler.bin
2025-09-28 14:31:13,746 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_185_step_300000/random_states_0.pkl
2025-09-28 14:35:29,043 Stage: Train 0.5 | Epoch: 184 | Iter: 300200 | Total Loss: 0.002558 | Recon Loss: 0.002197 | Commit Loss: 0.000722 | Perplexity: 2516.935225
2025-09-28 14:39:43,953 Stage: Train 0.5 | Epoch: 184 | Iter: 300400 | Total Loss: 0.002547 | Recon Loss: 0.002187 | Commit Loss: 0.000722 | Perplexity: 2518.262356
2025-09-28 14:43:59,525 Stage: Train 0.5 | Epoch: 184 | Iter: 300600 | Total Loss: 0.002563 | Recon Loss: 0.002201 | Commit Loss: 0.000724 | Perplexity: 2516.774708
Trainning Epoch:  60%|██████    | 396/658 [49:30:47<71:36:42, 983.98s/it]Trainning Epoch:  60%|██████    | 396/658 [49:30:47<71:36:42, 983.98s/it]2025-09-28 14:48:18,174 Stage: Train 0.5 | Epoch: 185 | Iter: 300800 | Total Loss: 0.002558 | Recon Loss: 0.002197 | Commit Loss: 0.000721 | Perplexity: 2511.749763
2025-09-28 14:52:33,018 Stage: Train 0.5 | Epoch: 185 | Iter: 301000 | Total Loss: 0.002584 | Recon Loss: 0.002228 | Commit Loss: 0.000712 | Perplexity: 2511.694520
2025-09-28 14:56:49,087 Stage: Train 0.5 | Epoch: 185 | Iter: 301200 | Total Loss: 0.002553 | Recon Loss: 0.002194 | Commit Loss: 0.000717 | Perplexity: 2516.596039
Trainning Epoch:  60%|██████    | 397/658 [49:47:00<71:06:12, 980.74s/it]Trainning Epoch:  60%|██████    | 397/658 [49:47:00<71:06:12, 980.74s/it]2025-09-28 15:01:07,885 Stage: Train 0.5 | Epoch: 186 | Iter: 301400 | Total Loss: 0.002587 | Recon Loss: 0.002225 | Commit Loss: 0.000723 | Perplexity: 2519.266805
2025-09-28 15:05:23,336 Stage: Train 0.5 | Epoch: 186 | Iter: 301600 | Total Loss: 0.002538 | Recon Loss: 0.002184 | Commit Loss: 0.000708 | Perplexity: 2513.965651
2025-09-28 15:09:38,959 Stage: Train 0.5 | Epoch: 186 | Iter: 301800 | Total Loss: 0.002589 | Recon Loss: 0.002238 | Commit Loss: 0.000703 | Perplexity: 2515.209935
2025-09-28 15:13:54,575 Stage: Train 0.5 | Epoch: 186 | Iter: 302000 | Total Loss: 0.002549 | Recon Loss: 0.002181 | Commit Loss: 0.000735 | Perplexity: 2514.259479
Trainning Epoch:  60%|██████    | 398/658 [50:03:15<70:43:00, 979.16s/it]Trainning Epoch:  60%|██████    | 398/658 [50:03:15<70:43:01, 979.16s/it]2025-09-28 15:18:15,296 Stage: Train 0.5 | Epoch: 187 | Iter: 302200 | Total Loss: 0.002533 | Recon Loss: 0.002180 | Commit Loss: 0.000705 | Perplexity: 2514.648254
2025-09-28 15:22:32,836 Stage: Train 0.5 | Epoch: 187 | Iter: 302400 | Total Loss: 0.002566 | Recon Loss: 0.002209 | Commit Loss: 0.000713 | Perplexity: 2513.768961
2025-09-28 15:26:50,717 Stage: Train 0.5 | Epoch: 187 | Iter: 302600 | Total Loss: 0.002591 | Recon Loss: 0.002232 | Commit Loss: 0.000718 | Perplexity: 2513.853542
2025-09-28 15:31:08,501 Stage: Train 0.5 | Epoch: 187 | Iter: 302800 | Total Loss: 0.002531 | Recon Loss: 0.002170 | Commit Loss: 0.000724 | Perplexity: 2513.563889
Trainning Epoch:  61%|██████    | 399/658 [50:19:39<70:32:06, 980.41s/it]Trainning Epoch:  61%|██████    | 399/658 [50:19:39<70:32:07, 980.41s/it]2025-09-28 15:35:31,619 Stage: Train 0.5 | Epoch: 188 | Iter: 303000 | Total Loss: 0.002539 | Recon Loss: 0.002182 | Commit Loss: 0.000713 | Perplexity: 2517.560089
2025-09-28 15:39:49,140 Stage: Train 0.5 | Epoch: 188 | Iter: 303200 | Total Loss: 0.002550 | Recon Loss: 0.002192 | Commit Loss: 0.000715 | Perplexity: 2507.368647
2025-09-28 15:44:06,870 Stage: Train 0.5 | Epoch: 188 | Iter: 303400 | Total Loss: 0.002530 | Recon Loss: 0.002164 | Commit Loss: 0.000732 | Perplexity: 2520.907063
2025-09-28 15:48:25,225 Stage: Train 0.5 | Epoch: 188 | Iter: 303600 | Total Loss: 0.002552 | Recon Loss: 0.002187 | Commit Loss: 0.000732 | Perplexity: 2511.969086
Trainning Epoch:  61%|██████    | 400/658 [50:36:04<70:21:45, 981.81s/it]Trainning Epoch:  61%|██████    | 400/658 [50:36:04<70:21:46, 981.81s/it]2025-09-28 15:52:45,622 Stage: Train 0.5 | Epoch: 189 | Iter: 303800 | Total Loss: 0.002555 | Recon Loss: 0.002197 | Commit Loss: 0.000716 | Perplexity: 2514.904410
2025-09-28 15:57:03,324 Stage: Train 0.5 | Epoch: 189 | Iter: 304000 | Total Loss: 0.002547 | Recon Loss: 0.002186 | Commit Loss: 0.000723 | Perplexity: 2516.088887
2025-09-28 16:01:21,222 Stage: Train 0.5 | Epoch: 189 | Iter: 304200 | Total Loss: 0.002559 | Recon Loss: 0.002205 | Commit Loss: 0.000709 | Perplexity: 2512.495500
2025-09-28 16:05:38,499 Stage: Train 0.5 | Epoch: 189 | Iter: 304400 | Total Loss: 0.002561 | Recon Loss: 0.002199 | Commit Loss: 0.000723 | Perplexity: 2516.215371
Trainning Epoch:  61%|██████    | 401/658 [50:52:26<70:05:34, 981.85s/it]Trainning Epoch:  61%|██████    | 401/658 [50:52:26<70:05:35, 981.85s/it]2025-09-28 16:10:01,182 Stage: Train 0.5 | Epoch: 190 | Iter: 304600 | Total Loss: 0.002531 | Recon Loss: 0.002176 | Commit Loss: 0.000709 | Perplexity: 2513.384957
2025-09-28 16:14:19,528 Stage: Train 0.5 | Epoch: 190 | Iter: 304800 | Total Loss: 0.002509 | Recon Loss: 0.002154 | Commit Loss: 0.000711 | Perplexity: 2508.156926
2025-09-28 16:18:38,961 Stage: Train 0.5 | Epoch: 190 | Iter: 305000 | Total Loss: 0.002554 | Recon Loss: 0.002192 | Commit Loss: 0.000723 | Perplexity: 2516.422639
Trainning Epoch:  61%|██████    | 402/658 [51:08:54<69:56:54, 983.65s/it]Trainning Epoch:  61%|██████    | 402/658 [51:08:54<69:56:54, 983.65s/it]2025-09-28 16:23:01,355 Stage: Train 0.5 | Epoch: 191 | Iter: 305200 | Total Loss: 0.002584 | Recon Loss: 0.002224 | Commit Loss: 0.000720 | Perplexity: 2515.206628
2025-09-28 16:27:17,161 Stage: Train 0.5 | Epoch: 191 | Iter: 305400 | Total Loss: 0.002541 | Recon Loss: 0.002183 | Commit Loss: 0.000717 | Perplexity: 2513.650963
2025-09-28 16:31:33,275 Stage: Train 0.5 | Epoch: 191 | Iter: 305600 | Total Loss: 0.002564 | Recon Loss: 0.002201 | Commit Loss: 0.000726 | Perplexity: 2518.853334
2025-09-28 16:35:50,297 Stage: Train 0.5 | Epoch: 191 | Iter: 305800 | Total Loss: 0.002542 | Recon Loss: 0.002183 | Commit Loss: 0.000717 | Perplexity: 2511.367155
Trainning Epoch:  61%|██████    | 403/658 [51:25:12<69:33:29, 982.00s/it]Trainning Epoch:  61%|██████    | 403/658 [51:25:12<69:33:30, 982.00s/it]2025-09-28 16:40:11,451 Stage: Train 0.5 | Epoch: 192 | Iter: 306000 | Total Loss: 0.002571 | Recon Loss: 0.002210 | Commit Loss: 0.000722 | Perplexity: 2516.285635
2025-09-28 16:44:28,773 Stage: Train 0.5 | Epoch: 192 | Iter: 306200 | Total Loss: 0.002523 | Recon Loss: 0.002162 | Commit Loss: 0.000722 | Perplexity: 2516.368157
2025-09-28 16:48:47,466 Stage: Train 0.5 | Epoch: 192 | Iter: 306400 | Total Loss: 0.002545 | Recon Loss: 0.002187 | Commit Loss: 0.000717 | Perplexity: 2512.345116
2025-09-28 16:53:05,582 Stage: Train 0.5 | Epoch: 192 | Iter: 306600 | Total Loss: 0.002554 | Recon Loss: 0.002191 | Commit Loss: 0.000727 | Perplexity: 2512.596234
Trainning Epoch:  61%|██████▏   | 404/658 [51:41:35<69:19:12, 982.49s/it]Trainning Epoch:  61%|██████▏   | 404/658 [51:41:35<69:19:15, 982.50s/it]2025-09-28 16:57:25,434 Stage: Train 0.5 | Epoch: 193 | Iter: 306800 | Total Loss: 0.002543 | Recon Loss: 0.002181 | Commit Loss: 0.000725 | Perplexity: 2511.874861
2025-09-28 17:01:40,401 Stage: Train 0.5 | Epoch: 193 | Iter: 307000 | Total Loss: 0.002537 | Recon Loss: 0.002173 | Commit Loss: 0.000727 | Perplexity: 2516.623889
2025-09-28 17:05:55,901 Stage: Train 0.5 | Epoch: 193 | Iter: 307200 | Total Loss: 0.002546 | Recon Loss: 0.002186 | Commit Loss: 0.000718 | Perplexity: 2519.376573
2025-09-28 17:10:11,483 Stage: Train 0.5 | Epoch: 193 | Iter: 307400 | Total Loss: 0.002563 | Recon Loss: 0.002205 | Commit Loss: 0.000716 | Perplexity: 2511.062222
Trainning Epoch:  62%|██████▏   | 405/658 [51:57:49<68:52:10, 979.96s/it]Trainning Epoch:  62%|██████▏   | 405/658 [51:57:49<68:52:13, 979.98s/it]2025-09-28 17:14:32,046 Stage: Train 0.5 | Epoch: 194 | Iter: 307600 | Total Loss: 0.002541 | Recon Loss: 0.002188 | Commit Loss: 0.000706 | Perplexity: 2515.030327
2025-09-28 17:18:49,925 Stage: Train 0.5 | Epoch: 194 | Iter: 307800 | Total Loss: 0.002524 | Recon Loss: 0.002158 | Commit Loss: 0.000732 | Perplexity: 2516.357490
2025-09-28 17:23:07,654 Stage: Train 0.5 | Epoch: 194 | Iter: 308000 | Total Loss: 0.002557 | Recon Loss: 0.002199 | Commit Loss: 0.000717 | Perplexity: 2515.325602
2025-09-28 17:27:25,434 Stage: Train 0.5 | Epoch: 194 | Iter: 308200 | Total Loss: 0.002506 | Recon Loss: 0.002145 | Commit Loss: 0.000723 | Perplexity: 2513.137034
Trainning Epoch:  62%|██████▏   | 406/658 [52:14:13<68:39:57, 980.94s/it]Trainning Epoch:  62%|██████▏   | 406/658 [52:14:13<68:39:57, 980.94s/it]2025-09-28 17:31:39,619 Stage: Train 0.5 | Epoch: 195 | Iter: 308400 | Total Loss: 0.002550 | Recon Loss: 0.002194 | Commit Loss: 0.000712 | Perplexity: 2512.721432
2025-09-28 17:35:51,686 Stage: Train 0.5 | Epoch: 195 | Iter: 308600 | Total Loss: 0.002609 | Recon Loss: 0.002246 | Commit Loss: 0.000728 | Perplexity: 2517.068119
2025-09-28 17:40:05,770 Stage: Train 0.5 | Epoch: 195 | Iter: 308800 | Total Loss: 0.002539 | Recon Loss: 0.002173 | Commit Loss: 0.000733 | Perplexity: 2519.128475
Trainning Epoch:  62%|██████▏   | 407/658 [52:30:15<68:00:36, 975.45s/it]Trainning Epoch:  62%|██████▏   | 407/658 [52:30:15<68:00:37, 975.45s/it]2025-09-28 17:44:23,442 Stage: Train 0.5 | Epoch: 196 | Iter: 309000 | Total Loss: 0.002528 | Recon Loss: 0.002174 | Commit Loss: 0.000708 | Perplexity: 2512.648485
2025-09-28 17:48:40,430 Stage: Train 0.5 | Epoch: 196 | Iter: 309200 | Total Loss: 0.002544 | Recon Loss: 0.002183 | Commit Loss: 0.000721 | Perplexity: 2516.629762
2025-09-28 17:52:58,969 Stage: Train 0.5 | Epoch: 196 | Iter: 309400 | Total Loss: 0.002555 | Recon Loss: 0.002193 | Commit Loss: 0.000725 | Perplexity: 2514.657926
2025-09-28 17:57:17,443 Stage: Train 0.5 | Epoch: 196 | Iter: 309600 | Total Loss: 0.002543 | Recon Loss: 0.002177 | Commit Loss: 0.000733 | Perplexity: 2518.999442
Trainning Epoch:  62%|██████▏   | 408/658 [52:46:40<67:55:51, 978.21s/it]Trainning Epoch:  62%|██████▏   | 408/658 [52:46:40<67:55:51, 978.21s/it]2025-09-28 18:01:41,660 Stage: Train 0.5 | Epoch: 197 | Iter: 309800 | Total Loss: 0.002535 | Recon Loss: 0.002176 | Commit Loss: 0.000717 | Perplexity: 2514.872509
2025-09-28 18:06:00,523 Stage: Train 0.5 | Epoch: 197 | Iter: 310000 | Total Loss: 0.002540 | Recon Loss: 0.002180 | Commit Loss: 0.000720 | Perplexity: 2513.441807
2025-09-28 18:10:19,669 Stage: Train 0.5 | Epoch: 197 | Iter: 310200 | Total Loss: 0.002549 | Recon Loss: 0.002182 | Commit Loss: 0.000734 | Perplexity: 2514.735704
2025-09-28 18:14:38,876 Stage: Train 0.5 | Epoch: 197 | Iter: 310400 | Total Loss: 0.002560 | Recon Loss: 0.002197 | Commit Loss: 0.000727 | Perplexity: 2509.626334
Trainning Epoch:  62%|██████▏   | 409/658 [53:03:09<67:53:39, 981.60s/it]Trainning Epoch:  62%|██████▏   | 409/658 [53:03:09<67:53:39, 981.60s/it]2025-09-28 18:19:00,866 Stage: Train 0.5 | Epoch: 198 | Iter: 310600 | Total Loss: 0.002528 | Recon Loss: 0.002171 | Commit Loss: 0.000714 | Perplexity: 2515.290912
2025-09-28 18:23:19,621 Stage: Train 0.5 | Epoch: 198 | Iter: 310800 | Total Loss: 0.002539 | Recon Loss: 0.002177 | Commit Loss: 0.000724 | Perplexity: 2515.830541
2025-09-28 18:27:38,652 Stage: Train 0.5 | Epoch: 198 | Iter: 311000 | Total Loss: 0.002509 | Recon Loss: 0.002149 | Commit Loss: 0.000720 | Perplexity: 2514.955411
2025-09-28 18:31:57,720 Stage: Train 0.5 | Epoch: 198 | Iter: 311200 | Total Loss: 0.002556 | Recon Loss: 0.002190 | Commit Loss: 0.000733 | Perplexity: 2521.331161
Trainning Epoch:  62%|██████▏   | 410/658 [53:19:36<67:43:50, 983.19s/it]Trainning Epoch:  62%|██████▏   | 410/658 [53:19:36<67:43:50, 983.19s/it]2025-09-28 18:36:20,373 Stage: Train 0.5 | Epoch: 199 | Iter: 311400 | Total Loss: 0.002533 | Recon Loss: 0.002169 | Commit Loss: 0.000726 | Perplexity: 2512.022194
2025-09-28 18:40:38,782 Stage: Train 0.5 | Epoch: 199 | Iter: 311600 | Total Loss: 0.002567 | Recon Loss: 0.002206 | Commit Loss: 0.000722 | Perplexity: 2515.036890
2025-09-28 18:44:57,173 Stage: Train 0.5 | Epoch: 199 | Iter: 311800 | Total Loss: 0.002535 | Recon Loss: 0.002173 | Commit Loss: 0.000724 | Perplexity: 2517.246948
2025-09-28 18:49:15,633 Stage: Train 0.5 | Epoch: 199 | Iter: 312000 | Total Loss: 0.002552 | Recon Loss: 0.002185 | Commit Loss: 0.000733 | Perplexity: 2512.833304
Trainning Epoch:  62%|██████▏   | 411/658 [53:36:03<67:31:31, 984.18s/it]Trainning Epoch:  62%|██████▏   | 411/658 [53:36:03<67:31:31, 984.18s/it]2025-09-28 18:53:35,897 Stage: Train 0.5 | Epoch: 200 | Iter: 312200 | Total Loss: 0.002508 | Recon Loss: 0.002149 | Commit Loss: 0.000718 | Perplexity: 2510.088048
2025-09-28 18:57:52,045 Stage: Train 0.5 | Epoch: 200 | Iter: 312400 | Total Loss: 0.002524 | Recon Loss: 0.002159 | Commit Loss: 0.000731 | Perplexity: 2513.482990
2025-09-28 19:02:08,550 Stage: Train 0.5 | Epoch: 200 | Iter: 312600 | Total Loss: 0.002546 | Recon Loss: 0.002180 | Commit Loss: 0.000732 | Perplexity: 2512.492925
Trainning Epoch:  63%|██████▎   | 412/658 [53:52:20<67:06:53, 982.17s/it]Trainning Epoch:  63%|██████▎   | 412/658 [53:52:20<67:06:54, 982.17s/it]2025-09-28 19:06:28,581 Stage: Train 0.5 | Epoch: 201 | Iter: 312800 | Total Loss: 0.002556 | Recon Loss: 0.002191 | Commit Loss: 0.000730 | Perplexity: 2517.231321
2025-09-28 19:10:45,752 Stage: Train 0.5 | Epoch: 201 | Iter: 313000 | Total Loss: 0.002524 | Recon Loss: 0.002166 | Commit Loss: 0.000717 | Perplexity: 2517.522552
2025-09-28 19:15:03,536 Stage: Train 0.5 | Epoch: 201 | Iter: 313200 | Total Loss: 0.002564 | Recon Loss: 0.002206 | Commit Loss: 0.000715 | Perplexity: 2506.498209
2025-09-28 19:19:20,989 Stage: Train 0.5 | Epoch: 201 | Iter: 313400 | Total Loss: 0.002533 | Recon Loss: 0.002171 | Commit Loss: 0.000724 | Perplexity: 2513.708250
Trainning Epoch:  63%|██████▎   | 413/658 [54:08:43<66:50:41, 982.21s/it]Trainning Epoch:  63%|██████▎   | 413/658 [54:08:43<66:50:41, 982.21s/it]2025-09-28 19:23:42,261 Stage: Train 0.5 | Epoch: 202 | Iter: 313600 | Total Loss: 0.002548 | Recon Loss: 0.002179 | Commit Loss: 0.000738 | Perplexity: 2510.570479
2025-09-28 19:27:58,172 Stage: Train 0.5 | Epoch: 202 | Iter: 313800 | Total Loss: 0.002505 | Recon Loss: 0.002143 | Commit Loss: 0.000725 | Perplexity: 2514.522589
2025-09-28 19:32:14,709 Stage: Train 0.5 | Epoch: 202 | Iter: 314000 | Total Loss: 0.002555 | Recon Loss: 0.002188 | Commit Loss: 0.000734 | Perplexity: 2514.815854
2025-09-28 19:36:31,665 Stage: Train 0.5 | Epoch: 202 | Iter: 314200 | Total Loss: 0.002515 | Recon Loss: 0.002154 | Commit Loss: 0.000723 | Perplexity: 2511.058165
Trainning Epoch:  63%|██████▎   | 414/658 [54:25:01<66:29:52, 981.12s/it]Trainning Epoch:  63%|██████▎   | 414/658 [54:25:01<66:29:53, 981.12s/it]2025-09-28 19:40:51,923 Stage: Train 0.5 | Epoch: 203 | Iter: 314400 | Total Loss: 0.002533 | Recon Loss: 0.002178 | Commit Loss: 0.000710 | Perplexity: 2511.738933
2025-09-28 19:45:08,053 Stage: Train 0.5 | Epoch: 203 | Iter: 314600 | Total Loss: 0.002547 | Recon Loss: 0.002184 | Commit Loss: 0.000727 | Perplexity: 2513.188604
2025-09-28 19:49:23,912 Stage: Train 0.5 | Epoch: 203 | Iter: 314800 | Total Loss: 0.002534 | Recon Loss: 0.002170 | Commit Loss: 0.000728 | Perplexity: 2514.163202
2025-09-28 19:53:40,252 Stage: Train 0.5 | Epoch: 203 | Iter: 315000 | Total Loss: 0.002552 | Recon Loss: 0.002185 | Commit Loss: 0.000734 | Perplexity: 2515.641681
Trainning Epoch:  63%|██████▎   | 415/658 [54:41:18<66:08:29, 979.87s/it]Trainning Epoch:  63%|██████▎   | 415/658 [54:41:18<66:08:30, 979.88s/it]2025-09-28 19:58:01,461 Stage: Train 0.5 | Epoch: 204 | Iter: 315200 | Total Loss: 0.002537 | Recon Loss: 0.002175 | Commit Loss: 0.000724 | Perplexity: 2512.435901
2025-09-28 20:02:19,822 Stage: Train 0.5 | Epoch: 204 | Iter: 315400 | Total Loss: 0.002535 | Recon Loss: 0.002169 | Commit Loss: 0.000733 | Perplexity: 2513.157100
2025-09-28 20:06:38,743 Stage: Train 0.5 | Epoch: 204 | Iter: 315600 | Total Loss: 0.002518 | Recon Loss: 0.002159 | Commit Loss: 0.000718 | Perplexity: 2509.069086
2025-09-28 20:10:56,371 Stage: Train 0.5 | Epoch: 204 | Iter: 315800 | Total Loss: 0.002548 | Recon Loss: 0.002182 | Commit Loss: 0.000733 | Perplexity: 2511.339072
Trainning Epoch:  63%|██████▎   | 416/658 [54:57:44<65:58:51, 981.54s/it]Trainning Epoch:  63%|██████▎   | 416/658 [54:57:44<65:58:51, 981.53s/it]2025-09-28 20:15:18,674 Stage: Train 0.5 | Epoch: 205 | Iter: 316000 | Total Loss: 0.002500 | Recon Loss: 0.002143 | Commit Loss: 0.000714 | Perplexity: 2510.078925
2025-09-28 20:19:37,283 Stage: Train 0.5 | Epoch: 205 | Iter: 316200 | Total Loss: 0.002552 | Recon Loss: 0.002190 | Commit Loss: 0.000723 | Perplexity: 2515.827471
2025-09-28 20:23:56,766 Stage: Train 0.5 | Epoch: 205 | Iter: 316400 | Total Loss: 0.002562 | Recon Loss: 0.002200 | Commit Loss: 0.000723 | Perplexity: 2511.432832
Trainning Epoch:  63%|██████▎   | 417/658 [55:14:11<65:49:09, 983.19s/it]Trainning Epoch:  63%|██████▎   | 417/658 [55:14:11<65:49:10, 983.20s/it]2025-09-28 20:28:18,469 Stage: Train 0.5 | Epoch: 206 | Iter: 316600 | Total Loss: 0.002536 | Recon Loss: 0.002172 | Commit Loss: 0.000727 | Perplexity: 2513.048534
2025-09-28 20:32:35,309 Stage: Train 0.5 | Epoch: 206 | Iter: 316800 | Total Loss: 0.002521 | Recon Loss: 0.002156 | Commit Loss: 0.000729 | Perplexity: 2515.881132
2025-09-28 20:36:53,673 Stage: Train 0.5 | Epoch: 206 | Iter: 317000 | Total Loss: 0.002529 | Recon Loss: 0.002164 | Commit Loss: 0.000730 | Perplexity: 2513.045679
2025-09-28 20:41:11,894 Stage: Train 0.5 | Epoch: 206 | Iter: 317200 | Total Loss: 0.002524 | Recon Loss: 0.002155 | Commit Loss: 0.000738 | Perplexity: 2515.667046
Trainning Epoch:  64%|██████▎   | 418/658 [55:30:34<65:32:31, 983.13s/it]Trainning Epoch:  64%|██████▎   | 418/658 [55:30:34<65:32:31, 983.13s/it]2025-09-28 20:45:33,725 Stage: Train 0.5 | Epoch: 207 | Iter: 317400 | Total Loss: 0.002519 | Recon Loss: 0.002154 | Commit Loss: 0.000731 | Perplexity: 2517.423033
2025-09-28 20:49:50,954 Stage: Train 0.5 | Epoch: 207 | Iter: 317600 | Total Loss: 0.002504 | Recon Loss: 0.002145 | Commit Loss: 0.000718 | Perplexity: 2514.214928
2025-09-28 20:54:08,165 Stage: Train 0.5 | Epoch: 207 | Iter: 317800 | Total Loss: 0.002544 | Recon Loss: 0.002177 | Commit Loss: 0.000733 | Perplexity: 2516.730886
2025-09-28 20:58:26,158 Stage: Train 0.5 | Epoch: 207 | Iter: 318000 | Total Loss: 0.002516 | Recon Loss: 0.002159 | Commit Loss: 0.000713 | Perplexity: 2508.120046
Trainning Epoch:  64%|██████▎   | 419/658 [55:46:56<65:15:26, 982.95s/it]Trainning Epoch:  64%|██████▎   | 419/658 [55:46:56<65:15:25, 982.95s/it]2025-09-28 21:02:45,801 Stage: Train 0.5 | Epoch: 208 | Iter: 318200 | Total Loss: 0.002510 | Recon Loss: 0.002149 | Commit Loss: 0.000722 | Perplexity: 2513.316642
2025-09-28 21:07:01,675 Stage: Train 0.5 | Epoch: 208 | Iter: 318400 | Total Loss: 0.002537 | Recon Loss: 0.002179 | Commit Loss: 0.000716 | Perplexity: 2512.204117
2025-09-28 21:11:18,192 Stage: Train 0.5 | Epoch: 208 | Iter: 318600 | Total Loss: 0.002539 | Recon Loss: 0.002171 | Commit Loss: 0.000736 | Perplexity: 2517.878259
2025-09-28 21:15:34,643 Stage: Train 0.5 | Epoch: 208 | Iter: 318800 | Total Loss: 0.002530 | Recon Loss: 0.002168 | Commit Loss: 0.000724 | Perplexity: 2513.565471
Trainning Epoch:  64%|██████▍   | 420/658 [56:03:12<64:51:08, 980.96s/it]Trainning Epoch:  64%|██████▍   | 420/658 [56:03:13<64:51:11, 980.97s/it]2025-09-28 21:19:55,132 Stage: Train 0.5 | Epoch: 209 | Iter: 319000 | Total Loss: 0.002526 | Recon Loss: 0.002168 | Commit Loss: 0.000716 | Perplexity: 2509.724738
2025-09-28 21:24:11,990 Stage: Train 0.5 | Epoch: 209 | Iter: 319200 | Total Loss: 0.002510 | Recon Loss: 0.002146 | Commit Loss: 0.000728 | Perplexity: 2511.736029
2025-09-28 21:28:29,504 Stage: Train 0.5 | Epoch: 209 | Iter: 319400 | Total Loss: 0.002536 | Recon Loss: 0.002174 | Commit Loss: 0.000725 | Perplexity: 2516.198755
2025-09-28 21:32:46,064 Stage: Train 0.5 | Epoch: 209 | Iter: 319600 | Total Loss: 0.002537 | Recon Loss: 0.002172 | Commit Loss: 0.000731 | Perplexity: 2511.764629
Trainning Epoch:  64%|██████▍   | 421/658 [56:19:33<64:34:34, 980.90s/it]Trainning Epoch:  64%|██████▍   | 421/658 [56:19:33<64:34:36, 980.91s/it]2025-09-28 21:37:07,826 Stage: Train 0.5 | Epoch: 210 | Iter: 319800 | Total Loss: 0.002490 | Recon Loss: 0.002132 | Commit Loss: 0.000716 | Perplexity: 2509.230547
2025-09-28 21:41:25,697 Stage: Train 0.5 | Epoch: 210 | Iter: 320000 | Total Loss: 0.002524 | Recon Loss: 0.002160 | Commit Loss: 0.000728 | Perplexity: 2510.831793
2025-09-28 21:41:25,698 Saving model at iteration 320000
2025-09-28 21:41:26,014 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_320000
2025-09-28 21:41:26,566 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_320000/model.safetensors
2025-09-28 21:41:27,013 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_320000/optimizer.bin
2025-09-28 21:41:27,013 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_320000/scheduler.bin
2025-09-28 21:41:27,013 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_320000/sampler.bin
2025-09-28 21:41:27,014 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_211_step_320000/random_states_0.pkl
2025-09-28 21:45:45,062 Stage: Train 0.5 | Epoch: 210 | Iter: 320200 | Total Loss: 0.002545 | Recon Loss: 0.002182 | Commit Loss: 0.000725 | Perplexity: 2515.312312
Trainning Epoch:  64%|██████▍   | 422/658 [56:35:58<64:23:09, 982.16s/it]Trainning Epoch:  64%|██████▍   | 422/658 [56:35:58<64:23:10, 982.16s/it]2025-09-28 21:50:06,964 Stage: Train 0.5 | Epoch: 211 | Iter: 320400 | Total Loss: 0.002536 | Recon Loss: 0.002175 | Commit Loss: 0.000722 | Perplexity: 2510.356033
2025-09-28 21:54:25,857 Stage: Train 0.5 | Epoch: 211 | Iter: 320600 | Total Loss: 0.002512 | Recon Loss: 0.002157 | Commit Loss: 0.000711 | Perplexity: 2512.280522
2025-09-28 21:58:45,836 Stage: Train 0.5 | Epoch: 211 | Iter: 320800 | Total Loss: 0.002560 | Recon Loss: 0.002194 | Commit Loss: 0.000733 | Perplexity: 2514.414414
2025-09-28 22:03:05,860 Stage: Train 0.5 | Epoch: 211 | Iter: 321000 | Total Loss: 0.002490 | Recon Loss: 0.002122 | Commit Loss: 0.000734 | Perplexity: 2516.227688
Trainning Epoch:  64%|██████▍   | 423/658 [56:52:28<64:15:52, 984.48s/it]Trainning Epoch:  64%|██████▍   | 423/658 [56:52:28<64:15:54, 984.49s/it]2025-09-28 22:07:27,961 Stage: Train 0.5 | Epoch: 212 | Iter: 321200 | Total Loss: 0.002548 | Recon Loss: 0.002189 | Commit Loss: 0.000719 | Perplexity: 2513.155940
2025-09-28 22:11:46,076 Stage: Train 0.5 | Epoch: 212 | Iter: 321400 | Total Loss: 0.002533 | Recon Loss: 0.002173 | Commit Loss: 0.000720 | Perplexity: 2508.991101
2025-09-28 22:16:04,410 Stage: Train 0.5 | Epoch: 212 | Iter: 321600 | Total Loss: 0.002520 | Recon Loss: 0.002154 | Commit Loss: 0.000732 | Perplexity: 2516.189854
2025-09-28 22:20:22,962 Stage: Train 0.5 | Epoch: 212 | Iter: 321800 | Total Loss: 0.002524 | Recon Loss: 0.002156 | Commit Loss: 0.000736 | Perplexity: 2512.105183
Trainning Epoch:  64%|██████▍   | 424/658 [57:08:53<63:59:51, 984.58s/it]Trainning Epoch:  64%|██████▍   | 424/658 [57:08:53<63:59:52, 984.58s/it]2025-09-28 22:24:44,508 Stage: Train 0.5 | Epoch: 213 | Iter: 322000 | Total Loss: 0.002532 | Recon Loss: 0.002173 | Commit Loss: 0.000720 | Perplexity: 2516.321100
2025-09-28 22:29:03,349 Stage: Train 0.5 | Epoch: 213 | Iter: 322200 | Total Loss: 0.002560 | Recon Loss: 0.002192 | Commit Loss: 0.000736 | Perplexity: 2507.343658
2025-09-28 22:33:21,833 Stage: Train 0.5 | Epoch: 213 | Iter: 322400 | Total Loss: 0.002518 | Recon Loss: 0.002159 | Commit Loss: 0.000719 | Perplexity: 2513.834045
2025-09-28 22:37:41,062 Stage: Train 0.5 | Epoch: 213 | Iter: 322600 | Total Loss: 0.002517 | Recon Loss: 0.002154 | Commit Loss: 0.000726 | Perplexity: 2508.138873
Trainning Epoch:  65%|██████▍   | 425/658 [57:25:20<63:45:50, 985.19s/it]Trainning Epoch:  65%|██████▍   | 425/658 [57:25:20<63:45:49, 985.19s/it]2025-09-28 22:42:05,200 Stage: Train 0.5 | Epoch: 214 | Iter: 322800 | Total Loss: 0.002505 | Recon Loss: 0.002141 | Commit Loss: 0.000729 | Perplexity: 2508.184841
2025-09-28 22:46:25,377 Stage: Train 0.5 | Epoch: 214 | Iter: 323000 | Total Loss: 0.002553 | Recon Loss: 0.002191 | Commit Loss: 0.000725 | Perplexity: 2509.951002
2025-09-28 22:50:46,183 Stage: Train 0.5 | Epoch: 214 | Iter: 323200 | Total Loss: 0.002506 | Recon Loss: 0.002138 | Commit Loss: 0.000735 | Perplexity: 2515.160424
2025-09-28 22:55:06,377 Stage: Train 0.5 | Epoch: 214 | Iter: 323400 | Total Loss: 0.002515 | Recon Loss: 0.002151 | Commit Loss: 0.000728 | Perplexity: 2508.823285
Trainning Epoch:  65%|██████▍   | 426/658 [57:41:54<63:39:29, 987.80s/it]Trainning Epoch:  65%|██████▍   | 426/658 [57:41:54<63:39:29, 987.80s/it]2025-09-28 22:59:26,840 Stage: Train 0.5 | Epoch: 215 | Iter: 323600 | Total Loss: 0.002526 | Recon Loss: 0.002165 | Commit Loss: 0.000721 | Perplexity: 2512.510396
2025-09-28 23:03:43,080 Stage: Train 0.5 | Epoch: 215 | Iter: 323800 | Total Loss: 0.002515 | Recon Loss: 0.002152 | Commit Loss: 0.000727 | Perplexity: 2510.409470
2025-09-28 23:07:59,230 Stage: Train 0.5 | Epoch: 215 | Iter: 324000 | Total Loss: 0.002510 | Recon Loss: 0.002144 | Commit Loss: 0.000732 | Perplexity: 2511.752665
Trainning Epoch:  65%|██████▍   | 427/658 [57:58:12<63:11:59, 984.93s/it]Trainning Epoch:  65%|██████▍   | 427/658 [57:58:12<63:11:59, 984.93s/it]2025-09-28 23:12:20,768 Stage: Train 0.5 | Epoch: 216 | Iter: 324200 | Total Loss: 0.002518 | Recon Loss: 0.002155 | Commit Loss: 0.000726 | Perplexity: 2510.984014
2025-09-28 23:16:38,678 Stage: Train 0.5 | Epoch: 216 | Iter: 324400 | Total Loss: 0.002513 | Recon Loss: 0.002153 | Commit Loss: 0.000719 | Perplexity: 2512.501609
2025-09-28 23:20:56,489 Stage: Train 0.5 | Epoch: 216 | Iter: 324600 | Total Loss: 0.002542 | Recon Loss: 0.002177 | Commit Loss: 0.000730 | Perplexity: 2515.283146
2025-09-28 23:25:13,962 Stage: Train 0.5 | Epoch: 216 | Iter: 324800 | Total Loss: 0.002528 | Recon Loss: 0.002159 | Commit Loss: 0.000737 | Perplexity: 2513.425396
Trainning Epoch:  65%|██████▌   | 428/658 [58:14:36<62:54:19, 984.61s/it]Trainning Epoch:  65%|██████▌   | 428/658 [58:14:36<62:54:19, 984.61s/it]2025-09-28 23:29:35,789 Stage: Train 0.5 | Epoch: 217 | Iter: 325000 | Total Loss: 0.002512 | Recon Loss: 0.002146 | Commit Loss: 0.000732 | Perplexity: 2510.715533
2025-09-28 23:33:53,416 Stage: Train 0.5 | Epoch: 217 | Iter: 325200 | Total Loss: 0.002512 | Recon Loss: 0.002152 | Commit Loss: 0.000720 | Perplexity: 2512.712307
2025-09-28 23:38:11,699 Stage: Train 0.5 | Epoch: 217 | Iter: 325400 | Total Loss: 0.002537 | Recon Loss: 0.002173 | Commit Loss: 0.000727 | Perplexity: 2508.835695
2025-09-28 23:42:29,601 Stage: Train 0.5 | Epoch: 217 | Iter: 325600 | Total Loss: 0.002507 | Recon Loss: 0.002142 | Commit Loss: 0.000732 | Perplexity: 2509.162479
Trainning Epoch:  65%|██████▌   | 429/658 [58:31:00<62:37:59, 984.62s/it]Trainning Epoch:  65%|██████▌   | 429/658 [58:31:00<62:37:59, 984.63s/it]2025-09-28 23:46:50,296 Stage: Train 0.5 | Epoch: 218 | Iter: 325800 | Total Loss: 0.002480 | Recon Loss: 0.002125 | Commit Loss: 0.000711 | Perplexity: 2509.373019
2025-09-28 23:51:07,788 Stage: Train 0.5 | Epoch: 218 | Iter: 326000 | Total Loss: 0.002507 | Recon Loss: 0.002141 | Commit Loss: 0.000731 | Perplexity: 2509.534437
2025-09-28 23:55:25,250 Stage: Train 0.5 | Epoch: 218 | Iter: 326200 | Total Loss: 0.002536 | Recon Loss: 0.002173 | Commit Loss: 0.000726 | Perplexity: 2517.620968
2025-09-28 23:59:43,313 Stage: Train 0.5 | Epoch: 218 | Iter: 326400 | Total Loss: 0.002507 | Recon Loss: 0.002139 | Commit Loss: 0.000737 | Perplexity: 2512.243903
Trainning Epoch:  65%|██████▌   | 430/658 [58:47:22<62:17:44, 983.62s/it]Trainning Epoch:  65%|██████▌   | 430/658 [58:47:22<62:17:44, 983.62s/it]2025-09-29 00:04:02,235 Stage: Train 0.5 | Epoch: 219 | Iter: 326600 | Total Loss: 0.002499 | Recon Loss: 0.002136 | Commit Loss: 0.000725 | Perplexity: 2511.427845
2025-09-29 00:08:19,612 Stage: Train 0.5 | Epoch: 219 | Iter: 326800 | Total Loss: 0.002522 | Recon Loss: 0.002159 | Commit Loss: 0.000727 | Perplexity: 2513.138846
2025-09-29 00:12:37,753 Stage: Train 0.5 | Epoch: 219 | Iter: 327000 | Total Loss: 0.002525 | Recon Loss: 0.002163 | Commit Loss: 0.000725 | Perplexity: 2507.161604
2025-09-29 00:16:55,166 Stage: Train 0.5 | Epoch: 219 | Iter: 327200 | Total Loss: 0.002507 | Recon Loss: 0.002139 | Commit Loss: 0.000737 | Perplexity: 2514.721017
Trainning Epoch:  66%|██████▌   | 431/658 [59:03:42<61:58:08, 982.77s/it]Trainning Epoch:  66%|██████▌   | 431/658 [59:03:42<61:58:07, 982.76s/it]2025-09-29 00:21:20,024 Stage: Train 0.5 | Epoch: 220 | Iter: 327400 | Total Loss: 0.002498 | Recon Loss: 0.002132 | Commit Loss: 0.000731 | Perplexity: 2513.665599
2025-09-29 00:25:40,505 Stage: Train 0.5 | Epoch: 220 | Iter: 327600 | Total Loss: 0.002524 | Recon Loss: 0.002163 | Commit Loss: 0.000722 | Perplexity: 2506.637488
2025-09-29 00:30:01,448 Stage: Train 0.5 | Epoch: 220 | Iter: 327800 | Total Loss: 0.002549 | Recon Loss: 0.002185 | Commit Loss: 0.000728 | Perplexity: 2510.188934
Trainning Epoch:  66%|██████▌   | 432/658 [59:20:17<61:54:36, 986.18s/it]Trainning Epoch:  66%|██████▌   | 432/658 [59:20:17<61:54:36, 986.18s/it]2025-09-29 00:34:25,576 Stage: Train 0.5 | Epoch: 221 | Iter: 328000 | Total Loss: 0.002514 | Recon Loss: 0.002147 | Commit Loss: 0.000733 | Perplexity: 2517.554399
2025-09-29 00:38:44,255 Stage: Train 0.5 | Epoch: 221 | Iter: 328200 | Total Loss: 0.002528 | Recon Loss: 0.002161 | Commit Loss: 0.000733 | Perplexity: 2512.536205
2025-09-29 00:43:03,365 Stage: Train 0.5 | Epoch: 221 | Iter: 328400 | Total Loss: 0.002512 | Recon Loss: 0.002146 | Commit Loss: 0.000731 | Perplexity: 2510.682200
2025-09-29 00:47:22,576 Stage: Train 0.5 | Epoch: 221 | Iter: 328600 | Total Loss: 0.002516 | Recon Loss: 0.002152 | Commit Loss: 0.000728 | Perplexity: 2512.107019
Trainning Epoch:  66%|██████▌   | 433/658 [59:36:45<61:41:07, 986.97s/it]Trainning Epoch:  66%|██████▌   | 433/658 [59:36:45<61:41:08, 986.97s/it]2025-09-29 00:51:47,199 Stage: Train 0.5 | Epoch: 222 | Iter: 328800 | Total Loss: 0.002524 | Recon Loss: 0.002155 | Commit Loss: 0.000738 | Perplexity: 2513.296945
2025-09-29 00:56:07,342 Stage: Train 0.5 | Epoch: 222 | Iter: 329000 | Total Loss: 0.002513 | Recon Loss: 0.002154 | Commit Loss: 0.000717 | Perplexity: 2513.304398
2025-09-29 01:00:27,174 Stage: Train 0.5 | Epoch: 222 | Iter: 329200 | Total Loss: 0.002487 | Recon Loss: 0.002121 | Commit Loss: 0.000731 | Perplexity: 2506.113999
2025-09-29 01:04:47,425 Stage: Train 0.5 | Epoch: 222 | Iter: 329400 | Total Loss: 0.002521 | Recon Loss: 0.002154 | Commit Loss: 0.000734 | Perplexity: 2517.038975
Trainning Epoch:  66%|██████▌   | 434/658 [59:53:18<61:30:57, 988.65s/it]Trainning Epoch:  66%|██████▌   | 434/658 [59:53:18<61:30:57, 988.65s/it]2025-09-29 01:09:09,171 Stage: Train 0.5 | Epoch: 223 | Iter: 329600 | Total Loss: 0.002493 | Recon Loss: 0.002134 | Commit Loss: 0.000717 | Perplexity: 2512.913525
2025-09-29 01:13:27,773 Stage: Train 0.5 | Epoch: 223 | Iter: 329800 | Total Loss: 0.002515 | Recon Loss: 0.002145 | Commit Loss: 0.000739 | Perplexity: 2508.148164
2025-09-29 01:17:46,065 Stage: Train 0.5 | Epoch: 223 | Iter: 330000 | Total Loss: 0.002496 | Recon Loss: 0.002132 | Commit Loss: 0.000726 | Perplexity: 2512.804880
2025-09-29 01:22:04,667 Stage: Train 0.5 | Epoch: 223 | Iter: 330200 | Total Loss: 0.002510 | Recon Loss: 0.002144 | Commit Loss: 0.000732 | Perplexity: 2513.224370
Trainning Epoch:  66%|██████▌   | 435/658 [60:09:43<61:10:31, 987.58s/it]Trainning Epoch:  66%|██████▌   | 435/658 [60:09:43<61:10:31, 987.59s/it]2025-09-29 01:26:27,143 Stage: Train 0.5 | Epoch: 224 | Iter: 330400 | Total Loss: 0.002492 | Recon Loss: 0.002133 | Commit Loss: 0.000718 | Perplexity: 2512.469037
2025-09-29 01:30:46,860 Stage: Train 0.5 | Epoch: 224 | Iter: 330600 | Total Loss: 0.002525 | Recon Loss: 0.002158 | Commit Loss: 0.000734 | Perplexity: 2510.790813
2025-09-29 01:35:07,139 Stage: Train 0.5 | Epoch: 224 | Iter: 330800 | Total Loss: 0.002509 | Recon Loss: 0.002144 | Commit Loss: 0.000730 | Perplexity: 2515.188300
2025-09-29 01:39:26,250 Stage: Train 0.5 | Epoch: 224 | Iter: 331000 | Total Loss: 0.002497 | Recon Loss: 0.002133 | Commit Loss: 0.000728 | Perplexity: 2507.441880
Trainning Epoch:  66%|██████▋   | 436/658 [60:26:13<60:57:14, 988.45s/it]Trainning Epoch:  66%|██████▋   | 436/658 [60:26:13<60:57:14, 988.44s/it]2025-09-29 01:43:50,489 Stage: Train 0.5 | Epoch: 225 | Iter: 331200 | Total Loss: 0.002498 | Recon Loss: 0.002131 | Commit Loss: 0.000734 | Perplexity: 2514.383549
2025-09-29 01:48:10,074 Stage: Train 0.5 | Epoch: 225 | Iter: 331400 | Total Loss: 0.002521 | Recon Loss: 0.002156 | Commit Loss: 0.000729 | Perplexity: 2509.756672
2025-09-29 01:52:30,237 Stage: Train 0.5 | Epoch: 225 | Iter: 331600 | Total Loss: 0.002518 | Recon Loss: 0.002158 | Commit Loss: 0.000721 | Perplexity: 2506.240131
Trainning Epoch:  66%|██████▋   | 437/658 [60:42:45<60:44:04, 989.34s/it]Trainning Epoch:  66%|██████▋   | 437/658 [60:42:45<60:44:04, 989.34s/it]2025-09-29 01:56:54,629 Stage: Train 0.5 | Epoch: 226 | Iter: 331800 | Total Loss: 0.002518 | Recon Loss: 0.002153 | Commit Loss: 0.000731 | Perplexity: 2513.350057
2025-09-29 02:01:14,357 Stage: Train 0.5 | Epoch: 226 | Iter: 332000 | Total Loss: 0.002509 | Recon Loss: 0.002151 | Commit Loss: 0.000717 | Perplexity: 2509.493115
2025-09-29 02:05:34,443 Stage: Train 0.5 | Epoch: 226 | Iter: 332200 | Total Loss: 0.002507 | Recon Loss: 0.002144 | Commit Loss: 0.000725 | Perplexity: 2511.069318
2025-09-29 02:09:54,565 Stage: Train 0.5 | Epoch: 226 | Iter: 332400 | Total Loss: 0.002531 | Recon Loss: 0.002164 | Commit Loss: 0.000735 | Perplexity: 2517.489209
Trainning Epoch:  67%|██████▋   | 438/658 [60:59:17<60:31:09, 990.32s/it]Trainning Epoch:  67%|██████▋   | 438/658 [60:59:17<60:31:10, 990.32s/it]2025-09-29 02:14:17,096 Stage: Train 0.5 | Epoch: 227 | Iter: 332600 | Total Loss: 0.002509 | Recon Loss: 0.002142 | Commit Loss: 0.000734 | Perplexity: 2512.219385
2025-09-29 02:18:34,022 Stage: Train 0.5 | Epoch: 227 | Iter: 332800 | Total Loss: 0.002475 | Recon Loss: 0.002113 | Commit Loss: 0.000725 | Perplexity: 2511.149459
2025-09-29 02:22:50,867 Stage: Train 0.5 | Epoch: 227 | Iter: 333000 | Total Loss: 0.002502 | Recon Loss: 0.002133 | Commit Loss: 0.000738 | Perplexity: 2509.212614
2025-09-29 02:27:08,218 Stage: Train 0.5 | Epoch: 227 | Iter: 333200 | Total Loss: 0.002495 | Recon Loss: 0.002127 | Commit Loss: 0.000737 | Perplexity: 2509.880134
Trainning Epoch:  67%|██████▋   | 439/658 [61:15:38<60:03:34, 987.28s/it]Trainning Epoch:  67%|██████▋   | 439/658 [61:15:38<60:03:34, 987.28s/it]2025-09-29 02:31:26,634 Stage: Train 0.5 | Epoch: 228 | Iter: 333400 | Total Loss: 0.002498 | Recon Loss: 0.002138 | Commit Loss: 0.000721 | Perplexity: 2512.314346
2025-09-29 02:35:41,955 Stage: Train 0.5 | Epoch: 228 | Iter: 333600 | Total Loss: 0.002518 | Recon Loss: 0.002155 | Commit Loss: 0.000728 | Perplexity: 2511.366765
2025-09-29 02:39:57,679 Stage: Train 0.5 | Epoch: 228 | Iter: 333800 | Total Loss: 0.002517 | Recon Loss: 0.002155 | Commit Loss: 0.000725 | Perplexity: 2508.852240
2025-09-29 02:44:13,578 Stage: Train 0.5 | Epoch: 228 | Iter: 334000 | Total Loss: 0.002529 | Recon Loss: 0.002164 | Commit Loss: 0.000731 | Perplexity: 2512.887390
Trainning Epoch:  67%|██████▋   | 440/658 [61:31:52<59:32:36, 983.29s/it]Trainning Epoch:  67%|██████▋   | 440/658 [61:31:52<59:32:38, 983.30s/it]2025-09-29 02:48:32,774 Stage: Train 0.5 | Epoch: 229 | Iter: 334200 | Total Loss: 0.002486 | Recon Loss: 0.002118 | Commit Loss: 0.000736 | Perplexity: 2512.858517
2025-09-29 02:52:50,232 Stage: Train 0.5 | Epoch: 229 | Iter: 334400 | Total Loss: 0.002497 | Recon Loss: 0.002136 | Commit Loss: 0.000723 | Perplexity: 2513.817588
2025-09-29 02:57:09,017 Stage: Train 0.5 | Epoch: 229 | Iter: 334600 | Total Loss: 0.002521 | Recon Loss: 0.002154 | Commit Loss: 0.000734 | Perplexity: 2512.374117
2025-09-29 03:01:26,629 Stage: Train 0.5 | Epoch: 229 | Iter: 334800 | Total Loss: 0.002508 | Recon Loss: 0.002147 | Commit Loss: 0.000721 | Perplexity: 2508.062935
Trainning Epoch:  67%|██████▋   | 441/658 [61:48:14<59:15:00, 982.95s/it]Trainning Epoch:  67%|██████▋   | 441/658 [61:48:14<59:15:01, 982.96s/it]2025-09-29 03:05:49,730 Stage: Train 0.5 | Epoch: 230 | Iter: 335000 | Total Loss: 0.002498 | Recon Loss: 0.002132 | Commit Loss: 0.000731 | Perplexity: 2513.351176
2025-09-29 03:10:08,551 Stage: Train 0.5 | Epoch: 230 | Iter: 335200 | Total Loss: 0.002506 | Recon Loss: 0.002133 | Commit Loss: 0.000745 | Perplexity: 2508.632504
2025-09-29 03:14:27,081 Stage: Train 0.5 | Epoch: 230 | Iter: 335400 | Total Loss: 0.002506 | Recon Loss: 0.002143 | Commit Loss: 0.000726 | Perplexity: 2510.950414
Trainning Epoch:  67%|██████▋   | 442/658 [62:04:41<59:03:14, 984.23s/it]Trainning Epoch:  67%|██████▋   | 442/658 [62:04:41<59:03:14, 984.24s/it]2025-09-29 03:18:49,915 Stage: Train 0.5 | Epoch: 231 | Iter: 335600 | Total Loss: 0.002489 | Recon Loss: 0.002124 | Commit Loss: 0.000729 | Perplexity: 2506.432233
2025-09-29 03:23:10,302 Stage: Train 0.5 | Epoch: 231 | Iter: 335800 | Total Loss: 0.002505 | Recon Loss: 0.002140 | Commit Loss: 0.000730 | Perplexity: 2514.356295
2025-09-29 03:27:31,222 Stage: Train 0.5 | Epoch: 231 | Iter: 336000 | Total Loss: 0.002522 | Recon Loss: 0.002157 | Commit Loss: 0.000730 | Perplexity: 2508.267023
2025-09-29 03:31:52,177 Stage: Train 0.5 | Epoch: 231 | Iter: 336200 | Total Loss: 0.002496 | Recon Loss: 0.002129 | Commit Loss: 0.000734 | Perplexity: 2510.184366
Trainning Epoch:  67%|██████▋   | 443/658 [62:21:15<58:57:39, 987.25s/it]Trainning Epoch:  67%|██████▋   | 443/658 [62:21:15<58:57:39, 987.25s/it]2025-09-29 03:36:14,582 Stage: Train 0.5 | Epoch: 232 | Iter: 336400 | Total Loss: 0.002496 | Recon Loss: 0.002137 | Commit Loss: 0.000718 | Perplexity: 2513.132705
2025-09-29 03:40:31,139 Stage: Train 0.5 | Epoch: 232 | Iter: 336600 | Total Loss: 0.002516 | Recon Loss: 0.002152 | Commit Loss: 0.000728 | Perplexity: 2513.691230
2025-09-29 03:44:49,093 Stage: Train 0.5 | Epoch: 232 | Iter: 336800 | Total Loss: 0.002549 | Recon Loss: 0.002186 | Commit Loss: 0.000727 | Perplexity: 2510.532585
2025-09-29 03:49:07,629 Stage: Train 0.5 | Epoch: 232 | Iter: 337000 | Total Loss: 0.002485 | Recon Loss: 0.002117 | Commit Loss: 0.000735 | Perplexity: 2515.470212
Trainning Epoch:  67%|██████▋   | 444/658 [62:37:38<58:36:03, 985.81s/it]Trainning Epoch:  67%|██████▋   | 444/658 [62:37:38<58:36:03, 985.81s/it]2025-09-29 03:53:28,372 Stage: Train 0.5 | Epoch: 233 | Iter: 337200 | Total Loss: 0.002504 | Recon Loss: 0.002144 | Commit Loss: 0.000721 | Perplexity: 2510.829343
2025-09-29 03:57:46,326 Stage: Train 0.5 | Epoch: 233 | Iter: 337400 | Total Loss: 0.002495 | Recon Loss: 0.002126 | Commit Loss: 0.000739 | Perplexity: 2513.642419
2025-09-29 04:02:04,547 Stage: Train 0.5 | Epoch: 233 | Iter: 337600 | Total Loss: 0.002496 | Recon Loss: 0.002126 | Commit Loss: 0.000740 | Perplexity: 2511.429934
2025-09-29 04:06:22,567 Stage: Train 0.5 | Epoch: 233 | Iter: 337800 | Total Loss: 0.002490 | Recon Loss: 0.002125 | Commit Loss: 0.000731 | Perplexity: 2512.941522
Trainning Epoch:  68%|██████▊   | 445/658 [62:54:01<58:17:01, 985.08s/it]Trainning Epoch:  68%|██████▊   | 445/658 [62:54:01<58:17:01, 985.08s/it]2025-09-29 04:10:44,463 Stage: Train 0.5 | Epoch: 234 | Iter: 338000 | Total Loss: 0.002489 | Recon Loss: 0.002127 | Commit Loss: 0.000723 | Perplexity: 2516.244884
2025-09-29 04:15:02,233 Stage: Train 0.5 | Epoch: 234 | Iter: 338200 | Total Loss: 0.002515 | Recon Loss: 0.002147 | Commit Loss: 0.000735 | Perplexity: 2512.764451
2025-09-29 04:19:20,979 Stage: Train 0.5 | Epoch: 234 | Iter: 338400 | Total Loss: 0.002480 | Recon Loss: 0.002115 | Commit Loss: 0.000730 | Perplexity: 2514.638832
2025-09-29 04:23:39,414 Stage: Train 0.5 | Epoch: 234 | Iter: 338600 | Total Loss: 0.002500 | Recon Loss: 0.002136 | Commit Loss: 0.000728 | Perplexity: 2518.128188
Trainning Epoch:  68%|██████▊   | 446/658 [63:10:27<58:00:59, 985.19s/it]Trainning Epoch:  68%|██████▊   | 446/658 [63:10:27<58:01:00, 985.19s/it]2025-09-29 04:28:01,139 Stage: Train 0.5 | Epoch: 235 | Iter: 338800 | Total Loss: 0.002478 | Recon Loss: 0.002115 | Commit Loss: 0.000724 | Perplexity: 2511.460880
2025-09-29 04:32:17,910 Stage: Train 0.5 | Epoch: 235 | Iter: 339000 | Total Loss: 0.002481 | Recon Loss: 0.002120 | Commit Loss: 0.000722 | Perplexity: 2510.625046
2025-09-29 04:36:35,119 Stage: Train 0.5 | Epoch: 235 | Iter: 339200 | Total Loss: 0.002509 | Recon Loss: 0.002136 | Commit Loss: 0.000746 | Perplexity: 2512.188944
Trainning Epoch:  68%|██████▊   | 447/658 [63:26:48<57:40:54, 984.15s/it]Trainning Epoch:  68%|██████▊   | 447/658 [63:26:48<57:40:55, 984.15s/it]2025-09-29 04:40:55,110 Stage: Train 0.5 | Epoch: 236 | Iter: 339400 | Total Loss: 0.002508 | Recon Loss: 0.002146 | Commit Loss: 0.000724 | Perplexity: 2509.194807
2025-09-29 04:45:08,046 Stage: Train 0.5 | Epoch: 236 | Iter: 339600 | Total Loss: 0.002524 | Recon Loss: 0.002157 | Commit Loss: 0.000734 | Perplexity: 2513.028805
2025-09-29 04:49:22,163 Stage: Train 0.5 | Epoch: 236 | Iter: 339800 | Total Loss: 0.002475 | Recon Loss: 0.002113 | Commit Loss: 0.000724 | Perplexity: 2506.745593
2025-09-29 04:53:36,033 Stage: Train 0.5 | Epoch: 236 | Iter: 340000 | Total Loss: 0.002515 | Recon Loss: 0.002152 | Commit Loss: 0.000725 | Perplexity: 2507.669445
2025-09-29 04:53:36,033 Saving model at iteration 340000
2025-09-29 04:53:36,260 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_237_step_340000
2025-09-29 04:53:36,792 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_237_step_340000/model.safetensors
2025-09-29 04:53:37,228 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_237_step_340000/optimizer.bin
2025-09-29 04:53:37,229 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_237_step_340000/scheduler.bin
2025-09-29 04:53:37,229 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_237_step_340000/sampler.bin
2025-09-29 04:53:37,230 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_237_step_340000/random_states_0.pkl
Trainning Epoch:  68%|██████▊   | 448/658 [63:42:56<57:07:40, 979.33s/it]Trainning Epoch:  68%|██████▊   | 448/658 [63:42:56<57:07:41, 979.34s/it]2025-09-29 04:57:56,944 Stage: Train 0.5 | Epoch: 237 | Iter: 340200 | Total Loss: 0.002496 | Recon Loss: 0.002130 | Commit Loss: 0.000731 | Perplexity: 2511.422336
2025-09-29 05:02:16,597 Stage: Train 0.5 | Epoch: 237 | Iter: 340400 | Total Loss: 0.002485 | Recon Loss: 0.002121 | Commit Loss: 0.000727 | Perplexity: 2511.354467
2025-09-29 05:06:36,678 Stage: Train 0.5 | Epoch: 237 | Iter: 340600 | Total Loss: 0.002490 | Recon Loss: 0.002120 | Commit Loss: 0.000739 | Perplexity: 2509.170032
2025-09-29 05:10:56,988 Stage: Train 0.5 | Epoch: 237 | Iter: 340800 | Total Loss: 0.002481 | Recon Loss: 0.002122 | Commit Loss: 0.000718 | Perplexity: 2507.665688
Trainning Epoch:  68%|██████▊   | 449/658 [63:59:28<57:03:45, 982.90s/it]Trainning Epoch:  68%|██████▊   | 449/658 [63:59:28<57:03:45, 982.90s/it]2025-09-29 05:15:18,565 Stage: Train 0.5 | Epoch: 238 | Iter: 341000 | Total Loss: 0.002507 | Recon Loss: 0.002139 | Commit Loss: 0.000738 | Perplexity: 2513.327914
2025-09-29 05:19:36,012 Stage: Train 0.5 | Epoch: 238 | Iter: 341200 | Total Loss: 0.002485 | Recon Loss: 0.002112 | Commit Loss: 0.000747 | Perplexity: 2515.442416
2025-09-29 05:23:52,394 Stage: Train 0.5 | Epoch: 238 | Iter: 341400 | Total Loss: 0.002509 | Recon Loss: 0.002142 | Commit Loss: 0.000734 | Perplexity: 2509.262883
2025-09-29 05:28:08,737 Stage: Train 0.5 | Epoch: 238 | Iter: 341600 | Total Loss: 0.002486 | Recon Loss: 0.002115 | Commit Loss: 0.000743 | Perplexity: 2510.937567
Trainning Epoch:  68%|██████▊   | 450/658 [64:15:47<56:43:21, 981.74s/it]Trainning Epoch:  68%|██████▊   | 450/658 [64:15:47<56:43:21, 981.74s/it]2025-09-29 05:32:31,157 Stage: Train 0.5 | Epoch: 239 | Iter: 341800 | Total Loss: 0.002486 | Recon Loss: 0.002118 | Commit Loss: 0.000735 | Perplexity: 2512.243140
2025-09-29 05:36:52,937 Stage: Train 0.5 | Epoch: 239 | Iter: 342000 | Total Loss: 0.002475 | Recon Loss: 0.002111 | Commit Loss: 0.000728 | Perplexity: 2511.006544
2025-09-29 05:41:16,186 Stage: Train 0.5 | Epoch: 239 | Iter: 342200 | Total Loss: 0.002497 | Recon Loss: 0.002130 | Commit Loss: 0.000733 | Perplexity: 2510.898108
2025-09-29 05:45:36,362 Stage: Train 0.5 | Epoch: 239 | Iter: 342400 | Total Loss: 0.002525 | Recon Loss: 0.002154 | Commit Loss: 0.000742 | Perplexity: 2508.960210
Trainning Epoch:  69%|██████▊   | 451/658 [64:32:24<56:42:41, 986.29s/it]Trainning Epoch:  69%|██████▊   | 451/658 [64:32:24<56:42:41, 986.29s/it]2025-09-29 05:49:58,668 Stage: Train 0.5 | Epoch: 240 | Iter: 342600 | Total Loss: 0.002462 | Recon Loss: 0.002102 | Commit Loss: 0.000719 | Perplexity: 2509.124307
2025-09-29 05:54:17,581 Stage: Train 0.5 | Epoch: 240 | Iter: 342800 | Total Loss: 0.002499 | Recon Loss: 0.002136 | Commit Loss: 0.000727 | Perplexity: 2519.628568
2025-09-29 05:58:36,724 Stage: Train 0.5 | Epoch: 240 | Iter: 343000 | Total Loss: 0.002513 | Recon Loss: 0.002144 | Commit Loss: 0.000738 | Perplexity: 2507.762255
Trainning Epoch:  69%|██████▊   | 452/658 [64:48:50<56:26:48, 986.45s/it]Trainning Epoch:  69%|██████▊   | 452/658 [64:48:50<56:26:48, 986.45s/it]2025-09-29 06:02:58,573 Stage: Train 0.5 | Epoch: 241 | Iter: 343200 | Total Loss: 0.002466 | Recon Loss: 0.002099 | Commit Loss: 0.000733 | Perplexity: 2510.795858
2025-09-29 06:07:16,222 Stage: Train 0.5 | Epoch: 241 | Iter: 343400 | Total Loss: 0.002487 | Recon Loss: 0.002120 | Commit Loss: 0.000734 | Perplexity: 2512.081691
2025-09-29 06:11:35,429 Stage: Train 0.5 | Epoch: 241 | Iter: 343600 | Total Loss: 0.002501 | Recon Loss: 0.002133 | Commit Loss: 0.000736 | Perplexity: 2510.361133
2025-09-29 06:15:54,849 Stage: Train 0.5 | Epoch: 241 | Iter: 343800 | Total Loss: 0.002483 | Recon Loss: 0.002116 | Commit Loss: 0.000733 | Perplexity: 2509.003604
Trainning Epoch:  69%|██████▉   | 453/658 [65:05:17<56:10:43, 986.55s/it]Trainning Epoch:  69%|██████▉   | 453/658 [65:05:17<56:10:46, 986.57s/it]2025-09-29 06:20:17,429 Stage: Train 0.5 | Epoch: 242 | Iter: 344000 | Total Loss: 0.002514 | Recon Loss: 0.002145 | Commit Loss: 0.000739 | Perplexity: 2515.799419
2025-09-29 06:24:35,794 Stage: Train 0.5 | Epoch: 242 | Iter: 344200 | Total Loss: 0.002481 | Recon Loss: 0.002114 | Commit Loss: 0.000733 | Perplexity: 2504.116384
2025-09-29 06:28:54,853 Stage: Train 0.5 | Epoch: 242 | Iter: 344400 | Total Loss: 0.002486 | Recon Loss: 0.002119 | Commit Loss: 0.000735 | Perplexity: 2505.844343
2025-09-29 06:33:13,777 Stage: Train 0.5 | Epoch: 242 | Iter: 344600 | Total Loss: 0.002486 | Recon Loss: 0.002117 | Commit Loss: 0.000737 | Perplexity: 2515.903949
Trainning Epoch:  69%|██████▉   | 454/658 [65:21:44<55:54:39, 986.66s/it]Trainning Epoch:  69%|██████▉   | 454/658 [65:21:44<55:54:40, 986.67s/it]2025-09-29 06:37:35,177 Stage: Train 0.5 | Epoch: 243 | Iter: 344800 | Total Loss: 0.002505 | Recon Loss: 0.002143 | Commit Loss: 0.000723 | Perplexity: 2512.554121
2025-09-29 06:41:53,418 Stage: Train 0.5 | Epoch: 243 | Iter: 345000 | Total Loss: 0.002449 | Recon Loss: 0.002082 | Commit Loss: 0.000734 | Perplexity: 2510.904630
2025-09-29 06:46:11,586 Stage: Train 0.5 | Epoch: 243 | Iter: 345200 | Total Loss: 0.002511 | Recon Loss: 0.002144 | Commit Loss: 0.000734 | Perplexity: 2513.386575
2025-09-29 06:50:29,919 Stage: Train 0.5 | Epoch: 243 | Iter: 345400 | Total Loss: 0.002485 | Recon Loss: 0.002114 | Commit Loss: 0.000741 | Perplexity: 2515.234608
Trainning Epoch:  69%|██████▉   | 455/658 [65:38:08<55:35:48, 985.95s/it]Trainning Epoch:  69%|██████▉   | 455/658 [65:38:08<55:35:49, 985.96s/it]2025-09-29 06:54:53,186 Stage: Train 0.5 | Epoch: 244 | Iter: 345600 | Total Loss: 0.002513 | Recon Loss: 0.002146 | Commit Loss: 0.000733 | Perplexity: 2509.741963
2025-09-29 06:59:12,230 Stage: Train 0.5 | Epoch: 244 | Iter: 345800 | Total Loss: 0.002468 | Recon Loss: 0.002104 | Commit Loss: 0.000728 | Perplexity: 2506.777126
2025-09-29 07:03:31,425 Stage: Train 0.5 | Epoch: 244 | Iter: 346000 | Total Loss: 0.002500 | Recon Loss: 0.002130 | Commit Loss: 0.000741 | Perplexity: 2511.994800
2025-09-29 07:07:50,087 Stage: Train 0.5 | Epoch: 244 | Iter: 346200 | Total Loss: 0.002501 | Recon Loss: 0.002126 | Commit Loss: 0.000750 | Perplexity: 2512.684437
Trainning Epoch:  69%|██████▉   | 456/658 [65:54:37<55:22:17, 986.82s/it]Trainning Epoch:  69%|██████▉   | 456/658 [65:54:37<55:22:19, 986.83s/it]2025-09-29 07:12:14,730 Stage: Train 0.5 | Epoch: 245 | Iter: 346400 | Total Loss: 0.002474 | Recon Loss: 0.002109 | Commit Loss: 0.000729 | Perplexity: 2511.311155
2025-09-29 07:16:35,695 Stage: Train 0.5 | Epoch: 245 | Iter: 346600 | Total Loss: 0.002486 | Recon Loss: 0.002121 | Commit Loss: 0.000730 | Perplexity: 2510.708767
2025-09-29 07:20:56,479 Stage: Train 0.5 | Epoch: 245 | Iter: 346800 | Total Loss: 0.002485 | Recon Loss: 0.002113 | Commit Loss: 0.000743 | Perplexity: 2512.122275
Trainning Epoch:  69%|██████▉   | 457/658 [66:11:12<55:13:26, 989.09s/it]Trainning Epoch:  69%|██████▉   | 457/658 [66:11:12<55:13:26, 989.08s/it]2025-09-29 07:25:19,541 Stage: Train 0.5 | Epoch: 246 | Iter: 347000 | Total Loss: 0.002474 | Recon Loss: 0.002112 | Commit Loss: 0.000724 | Perplexity: 2511.157837
2025-09-29 07:29:36,008 Stage: Train 0.5 | Epoch: 246 | Iter: 347200 | Total Loss: 0.002486 | Recon Loss: 0.002118 | Commit Loss: 0.000736 | Perplexity: 2510.913088
2025-09-29 07:33:54,065 Stage: Train 0.5 | Epoch: 246 | Iter: 347400 | Total Loss: 0.002472 | Recon Loss: 0.002109 | Commit Loss: 0.000725 | Perplexity: 2511.796178
2025-09-29 07:38:12,031 Stage: Train 0.5 | Epoch: 246 | Iter: 347600 | Total Loss: 0.002504 | Recon Loss: 0.002133 | Commit Loss: 0.000742 | Perplexity: 2510.938104
Trainning Epoch:  70%|██████▉   | 458/658 [66:27:34<54:49:47, 986.94s/it]Trainning Epoch:  70%|██████▉   | 458/658 [66:27:34<54:49:48, 986.94s/it]2025-09-29 07:42:32,888 Stage: Train 0.5 | Epoch: 247 | Iter: 347800 | Total Loss: 0.002489 | Recon Loss: 0.002121 | Commit Loss: 0.000737 | Perplexity: 2506.825562
2025-09-29 07:46:49,479 Stage: Train 0.5 | Epoch: 247 | Iter: 348000 | Total Loss: 0.002471 | Recon Loss: 0.002099 | Commit Loss: 0.000744 | Perplexity: 2514.261190
2025-09-29 07:51:06,986 Stage: Train 0.5 | Epoch: 247 | Iter: 348200 | Total Loss: 0.002460 | Recon Loss: 0.002093 | Commit Loss: 0.000734 | Perplexity: 2509.446508
2025-09-29 07:55:24,963 Stage: Train 0.5 | Epoch: 247 | Iter: 348400 | Total Loss: 0.002516 | Recon Loss: 0.002148 | Commit Loss: 0.000736 | Perplexity: 2513.858007
Trainning Epoch:  70%|██████▉   | 459/658 [66:43:55<54:28:18, 985.42s/it]Trainning Epoch:  70%|██████▉   | 459/658 [66:43:55<54:28:19, 985.42s/it]2025-09-29 07:59:45,539 Stage: Train 0.5 | Epoch: 248 | Iter: 348600 | Total Loss: 0.002472 | Recon Loss: 0.002104 | Commit Loss: 0.000736 | Perplexity: 2506.838074
2025-09-29 08:04:01,548 Stage: Train 0.5 | Epoch: 248 | Iter: 348800 | Total Loss: 0.002496 | Recon Loss: 0.002126 | Commit Loss: 0.000740 | Perplexity: 2511.302739
2025-09-29 08:08:18,515 Stage: Train 0.5 | Epoch: 248 | Iter: 349000 | Total Loss: 0.002472 | Recon Loss: 0.002106 | Commit Loss: 0.000732 | Perplexity: 2514.679058
2025-09-29 08:12:35,273 Stage: Train 0.5 | Epoch: 248 | Iter: 349200 | Total Loss: 0.002496 | Recon Loss: 0.002134 | Commit Loss: 0.000725 | Perplexity: 2509.686393
Trainning Epoch:  70%|██████▉   | 460/658 [67:00:13<54:04:23, 983.15s/it]Trainning Epoch:  70%|██████▉   | 460/658 [67:00:13<54:04:23, 983.15s/it]2025-09-29 08:16:57,836 Stage: Train 0.5 | Epoch: 249 | Iter: 349400 | Total Loss: 0.002465 | Recon Loss: 0.002098 | Commit Loss: 0.000734 | Perplexity: 2512.625602
2025-09-29 08:21:16,578 Stage: Train 0.5 | Epoch: 249 | Iter: 349600 | Total Loss: 0.002484 | Recon Loss: 0.002114 | Commit Loss: 0.000740 | Perplexity: 2514.654951
2025-09-29 08:25:35,734 Stage: Train 0.5 | Epoch: 249 | Iter: 349800 | Total Loss: 0.002490 | Recon Loss: 0.002121 | Commit Loss: 0.000738 | Perplexity: 2515.150045
2025-09-29 08:29:56,598 Stage: Train 0.5 | Epoch: 249 | Iter: 350000 | Total Loss: 0.002486 | Recon Loss: 0.002117 | Commit Loss: 0.000738 | Perplexity: 2506.507291
Trainning Epoch:  70%|███████   | 461/658 [67:16:44<53:55:12, 985.34s/it]Trainning Epoch:  70%|███████   | 461/658 [67:16:44<53:55:13, 985.35s/it]2025-09-29 08:34:19,857 Stage: Train 0.5 | Epoch: 250 | Iter: 350200 | Total Loss: 0.002478 | Recon Loss: 0.002113 | Commit Loss: 0.000729 | Perplexity: 2507.056534
2025-09-29 08:38:38,471 Stage: Train 0.5 | Epoch: 250 | Iter: 350400 | Total Loss: 0.002477 | Recon Loss: 0.002119 | Commit Loss: 0.000715 | Perplexity: 2506.664819
2025-09-29 08:42:56,078 Stage: Train 0.5 | Epoch: 250 | Iter: 350600 | Total Loss: 0.002502 | Recon Loss: 0.002130 | Commit Loss: 0.000744 | Perplexity: 2517.731378
Trainning Epoch:  70%|███████   | 462/658 [67:33:10<53:39:46, 985.64s/it]Trainning Epoch:  70%|███████   | 462/658 [67:33:10<53:39:47, 985.65s/it]2025-09-29 08:47:17,672 Stage: Train 0.5 | Epoch: 251 | Iter: 350800 | Total Loss: 0.002451 | Recon Loss: 0.002083 | Commit Loss: 0.000736 | Perplexity: 2511.708516
2025-09-29 08:51:32,905 Stage: Train 0.5 | Epoch: 251 | Iter: 351000 | Total Loss: 0.002462 | Recon Loss: 0.002093 | Commit Loss: 0.000739 | Perplexity: 2509.119680
2025-09-29 08:55:49,120 Stage: Train 0.5 | Epoch: 251 | Iter: 351200 | Total Loss: 0.002476 | Recon Loss: 0.002107 | Commit Loss: 0.000739 | Perplexity: 2517.027444
2025-09-29 09:00:05,090 Stage: Train 0.5 | Epoch: 251 | Iter: 351400 | Total Loss: 0.002482 | Recon Loss: 0.002117 | Commit Loss: 0.000729 | Perplexity: 2506.759041
Trainning Epoch:  70%|███████   | 463/658 [67:49:26<53:13:27, 982.60s/it]Trainning Epoch:  70%|███████   | 463/658 [67:49:26<53:13:28, 982.61s/it]2025-09-29 09:04:25,317 Stage: Train 0.5 | Epoch: 252 | Iter: 351600 | Total Loss: 0.002499 | Recon Loss: 0.002132 | Commit Loss: 0.000734 | Perplexity: 2510.123887
2025-09-29 09:08:42,069 Stage: Train 0.5 | Epoch: 252 | Iter: 351800 | Total Loss: 0.002471 | Recon Loss: 0.002106 | Commit Loss: 0.000731 | Perplexity: 2504.543302
2025-09-29 09:12:58,629 Stage: Train 0.5 | Epoch: 252 | Iter: 352000 | Total Loss: 0.002470 | Recon Loss: 0.002103 | Commit Loss: 0.000733 | Perplexity: 2511.206669
2025-09-29 09:17:15,921 Stage: Train 0.5 | Epoch: 252 | Iter: 352200 | Total Loss: 0.002503 | Recon Loss: 0.002138 | Commit Loss: 0.000732 | Perplexity: 2511.780948
Trainning Epoch:  71%|███████   | 464/658 [68:05:46<52:54:31, 981.81s/it]Trainning Epoch:  71%|███████   | 464/658 [68:05:46<52:54:32, 981.82s/it]2025-09-29 09:21:37,407 Stage: Train 0.5 | Epoch: 253 | Iter: 352400 | Total Loss: 0.002458 | Recon Loss: 0.002092 | Commit Loss: 0.000734 | Perplexity: 2513.719897
2025-09-29 09:25:55,806 Stage: Train 0.5 | Epoch: 253 | Iter: 352600 | Total Loss: 0.002472 | Recon Loss: 0.002110 | Commit Loss: 0.000724 | Perplexity: 2506.514209
2025-09-29 09:30:14,902 Stage: Train 0.5 | Epoch: 253 | Iter: 352800 | Total Loss: 0.002505 | Recon Loss: 0.002138 | Commit Loss: 0.000733 | Perplexity: 2510.068436
2025-09-29 09:34:33,189 Stage: Train 0.5 | Epoch: 253 | Iter: 353000 | Total Loss: 0.002465 | Recon Loss: 0.002102 | Commit Loss: 0.000726 | Perplexity: 2508.322307
Trainning Epoch:  71%|███████   | 465/658 [68:22:12<52:42:11, 983.07s/it]Trainning Epoch:  71%|███████   | 465/658 [68:22:12<52:42:12, 983.07s/it]2025-09-29 09:38:56,874 Stage: Train 0.5 | Epoch: 254 | Iter: 353200 | Total Loss: 0.002457 | Recon Loss: 0.002092 | Commit Loss: 0.000729 | Perplexity: 2510.267920
2025-09-29 09:43:17,341 Stage: Train 0.5 | Epoch: 254 | Iter: 353400 | Total Loss: 0.002491 | Recon Loss: 0.002126 | Commit Loss: 0.000730 | Perplexity: 2513.422184
2025-09-29 09:47:38,110 Stage: Train 0.5 | Epoch: 254 | Iter: 353600 | Total Loss: 0.002492 | Recon Loss: 0.002123 | Commit Loss: 0.000738 | Perplexity: 2508.984036
2025-09-29 09:51:58,177 Stage: Train 0.5 | Epoch: 254 | Iter: 353800 | Total Loss: 0.002466 | Recon Loss: 0.002102 | Commit Loss: 0.000728 | Perplexity: 2509.552098
Trainning Epoch:  71%|███████   | 466/658 [68:38:45<52:36:05, 986.28s/it]Trainning Epoch:  71%|███████   | 466/658 [68:38:45<52:36:05, 986.28s/it]2025-09-29 09:56:22,757 Stage: Train 0.5 | Epoch: 255 | Iter: 354000 | Total Loss: 0.002444 | Recon Loss: 0.002075 | Commit Loss: 0.000737 | Perplexity: 2509.333379
2025-09-29 10:00:42,268 Stage: Train 0.5 | Epoch: 255 | Iter: 354200 | Total Loss: 0.002493 | Recon Loss: 0.002126 | Commit Loss: 0.000733 | Perplexity: 2509.606969
2025-09-29 10:05:02,131 Stage: Train 0.5 | Epoch: 255 | Iter: 354400 | Total Loss: 0.002501 | Recon Loss: 0.002123 | Commit Loss: 0.000755 | Perplexity: 2516.004000
Trainning Epoch:  71%|███████   | 467/658 [68:55:17<52:24:21, 987.76s/it]Trainning Epoch:  71%|███████   | 467/658 [68:55:17<52:24:22, 987.76s/it]2025-09-29 10:09:25,692 Stage: Train 0.5 | Epoch: 256 | Iter: 354600 | Total Loss: 0.002474 | Recon Loss: 0.002101 | Commit Loss: 0.000746 | Perplexity: 2510.826638
2025-09-29 10:13:46,463 Stage: Train 0.5 | Epoch: 256 | Iter: 354800 | Total Loss: 0.002473 | Recon Loss: 0.002107 | Commit Loss: 0.000732 | Perplexity: 2511.437131
2025-09-29 10:18:07,685 Stage: Train 0.5 | Epoch: 256 | Iter: 355000 | Total Loss: 0.002462 | Recon Loss: 0.002092 | Commit Loss: 0.000739 | Perplexity: 2513.535820
2025-09-29 10:22:28,719 Stage: Train 0.5 | Epoch: 256 | Iter: 355200 | Total Loss: 0.002479 | Recon Loss: 0.002105 | Commit Loss: 0.000749 | Perplexity: 2511.233300
Trainning Epoch:  71%|███████   | 468/658 [69:11:51<52:14:40, 989.90s/it]Trainning Epoch:  71%|███████   | 468/658 [69:11:51<52:14:41, 989.90s/it]2025-09-29 10:26:52,887 Stage: Train 0.5 | Epoch: 257 | Iter: 355400 | Total Loss: 0.002482 | Recon Loss: 0.002119 | Commit Loss: 0.000725 | Perplexity: 2513.444905
2025-09-29 10:31:13,051 Stage: Train 0.5 | Epoch: 257 | Iter: 355600 | Total Loss: 0.002477 | Recon Loss: 0.002110 | Commit Loss: 0.000734 | Perplexity: 2509.457495
2025-09-29 10:35:33,593 Stage: Train 0.5 | Epoch: 257 | Iter: 355800 | Total Loss: 0.002460 | Recon Loss: 0.002093 | Commit Loss: 0.000734 | Perplexity: 2509.682419
2025-09-29 10:39:54,026 Stage: Train 0.5 | Epoch: 257 | Iter: 356000 | Total Loss: 0.002504 | Recon Loss: 0.002134 | Commit Loss: 0.000739 | Perplexity: 2511.596859
Trainning Epoch:  71%|███████▏  | 469/658 [69:28:25<52:01:31, 990.96s/it]Trainning Epoch:  71%|███████▏  | 469/658 [69:28:25<52:01:31, 990.96s/it]2025-09-29 10:44:15,640 Stage: Train 0.5 | Epoch: 258 | Iter: 356200 | Total Loss: 0.002467 | Recon Loss: 0.002100 | Commit Loss: 0.000735 | Perplexity: 2510.847313
2025-09-29 10:48:33,328 Stage: Train 0.5 | Epoch: 258 | Iter: 356400 | Total Loss: 0.002462 | Recon Loss: 0.002098 | Commit Loss: 0.000728 | Perplexity: 2505.755331
2025-09-29 10:52:52,527 Stage: Train 0.5 | Epoch: 258 | Iter: 356600 | Total Loss: 0.002468 | Recon Loss: 0.002105 | Commit Loss: 0.000725 | Perplexity: 2508.151520
2025-09-29 10:57:11,998 Stage: Train 0.5 | Epoch: 258 | Iter: 356800 | Total Loss: 0.002467 | Recon Loss: 0.002094 | Commit Loss: 0.000746 | Perplexity: 2510.014045
Trainning Epoch:  71%|███████▏  | 470/658 [69:44:51<51:40:08, 989.41s/it]Trainning Epoch:  71%|███████▏  | 470/658 [69:44:51<51:40:08, 989.41s/it]2025-09-29 11:01:35,738 Stage: Train 0.5 | Epoch: 259 | Iter: 357000 | Total Loss: 0.002477 | Recon Loss: 0.002113 | Commit Loss: 0.000728 | Perplexity: 2510.249138
2025-09-29 11:05:55,605 Stage: Train 0.5 | Epoch: 259 | Iter: 357200 | Total Loss: 0.002454 | Recon Loss: 0.002082 | Commit Loss: 0.000745 | Perplexity: 2510.453868
2025-09-29 11:10:15,920 Stage: Train 0.5 | Epoch: 259 | Iter: 357400 | Total Loss: 0.002487 | Recon Loss: 0.002115 | Commit Loss: 0.000742 | Perplexity: 2509.757854
2025-09-29 11:14:35,733 Stage: Train 0.5 | Epoch: 259 | Iter: 357600 | Total Loss: 0.002464 | Recon Loss: 0.002096 | Commit Loss: 0.000737 | Perplexity: 2515.855706
Trainning Epoch:  72%|███████▏  | 471/658 [70:01:23<51:26:17, 990.25s/it]Trainning Epoch:  72%|███████▏  | 471/658 [70:01:23<51:26:17, 990.26s/it]2025-09-29 11:18:56,761 Stage: Train 0.5 | Epoch: 260 | Iter: 357800 | Total Loss: 0.002495 | Recon Loss: 0.002128 | Commit Loss: 0.000735 | Perplexity: 2511.395055
2025-09-29 11:23:15,011 Stage: Train 0.5 | Epoch: 260 | Iter: 358000 | Total Loss: 0.002470 | Recon Loss: 0.002103 | Commit Loss: 0.000734 | Perplexity: 2511.747274
2025-09-29 11:27:34,173 Stage: Train 0.5 | Epoch: 260 | Iter: 358200 | Total Loss: 0.002477 | Recon Loss: 0.002101 | Commit Loss: 0.000752 | Perplexity: 2514.705815
Trainning Epoch:  72%|███████▏  | 472/658 [70:17:48<51:05:15, 988.79s/it]Trainning Epoch:  72%|███████▏  | 472/658 [70:17:48<51:05:15, 988.79s/it]2025-09-29 11:31:54,446 Stage: Train 0.5 | Epoch: 261 | Iter: 358400 | Total Loss: 0.002458 | Recon Loss: 0.002093 | Commit Loss: 0.000732 | Perplexity: 2507.158162
2025-09-29 11:36:06,132 Stage: Train 0.5 | Epoch: 261 | Iter: 358600 | Total Loss: 0.002483 | Recon Loss: 0.002110 | Commit Loss: 0.000745 | Perplexity: 2509.790583
2025-09-29 11:40:21,573 Stage: Train 0.5 | Epoch: 261 | Iter: 358800 | Total Loss: 0.002486 | Recon Loss: 0.002113 | Commit Loss: 0.000745 | Perplexity: 2513.623625
2025-09-29 11:44:36,922 Stage: Train 0.5 | Epoch: 261 | Iter: 359000 | Total Loss: 0.002490 | Recon Loss: 0.002118 | Commit Loss: 0.000743 | Perplexity: 2514.714595
Trainning Epoch:  72%|███████▏  | 473/658 [70:33:58<50:30:52, 982.99s/it]Trainning Epoch:  72%|███████▏  | 473/658 [70:33:58<50:30:54, 983.00s/it]2025-09-29 11:48:57,646 Stage: Train 0.5 | Epoch: 262 | Iter: 359200 | Total Loss: 0.002488 | Recon Loss: 0.002115 | Commit Loss: 0.000747 | Perplexity: 2508.680742
2025-09-29 11:53:15,243 Stage: Train 0.5 | Epoch: 262 | Iter: 359400 | Total Loss: 0.002461 | Recon Loss: 0.002092 | Commit Loss: 0.000739 | Perplexity: 2510.791523
2025-09-29 11:57:33,045 Stage: Train 0.5 | Epoch: 262 | Iter: 359600 | Total Loss: 0.002468 | Recon Loss: 0.002099 | Commit Loss: 0.000738 | Perplexity: 2512.858021
2025-09-29 12:01:50,226 Stage: Train 0.5 | Epoch: 262 | Iter: 359800 | Total Loss: 0.002493 | Recon Loss: 0.002124 | Commit Loss: 0.000738 | Perplexity: 2511.574973
Trainning Epoch:  72%|███████▏  | 474/658 [70:50:20<50:13:45, 982.75s/it]Trainning Epoch:  72%|███████▏  | 474/658 [70:50:20<50:13:47, 982.76s/it]2025-09-29 12:06:10,908 Stage: Train 0.5 | Epoch: 263 | Iter: 360000 | Total Loss: 0.002443 | Recon Loss: 0.002072 | Commit Loss: 0.000741 | Perplexity: 2505.790719
2025-09-29 12:06:10,909 Saving model at iteration 360000
2025-09-29 12:06:11,593 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_264_step_360000
2025-09-29 12:06:12,088 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_264_step_360000/model.safetensors
2025-09-29 12:06:12,518 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_264_step_360000/optimizer.bin
2025-09-29 12:06:12,518 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_264_step_360000/scheduler.bin
2025-09-29 12:06:12,519 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_264_step_360000/sampler.bin
2025-09-29 12:06:12,519 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_264_step_360000/random_states_0.pkl
2025-09-29 12:10:29,035 Stage: Train 0.5 | Epoch: 263 | Iter: 360200 | Total Loss: 0.002462 | Recon Loss: 0.002096 | Commit Loss: 0.000731 | Perplexity: 2510.802905
2025-09-29 12:14:46,695 Stage: Train 0.5 | Epoch: 263 | Iter: 360400 | Total Loss: 0.002469 | Recon Loss: 0.002100 | Commit Loss: 0.000738 | Perplexity: 2508.458292
2025-09-29 12:19:05,465 Stage: Train 0.5 | Epoch: 263 | Iter: 360600 | Total Loss: 0.002476 | Recon Loss: 0.002103 | Commit Loss: 0.000745 | Perplexity: 2514.079454
Trainning Epoch:  72%|███████▏  | 475/658 [71:06:44<49:58:29, 983.11s/it]Trainning Epoch:  72%|███████▏  | 475/658 [71:06:44<49:58:30, 983.12s/it]2025-09-29 12:23:22,902 Stage: Train 0.5 | Epoch: 264 | Iter: 360800 | Total Loss: 0.002466 | Recon Loss: 0.002093 | Commit Loss: 0.000746 | Perplexity: 2512.325759
2025-09-29 12:27:36,024 Stage: Train 0.5 | Epoch: 264 | Iter: 361000 | Total Loss: 0.002479 | Recon Loss: 0.002108 | Commit Loss: 0.000742 | Perplexity: 2513.821910
2025-09-29 12:31:49,843 Stage: Train 0.5 | Epoch: 264 | Iter: 361200 | Total Loss: 0.002476 | Recon Loss: 0.002111 | Commit Loss: 0.000730 | Perplexity: 2506.046211
2025-09-29 12:36:05,211 Stage: Train 0.5 | Epoch: 264 | Iter: 361400 | Total Loss: 0.002431 | Recon Loss: 0.002064 | Commit Loss: 0.000734 | Perplexity: 2500.392115
Trainning Epoch:  72%|███████▏  | 476/658 [71:22:52<49:28:46, 978.72s/it]Trainning Epoch:  72%|███████▏  | 476/658 [71:22:52<49:28:47, 978.72s/it]2025-09-29 12:40:26,330 Stage: Train 0.5 | Epoch: 265 | Iter: 361600 | Total Loss: 0.002467 | Recon Loss: 0.002100 | Commit Loss: 0.000734 | Perplexity: 2510.141466
2025-09-29 12:44:45,328 Stage: Train 0.5 | Epoch: 265 | Iter: 361800 | Total Loss: 0.002472 | Recon Loss: 0.002099 | Commit Loss: 0.000746 | Perplexity: 2512.038994
2025-09-29 12:49:04,946 Stage: Train 0.5 | Epoch: 265 | Iter: 362000 | Total Loss: 0.002472 | Recon Loss: 0.002103 | Commit Loss: 0.000738 | Perplexity: 2505.375319
Trainning Epoch:  72%|███████▏  | 477/658 [71:39:20<49:20:15, 981.30s/it]Trainning Epoch:  72%|███████▏  | 477/658 [71:39:20<49:20:16, 981.31s/it]2025-09-29 12:53:28,941 Stage: Train 0.5 | Epoch: 266 | Iter: 362200 | Total Loss: 0.002461 | Recon Loss: 0.002091 | Commit Loss: 0.000741 | Perplexity: 2512.329180
2025-09-29 12:57:49,038 Stage: Train 0.5 | Epoch: 266 | Iter: 362400 | Total Loss: 0.002472 | Recon Loss: 0.002103 | Commit Loss: 0.000738 | Perplexity: 2513.558575
2025-09-29 13:02:09,239 Stage: Train 0.5 | Epoch: 266 | Iter: 362600 | Total Loss: 0.002482 | Recon Loss: 0.002114 | Commit Loss: 0.000736 | Perplexity: 2510.747009
2025-09-29 13:06:30,005 Stage: Train 0.5 | Epoch: 266 | Iter: 362800 | Total Loss: 0.002472 | Recon Loss: 0.002099 | Commit Loss: 0.000746 | Perplexity: 2507.064780
Trainning Epoch:  73%|███████▎  | 478/658 [71:55:53<49:14:44, 984.91s/it]Trainning Epoch:  73%|███████▎  | 478/658 [71:55:53<49:14:44, 984.92s/it]2025-09-29 13:10:54,707 Stage: Train 0.5 | Epoch: 267 | Iter: 363000 | Total Loss: 0.002456 | Recon Loss: 0.002085 | Commit Loss: 0.000742 | Perplexity: 2509.998689
2025-09-29 13:15:15,608 Stage: Train 0.5 | Epoch: 267 | Iter: 363200 | Total Loss: 0.002473 | Recon Loss: 0.002102 | Commit Loss: 0.000743 | Perplexity: 2513.721359
2025-09-29 13:19:35,883 Stage: Train 0.5 | Epoch: 267 | Iter: 363400 | Total Loss: 0.002474 | Recon Loss: 0.002104 | Commit Loss: 0.000739 | Perplexity: 2512.403314
2025-09-29 13:23:56,596 Stage: Train 0.5 | Epoch: 267 | Iter: 363600 | Total Loss: 0.002449 | Recon Loss: 0.002078 | Commit Loss: 0.000741 | Perplexity: 2506.143745
Trainning Epoch:  73%|███████▎  | 479/658 [72:12:28<49:07:06, 987.86s/it]Trainning Epoch:  73%|███████▎  | 479/658 [72:12:28<49:07:06, 987.86s/it]2025-09-29 13:28:18,485 Stage: Train 0.5 | Epoch: 268 | Iter: 363800 | Total Loss: 0.002453 | Recon Loss: 0.002088 | Commit Loss: 0.000731 | Perplexity: 2508.425056
2025-09-29 13:32:35,474 Stage: Train 0.5 | Epoch: 268 | Iter: 364000 | Total Loss: 0.002452 | Recon Loss: 0.002085 | Commit Loss: 0.000734 | Perplexity: 2506.839199
2025-09-29 13:36:53,288 Stage: Train 0.5 | Epoch: 268 | Iter: 364200 | Total Loss: 0.002462 | Recon Loss: 0.002099 | Commit Loss: 0.000726 | Perplexity: 2512.657631
2025-09-29 13:41:11,158 Stage: Train 0.5 | Epoch: 268 | Iter: 364400 | Total Loss: 0.002478 | Recon Loss: 0.002113 | Commit Loss: 0.000729 | Perplexity: 2507.954144
Trainning Epoch:  73%|███████▎  | 480/658 [72:28:50<48:45:16, 986.05s/it]Trainning Epoch:  73%|███████▎  | 480/658 [72:28:50<48:45:17, 986.05s/it]2025-09-29 13:45:33,821 Stage: Train 0.5 | Epoch: 269 | Iter: 364600 | Total Loss: 0.002473 | Recon Loss: 0.002102 | Commit Loss: 0.000743 | Perplexity: 2517.500791
2025-09-29 13:49:53,422 Stage: Train 0.5 | Epoch: 269 | Iter: 364800 | Total Loss: 0.002424 | Recon Loss: 0.002054 | Commit Loss: 0.000739 | Perplexity: 2508.488735
2025-09-29 13:54:12,906 Stage: Train 0.5 | Epoch: 269 | Iter: 365000 | Total Loss: 0.002454 | Recon Loss: 0.002085 | Commit Loss: 0.000739 | Perplexity: 2512.280164
2025-09-29 13:58:32,942 Stage: Train 0.5 | Epoch: 269 | Iter: 365200 | Total Loss: 0.002472 | Recon Loss: 0.002103 | Commit Loss: 0.000739 | Perplexity: 2505.691919
Trainning Epoch:  73%|███████▎  | 481/658 [72:45:20<48:32:47, 987.39s/it]Trainning Epoch:  73%|███████▎  | 481/658 [72:45:20<48:32:48, 987.39s/it]2025-09-29 14:02:53,295 Stage: Train 0.5 | Epoch: 270 | Iter: 365400 | Total Loss: 0.002450 | Recon Loss: 0.002084 | Commit Loss: 0.000731 | Perplexity: 2512.086071
2025-09-29 14:07:12,567 Stage: Train 0.5 | Epoch: 270 | Iter: 365600 | Total Loss: 0.002482 | Recon Loss: 0.002110 | Commit Loss: 0.000743 | Perplexity: 2509.766815
2025-09-29 14:11:31,691 Stage: Train 0.5 | Epoch: 270 | Iter: 365800 | Total Loss: 0.002461 | Recon Loss: 0.002090 | Commit Loss: 0.000741 | Perplexity: 2511.422924
Trainning Epoch:  73%|███████▎  | 482/658 [73:01:45<48:14:34, 986.79s/it]Trainning Epoch:  73%|███████▎  | 482/658 [73:01:46<48:14:34, 986.79s/it]2025-09-29 14:15:54,843 Stage: Train 0.5 | Epoch: 271 | Iter: 366000 | Total Loss: 0.002464 | Recon Loss: 0.002096 | Commit Loss: 0.000736 | Perplexity: 2508.137336
2025-09-29 14:20:10,778 Stage: Train 0.5 | Epoch: 271 | Iter: 366200 | Total Loss: 0.002473 | Recon Loss: 0.002104 | Commit Loss: 0.000738 | Perplexity: 2510.362454
2025-09-29 14:24:28,852 Stage: Train 0.5 | Epoch: 271 | Iter: 366400 | Total Loss: 0.002466 | Recon Loss: 0.002095 | Commit Loss: 0.000740 | Perplexity: 2516.956982
2025-09-29 14:28:47,893 Stage: Train 0.5 | Epoch: 271 | Iter: 366600 | Total Loss: 0.002463 | Recon Loss: 0.002091 | Commit Loss: 0.000744 | Perplexity: 2512.876067
Trainning Epoch:  73%|███████▎  | 483/658 [73:18:10<47:55:54, 986.03s/it]Trainning Epoch:  73%|███████▎  | 483/658 [73:18:10<47:55:55, 986.03s/it]2025-09-29 14:33:10,581 Stage: Train 0.5 | Epoch: 272 | Iter: 366800 | Total Loss: 0.002470 | Recon Loss: 0.002103 | Commit Loss: 0.000735 | Perplexity: 2501.232690
2025-09-29 14:37:28,470 Stage: Train 0.5 | Epoch: 272 | Iter: 367000 | Total Loss: 0.002468 | Recon Loss: 0.002102 | Commit Loss: 0.000733 | Perplexity: 2507.358141
2025-09-29 14:41:46,696 Stage: Train 0.5 | Epoch: 272 | Iter: 367200 | Total Loss: 0.002456 | Recon Loss: 0.002079 | Commit Loss: 0.000755 | Perplexity: 2510.812479
2025-09-29 14:46:05,041 Stage: Train 0.5 | Epoch: 272 | Iter: 367400 | Total Loss: 0.002440 | Recon Loss: 0.002069 | Commit Loss: 0.000743 | Perplexity: 2510.147819
Trainning Epoch:  74%|███████▎  | 484/658 [73:34:35<47:38:44, 985.77s/it]Trainning Epoch:  74%|███████▎  | 484/658 [73:34:35<47:38:45, 985.78s/it]2025-09-29 14:50:26,367 Stage: Train 0.5 | Epoch: 273 | Iter: 367600 | Total Loss: 0.002457 | Recon Loss: 0.002090 | Commit Loss: 0.000734 | Perplexity: 2510.983684
2025-09-29 14:54:45,875 Stage: Train 0.5 | Epoch: 273 | Iter: 367800 | Total Loss: 0.002451 | Recon Loss: 0.002084 | Commit Loss: 0.000733 | Perplexity: 2503.818022
2025-09-29 14:59:06,681 Stage: Train 0.5 | Epoch: 273 | Iter: 368000 | Total Loss: 0.002465 | Recon Loss: 0.002090 | Commit Loss: 0.000750 | Perplexity: 2510.251011
2025-09-29 15:03:26,891 Stage: Train 0.5 | Epoch: 273 | Iter: 368200 | Total Loss: 0.002464 | Recon Loss: 0.002089 | Commit Loss: 0.000749 | Perplexity: 2514.993141
Trainning Epoch:  74%|███████▎  | 485/658 [73:51:06<47:26:43, 987.30s/it]Trainning Epoch:  74%|███████▎  | 485/658 [73:51:06<47:26:44, 987.31s/it]2025-09-29 15:07:48,147 Stage: Train 0.5 | Epoch: 274 | Iter: 368400 | Total Loss: 0.002464 | Recon Loss: 0.002099 | Commit Loss: 0.000730 | Perplexity: 2501.782527
2025-09-29 15:12:05,186 Stage: Train 0.5 | Epoch: 274 | Iter: 368600 | Total Loss: 0.002451 | Recon Loss: 0.002073 | Commit Loss: 0.000756 | Perplexity: 2513.797400
2025-09-29 15:16:22,772 Stage: Train 0.5 | Epoch: 274 | Iter: 368800 | Total Loss: 0.002478 | Recon Loss: 0.002102 | Commit Loss: 0.000752 | Perplexity: 2513.564028
2025-09-29 15:20:40,074 Stage: Train 0.5 | Epoch: 274 | Iter: 369000 | Total Loss: 0.002471 | Recon Loss: 0.002101 | Commit Loss: 0.000739 | Perplexity: 2505.305417
Trainning Epoch:  74%|███████▍  | 486/658 [74:07:27<47:05:12, 985.54s/it]Trainning Epoch:  74%|███████▍  | 486/658 [74:07:27<47:05:13, 985.54s/it]2025-09-29 15:25:01,644 Stage: Train 0.5 | Epoch: 275 | Iter: 369200 | Total Loss: 0.002442 | Recon Loss: 0.002077 | Commit Loss: 0.000729 | Perplexity: 2508.395012
2025-09-29 15:29:20,685 Stage: Train 0.5 | Epoch: 275 | Iter: 369400 | Total Loss: 0.002438 | Recon Loss: 0.002066 | Commit Loss: 0.000744 | Perplexity: 2511.515819
2025-09-29 15:33:40,247 Stage: Train 0.5 | Epoch: 275 | Iter: 369600 | Total Loss: 0.002458 | Recon Loss: 0.002081 | Commit Loss: 0.000753 | Perplexity: 2506.648420
Trainning Epoch:  74%|███████▍  | 487/658 [74:23:55<46:50:36, 986.18s/it]Trainning Epoch:  74%|███████▍  | 487/658 [74:23:55<46:50:37, 986.18s/it]2025-09-29 15:38:04,535 Stage: Train 0.5 | Epoch: 276 | Iter: 369800 | Total Loss: 0.002479 | Recon Loss: 0.002101 | Commit Loss: 0.000756 | Perplexity: 2511.546078
2025-09-29 15:42:25,198 Stage: Train 0.5 | Epoch: 276 | Iter: 370000 | Total Loss: 0.002444 | Recon Loss: 0.002074 | Commit Loss: 0.000738 | Perplexity: 2507.479725
2025-09-29 15:46:45,567 Stage: Train 0.5 | Epoch: 276 | Iter: 370200 | Total Loss: 0.002467 | Recon Loss: 0.002095 | Commit Loss: 0.000744 | Perplexity: 2506.895776
2025-09-29 15:51:06,402 Stage: Train 0.5 | Epoch: 276 | Iter: 370400 | Total Loss: 0.002461 | Recon Loss: 0.002089 | Commit Loss: 0.000744 | Perplexity: 2510.729102
Trainning Epoch:  74%|███████▍  | 488/658 [74:40:29<46:41:15, 988.68s/it]Trainning Epoch:  74%|███████▍  | 488/658 [74:40:29<46:41:16, 988.69s/it]2025-09-29 15:55:28,857 Stage: Train 0.5 | Epoch: 277 | Iter: 370600 | Total Loss: 0.002427 | Recon Loss: 0.002061 | Commit Loss: 0.000733 | Perplexity: 2503.579918
2025-09-29 15:59:47,017 Stage: Train 0.5 | Epoch: 277 | Iter: 370800 | Total Loss: 0.002438 | Recon Loss: 0.002070 | Commit Loss: 0.000735 | Perplexity: 2506.165415
2025-09-29 16:04:05,443 Stage: Train 0.5 | Epoch: 277 | Iter: 371000 | Total Loss: 0.002455 | Recon Loss: 0.002081 | Commit Loss: 0.000748 | Perplexity: 2509.637772
2025-09-29 16:08:23,161 Stage: Train 0.5 | Epoch: 277 | Iter: 371200 | Total Loss: 0.002486 | Recon Loss: 0.002107 | Commit Loss: 0.000757 | Perplexity: 2508.284365
Trainning Epoch:  74%|███████▍  | 489/658 [74:56:54<46:21:07, 987.38s/it]Trainning Epoch:  74%|███████▍  | 489/658 [74:56:54<46:21:07, 987.38s/it]2025-09-29 16:12:44,757 Stage: Train 0.5 | Epoch: 278 | Iter: 371400 | Total Loss: 0.002433 | Recon Loss: 0.002064 | Commit Loss: 0.000738 | Perplexity: 2508.681284
2025-09-29 16:17:03,679 Stage: Train 0.5 | Epoch: 278 | Iter: 371600 | Total Loss: 0.002413 | Recon Loss: 0.002040 | Commit Loss: 0.000745 | Perplexity: 2510.412997
2025-09-29 16:21:22,654 Stage: Train 0.5 | Epoch: 278 | Iter: 371800 | Total Loss: 0.002470 | Recon Loss: 0.002096 | Commit Loss: 0.000748 | Perplexity: 2507.727235
2025-09-29 16:25:41,821 Stage: Train 0.5 | Epoch: 278 | Iter: 372000 | Total Loss: 0.002461 | Recon Loss: 0.002087 | Commit Loss: 0.000748 | Perplexity: 2505.349744
Trainning Epoch:  74%|███████▍  | 490/658 [75:13:21<46:04:10, 987.21s/it]Trainning Epoch:  74%|███████▍  | 490/658 [75:13:21<46:04:10, 987.21s/it]2025-09-29 16:29:58,109 Stage: Train 0.5 | Epoch: 279 | Iter: 372200 | Total Loss: 0.002450 | Recon Loss: 0.002084 | Commit Loss: 0.000732 | Perplexity: 2505.608885
2025-09-29 16:34:09,271 Stage: Train 0.5 | Epoch: 279 | Iter: 372400 | Total Loss: 0.002474 | Recon Loss: 0.002100 | Commit Loss: 0.000748 | Perplexity: 2511.528109
2025-09-29 16:38:22,187 Stage: Train 0.5 | Epoch: 279 | Iter: 372600 | Total Loss: 0.002444 | Recon Loss: 0.002072 | Commit Loss: 0.000743 | Perplexity: 2508.617883
2025-09-29 16:42:35,600 Stage: Train 0.5 | Epoch: 279 | Iter: 372800 | Total Loss: 0.002458 | Recon Loss: 0.002087 | Commit Loss: 0.000741 | Perplexity: 2505.941665
Trainning Epoch:  75%|███████▍  | 491/658 [75:29:23<45:26:49, 979.70s/it]Trainning Epoch:  75%|███████▍  | 491/658 [75:29:23<45:26:49, 979.70s/it]2025-09-29 16:46:53,811 Stage: Train 0.5 | Epoch: 280 | Iter: 373000 | Total Loss: 0.002469 | Recon Loss: 0.002100 | Commit Loss: 0.000739 | Perplexity: 2507.857158
2025-09-29 16:51:10,049 Stage: Train 0.5 | Epoch: 280 | Iter: 373200 | Total Loss: 0.002435 | Recon Loss: 0.002061 | Commit Loss: 0.000747 | Perplexity: 2508.534291
2025-09-29 16:55:26,562 Stage: Train 0.5 | Epoch: 280 | Iter: 373400 | Total Loss: 0.002448 | Recon Loss: 0.002074 | Commit Loss: 0.000748 | Perplexity: 2510.920409
Trainning Epoch:  75%|███████▍  | 492/658 [75:45:39<45:07:15, 978.52s/it]Trainning Epoch:  75%|███████▍  | 492/658 [75:45:39<45:07:15, 978.53s/it]2025-09-29 16:59:46,697 Stage: Train 0.5 | Epoch: 281 | Iter: 373600 | Total Loss: 0.002424 | Recon Loss: 0.002053 | Commit Loss: 0.000741 | Perplexity: 2509.352455
2025-09-29 17:04:03,653 Stage: Train 0.5 | Epoch: 281 | Iter: 373800 | Total Loss: 0.002428 | Recon Loss: 0.002063 | Commit Loss: 0.000730 | Perplexity: 2507.866230
2025-09-29 17:08:21,059 Stage: Train 0.5 | Epoch: 281 | Iter: 374000 | Total Loss: 0.002450 | Recon Loss: 0.002075 | Commit Loss: 0.000750 | Perplexity: 2512.572402
2025-09-29 17:12:40,010 Stage: Train 0.5 | Epoch: 281 | Iter: 374200 | Total Loss: 0.002445 | Recon Loss: 0.002070 | Commit Loss: 0.000750 | Perplexity: 2505.428684
Trainning Epoch:  75%|███████▍  | 493/658 [76:02:02<44:54:56, 979.98s/it]Trainning Epoch:  75%|███████▍  | 493/658 [76:02:02<44:54:57, 979.98s/it]2025-09-29 17:17:01,585 Stage: Train 0.5 | Epoch: 282 | Iter: 374400 | Total Loss: 0.002472 | Recon Loss: 0.002097 | Commit Loss: 0.000751 | Perplexity: 2510.180345
2025-09-29 17:21:18,347 Stage: Train 0.5 | Epoch: 282 | Iter: 374600 | Total Loss: 0.002474 | Recon Loss: 0.002102 | Commit Loss: 0.000742 | Perplexity: 2504.768899
2025-09-29 17:25:35,838 Stage: Train 0.5 | Epoch: 282 | Iter: 374800 | Total Loss: 0.002468 | Recon Loss: 0.002099 | Commit Loss: 0.000738 | Perplexity: 2510.801669
2025-09-29 17:29:54,254 Stage: Train 0.5 | Epoch: 282 | Iter: 375000 | Total Loss: 0.002448 | Recon Loss: 0.002073 | Commit Loss: 0.000751 | Perplexity: 2505.713740
Trainning Epoch:  75%|███████▌  | 494/658 [76:18:24<44:40:42, 980.75s/it]Trainning Epoch:  75%|███████▌  | 494/658 [76:18:24<44:40:42, 980.75s/it]2025-09-29 17:34:12,361 Stage: Train 0.5 | Epoch: 283 | Iter: 375200 | Total Loss: 0.002441 | Recon Loss: 0.002073 | Commit Loss: 0.000737 | Perplexity: 2504.524569
2025-09-29 17:38:25,443 Stage: Train 0.5 | Epoch: 283 | Iter: 375400 | Total Loss: 0.002445 | Recon Loss: 0.002076 | Commit Loss: 0.000739 | Perplexity: 2511.963640
2025-09-29 17:42:38,672 Stage: Train 0.5 | Epoch: 283 | Iter: 375600 | Total Loss: 0.002456 | Recon Loss: 0.002085 | Commit Loss: 0.000743 | Perplexity: 2512.512045
2025-09-29 17:46:52,278 Stage: Train 0.5 | Epoch: 283 | Iter: 375800 | Total Loss: 0.002456 | Recon Loss: 0.002080 | Commit Loss: 0.000751 | Perplexity: 2508.788058
Trainning Epoch:  75%|███████▌  | 495/658 [76:34:30<44:12:02, 976.21s/it]Trainning Epoch:  75%|███████▌  | 495/658 [76:34:30<44:12:02, 976.21s/it]2025-09-29 17:51:09,758 Stage: Train 0.5 | Epoch: 284 | Iter: 376000 | Total Loss: 0.002439 | Recon Loss: 0.002064 | Commit Loss: 0.000751 | Perplexity: 2510.437222
2025-09-29 17:55:25,373 Stage: Train 0.5 | Epoch: 284 | Iter: 376200 | Total Loss: 0.002453 | Recon Loss: 0.002083 | Commit Loss: 0.000739 | Perplexity: 2509.014930
2025-09-29 17:59:41,201 Stage: Train 0.5 | Epoch: 284 | Iter: 376400 | Total Loss: 0.002450 | Recon Loss: 0.002079 | Commit Loss: 0.000742 | Perplexity: 2504.694948
2025-09-29 18:03:56,367 Stage: Train 0.5 | Epoch: 284 | Iter: 376600 | Total Loss: 0.002431 | Recon Loss: 0.002063 | Commit Loss: 0.000736 | Perplexity: 2508.528170
Trainning Epoch:  75%|███████▌  | 496/658 [76:50:44<43:53:32, 975.39s/it]Trainning Epoch:  75%|███████▌  | 496/658 [76:50:44<43:53:33, 975.39s/it]2025-09-29 18:08:16,578 Stage: Train 0.5 | Epoch: 285 | Iter: 376800 | Total Loss: 0.002453 | Recon Loss: 0.002077 | Commit Loss: 0.000752 | Perplexity: 2511.735035
2025-09-29 18:12:36,134 Stage: Train 0.5 | Epoch: 285 | Iter: 377000 | Total Loss: 0.002454 | Recon Loss: 0.002091 | Commit Loss: 0.000727 | Perplexity: 2505.943042
2025-09-29 18:16:55,871 Stage: Train 0.5 | Epoch: 285 | Iter: 377200 | Total Loss: 0.002460 | Recon Loss: 0.002083 | Commit Loss: 0.000753 | Perplexity: 2511.485753
Trainning Epoch:  76%|███████▌  | 497/658 [77:07:10<43:46:20, 978.76s/it]Trainning Epoch:  76%|███████▌  | 497/658 [77:07:10<43:46:20, 978.76s/it]2025-09-29 18:21:19,781 Stage: Train 0.5 | Epoch: 286 | Iter: 377400 | Total Loss: 0.002447 | Recon Loss: 0.002075 | Commit Loss: 0.000744 | Perplexity: 2510.229543
2025-09-29 18:25:39,058 Stage: Train 0.5 | Epoch: 286 | Iter: 377600 | Total Loss: 0.002446 | Recon Loss: 0.002075 | Commit Loss: 0.000741 | Perplexity: 2510.680994
2025-09-29 18:29:58,722 Stage: Train 0.5 | Epoch: 286 | Iter: 377800 | Total Loss: 0.002449 | Recon Loss: 0.002073 | Commit Loss: 0.000751 | Perplexity: 2507.720995
2025-09-29 18:34:18,415 Stage: Train 0.5 | Epoch: 286 | Iter: 378000 | Total Loss: 0.002456 | Recon Loss: 0.002082 | Commit Loss: 0.000748 | Perplexity: 2503.314127
Trainning Epoch:  76%|███████▌  | 498/658 [77:23:41<43:39:31, 982.32s/it]Trainning Epoch:  76%|███████▌  | 498/658 [77:23:41<43:39:31, 982.32s/it]2025-09-29 18:38:42,234 Stage: Train 0.5 | Epoch: 287 | Iter: 378200 | Total Loss: 0.002437 | Recon Loss: 0.002062 | Commit Loss: 0.000750 | Perplexity: 2507.380018
2025-09-29 18:43:01,727 Stage: Train 0.5 | Epoch: 287 | Iter: 378400 | Total Loss: 0.002441 | Recon Loss: 0.002066 | Commit Loss: 0.000749 | Perplexity: 2508.590476
2025-09-29 18:47:22,132 Stage: Train 0.5 | Epoch: 287 | Iter: 378600 | Total Loss: 0.002456 | Recon Loss: 0.002091 | Commit Loss: 0.000731 | Perplexity: 2500.196692
2025-09-29 18:51:41,829 Stage: Train 0.5 | Epoch: 287 | Iter: 378800 | Total Loss: 0.002453 | Recon Loss: 0.002073 | Commit Loss: 0.000759 | Perplexity: 2510.717122
Trainning Epoch:  76%|███████▌  | 499/658 [77:40:13<43:30:41, 985.17s/it]Trainning Epoch:  76%|███████▌  | 499/658 [77:40:13<43:30:41, 985.17s/it]2025-09-29 18:56:04,309 Stage: Train 0.5 | Epoch: 288 | Iter: 379000 | Total Loss: 0.002457 | Recon Loss: 0.002085 | Commit Loss: 0.000744 | Perplexity: 2507.596873
2025-09-29 19:00:22,796 Stage: Train 0.5 | Epoch: 288 | Iter: 379200 | Total Loss: 0.002449 | Recon Loss: 0.002078 | Commit Loss: 0.000741 | Perplexity: 2503.715189
2025-09-29 19:04:41,288 Stage: Train 0.5 | Epoch: 288 | Iter: 379400 | Total Loss: 0.002431 | Recon Loss: 0.002061 | Commit Loss: 0.000741 | Perplexity: 2505.255413
2025-09-29 19:08:59,952 Stage: Train 0.5 | Epoch: 288 | Iter: 379600 | Total Loss: 0.002456 | Recon Loss: 0.002090 | Commit Loss: 0.000733 | Perplexity: 2503.768989
Trainning Epoch:  76%|███████▌  | 500/658 [77:56:39<43:14:52, 985.39s/it]Trainning Epoch:  76%|███████▌  | 500/658 [77:56:39<43:14:52, 985.39s/it]2025-09-29 19:13:21,194 Stage: Train 0.5 | Epoch: 289 | Iter: 379800 | Total Loss: 0.002416 | Recon Loss: 0.002048 | Commit Loss: 0.000735 | Perplexity: 2502.250109
2025-09-29 19:17:39,921 Stage: Train 0.5 | Epoch: 289 | Iter: 380000 | Total Loss: 0.002420 | Recon Loss: 0.002046 | Commit Loss: 0.000748 | Perplexity: 2500.995164
2025-09-29 19:17:39,922 Saving model at iteration 380000
2025-09-29 19:17:40,086 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_290_step_380000
2025-09-29 19:17:40,586 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_290_step_380000/model.safetensors
2025-09-29 19:17:41,000 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_290_step_380000/optimizer.bin
2025-09-29 19:17:41,000 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_290_step_380000/scheduler.bin
2025-09-29 19:17:41,001 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_290_step_380000/sampler.bin
2025-09-29 19:17:41,002 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_290_step_380000/random_states_0.pkl
2025-09-29 19:21:59,973 Stage: Train 0.5 | Epoch: 289 | Iter: 380200 | Total Loss: 0.002433 | Recon Loss: 0.002059 | Commit Loss: 0.000748 | Perplexity: 2508.475367
2025-09-29 19:26:18,841 Stage: Train 0.5 | Epoch: 289 | Iter: 380400 | Total Loss: 0.002457 | Recon Loss: 0.002083 | Commit Loss: 0.000748 | Perplexity: 2516.037502
Trainning Epoch:  76%|███████▌  | 501/658 [78:13:06<43:00:04, 986.02s/it]Trainning Epoch:  76%|███████▌  | 501/658 [78:13:06<43:00:05, 986.02s/it]2025-09-29 19:30:37,092 Stage: Train 0.5 | Epoch: 290 | Iter: 380600 | Total Loss: 0.002429 | Recon Loss: 0.002055 | Commit Loss: 0.000746 | Perplexity: 2504.940101
2025-09-29 19:34:51,474 Stage: Train 0.5 | Epoch: 290 | Iter: 380800 | Total Loss: 0.002444 | Recon Loss: 0.002076 | Commit Loss: 0.000736 | Perplexity: 2505.293286
2025-09-29 19:39:06,327 Stage: Train 0.5 | Epoch: 290 | Iter: 381000 | Total Loss: 0.002446 | Recon Loss: 0.002070 | Commit Loss: 0.000753 | Perplexity: 2506.084032
Trainning Epoch:  76%|███████▋  | 502/658 [78:29:17<42:31:41, 981.42s/it]Trainning Epoch:  76%|███████▋  | 502/658 [78:29:17<42:31:41, 981.42s/it]2025-09-29 19:43:25,371 Stage: Train 0.5 | Epoch: 291 | Iter: 381200 | Total Loss: 0.002466 | Recon Loss: 0.002098 | Commit Loss: 0.000736 | Perplexity: 2503.108920
2025-09-29 19:47:44,197 Stage: Train 0.5 | Epoch: 291 | Iter: 381400 | Total Loss: 0.002410 | Recon Loss: 0.002045 | Commit Loss: 0.000731 | Perplexity: 2503.160011
2025-09-29 19:52:02,737 Stage: Train 0.5 | Epoch: 291 | Iter: 381600 | Total Loss: 0.002444 | Recon Loss: 0.002072 | Commit Loss: 0.000744 | Perplexity: 2505.121223
2025-09-29 19:56:21,957 Stage: Train 0.5 | Epoch: 291 | Iter: 381800 | Total Loss: 0.002457 | Recon Loss: 0.002085 | Commit Loss: 0.000743 | Perplexity: 2506.180732
Trainning Epoch:  76%|███████▋  | 503/658 [78:45:44<42:20:07, 983.27s/it]Trainning Epoch:  76%|███████▋  | 503/658 [78:45:44<42:20:07, 983.27s/it]2025-09-29 20:00:41,858 Stage: Train 0.5 | Epoch: 292 | Iter: 382000 | Total Loss: 0.002416 | Recon Loss: 0.002049 | Commit Loss: 0.000735 | Perplexity: 2507.825170
2025-09-29 20:04:54,332 Stage: Train 0.5 | Epoch: 292 | Iter: 382200 | Total Loss: 0.002414 | Recon Loss: 0.002040 | Commit Loss: 0.000747 | Perplexity: 2508.193906
2025-09-29 20:09:07,973 Stage: Train 0.5 | Epoch: 292 | Iter: 382400 | Total Loss: 0.002467 | Recon Loss: 0.002098 | Commit Loss: 0.000740 | Perplexity: 2506.904945
2025-09-29 20:13:21,597 Stage: Train 0.5 | Epoch: 292 | Iter: 382600 | Total Loss: 0.002428 | Recon Loss: 0.002054 | Commit Loss: 0.000747 | Perplexity: 2503.461539
Trainning Epoch:  77%|███████▋  | 504/658 [79:01:50<41:50:16, 978.03s/it]Trainning Epoch:  77%|███████▋  | 504/658 [79:01:50<41:50:16, 978.03s/it]2025-09-29 20:17:42,315 Stage: Train 0.5 | Epoch: 293 | Iter: 382800 | Total Loss: 0.002456 | Recon Loss: 0.002085 | Commit Loss: 0.000741 | Perplexity: 2506.927251
2025-09-29 20:22:01,336 Stage: Train 0.5 | Epoch: 293 | Iter: 383000 | Total Loss: 0.002425 | Recon Loss: 0.002050 | Commit Loss: 0.000750 | Perplexity: 2503.002096
2025-09-29 20:26:19,599 Stage: Train 0.5 | Epoch: 293 | Iter: 383200 | Total Loss: 0.002454 | Recon Loss: 0.002082 | Commit Loss: 0.000743 | Perplexity: 2511.711477
2025-09-29 20:30:39,218 Stage: Train 0.5 | Epoch: 293 | Iter: 383400 | Total Loss: 0.002451 | Recon Loss: 0.002069 | Commit Loss: 0.000765 | Perplexity: 2511.905177
Trainning Epoch:  77%|███████▋  | 505/658 [79:18:18<41:41:24, 980.95s/it]Trainning Epoch:  77%|███████▋  | 505/658 [79:18:18<41:41:25, 980.95s/it]2025-09-29 20:35:00,048 Stage: Train 0.5 | Epoch: 294 | Iter: 383600 | Total Loss: 0.002455 | Recon Loss: 0.002087 | Commit Loss: 0.000736 | Perplexity: 2504.376023
2025-09-29 20:39:17,220 Stage: Train 0.5 | Epoch: 294 | Iter: 383800 | Total Loss: 0.002430 | Recon Loss: 0.002058 | Commit Loss: 0.000744 | Perplexity: 2501.964534
2025-09-29 20:43:35,847 Stage: Train 0.5 | Epoch: 294 | Iter: 384000 | Total Loss: 0.002436 | Recon Loss: 0.002061 | Commit Loss: 0.000750 | Perplexity: 2508.992201
2025-09-29 20:47:54,782 Stage: Train 0.5 | Epoch: 294 | Iter: 384200 | Total Loss: 0.002429 | Recon Loss: 0.002056 | Commit Loss: 0.000747 | Perplexity: 2505.878047
Trainning Epoch:  77%|███████▋  | 506/658 [79:34:42<41:27:26, 981.89s/it]Trainning Epoch:  77%|███████▋  | 506/658 [79:34:42<41:27:28, 981.90s/it]2025-09-29 20:52:17,202 Stage: Train 0.5 | Epoch: 295 | Iter: 384400 | Total Loss: 0.002404 | Recon Loss: 0.002040 | Commit Loss: 0.000730 | Perplexity: 2504.037278
2025-09-29 20:56:36,152 Stage: Train 0.5 | Epoch: 295 | Iter: 384600 | Total Loss: 0.002435 | Recon Loss: 0.002059 | Commit Loss: 0.000752 | Perplexity: 2512.257073
2025-09-29 21:00:55,723 Stage: Train 0.5 | Epoch: 295 | Iter: 384800 | Total Loss: 0.002442 | Recon Loss: 0.002068 | Commit Loss: 0.000748 | Perplexity: 2514.511193
Trainning Epoch:  77%|███████▋  | 507/658 [79:51:10<41:15:41, 983.72s/it]Trainning Epoch:  77%|███████▋  | 507/658 [79:51:10<41:15:42, 983.73s/it]2025-09-29 21:05:19,828 Stage: Train 0.5 | Epoch: 296 | Iter: 385000 | Total Loss: 0.002465 | Recon Loss: 0.002090 | Commit Loss: 0.000750 | Perplexity: 2506.547068
2025-09-29 21:09:39,014 Stage: Train 0.5 | Epoch: 296 | Iter: 385200 | Total Loss: 0.002424 | Recon Loss: 0.002048 | Commit Loss: 0.000752 | Perplexity: 2512.042230
2025-09-29 21:13:57,975 Stage: Train 0.5 | Epoch: 296 | Iter: 385400 | Total Loss: 0.002445 | Recon Loss: 0.002067 | Commit Loss: 0.000756 | Perplexity: 2505.209042
2025-09-29 21:18:17,976 Stage: Train 0.5 | Epoch: 296 | Iter: 385600 | Total Loss: 0.002427 | Recon Loss: 0.002057 | Commit Loss: 0.000740 | Perplexity: 2504.118950
Trainning Epoch:  77%|███████▋  | 508/658 [80:07:41<41:04:46, 985.91s/it]Trainning Epoch:  77%|███████▋  | 508/658 [80:07:41<41:04:47, 985.91s/it]2025-09-29 21:22:39,643 Stage: Train 0.5 | Epoch: 297 | Iter: 385800 | Total Loss: 0.002412 | Recon Loss: 0.002037 | Commit Loss: 0.000749 | Perplexity: 2505.793856
2025-09-29 21:26:55,536 Stage: Train 0.5 | Epoch: 297 | Iter: 386000 | Total Loss: 0.002444 | Recon Loss: 0.002068 | Commit Loss: 0.000752 | Perplexity: 2509.841256
2025-09-29 21:31:11,268 Stage: Train 0.5 | Epoch: 297 | Iter: 386200 | Total Loss: 0.002416 | Recon Loss: 0.002049 | Commit Loss: 0.000733 | Perplexity: 2505.191958
2025-09-29 21:35:27,514 Stage: Train 0.5 | Epoch: 297 | Iter: 386400 | Total Loss: 0.002416 | Recon Loss: 0.002046 | Commit Loss: 0.000741 | Perplexity: 2506.578569
Trainning Epoch:  77%|███████▋  | 509/658 [80:23:57<40:40:55, 982.92s/it]Trainning Epoch:  77%|███████▋  | 509/658 [80:23:57<40:40:55, 982.92s/it]2025-09-29 21:39:49,174 Stage: Train 0.5 | Epoch: 298 | Iter: 386600 | Total Loss: 0.002443 | Recon Loss: 0.002072 | Commit Loss: 0.000743 | Perplexity: 2509.095000
2025-09-29 21:44:09,333 Stage: Train 0.5 | Epoch: 298 | Iter: 386800 | Total Loss: 0.002417 | Recon Loss: 0.002045 | Commit Loss: 0.000746 | Perplexity: 2510.053989
2025-09-29 21:48:29,993 Stage: Train 0.5 | Epoch: 298 | Iter: 387000 | Total Loss: 0.002454 | Recon Loss: 0.002081 | Commit Loss: 0.000745 | Perplexity: 2511.189675
2025-09-29 21:52:50,446 Stage: Train 0.5 | Epoch: 298 | Iter: 387200 | Total Loss: 0.002437 | Recon Loss: 0.002065 | Commit Loss: 0.000744 | Perplexity: 2500.471631
Trainning Epoch:  78%|███████▊  | 510/658 [80:40:29<40:31:30, 985.75s/it]Trainning Epoch:  78%|███████▊  | 510/658 [80:40:29<40:31:30, 985.75s/it]2025-09-29 21:57:11,255 Stage: Train 0.5 | Epoch: 299 | Iter: 387400 | Total Loss: 0.002429 | Recon Loss: 0.002062 | Commit Loss: 0.000735 | Perplexity: 2510.596398
2025-09-29 22:01:28,355 Stage: Train 0.5 | Epoch: 299 | Iter: 387600 | Total Loss: 0.002453 | Recon Loss: 0.002080 | Commit Loss: 0.000746 | Perplexity: 2507.535967
2025-09-29 22:05:47,094 Stage: Train 0.5 | Epoch: 299 | Iter: 387800 | Total Loss: 0.002457 | Recon Loss: 0.002080 | Commit Loss: 0.000753 | Perplexity: 2503.628999
2025-09-29 22:10:05,357 Stage: Train 0.5 | Epoch: 299 | Iter: 388000 | Total Loss: 0.002431 | Recon Loss: 0.002056 | Commit Loss: 0.000749 | Perplexity: 2508.216796
Trainning Epoch:  78%|███████▊  | 511/658 [80:56:53<40:13:20, 985.04s/it]Trainning Epoch:  78%|███████▊  | 511/658 [80:56:53<40:13:20, 985.03s/it]2025-09-29 22:14:25,500 Stage: Train 0.5 | Epoch: 300 | Iter: 388200 | Total Loss: 0.002410 | Recon Loss: 0.002042 | Commit Loss: 0.000735 | Perplexity: 2512.483494
2025-09-29 22:18:41,558 Stage: Train 0.5 | Epoch: 300 | Iter: 388400 | Total Loss: 0.002437 | Recon Loss: 0.002059 | Commit Loss: 0.000755 | Perplexity: 2510.160585
2025-09-29 22:22:57,426 Stage: Train 0.5 | Epoch: 300 | Iter: 388600 | Total Loss: 0.002476 | Recon Loss: 0.002098 | Commit Loss: 0.000756 | Perplexity: 2507.634056
Trainning Epoch:  78%|███████▊  | 512/658 [81:13:09<39:50:47, 982.52s/it]Trainning Epoch:  78%|███████▊  | 512/658 [81:13:09<39:50:47, 982.52s/it]2025-09-29 22:27:18,293 Stage: Train 0.5 | Epoch: 301 | Iter: 388800 | Total Loss: 0.002437 | Recon Loss: 0.002062 | Commit Loss: 0.000749 | Perplexity: 2506.298815
2025-09-29 22:31:36,470 Stage: Train 0.5 | Epoch: 301 | Iter: 389000 | Total Loss: 0.002437 | Recon Loss: 0.002063 | Commit Loss: 0.000748 | Perplexity: 2505.052069
2025-09-29 22:35:54,925 Stage: Train 0.5 | Epoch: 301 | Iter: 389200 | Total Loss: 0.002439 | Recon Loss: 0.002067 | Commit Loss: 0.000744 | Perplexity: 2511.463076
2025-09-29 22:40:14,129 Stage: Train 0.5 | Epoch: 301 | Iter: 389400 | Total Loss: 0.002428 | Recon Loss: 0.002053 | Commit Loss: 0.000749 | Perplexity: 2512.009342
Trainning Epoch:  78%|███████▊  | 513/658 [81:29:36<39:37:37, 983.85s/it]Trainning Epoch:  78%|███████▊  | 513/658 [81:29:36<39:37:37, 983.85s/it]2025-09-29 22:44:38,048 Stage: Train 0.5 | Epoch: 302 | Iter: 389600 | Total Loss: 0.002446 | Recon Loss: 0.002071 | Commit Loss: 0.000748 | Perplexity: 2510.883807
2025-09-29 22:48:58,697 Stage: Train 0.5 | Epoch: 302 | Iter: 389800 | Total Loss: 0.002424 | Recon Loss: 0.002056 | Commit Loss: 0.000737 | Perplexity: 2504.044371
2025-09-29 22:53:19,794 Stage: Train 0.5 | Epoch: 302 | Iter: 390000 | Total Loss: 0.002437 | Recon Loss: 0.002060 | Commit Loss: 0.000754 | Perplexity: 2506.504088
2025-09-29 22:57:40,895 Stage: Train 0.5 | Epoch: 302 | Iter: 390200 | Total Loss: 0.002431 | Recon Loss: 0.002054 | Commit Loss: 0.000754 | Perplexity: 2504.387267
Trainning Epoch:  78%|███████▊  | 514/658 [81:46:12<39:29:42, 987.38s/it]Trainning Epoch:  78%|███████▊  | 514/658 [81:46:12<39:29:42, 987.38s/it]2025-09-29 23:02:03,167 Stage: Train 0.5 | Epoch: 303 | Iter: 390400 | Total Loss: 0.002447 | Recon Loss: 0.002075 | Commit Loss: 0.000743 | Perplexity: 2507.713959
2025-09-29 23:06:20,622 Stage: Train 0.5 | Epoch: 303 | Iter: 390600 | Total Loss: 0.002426 | Recon Loss: 0.002052 | Commit Loss: 0.000749 | Perplexity: 2510.375234
2025-09-29 23:10:38,426 Stage: Train 0.5 | Epoch: 303 | Iter: 390800 | Total Loss: 0.002453 | Recon Loss: 0.002080 | Commit Loss: 0.000746 | Perplexity: 2503.979613
2025-09-29 23:14:55,936 Stage: Train 0.5 | Epoch: 303 | Iter: 391000 | Total Loss: 0.002427 | Recon Loss: 0.002054 | Commit Loss: 0.000746 | Perplexity: 2508.639388
Trainning Epoch:  78%|███████▊  | 515/658 [82:02:34<39:09:36, 985.85s/it]Trainning Epoch:  78%|███████▊  | 515/658 [82:02:34<39:09:36, 985.85s/it]2025-09-29 23:19:17,546 Stage: Train 0.5 | Epoch: 304 | Iter: 391200 | Total Loss: 0.002431 | Recon Loss: 0.002058 | Commit Loss: 0.000746 | Perplexity: 2505.257620
2025-09-29 23:23:36,307 Stage: Train 0.5 | Epoch: 304 | Iter: 391400 | Total Loss: 0.002427 | Recon Loss: 0.002051 | Commit Loss: 0.000752 | Perplexity: 2506.680344
2025-09-29 23:27:55,224 Stage: Train 0.5 | Epoch: 304 | Iter: 391600 | Total Loss: 0.002443 | Recon Loss: 0.002064 | Commit Loss: 0.000758 | Perplexity: 2510.781445
2025-09-29 23:32:13,695 Stage: Train 0.5 | Epoch: 304 | Iter: 391800 | Total Loss: 0.002438 | Recon Loss: 0.002064 | Commit Loss: 0.000749 | Perplexity: 2502.945155
Trainning Epoch:  78%|███████▊  | 516/658 [82:19:01<38:53:49, 986.12s/it]Trainning Epoch:  78%|███████▊  | 516/658 [82:19:01<38:53:49, 986.12s/it]2025-09-29 23:36:35,866 Stage: Train 0.5 | Epoch: 305 | Iter: 392000 | Total Loss: 0.002426 | Recon Loss: 0.002054 | Commit Loss: 0.000744 | Perplexity: 2509.401064
2025-09-29 23:40:53,979 Stage: Train 0.5 | Epoch: 305 | Iter: 392200 | Total Loss: 0.002403 | Recon Loss: 0.002029 | Commit Loss: 0.000748 | Perplexity: 2507.938262
2025-09-29 23:45:12,287 Stage: Train 0.5 | Epoch: 305 | Iter: 392400 | Total Loss: 0.002440 | Recon Loss: 0.002067 | Commit Loss: 0.000745 | Perplexity: 2506.106331
Trainning Epoch:  79%|███████▊  | 517/658 [82:35:26<38:36:24, 985.70s/it]Trainning Epoch:  79%|███████▊  | 517/658 [82:35:26<38:36:24, 985.71s/it]2025-09-29 23:49:35,109 Stage: Train 0.5 | Epoch: 306 | Iter: 392600 | Total Loss: 0.002441 | Recon Loss: 0.002065 | Commit Loss: 0.000752 | Perplexity: 2501.296643
2025-09-29 23:53:54,685 Stage: Train 0.5 | Epoch: 306 | Iter: 392800 | Total Loss: 0.002421 | Recon Loss: 0.002050 | Commit Loss: 0.000742 | Perplexity: 2506.418357
2025-09-29 23:58:13,840 Stage: Train 0.5 | Epoch: 306 | Iter: 393000 | Total Loss: 0.002406 | Recon Loss: 0.002029 | Commit Loss: 0.000753 | Perplexity: 2507.213948
2025-09-30 00:02:33,568 Stage: Train 0.5 | Epoch: 306 | Iter: 393200 | Total Loss: 0.002454 | Recon Loss: 0.002078 | Commit Loss: 0.000754 | Perplexity: 2505.618287
Trainning Epoch:  79%|███████▊  | 518/658 [82:51:56<38:23:11, 987.08s/it]Trainning Epoch:  79%|███████▊  | 518/658 [82:51:56<38:23:11, 987.08s/it]2025-09-30 00:06:55,922 Stage: Train 0.5 | Epoch: 307 | Iter: 393400 | Total Loss: 0.002417 | Recon Loss: 0.002047 | Commit Loss: 0.000738 | Perplexity: 2506.142726
2025-09-30 00:11:13,922 Stage: Train 0.5 | Epoch: 307 | Iter: 393600 | Total Loss: 0.002411 | Recon Loss: 0.002038 | Commit Loss: 0.000746 | Perplexity: 2505.175446
2025-09-30 00:15:32,410 Stage: Train 0.5 | Epoch: 307 | Iter: 393800 | Total Loss: 0.002436 | Recon Loss: 0.002066 | Commit Loss: 0.000742 | Perplexity: 2507.273153
2025-09-30 00:19:51,335 Stage: Train 0.5 | Epoch: 307 | Iter: 394000 | Total Loss: 0.002443 | Recon Loss: 0.002072 | Commit Loss: 0.000743 | Perplexity: 2503.589429
Trainning Epoch:  79%|███████▉  | 519/658 [83:08:22<38:05:54, 986.73s/it]Trainning Epoch:  79%|███████▉  | 519/658 [83:08:22<38:05:55, 986.73s/it]2025-09-30 00:24:10,661 Stage: Train 0.5 | Epoch: 308 | Iter: 394200 | Total Loss: 0.002395 | Recon Loss: 0.002024 | Commit Loss: 0.000740 | Perplexity: 2504.436576
2025-09-30 00:28:26,435 Stage: Train 0.5 | Epoch: 308 | Iter: 394400 | Total Loss: 0.002405 | Recon Loss: 0.002030 | Commit Loss: 0.000751 | Perplexity: 2506.790747
2025-09-30 00:32:43,756 Stage: Train 0.5 | Epoch: 308 | Iter: 394600 | Total Loss: 0.002452 | Recon Loss: 0.002075 | Commit Loss: 0.000754 | Perplexity: 2507.100144
2025-09-30 00:37:01,490 Stage: Train 0.5 | Epoch: 308 | Iter: 394800 | Total Loss: 0.002445 | Recon Loss: 0.002072 | Commit Loss: 0.000746 | Perplexity: 2508.759121
Trainning Epoch:  79%|███████▉  | 520/658 [83:24:40<37:43:32, 984.15s/it]Trainning Epoch:  79%|███████▉  | 520/658 [83:24:40<37:43:32, 984.15s/it]2025-09-30 00:41:23,756 Stage: Train 0.5 | Epoch: 309 | Iter: 395000 | Total Loss: 0.002382 | Recon Loss: 0.002009 | Commit Loss: 0.000746 | Perplexity: 2508.778900
2025-09-30 00:45:42,657 Stage: Train 0.5 | Epoch: 309 | Iter: 395200 | Total Loss: 0.002427 | Recon Loss: 0.002050 | Commit Loss: 0.000754 | Perplexity: 2505.305470
2025-09-30 00:50:00,952 Stage: Train 0.5 | Epoch: 309 | Iter: 395400 | Total Loss: 0.002431 | Recon Loss: 0.002055 | Commit Loss: 0.000753 | Perplexity: 2511.058864
2025-09-30 00:54:18,273 Stage: Train 0.5 | Epoch: 309 | Iter: 395600 | Total Loss: 0.002449 | Recon Loss: 0.002076 | Commit Loss: 0.000747 | Perplexity: 2506.368442
Trainning Epoch:  79%|███████▉  | 521/658 [83:41:05<37:28:04, 984.56s/it]Trainning Epoch:  79%|███████▉  | 521/658 [83:41:05<37:28:04, 984.56s/it]2025-09-30 00:58:39,525 Stage: Train 0.5 | Epoch: 310 | Iter: 395800 | Total Loss: 0.002413 | Recon Loss: 0.002042 | Commit Loss: 0.000742 | Perplexity: 2509.170117
2025-09-30 01:02:56,522 Stage: Train 0.5 | Epoch: 310 | Iter: 396000 | Total Loss: 0.002410 | Recon Loss: 0.002039 | Commit Loss: 0.000742 | Perplexity: 2506.356980
2025-09-30 01:07:14,019 Stage: Train 0.5 | Epoch: 310 | Iter: 396200 | Total Loss: 0.002431 | Recon Loss: 0.002054 | Commit Loss: 0.000754 | Perplexity: 2508.877897
Trainning Epoch:  79%|███████▉  | 522/658 [83:57:28<37:10:09, 983.89s/it]Trainning Epoch:  79%|███████▉  | 522/658 [83:57:28<37:10:09, 983.90s/it]2025-09-30 01:11:36,379 Stage: Train 0.5 | Epoch: 311 | Iter: 396400 | Total Loss: 0.002416 | Recon Loss: 0.002044 | Commit Loss: 0.000743 | Perplexity: 2507.725380
2025-09-30 01:15:55,823 Stage: Train 0.5 | Epoch: 311 | Iter: 396600 | Total Loss: 0.002432 | Recon Loss: 0.002054 | Commit Loss: 0.000757 | Perplexity: 2509.553547
2025-09-30 01:20:14,769 Stage: Train 0.5 | Epoch: 311 | Iter: 396800 | Total Loss: 0.002423 | Recon Loss: 0.002049 | Commit Loss: 0.000747 | Perplexity: 2503.397472
2025-09-30 01:24:34,057 Stage: Train 0.5 | Epoch: 311 | Iter: 397000 | Total Loss: 0.002431 | Recon Loss: 0.002057 | Commit Loss: 0.000747 | Perplexity: 2509.141880
Trainning Epoch:  79%|███████▉  | 523/658 [84:13:57<36:57:14, 985.44s/it]Trainning Epoch:  79%|███████▉  | 523/658 [84:13:57<36:57:14, 985.44s/it]2025-09-30 01:28:57,638 Stage: Train 0.5 | Epoch: 312 | Iter: 397200 | Total Loss: 0.002442 | Recon Loss: 0.002064 | Commit Loss: 0.000755 | Perplexity: 2506.390558
2025-09-30 01:33:16,778 Stage: Train 0.5 | Epoch: 312 | Iter: 397400 | Total Loss: 0.002407 | Recon Loss: 0.002033 | Commit Loss: 0.000749 | Perplexity: 2507.403633
2025-09-30 01:37:36,707 Stage: Train 0.5 | Epoch: 312 | Iter: 397600 | Total Loss: 0.002424 | Recon Loss: 0.002050 | Commit Loss: 0.000747 | Perplexity: 2508.805515
2025-09-30 01:41:56,684 Stage: Train 0.5 | Epoch: 312 | Iter: 397800 | Total Loss: 0.002425 | Recon Loss: 0.002053 | Commit Loss: 0.000744 | Perplexity: 2507.571200
Trainning Epoch:  80%|███████▉  | 524/658 [84:30:28<36:44:25, 987.05s/it]Trainning Epoch:  80%|███████▉  | 524/658 [84:30:28<36:44:25, 987.05s/it]2025-09-30 01:46:17,648 Stage: Train 0.5 | Epoch: 313 | Iter: 398000 | Total Loss: 0.002421 | Recon Loss: 0.002047 | Commit Loss: 0.000747 | Perplexity: 2506.903363
2025-09-30 01:50:33,806 Stage: Train 0.5 | Epoch: 313 | Iter: 398200 | Total Loss: 0.002444 | Recon Loss: 0.002073 | Commit Loss: 0.000744 | Perplexity: 2509.837673
2025-09-30 01:54:50,180 Stage: Train 0.5 | Epoch: 313 | Iter: 398400 | Total Loss: 0.002434 | Recon Loss: 0.002059 | Commit Loss: 0.000750 | Perplexity: 2502.335103
2025-09-30 01:59:07,659 Stage: Train 0.5 | Epoch: 313 | Iter: 398600 | Total Loss: 0.002446 | Recon Loss: 0.002071 | Commit Loss: 0.000749 | Perplexity: 2508.837208
Trainning Epoch:  80%|███████▉  | 525/658 [84:46:46<36:22:08, 984.43s/it]Trainning Epoch:  80%|███████▉  | 525/658 [84:46:46<36:22:09, 984.43s/it]2025-09-30 02:03:26,653 Stage: Train 0.5 | Epoch: 314 | Iter: 398800 | Total Loss: 0.002418 | Recon Loss: 0.002045 | Commit Loss: 0.000745 | Perplexity: 2511.052426
2025-09-30 02:07:42,796 Stage: Train 0.5 | Epoch: 314 | Iter: 399000 | Total Loss: 0.002441 | Recon Loss: 0.002064 | Commit Loss: 0.000753 | Perplexity: 2505.378497
2025-09-30 02:11:59,142 Stage: Train 0.5 | Epoch: 314 | Iter: 399200 | Total Loss: 0.002389 | Recon Loss: 0.002015 | Commit Loss: 0.000748 | Perplexity: 2501.806619
2025-09-30 02:16:15,831 Stage: Train 0.5 | Epoch: 314 | Iter: 399400 | Total Loss: 0.002434 | Recon Loss: 0.002053 | Commit Loss: 0.000764 | Perplexity: 2510.276527
Trainning Epoch:  80%|███████▉  | 526/658 [85:03:03<36:00:51, 982.21s/it]Trainning Epoch:  80%|███████▉  | 526/658 [85:03:03<36:00:52, 982.21s/it]2025-09-30 02:20:40,249 Stage: Train 0.5 | Epoch: 315 | Iter: 399600 | Total Loss: 0.002428 | Recon Loss: 0.002053 | Commit Loss: 0.000750 | Perplexity: 2507.197738
2025-09-30 02:25:00,417 Stage: Train 0.5 | Epoch: 315 | Iter: 399800 | Total Loss: 0.002418 | Recon Loss: 0.002041 | Commit Loss: 0.000754 | Perplexity: 2505.196000
2025-09-30 02:29:20,623 Stage: Train 0.5 | Epoch: 315 | Iter: 400000 | Total Loss: 0.002455 | Recon Loss: 0.002072 | Commit Loss: 0.000765 | Perplexity: 2516.853936
2025-09-30 02:29:20,623 Saving model at iteration 400000
2025-09-30 02:29:21,180 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_316_step_400000
2025-09-30 02:29:21,700 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_316_step_400000/model.safetensors
2025-09-30 02:29:22,109 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_316_step_400000/optimizer.bin
2025-09-30 02:29:22,110 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_316_step_400000/scheduler.bin
2025-09-30 02:29:22,110 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_316_step_400000/sampler.bin
2025-09-30 02:29:22,111 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_316_step_400000/random_states_0.pkl
Trainning Epoch:  80%|████████  | 527/658 [85:19:36<35:51:53, 985.60s/it]Trainning Epoch:  80%|████████  | 527/658 [85:19:36<35:51:53, 985.60s/it]2025-09-30 02:33:44,765 Stage: Train 0.5 | Epoch: 316 | Iter: 400200 | Total Loss: 0.002446 | Recon Loss: 0.002070 | Commit Loss: 0.000752 | Perplexity: 2505.746683
2025-09-30 02:38:01,990 Stage: Train 0.5 | Epoch: 316 | Iter: 400400 | Total Loss: 0.002436 | Recon Loss: 0.002063 | Commit Loss: 0.000746 | Perplexity: 2507.607290
2025-09-30 02:42:19,679 Stage: Train 0.5 | Epoch: 316 | Iter: 400600 | Total Loss: 0.002401 | Recon Loss: 0.002026 | Commit Loss: 0.000749 | Perplexity: 2506.471295
2025-09-30 02:46:37,761 Stage: Train 0.5 | Epoch: 316 | Iter: 400800 | Total Loss: 0.002407 | Recon Loss: 0.002035 | Commit Loss: 0.000745 | Perplexity: 2511.737716
Trainning Epoch:  80%|████████  | 528/658 [85:36:00<35:33:59, 984.92s/it]Trainning Epoch:  80%|████████  | 528/658 [85:36:00<35:34:00, 984.92s/it]2025-09-30 02:51:00,249 Stage: Train 0.5 | Epoch: 317 | Iter: 401000 | Total Loss: 0.002408 | Recon Loss: 0.002032 | Commit Loss: 0.000752 | Perplexity: 2502.323727
2025-09-30 02:55:19,057 Stage: Train 0.5 | Epoch: 317 | Iter: 401200 | Total Loss: 0.002444 | Recon Loss: 0.002065 | Commit Loss: 0.000759 | Perplexity: 2501.031560
2025-09-30 02:59:38,461 Stage: Train 0.5 | Epoch: 317 | Iter: 401400 | Total Loss: 0.002379 | Recon Loss: 0.002003 | Commit Loss: 0.000753 | Perplexity: 2504.657937
2025-09-30 03:03:56,886 Stage: Train 0.5 | Epoch: 317 | Iter: 401600 | Total Loss: 0.002426 | Recon Loss: 0.002041 | Commit Loss: 0.000770 | Perplexity: 2505.289150
Trainning Epoch:  80%|████████  | 529/658 [85:52:27<35:18:59, 985.58s/it]Trainning Epoch:  80%|████████  | 529/658 [85:52:27<35:18:59, 985.58s/it]2025-09-30 03:08:20,061 Stage: Train 0.5 | Epoch: 318 | Iter: 401800 | Total Loss: 0.002464 | Recon Loss: 0.002087 | Commit Loss: 0.000754 | Perplexity: 2514.285948
2025-09-30 03:12:39,868 Stage: Train 0.5 | Epoch: 318 | Iter: 402000 | Total Loss: 0.002453 | Recon Loss: 0.002080 | Commit Loss: 0.000746 | Perplexity: 2509.019723
2025-09-30 03:16:59,882 Stage: Train 0.5 | Epoch: 318 | Iter: 402200 | Total Loss: 0.002408 | Recon Loss: 0.002036 | Commit Loss: 0.000743 | Perplexity: 2503.768713
2025-09-30 03:21:19,712 Stage: Train 0.5 | Epoch: 318 | Iter: 402400 | Total Loss: 0.002430 | Recon Loss: 0.002053 | Commit Loss: 0.000753 | Perplexity: 2508.298641
Trainning Epoch:  81%|████████  | 530/658 [86:08:59<35:06:25, 987.39s/it]Trainning Epoch:  81%|████████  | 530/658 [86:08:59<35:06:25, 987.39s/it]2025-09-30 03:25:41,171 Stage: Train 0.5 | Epoch: 319 | Iter: 402600 | Total Loss: 0.002416 | Recon Loss: 0.002039 | Commit Loss: 0.000754 | Perplexity: 2506.723057
2025-09-30 03:30:00,460 Stage: Train 0.5 | Epoch: 319 | Iter: 402800 | Total Loss: 0.002430 | Recon Loss: 0.002054 | Commit Loss: 0.000753 | Perplexity: 2504.013331
2025-09-30 03:34:20,361 Stage: Train 0.5 | Epoch: 319 | Iter: 403000 | Total Loss: 0.002429 | Recon Loss: 0.002049 | Commit Loss: 0.000759 | Perplexity: 2507.072817
2025-09-30 03:38:40,139 Stage: Train 0.5 | Epoch: 319 | Iter: 403200 | Total Loss: 0.002408 | Recon Loss: 0.002037 | Commit Loss: 0.000742 | Perplexity: 2508.005682
Trainning Epoch:  81%|████████  | 531/658 [86:25:27<34:50:50, 987.80s/it]Trainning Epoch:  81%|████████  | 531/658 [86:25:27<34:50:50, 987.80s/it]2025-09-30 03:43:02,234 Stage: Train 0.5 | Epoch: 320 | Iter: 403400 | Total Loss: 0.002416 | Recon Loss: 0.002040 | Commit Loss: 0.000751 | Perplexity: 2506.134370
2025-09-30 03:47:19,731 Stage: Train 0.5 | Epoch: 320 | Iter: 403600 | Total Loss: 0.002400 | Recon Loss: 0.002021 | Commit Loss: 0.000757 | Perplexity: 2508.982186
2025-09-30 03:51:37,662 Stage: Train 0.5 | Epoch: 320 | Iter: 403800 | Total Loss: 0.002433 | Recon Loss: 0.002053 | Commit Loss: 0.000759 | Perplexity: 2503.984784
Trainning Epoch:  81%|████████  | 532/658 [86:41:51<34:31:49, 986.58s/it]Trainning Epoch:  81%|████████  | 532/658 [86:41:51<34:31:50, 986.59s/it]2025-09-30 03:56:00,081 Stage: Train 0.5 | Epoch: 321 | Iter: 404000 | Total Loss: 0.002418 | Recon Loss: 0.002037 | Commit Loss: 0.000763 | Perplexity: 2508.176049
2025-09-30 04:00:19,265 Stage: Train 0.5 | Epoch: 321 | Iter: 404200 | Total Loss: 0.002408 | Recon Loss: 0.002037 | Commit Loss: 0.000742 | Perplexity: 2503.865101
2025-09-30 04:04:39,026 Stage: Train 0.5 | Epoch: 321 | Iter: 404400 | Total Loss: 0.002399 | Recon Loss: 0.002028 | Commit Loss: 0.000743 | Perplexity: 2503.214413
2025-09-30 04:08:58,727 Stage: Train 0.5 | Epoch: 321 | Iter: 404600 | Total Loss: 0.002440 | Recon Loss: 0.002058 | Commit Loss: 0.000765 | Perplexity: 2506.474707
Trainning Epoch:  81%|████████  | 533/658 [86:58:22<34:18:04, 987.87s/it]Trainning Epoch:  81%|████████  | 533/658 [86:58:22<34:18:03, 987.87s/it]2025-09-30 04:13:20,179 Stage: Train 0.5 | Epoch: 322 | Iter: 404800 | Total Loss: 0.002409 | Recon Loss: 0.002030 | Commit Loss: 0.000759 | Perplexity: 2506.415270
2025-09-30 04:17:36,261 Stage: Train 0.5 | Epoch: 322 | Iter: 405000 | Total Loss: 0.002426 | Recon Loss: 0.002052 | Commit Loss: 0.000748 | Perplexity: 2498.752323
2025-09-30 04:21:54,438 Stage: Train 0.5 | Epoch: 322 | Iter: 405200 | Total Loss: 0.002406 | Recon Loss: 0.002033 | Commit Loss: 0.000747 | Perplexity: 2506.364453
2025-09-30 04:26:13,313 Stage: Train 0.5 | Epoch: 322 | Iter: 405400 | Total Loss: 0.002418 | Recon Loss: 0.002042 | Commit Loss: 0.000752 | Perplexity: 2502.098633
Trainning Epoch:  81%|████████  | 534/658 [87:14:44<33:57:55, 986.09s/it]Trainning Epoch:  81%|████████  | 534/658 [87:14:44<33:57:55, 986.09s/it]2025-09-30 04:30:36,440 Stage: Train 0.5 | Epoch: 323 | Iter: 405600 | Total Loss: 0.002416 | Recon Loss: 0.002040 | Commit Loss: 0.000751 | Perplexity: 2510.658466
2025-09-30 04:34:56,089 Stage: Train 0.5 | Epoch: 323 | Iter: 405800 | Total Loss: 0.002420 | Recon Loss: 0.002045 | Commit Loss: 0.000750 | Perplexity: 2502.225219
2025-09-30 04:39:15,878 Stage: Train 0.5 | Epoch: 323 | Iter: 406000 | Total Loss: 0.002420 | Recon Loss: 0.002049 | Commit Loss: 0.000741 | Perplexity: 2504.457883
2025-09-30 04:43:36,242 Stage: Train 0.5 | Epoch: 323 | Iter: 406200 | Total Loss: 0.002410 | Recon Loss: 0.002030 | Commit Loss: 0.000761 | Perplexity: 2511.492487
Trainning Epoch:  81%|████████▏ | 535/658 [87:31:15<33:44:32, 987.58s/it]Trainning Epoch:  81%|████████▏ | 535/658 [87:31:15<33:44:32, 987.58s/it]2025-09-30 04:47:56,259 Stage: Train 0.5 | Epoch: 324 | Iter: 406400 | Total Loss: 0.002408 | Recon Loss: 0.002033 | Commit Loss: 0.000749 | Perplexity: 2506.606063
2025-09-30 04:52:12,817 Stage: Train 0.5 | Epoch: 324 | Iter: 406600 | Total Loss: 0.002425 | Recon Loss: 0.002049 | Commit Loss: 0.000752 | Perplexity: 2506.478872
2025-09-30 04:56:29,950 Stage: Train 0.5 | Epoch: 324 | Iter: 406800 | Total Loss: 0.002421 | Recon Loss: 0.002044 | Commit Loss: 0.000755 | Perplexity: 2505.019191
2025-09-30 05:00:46,334 Stage: Train 0.5 | Epoch: 324 | Iter: 407000 | Total Loss: 0.002435 | Recon Loss: 0.002053 | Commit Loss: 0.000763 | Perplexity: 2506.497905
Trainning Epoch:  81%|████████▏ | 536/658 [87:47:33<33:22:34, 984.87s/it]Trainning Epoch:  81%|████████▏ | 536/658 [87:47:34<33:22:35, 984.88s/it]2025-09-30 05:05:06,020 Stage: Train 0.5 | Epoch: 325 | Iter: 407200 | Total Loss: 0.002401 | Recon Loss: 0.002027 | Commit Loss: 0.000748 | Perplexity: 2503.966522
2025-09-30 05:09:22,538 Stage: Train 0.5 | Epoch: 325 | Iter: 407400 | Total Loss: 0.002433 | Recon Loss: 0.002051 | Commit Loss: 0.000764 | Perplexity: 2512.252848
2025-09-30 05:13:40,209 Stage: Train 0.5 | Epoch: 325 | Iter: 407600 | Total Loss: 0.002394 | Recon Loss: 0.002020 | Commit Loss: 0.000749 | Perplexity: 2502.863579
Trainning Epoch:  82%|████████▏ | 537/658 [88:03:53<33:03:01, 983.32s/it]Trainning Epoch:  82%|████████▏ | 537/658 [88:03:53<33:03:01, 983.32s/it]2025-09-30 05:18:00,986 Stage: Train 0.5 | Epoch: 326 | Iter: 407800 | Total Loss: 0.002416 | Recon Loss: 0.002040 | Commit Loss: 0.000751 | Perplexity: 2507.366992
2025-09-30 05:22:17,183 Stage: Train 0.5 | Epoch: 326 | Iter: 408000 | Total Loss: 0.002393 | Recon Loss: 0.002015 | Commit Loss: 0.000757 | Perplexity: 2507.898822
2025-09-30 05:26:34,661 Stage: Train 0.5 | Epoch: 326 | Iter: 408200 | Total Loss: 0.002424 | Recon Loss: 0.002049 | Commit Loss: 0.000751 | Perplexity: 2504.973605
2025-09-30 05:30:52,398 Stage: Train 0.5 | Epoch: 326 | Iter: 408400 | Total Loss: 0.002407 | Recon Loss: 0.002031 | Commit Loss: 0.000753 | Perplexity: 2511.171653
Trainning Epoch:  82%|████████▏ | 538/658 [88:20:14<32:44:50, 982.42s/it]Trainning Epoch:  82%|████████▏ | 538/658 [88:20:14<32:44:51, 982.43s/it]2025-09-30 05:35:12,794 Stage: Train 0.5 | Epoch: 327 | Iter: 408600 | Total Loss: 0.002387 | Recon Loss: 0.002010 | Commit Loss: 0.000755 | Perplexity: 2506.332559
2025-09-30 05:39:29,513 Stage: Train 0.5 | Epoch: 327 | Iter: 408800 | Total Loss: 0.002414 | Recon Loss: 0.002040 | Commit Loss: 0.000749 | Perplexity: 2504.876251
2025-09-30 05:43:46,897 Stage: Train 0.5 | Epoch: 327 | Iter: 409000 | Total Loss: 0.002386 | Recon Loss: 0.002012 | Commit Loss: 0.000748 | Perplexity: 2500.998745
2025-09-30 05:48:04,269 Stage: Train 0.5 | Epoch: 327 | Iter: 409200 | Total Loss: 0.002422 | Recon Loss: 0.002043 | Commit Loss: 0.000759 | Perplexity: 2497.606652
Trainning Epoch:  82%|████████▏ | 539/658 [88:36:34<32:27:16, 981.82s/it]Trainning Epoch:  82%|████████▏ | 539/658 [88:36:34<32:27:15, 981.81s/it]2025-09-30 05:52:27,115 Stage: Train 0.5 | Epoch: 328 | Iter: 409400 | Total Loss: 0.002407 | Recon Loss: 0.002030 | Commit Loss: 0.000755 | Perplexity: 2509.002932
2025-09-30 05:56:47,888 Stage: Train 0.5 | Epoch: 328 | Iter: 409600 | Total Loss: 0.002419 | Recon Loss: 0.002041 | Commit Loss: 0.000756 | Perplexity: 2508.844827
2025-09-30 06:01:08,631 Stage: Train 0.5 | Epoch: 328 | Iter: 409800 | Total Loss: 0.002409 | Recon Loss: 0.002033 | Commit Loss: 0.000753 | Perplexity: 2503.738368
2025-09-30 06:05:28,980 Stage: Train 0.5 | Epoch: 328 | Iter: 410000 | Total Loss: 0.002388 | Recon Loss: 0.002013 | Commit Loss: 0.000750 | Perplexity: 2501.600781
Trainning Epoch:  82%|████████▏ | 540/658 [88:53:08<32:17:56, 985.40s/it]Trainning Epoch:  82%|████████▏ | 540/658 [88:53:08<32:17:57, 985.40s/it]2025-09-30 06:09:53,085 Stage: Train 0.5 | Epoch: 329 | Iter: 410200 | Total Loss: 0.002420 | Recon Loss: 0.002045 | Commit Loss: 0.000750 | Perplexity: 2503.099364
2025-09-30 06:14:14,197 Stage: Train 0.5 | Epoch: 329 | Iter: 410400 | Total Loss: 0.002404 | Recon Loss: 0.002027 | Commit Loss: 0.000754 | Perplexity: 2505.681205
2025-09-30 06:18:35,022 Stage: Train 0.5 | Epoch: 329 | Iter: 410600 | Total Loss: 0.002425 | Recon Loss: 0.002044 | Commit Loss: 0.000761 | Perplexity: 2504.562736
2025-09-30 06:22:55,205 Stage: Train 0.5 | Epoch: 329 | Iter: 410800 | Total Loss: 0.002428 | Recon Loss: 0.002045 | Commit Loss: 0.000766 | Perplexity: 2509.529133
Trainning Epoch:  82%|████████▏ | 541/658 [89:09:42<32:06:58, 988.20s/it]Trainning Epoch:  82%|████████▏ | 541/658 [89:09:42<32:06:59, 988.20s/it]2025-09-30 06:27:16,759 Stage: Train 0.5 | Epoch: 330 | Iter: 411000 | Total Loss: 0.002401 | Recon Loss: 0.002025 | Commit Loss: 0.000753 | Perplexity: 2508.007238
2025-09-30 06:31:34,720 Stage: Train 0.5 | Epoch: 330 | Iter: 411200 | Total Loss: 0.002418 | Recon Loss: 0.002038 | Commit Loss: 0.000760 | Perplexity: 2507.922742
2025-09-30 06:35:53,344 Stage: Train 0.5 | Epoch: 330 | Iter: 411400 | Total Loss: 0.002410 | Recon Loss: 0.002032 | Commit Loss: 0.000757 | Perplexity: 2505.799202
Trainning Epoch:  82%|████████▏ | 542/658 [89:26:06<31:48:00, 986.90s/it]Trainning Epoch:  82%|████████▏ | 542/658 [89:26:06<31:48:00, 986.90s/it]2025-09-30 06:40:15,110 Stage: Train 0.5 | Epoch: 331 | Iter: 411600 | Total Loss: 0.002404 | Recon Loss: 0.002027 | Commit Loss: 0.000752 | Perplexity: 2504.648420
2025-09-30 06:44:31,282 Stage: Train 0.5 | Epoch: 331 | Iter: 411800 | Total Loss: 0.002396 | Recon Loss: 0.002022 | Commit Loss: 0.000748 | Perplexity: 2507.955392
2025-09-30 06:48:49,683 Stage: Train 0.5 | Epoch: 331 | Iter: 412000 | Total Loss: 0.002430 | Recon Loss: 0.002053 | Commit Loss: 0.000753 | Perplexity: 2505.895597
2025-09-30 06:53:07,826 Stage: Train 0.5 | Epoch: 331 | Iter: 412200 | Total Loss: 0.002400 | Recon Loss: 0.002026 | Commit Loss: 0.000749 | Perplexity: 2502.503579
Trainning Epoch:  83%|████████▎ | 543/658 [89:42:29<31:29:20, 985.74s/it]Trainning Epoch:  83%|████████▎ | 543/658 [89:42:29<31:29:20, 985.74s/it]2025-09-30 06:57:28,701 Stage: Train 0.5 | Epoch: 332 | Iter: 412400 | Total Loss: 0.002414 | Recon Loss: 0.002034 | Commit Loss: 0.000761 | Perplexity: 2503.358883
2025-09-30 07:01:43,633 Stage: Train 0.5 | Epoch: 332 | Iter: 412600 | Total Loss: 0.002410 | Recon Loss: 0.002029 | Commit Loss: 0.000761 | Perplexity: 2509.585249
2025-09-30 07:06:01,004 Stage: Train 0.5 | Epoch: 332 | Iter: 412800 | Total Loss: 0.002413 | Recon Loss: 0.002034 | Commit Loss: 0.000759 | Perplexity: 2504.189716
2025-09-30 07:10:19,108 Stage: Train 0.5 | Epoch: 332 | Iter: 413000 | Total Loss: 0.002400 | Recon Loss: 0.002024 | Commit Loss: 0.000752 | Perplexity: 2505.371409
Trainning Epoch:  83%|████████▎ | 544/658 [89:58:49<31:09:44, 984.07s/it]Trainning Epoch:  83%|████████▎ | 544/658 [89:58:50<31:09:45, 984.08s/it]2025-09-30 07:14:42,882 Stage: Train 0.5 | Epoch: 333 | Iter: 413200 | Total Loss: 0.002406 | Recon Loss: 0.002032 | Commit Loss: 0.000747 | Perplexity: 2505.061917
2025-09-30 07:19:02,421 Stage: Train 0.5 | Epoch: 333 | Iter: 413400 | Total Loss: 0.002389 | Recon Loss: 0.002010 | Commit Loss: 0.000760 | Perplexity: 2501.392113
2025-09-30 07:23:22,704 Stage: Train 0.5 | Epoch: 333 | Iter: 413600 | Total Loss: 0.002432 | Recon Loss: 0.002053 | Commit Loss: 0.000757 | Perplexity: 2506.827955
2025-09-30 07:27:43,411 Stage: Train 0.5 | Epoch: 333 | Iter: 413800 | Total Loss: 0.002386 | Recon Loss: 0.002010 | Commit Loss: 0.000753 | Perplexity: 2502.814835
Trainning Epoch:  83%|████████▎ | 545/658 [90:15:22<30:58:18, 986.72s/it]Trainning Epoch:  83%|████████▎ | 545/658 [90:15:22<30:58:19, 986.72s/it]2025-09-30 07:32:01,503 Stage: Train 0.5 | Epoch: 334 | Iter: 414000 | Total Loss: 0.002404 | Recon Loss: 0.002026 | Commit Loss: 0.000756 | Perplexity: 2503.729480
2025-09-30 07:36:18,202 Stage: Train 0.5 | Epoch: 334 | Iter: 414200 | Total Loss: 0.002398 | Recon Loss: 0.002022 | Commit Loss: 0.000752 | Perplexity: 2509.803075
2025-09-30 07:40:35,040 Stage: Train 0.5 | Epoch: 334 | Iter: 414400 | Total Loss: 0.002414 | Recon Loss: 0.002032 | Commit Loss: 0.000764 | Perplexity: 2505.764619
2025-09-30 07:44:51,106 Stage: Train 0.5 | Epoch: 334 | Iter: 414600 | Total Loss: 0.002393 | Recon Loss: 0.002014 | Commit Loss: 0.000758 | Perplexity: 2504.312095
Trainning Epoch:  83%|████████▎ | 546/658 [90:31:38<30:35:48, 983.47s/it]Trainning Epoch:  83%|████████▎ | 546/658 [90:31:38<30:35:48, 983.47s/it]2025-09-30 07:49:10,799 Stage: Train 0.5 | Epoch: 335 | Iter: 414800 | Total Loss: 0.002405 | Recon Loss: 0.002029 | Commit Loss: 0.000751 | Perplexity: 2501.251222
2025-09-30 07:53:27,161 Stage: Train 0.5 | Epoch: 335 | Iter: 415000 | Total Loss: 0.002414 | Recon Loss: 0.002035 | Commit Loss: 0.000758 | Perplexity: 2504.353524
2025-09-30 07:57:43,669 Stage: Train 0.5 | Epoch: 335 | Iter: 415200 | Total Loss: 0.002426 | Recon Loss: 0.002048 | Commit Loss: 0.000757 | Perplexity: 2503.941804
Trainning Epoch:  83%|████████▎ | 547/658 [90:47:55<30:15:45, 981.49s/it]Trainning Epoch:  83%|████████▎ | 547/658 [90:47:55<30:15:46, 981.50s/it]2025-09-30 08:02:03,487 Stage: Train 0.5 | Epoch: 336 | Iter: 415400 | Total Loss: 0.002419 | Recon Loss: 0.002042 | Commit Loss: 0.000754 | Perplexity: 2509.653845
2025-09-30 08:06:17,040 Stage: Train 0.5 | Epoch: 336 | Iter: 415600 | Total Loss: 0.002407 | Recon Loss: 0.002032 | Commit Loss: 0.000748 | Perplexity: 2507.560767
2025-09-30 08:10:33,249 Stage: Train 0.5 | Epoch: 336 | Iter: 415800 | Total Loss: 0.002404 | Recon Loss: 0.002024 | Commit Loss: 0.000760 | Perplexity: 2499.951875
2025-09-30 08:14:49,302 Stage: Train 0.5 | Epoch: 336 | Iter: 416000 | Total Loss: 0.002397 | Recon Loss: 0.002017 | Commit Loss: 0.000760 | Perplexity: 2504.703949
Trainning Epoch:  83%|████████▎ | 548/658 [91:04:10<29:55:36, 979.42s/it]Trainning Epoch:  83%|████████▎ | 548/658 [91:04:10<29:55:36, 979.42s/it]2025-09-30 08:19:09,474 Stage: Train 0.5 | Epoch: 337 | Iter: 416200 | Total Loss: 0.002395 | Recon Loss: 0.002016 | Commit Loss: 0.000758 | Perplexity: 2508.046614
2025-09-30 08:23:25,736 Stage: Train 0.5 | Epoch: 337 | Iter: 416400 | Total Loss: 0.002392 | Recon Loss: 0.002014 | Commit Loss: 0.000757 | Perplexity: 2505.457163
2025-09-30 08:27:42,078 Stage: Train 0.5 | Epoch: 337 | Iter: 416600 | Total Loss: 0.002406 | Recon Loss: 0.002029 | Commit Loss: 0.000753 | Perplexity: 2504.437574
2025-09-30 08:31:59,748 Stage: Train 0.5 | Epoch: 337 | Iter: 416800 | Total Loss: 0.002407 | Recon Loss: 0.002022 | Commit Loss: 0.000771 | Perplexity: 2504.619115
Trainning Epoch:  83%|████████▎ | 549/658 [91:20:29<29:39:21, 979.46s/it]Trainning Epoch:  83%|████████▎ | 549/658 [91:20:29<29:39:22, 979.47s/it]2025-09-30 08:36:21,899 Stage: Train 0.5 | Epoch: 338 | Iter: 417000 | Total Loss: 0.002400 | Recon Loss: 0.002020 | Commit Loss: 0.000760 | Perplexity: 2504.476310
2025-09-30 08:40:41,971 Stage: Train 0.5 | Epoch: 338 | Iter: 417200 | Total Loss: 0.002396 | Recon Loss: 0.002020 | Commit Loss: 0.000752 | Perplexity: 2504.002754
2025-09-30 08:45:03,568 Stage: Train 0.5 | Epoch: 338 | Iter: 417400 | Total Loss: 0.002413 | Recon Loss: 0.002026 | Commit Loss: 0.000775 | Perplexity: 2503.390880
2025-09-30 08:49:26,130 Stage: Train 0.5 | Epoch: 338 | Iter: 417600 | Total Loss: 0.002407 | Recon Loss: 0.002030 | Commit Loss: 0.000754 | Perplexity: 2508.747128
Trainning Epoch:  84%|████████▎ | 550/658 [91:37:06<29:32:28, 984.71s/it]Trainning Epoch:  84%|████████▎ | 550/658 [91:37:06<29:32:28, 984.71s/it]2025-09-30 08:53:49,642 Stage: Train 0.5 | Epoch: 339 | Iter: 417800 | Total Loss: 0.002406 | Recon Loss: 0.002023 | Commit Loss: 0.000765 | Perplexity: 2504.430096
2025-09-30 08:58:06,540 Stage: Train 0.5 | Epoch: 339 | Iter: 418000 | Total Loss: 0.002400 | Recon Loss: 0.002017 | Commit Loss: 0.000764 | Perplexity: 2504.116232
2025-09-30 09:02:24,252 Stage: Train 0.5 | Epoch: 339 | Iter: 418200 | Total Loss: 0.002381 | Recon Loss: 0.002002 | Commit Loss: 0.000758 | Perplexity: 2508.502351
2025-09-30 09:06:42,109 Stage: Train 0.5 | Epoch: 339 | Iter: 418400 | Total Loss: 0.002422 | Recon Loss: 0.002044 | Commit Loss: 0.000755 | Perplexity: 2505.999786
Trainning Epoch:  84%|████████▎ | 551/658 [91:53:29<29:15:10, 984.21s/it]Trainning Epoch:  84%|████████▎ | 551/658 [91:53:29<29:15:10, 984.21s/it]2025-09-30 09:10:58,549 Stage: Train 0.5 | Epoch: 340 | Iter: 418600 | Total Loss: 0.002386 | Recon Loss: 0.002009 | Commit Loss: 0.000754 | Perplexity: 2503.990304
2025-09-30 09:15:11,620 Stage: Train 0.5 | Epoch: 340 | Iter: 418800 | Total Loss: 0.002396 | Recon Loss: 0.002018 | Commit Loss: 0.000756 | Perplexity: 2507.587189
2025-09-30 09:19:26,033 Stage: Train 0.5 | Epoch: 340 | Iter: 419000 | Total Loss: 0.002413 | Recon Loss: 0.002029 | Commit Loss: 0.000770 | Perplexity: 2508.804716
Trainning Epoch:  84%|████████▍ | 552/658 [92:09:37<28:50:12, 979.36s/it]Trainning Epoch:  84%|████████▍ | 552/658 [92:09:37<28:50:12, 979.37s/it]2025-09-30 09:23:46,562 Stage: Train 0.5 | Epoch: 341 | Iter: 419200 | Total Loss: 0.002430 | Recon Loss: 0.002049 | Commit Loss: 0.000761 | Perplexity: 2505.535801
2025-09-30 09:28:04,790 Stage: Train 0.5 | Epoch: 341 | Iter: 419400 | Total Loss: 0.002391 | Recon Loss: 0.002014 | Commit Loss: 0.000752 | Perplexity: 2507.503829
2025-09-30 09:32:23,205 Stage: Train 0.5 | Epoch: 341 | Iter: 419600 | Total Loss: 0.002400 | Recon Loss: 0.002020 | Commit Loss: 0.000759 | Perplexity: 2506.957474
2025-09-30 09:36:41,335 Stage: Train 0.5 | Epoch: 341 | Iter: 419800 | Total Loss: 0.002404 | Recon Loss: 0.002027 | Commit Loss: 0.000753 | Perplexity: 2503.952590
Trainning Epoch:  84%|████████▍ | 553/658 [92:26:03<28:37:03, 981.18s/it]Trainning Epoch:  84%|████████▍ | 553/658 [92:26:03<28:37:03, 981.18s/it]2025-09-30 09:41:00,492 Stage: Train 0.5 | Epoch: 342 | Iter: 420000 | Total Loss: 0.002370 | Recon Loss: 0.001986 | Commit Loss: 0.000767 | Perplexity: 2507.700093
2025-09-30 09:41:00,492 Saving model at iteration 420000
2025-09-30 09:41:00,732 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_343_step_420000
2025-09-30 09:41:01,266 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_343_step_420000/model.safetensors
2025-09-30 09:41:01,693 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_343_step_420000/optimizer.bin
2025-09-30 09:41:01,694 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_343_step_420000/scheduler.bin
2025-09-30 09:41:01,694 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_343_step_420000/sampler.bin
2025-09-30 09:41:01,695 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_343_step_420000/random_states_0.pkl
2025-09-30 09:45:17,338 Stage: Train 0.5 | Epoch: 342 | Iter: 420200 | Total Loss: 0.002406 | Recon Loss: 0.002030 | Commit Loss: 0.000751 | Perplexity: 2509.699054
2025-09-30 09:49:34,494 Stage: Train 0.5 | Epoch: 342 | Iter: 420400 | Total Loss: 0.002433 | Recon Loss: 0.002052 | Commit Loss: 0.000761 | Perplexity: 2499.688420
2025-09-30 09:53:52,240 Stage: Train 0.5 | Epoch: 342 | Iter: 420600 | Total Loss: 0.002375 | Recon Loss: 0.001994 | Commit Loss: 0.000762 | Perplexity: 2504.479250
Trainning Epoch:  84%|████████▍ | 554/658 [92:42:22<28:19:51, 980.68s/it]Trainning Epoch:  84%|████████▍ | 554/658 [92:42:22<28:19:51, 980.69s/it]2025-09-30 09:58:15,189 Stage: Train 0.5 | Epoch: 343 | Iter: 420800 | Total Loss: 0.002404 | Recon Loss: 0.002028 | Commit Loss: 0.000752 | Perplexity: 2508.310276
2025-09-30 10:02:34,504 Stage: Train 0.5 | Epoch: 343 | Iter: 421000 | Total Loss: 0.002401 | Recon Loss: 0.002020 | Commit Loss: 0.000761 | Perplexity: 2510.876962
2025-09-30 10:06:53,555 Stage: Train 0.5 | Epoch: 343 | Iter: 421200 | Total Loss: 0.002401 | Recon Loss: 0.002021 | Commit Loss: 0.000760 | Perplexity: 2504.283761
2025-09-30 10:11:12,844 Stage: Train 0.5 | Epoch: 343 | Iter: 421400 | Total Loss: 0.002385 | Recon Loss: 0.002006 | Commit Loss: 0.000758 | Perplexity: 2507.319120
Trainning Epoch:  84%|████████▍ | 555/658 [92:58:51<28:07:43, 983.14s/it]Trainning Epoch:  84%|████████▍ | 555/658 [92:58:51<28:07:44, 983.15s/it]2025-09-30 10:15:35,189 Stage: Train 0.5 | Epoch: 344 | Iter: 421600 | Total Loss: 0.002391 | Recon Loss: 0.002012 | Commit Loss: 0.000759 | Perplexity: 2505.119611
2025-09-30 10:19:52,950 Stage: Train 0.5 | Epoch: 344 | Iter: 421800 | Total Loss: 0.002415 | Recon Loss: 0.002036 | Commit Loss: 0.000758 | Perplexity: 2504.711190
2025-09-30 10:24:12,247 Stage: Train 0.5 | Epoch: 344 | Iter: 422000 | Total Loss: 0.002395 | Recon Loss: 0.002013 | Commit Loss: 0.000764 | Perplexity: 2507.362506
2025-09-30 10:28:31,477 Stage: Train 0.5 | Epoch: 344 | Iter: 422200 | Total Loss: 0.002415 | Recon Loss: 0.002032 | Commit Loss: 0.000766 | Perplexity: 2505.722191
Trainning Epoch:  84%|████████▍ | 556/658 [93:15:19<27:53:33, 984.44s/it]Trainning Epoch:  84%|████████▍ | 556/658 [93:15:19<27:53:32, 984.44s/it]2025-09-30 10:32:54,573 Stage: Train 0.5 | Epoch: 345 | Iter: 422400 | Total Loss: 0.002418 | Recon Loss: 0.002037 | Commit Loss: 0.000761 | Perplexity: 2499.821602
2025-09-30 10:37:13,089 Stage: Train 0.5 | Epoch: 345 | Iter: 422600 | Total Loss: 0.002384 | Recon Loss: 0.002001 | Commit Loss: 0.000767 | Perplexity: 2509.309893
2025-09-30 10:41:32,064 Stage: Train 0.5 | Epoch: 345 | Iter: 422800 | Total Loss: 0.002402 | Recon Loss: 0.002022 | Commit Loss: 0.000759 | Perplexity: 2507.907474
Trainning Epoch:  85%|████████▍ | 557/658 [93:31:46<27:38:22, 985.17s/it]Trainning Epoch:  85%|████████▍ | 557/658 [93:31:46<27:38:23, 985.18s/it]2025-09-30 10:45:54,486 Stage: Train 0.5 | Epoch: 346 | Iter: 423000 | Total Loss: 0.002430 | Recon Loss: 0.002053 | Commit Loss: 0.000754 | Perplexity: 2502.842255
2025-09-30 10:50:13,202 Stage: Train 0.5 | Epoch: 346 | Iter: 423200 | Total Loss: 0.002389 | Recon Loss: 0.002008 | Commit Loss: 0.000762 | Perplexity: 2503.473729
2025-09-30 10:54:32,733 Stage: Train 0.5 | Epoch: 346 | Iter: 423400 | Total Loss: 0.002416 | Recon Loss: 0.002034 | Commit Loss: 0.000763 | Perplexity: 2504.137239
2025-09-30 10:58:51,056 Stage: Train 0.5 | Epoch: 346 | Iter: 423600 | Total Loss: 0.002352 | Recon Loss: 0.001973 | Commit Loss: 0.000757 | Perplexity: 2502.209536
Trainning Epoch:  85%|████████▍ | 558/658 [93:48:13<27:23:04, 985.84s/it]Trainning Epoch:  85%|████████▍ | 558/658 [93:48:13<27:23:04, 985.85s/it]2025-09-30 11:03:10,611 Stage: Train 0.5 | Epoch: 347 | Iter: 423800 | Total Loss: 0.002405 | Recon Loss: 0.002025 | Commit Loss: 0.000762 | Perplexity: 2507.109379
2025-09-30 11:07:25,861 Stage: Train 0.5 | Epoch: 347 | Iter: 424000 | Total Loss: 0.002399 | Recon Loss: 0.002019 | Commit Loss: 0.000761 | Perplexity: 2501.879032
2025-09-30 11:11:41,333 Stage: Train 0.5 | Epoch: 347 | Iter: 424200 | Total Loss: 0.002396 | Recon Loss: 0.002013 | Commit Loss: 0.000765 | Perplexity: 2504.426448
2025-09-30 11:15:57,254 Stage: Train 0.5 | Epoch: 347 | Iter: 424400 | Total Loss: 0.002410 | Recon Loss: 0.002029 | Commit Loss: 0.000760 | Perplexity: 2500.668407
Trainning Epoch:  85%|████████▍ | 559/658 [94:04:26<27:00:26, 982.08s/it]Trainning Epoch:  85%|████████▍ | 559/658 [94:04:26<27:00:26, 982.08s/it]2025-09-30 11:20:19,379 Stage: Train 0.5 | Epoch: 348 | Iter: 424600 | Total Loss: 0.002394 | Recon Loss: 0.002007 | Commit Loss: 0.000774 | Perplexity: 2498.154882
2025-09-30 11:24:39,183 Stage: Train 0.5 | Epoch: 348 | Iter: 424800 | Total Loss: 0.002391 | Recon Loss: 0.002012 | Commit Loss: 0.000758 | Perplexity: 2503.282137
2025-09-30 11:28:58,797 Stage: Train 0.5 | Epoch: 348 | Iter: 425000 | Total Loss: 0.002401 | Recon Loss: 0.002020 | Commit Loss: 0.000762 | Perplexity: 2511.193770
2025-09-30 11:33:18,019 Stage: Train 0.5 | Epoch: 348 | Iter: 425200 | Total Loss: 0.002405 | Recon Loss: 0.002027 | Commit Loss: 0.000756 | Perplexity: 2505.180406
Trainning Epoch:  85%|████████▌ | 560/658 [94:20:57<26:48:10, 984.60s/it]Trainning Epoch:  85%|████████▌ | 560/658 [94:20:57<26:48:10, 984.60s/it]2025-09-30 11:37:41,960 Stage: Train 0.5 | Epoch: 349 | Iter: 425400 | Total Loss: 0.002400 | Recon Loss: 0.002025 | Commit Loss: 0.000751 | Perplexity: 2506.572445
2025-09-30 11:42:01,764 Stage: Train 0.5 | Epoch: 349 | Iter: 425600 | Total Loss: 0.002370 | Recon Loss: 0.001993 | Commit Loss: 0.000754 | Perplexity: 2497.633541
2025-09-30 11:46:21,939 Stage: Train 0.5 | Epoch: 349 | Iter: 425800 | Total Loss: 0.002405 | Recon Loss: 0.002019 | Commit Loss: 0.000772 | Perplexity: 2512.229427
2025-09-30 11:50:41,532 Stage: Train 0.5 | Epoch: 349 | Iter: 426000 | Total Loss: 0.002358 | Recon Loss: 0.001981 | Commit Loss: 0.000754 | Perplexity: 2504.213807
Trainning Epoch:  85%|████████▌ | 561/658 [94:37:29<26:35:20, 986.80s/it]Trainning Epoch:  85%|████████▌ | 561/658 [94:37:29<26:35:20, 986.81s/it]2025-09-30 11:55:00,590 Stage: Train 0.5 | Epoch: 350 | Iter: 426200 | Total Loss: 0.002408 | Recon Loss: 0.002032 | Commit Loss: 0.000753 | Perplexity: 2502.774785
2025-09-30 11:59:18,318 Stage: Train 0.5 | Epoch: 350 | Iter: 426400 | Total Loss: 0.002380 | Recon Loss: 0.002000 | Commit Loss: 0.000760 | Perplexity: 2499.881265
2025-09-30 12:03:35,753 Stage: Train 0.5 | Epoch: 350 | Iter: 426600 | Total Loss: 0.002401 | Recon Loss: 0.002019 | Commit Loss: 0.000765 | Perplexity: 2506.548809
Trainning Epoch:  85%|████████▌ | 562/658 [94:53:49<26:15:55, 984.95s/it]Trainning Epoch:  85%|████████▌ | 562/658 [94:53:49<26:15:55, 984.95s/it]2025-09-30 12:07:57,522 Stage: Train 0.5 | Epoch: 351 | Iter: 426800 | Total Loss: 0.002397 | Recon Loss: 0.002017 | Commit Loss: 0.000761 | Perplexity: 2507.183322
2025-09-30 12:12:15,146 Stage: Train 0.5 | Epoch: 351 | Iter: 427000 | Total Loss: 0.002420 | Recon Loss: 0.002043 | Commit Loss: 0.000754 | Perplexity: 2501.850087
2025-09-30 12:16:32,830 Stage: Train 0.5 | Epoch: 351 | Iter: 427200 | Total Loss: 0.002398 | Recon Loss: 0.002015 | Commit Loss: 0.000765 | Perplexity: 2508.758438
2025-09-30 12:20:51,044 Stage: Train 0.5 | Epoch: 351 | Iter: 427400 | Total Loss: 0.002382 | Recon Loss: 0.002006 | Commit Loss: 0.000753 | Perplexity: 2506.928804
Trainning Epoch:  86%|████████▌ | 563/658 [95:10:14<25:59:10, 984.75s/it]Trainning Epoch:  86%|████████▌ | 563/658 [95:10:14<25:59:11, 984.75s/it]2025-09-30 12:25:14,121 Stage: Train 0.5 | Epoch: 352 | Iter: 427600 | Total Loss: 0.002380 | Recon Loss: 0.002005 | Commit Loss: 0.000751 | Perplexity: 2504.843035
2025-09-30 12:29:32,782 Stage: Train 0.5 | Epoch: 352 | Iter: 427800 | Total Loss: 0.002410 | Recon Loss: 0.002027 | Commit Loss: 0.000765 | Perplexity: 2508.196820
2025-09-30 12:33:52,756 Stage: Train 0.5 | Epoch: 352 | Iter: 428000 | Total Loss: 0.002393 | Recon Loss: 0.002013 | Commit Loss: 0.000761 | Perplexity: 2501.471606
2025-09-30 12:38:14,124 Stage: Train 0.5 | Epoch: 352 | Iter: 428200 | Total Loss: 0.002398 | Recon Loss: 0.002014 | Commit Loss: 0.000768 | Perplexity: 2505.394987
Trainning Epoch:  86%|████████▌ | 564/658 [95:26:46<25:46:10, 986.92s/it]Trainning Epoch:  86%|████████▌ | 564/658 [95:26:46<25:46:10, 986.92s/it]2025-09-30 12:42:37,817 Stage: Train 0.5 | Epoch: 353 | Iter: 428400 | Total Loss: 0.002390 | Recon Loss: 0.002011 | Commit Loss: 0.000757 | Perplexity: 2507.870033
2025-09-30 12:47:03,843 Stage: Train 0.5 | Epoch: 353 | Iter: 428600 | Total Loss: 0.002387 | Recon Loss: 0.002002 | Commit Loss: 0.000770 | Perplexity: 2505.749902
2025-09-30 12:51:35,093 Stage: Train 0.5 | Epoch: 353 | Iter: 428800 | Total Loss: 0.002381 | Recon Loss: 0.001997 | Commit Loss: 0.000768 | Perplexity: 2510.344575
2025-09-30 12:56:11,027 Stage: Train 0.5 | Epoch: 353 | Iter: 429000 | Total Loss: 0.002394 | Recon Loss: 0.002015 | Commit Loss: 0.000758 | Perplexity: 2502.104918
Trainning Epoch:  86%|████████▌ | 565/658 [95:43:53<25:48:26, 998.99s/it]Trainning Epoch:  86%|████████▌ | 565/658 [95:43:53<25:48:26, 999.00s/it]2025-09-30 13:00:47,536 Stage: Train 0.5 | Epoch: 354 | Iter: 429200 | Total Loss: 0.002405 | Recon Loss: 0.002020 | Commit Loss: 0.000769 | Perplexity: 2509.647375
2025-09-30 13:05:18,920 Stage: Train 0.5 | Epoch: 354 | Iter: 429400 | Total Loss: 0.002408 | Recon Loss: 0.002029 | Commit Loss: 0.000757 | Perplexity: 2506.386072
2025-09-30 13:09:51,922 Stage: Train 0.5 | Epoch: 354 | Iter: 429600 | Total Loss: 0.002377 | Recon Loss: 0.001991 | Commit Loss: 0.000772 | Perplexity: 2503.501794
2025-09-30 13:14:23,943 Stage: Train 0.5 | Epoch: 354 | Iter: 429800 | Total Loss: 0.002393 | Recon Loss: 0.002012 | Commit Loss: 0.000762 | Perplexity: 2495.898153
Trainning Epoch:  86%|████████▌ | 566/658 [96:01:11<25:49:54, 1010.80s/it]Trainning Epoch:  86%|████████▌ | 566/658 [96:01:11<25:49:55, 1010.82s/it]2025-09-30 13:19:02,068 Stage: Train 0.5 | Epoch: 355 | Iter: 430000 | Total Loss: 0.002355 | Recon Loss: 0.001977 | Commit Loss: 0.000757 | Perplexity: 2504.019720
2025-09-30 13:23:35,055 Stage: Train 0.5 | Epoch: 355 | Iter: 430200 | Total Loss: 0.002378 | Recon Loss: 0.001997 | Commit Loss: 0.000760 | Perplexity: 2506.600009
2025-09-30 13:28:09,388 Stage: Train 0.5 | Epoch: 355 | Iter: 430400 | Total Loss: 0.002388 | Recon Loss: 0.002001 | Commit Loss: 0.000775 | Perplexity: 2505.445322
Trainning Epoch:  86%|████████▌ | 567/658 [96:18:33<25:47:19, 1020.21s/it]Trainning Epoch:  86%|████████▌ | 567/658 [96:18:33<25:47:20, 1020.22s/it]2025-09-30 13:32:44,410 Stage: Train 0.5 | Epoch: 356 | Iter: 430600 | Total Loss: 0.002391 | Recon Loss: 0.002013 | Commit Loss: 0.000756 | Perplexity: 2503.826676
2025-09-30 13:37:08,849 Stage: Train 0.5 | Epoch: 356 | Iter: 430800 | Total Loss: 0.002364 | Recon Loss: 0.001985 | Commit Loss: 0.000758 | Perplexity: 2511.470406
2025-09-30 13:41:35,105 Stage: Train 0.5 | Epoch: 356 | Iter: 431000 | Total Loss: 0.002394 | Recon Loss: 0.002016 | Commit Loss: 0.000757 | Perplexity: 2500.833970
2025-09-30 13:46:00,322 Stage: Train 0.5 | Epoch: 356 | Iter: 431200 | Total Loss: 0.002396 | Recon Loss: 0.002019 | Commit Loss: 0.000754 | Perplexity: 2502.937161
Trainning Epoch:  86%|████████▋ | 568/658 [96:35:27<25:27:33, 1018.37s/it]Trainning Epoch:  86%|████████▋ | 568/658 [96:35:27<25:27:34, 1018.38s/it]2025-09-30 13:50:32,300 Stage: Train 0.5 | Epoch: 357 | Iter: 431400 | Total Loss: 0.002364 | Recon Loss: 0.001985 | Commit Loss: 0.000758 | Perplexity: 2502.389844
2025-09-30 13:55:02,283 Stage: Train 0.5 | Epoch: 357 | Iter: 431600 | Total Loss: 0.002394 | Recon Loss: 0.002011 | Commit Loss: 0.000766 | Perplexity: 2506.718650
2025-09-30 13:59:32,447 Stage: Train 0.5 | Epoch: 357 | Iter: 431800 | Total Loss: 0.002375 | Recon Loss: 0.001996 | Commit Loss: 0.000757 | Perplexity: 2502.510109
2025-09-30 14:04:02,196 Stage: Train 0.5 | Epoch: 357 | Iter: 432000 | Total Loss: 0.002403 | Recon Loss: 0.002027 | Commit Loss: 0.000752 | Perplexity: 2500.061527
Trainning Epoch:  86%|████████▋ | 569/658 [96:52:37<25:15:39, 1021.79s/it]Trainning Epoch:  86%|████████▋ | 569/658 [96:52:37<25:15:38, 1021.78s/it]2025-09-30 14:08:36,112 Stage: Train 0.5 | Epoch: 358 | Iter: 432200 | Total Loss: 0.002370 | Recon Loss: 0.001989 | Commit Loss: 0.000762 | Perplexity: 2504.111132
2025-09-30 14:13:06,014 Stage: Train 0.5 | Epoch: 358 | Iter: 432400 | Total Loss: 0.002384 | Recon Loss: 0.002004 | Commit Loss: 0.000759 | Perplexity: 2506.718451
2025-09-30 14:17:35,768 Stage: Train 0.5 | Epoch: 358 | Iter: 432600 | Total Loss: 0.002378 | Recon Loss: 0.001996 | Commit Loss: 0.000765 | Perplexity: 2508.147086
2025-09-30 14:22:05,122 Stage: Train 0.5 | Epoch: 358 | Iter: 432800 | Total Loss: 0.002400 | Recon Loss: 0.002019 | Commit Loss: 0.000761 | Perplexity: 2504.426041
Trainning Epoch:  87%|████████▋ | 570/658 [97:09:45<25:01:22, 1023.67s/it]Trainning Epoch:  87%|████████▋ | 570/658 [97:09:45<25:01:22, 1023.67s/it]2025-09-30 14:26:36,626 Stage: Train 0.5 | Epoch: 359 | Iter: 433000 | Total Loss: 0.002381 | Recon Loss: 0.002001 | Commit Loss: 0.000760 | Perplexity: 2500.584260
2025-09-30 14:31:05,402 Stage: Train 0.5 | Epoch: 359 | Iter: 433200 | Total Loss: 0.002412 | Recon Loss: 0.002028 | Commit Loss: 0.000768 | Perplexity: 2507.461166
2025-09-30 14:35:36,959 Stage: Train 0.5 | Epoch: 359 | Iter: 433400 | Total Loss: 0.002385 | Recon Loss: 0.002002 | Commit Loss: 0.000765 | Perplexity: 2507.256783
2025-09-30 14:40:06,794 Stage: Train 0.5 | Epoch: 359 | Iter: 433600 | Total Loss: 0.002430 | Recon Loss: 0.002046 | Commit Loss: 0.000768 | Perplexity: 2507.571074
Trainning Epoch:  87%|████████▋ | 571/658 [97:26:54<24:46:34, 1025.22s/it]Trainning Epoch:  87%|████████▋ | 571/658 [97:26:54<24:46:34, 1025.22s/it]2025-09-30 14:44:45,056 Stage: Train 0.5 | Epoch: 360 | Iter: 433800 | Total Loss: 0.002388 | Recon Loss: 0.002005 | Commit Loss: 0.000765 | Perplexity: 2508.493348
2025-09-30 14:49:17,409 Stage: Train 0.5 | Epoch: 360 | Iter: 434000 | Total Loss: 0.002372 | Recon Loss: 0.001991 | Commit Loss: 0.000761 | Perplexity: 2496.761160
2025-09-30 14:53:49,069 Stage: Train 0.5 | Epoch: 360 | Iter: 434200 | Total Loss: 0.002378 | Recon Loss: 0.001994 | Commit Loss: 0.000769 | Perplexity: 2505.074175
Trainning Epoch:  87%|████████▋ | 572/658 [97:44:12<24:34:57, 1029.04s/it]Trainning Epoch:  87%|████████▋ | 572/658 [97:44:12<24:34:57, 1029.04s/it]2025-09-30 14:58:24,896 Stage: Train 0.5 | Epoch: 361 | Iter: 434400 | Total Loss: 0.002369 | Recon Loss: 0.001992 | Commit Loss: 0.000756 | Perplexity: 2511.067015
2025-09-30 15:02:55,790 Stage: Train 0.5 | Epoch: 361 | Iter: 434600 | Total Loss: 0.002385 | Recon Loss: 0.002010 | Commit Loss: 0.000751 | Perplexity: 2503.848871
2025-09-30 15:07:26,397 Stage: Train 0.5 | Epoch: 361 | Iter: 434800 | Total Loss: 0.002409 | Recon Loss: 0.002032 | Commit Loss: 0.000756 | Perplexity: 2504.081318
2025-09-30 15:11:58,180 Stage: Train 0.5 | Epoch: 361 | Iter: 435000 | Total Loss: 0.002369 | Recon Loss: 0.001990 | Commit Loss: 0.000758 | Perplexity: 2499.991024
Trainning Epoch:  87%|████████▋ | 573/658 [98:01:28<24:20:53, 1031.21s/it]Trainning Epoch:  87%|████████▋ | 573/658 [98:01:28<24:20:53, 1031.22s/it]2025-09-30 15:16:30,900 Stage: Train 0.5 | Epoch: 362 | Iter: 435200 | Total Loss: 0.002367 | Recon Loss: 0.001985 | Commit Loss: 0.000763 | Perplexity: 2502.770387
2025-09-30 15:20:56,438 Stage: Train 0.5 | Epoch: 362 | Iter: 435400 | Total Loss: 0.002383 | Recon Loss: 0.002004 | Commit Loss: 0.000758 | Perplexity: 2498.835465
2025-09-30 15:25:22,914 Stage: Train 0.5 | Epoch: 362 | Iter: 435600 | Total Loss: 0.002399 | Recon Loss: 0.002019 | Commit Loss: 0.000761 | Perplexity: 2506.009462
2025-09-30 15:29:51,184 Stage: Train 0.5 | Epoch: 362 | Iter: 435800 | Total Loss: 0.002383 | Recon Loss: 0.002001 | Commit Loss: 0.000764 | Perplexity: 2500.468513
Trainning Epoch:  87%|████████▋ | 574/658 [98:18:25<23:57:37, 1026.88s/it]Trainning Epoch:  87%|████████▋ | 574/658 [98:18:25<23:57:39, 1026.90s/it]2025-09-30 15:34:19,332 Stage: Train 0.5 | Epoch: 363 | Iter: 436000 | Total Loss: 0.002382 | Recon Loss: 0.002000 | Commit Loss: 0.000764 | Perplexity: 2503.299207
2025-09-30 15:38:41,539 Stage: Train 0.5 | Epoch: 363 | Iter: 436200 | Total Loss: 0.002397 | Recon Loss: 0.002018 | Commit Loss: 0.000758 | Perplexity: 2506.794960
2025-09-30 15:43:03,797 Stage: Train 0.5 | Epoch: 363 | Iter: 436400 | Total Loss: 0.002355 | Recon Loss: 0.001973 | Commit Loss: 0.000764 | Perplexity: 2509.634691
2025-09-30 15:47:25,661 Stage: Train 0.5 | Epoch: 363 | Iter: 436600 | Total Loss: 0.002429 | Recon Loss: 0.002046 | Commit Loss: 0.000765 | Perplexity: 2504.141418
Trainning Epoch:  87%|████████▋ | 575/658 [98:35:06<23:29:33, 1018.96s/it]Trainning Epoch:  87%|████████▋ | 575/658 [98:35:06<23:29:34, 1018.97s/it]2025-09-30 15:51:55,328 Stage: Train 0.5 | Epoch: 364 | Iter: 436800 | Total Loss: 0.002354 | Recon Loss: 0.001976 | Commit Loss: 0.000758 | Perplexity: 2501.790065
2025-09-30 15:56:23,132 Stage: Train 0.5 | Epoch: 364 | Iter: 437000 | Total Loss: 0.002382 | Recon Loss: 0.001995 | Commit Loss: 0.000774 | Perplexity: 2505.482957
2025-09-30 16:00:51,513 Stage: Train 0.5 | Epoch: 364 | Iter: 437200 | Total Loss: 0.002367 | Recon Loss: 0.001987 | Commit Loss: 0.000760 | Perplexity: 2502.858293
2025-09-30 16:05:18,868 Stage: Train 0.5 | Epoch: 364 | Iter: 437400 | Total Loss: 0.002388 | Recon Loss: 0.002004 | Commit Loss: 0.000768 | Perplexity: 2502.904213
Trainning Epoch:  88%|████████▊ | 576/658 [98:52:06<23:13:14, 1019.44s/it]Trainning Epoch:  88%|████████▊ | 576/658 [98:52:06<23:13:14, 1019.45s/it]2025-09-30 16:09:53,143 Stage: Train 0.5 | Epoch: 365 | Iter: 437600 | Total Loss: 0.002369 | Recon Loss: 0.001988 | Commit Loss: 0.000761 | Perplexity: 2507.260710
2025-09-30 16:14:23,281 Stage: Train 0.5 | Epoch: 365 | Iter: 437800 | Total Loss: 0.002390 | Recon Loss: 0.002013 | Commit Loss: 0.000754 | Perplexity: 2500.767495
2025-09-30 16:18:53,906 Stage: Train 0.5 | Epoch: 365 | Iter: 438000 | Total Loss: 0.002385 | Recon Loss: 0.002001 | Commit Loss: 0.000766 | Perplexity: 2503.662542
Trainning Epoch:  88%|████████▊ | 577/658 [99:09:18<23:01:07, 1023.06s/it]Trainning Epoch:  88%|████████▊ | 577/658 [99:09:18<23:01:07, 1023.06s/it]2025-09-30 16:23:28,593 Stage: Train 0.5 | Epoch: 366 | Iter: 438200 | Total Loss: 0.002373 | Recon Loss: 0.001996 | Commit Loss: 0.000753 | Perplexity: 2505.233602
2025-09-30 16:27:56,588 Stage: Train 0.5 | Epoch: 366 | Iter: 438400 | Total Loss: 0.002387 | Recon Loss: 0.002004 | Commit Loss: 0.000766 | Perplexity: 2504.763242
2025-09-30 16:32:24,481 Stage: Train 0.5 | Epoch: 366 | Iter: 438600 | Total Loss: 0.002387 | Recon Loss: 0.002004 | Commit Loss: 0.000765 | Perplexity: 2501.711802
2025-09-30 16:36:51,911 Stage: Train 0.5 | Epoch: 366 | Iter: 438800 | Total Loss: 0.002391 | Recon Loss: 0.002009 | Commit Loss: 0.000764 | Perplexity: 2506.484155
Trainning Epoch:  88%|████████▊ | 578/658 [99:26:20<22:43:46, 1022.83s/it]Trainning Epoch:  88%|████████▊ | 578/658 [99:26:20<22:43:46, 1022.84s/it]2025-09-30 16:41:23,863 Stage: Train 0.5 | Epoch: 367 | Iter: 439000 | Total Loss: 0.002385 | Recon Loss: 0.002002 | Commit Loss: 0.000766 | Perplexity: 2508.505090
2025-09-30 16:45:49,132 Stage: Train 0.5 | Epoch: 367 | Iter: 439200 | Total Loss: 0.002397 | Recon Loss: 0.002017 | Commit Loss: 0.000761 | Perplexity: 2509.504230
2025-09-30 16:50:16,595 Stage: Train 0.5 | Epoch: 367 | Iter: 439400 | Total Loss: 0.002353 | Recon Loss: 0.001973 | Commit Loss: 0.000761 | Perplexity: 2509.592563
2025-09-30 16:54:44,290 Stage: Train 0.5 | Epoch: 367 | Iter: 439600 | Total Loss: 0.002394 | Recon Loss: 0.002013 | Commit Loss: 0.000762 | Perplexity: 2507.328519
Trainning Epoch:  88%|████████▊ | 579/658 [99:43:18<22:24:48, 1021.37s/it]Trainning Epoch:  88%|████████▊ | 579/658 [99:43:18<22:24:48, 1021.37s/it]2025-09-30 16:59:15,922 Stage: Train 0.5 | Epoch: 368 | Iter: 439800 | Total Loss: 0.002375 | Recon Loss: 0.001991 | Commit Loss: 0.000769 | Perplexity: 2505.091580
2025-09-30 17:03:49,894 Stage: Train 0.5 | Epoch: 368 | Iter: 440000 | Total Loss: 0.002366 | Recon Loss: 0.001984 | Commit Loss: 0.000764 | Perplexity: 2507.936621
2025-09-30 17:03:49,895 Saving model at iteration 440000
2025-09-30 17:03:50,547 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_369_step_440000
2025-09-30 17:03:51,081 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_369_step_440000/model.safetensors
2025-09-30 17:03:51,535 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_369_step_440000/optimizer.bin
2025-09-30 17:03:51,535 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_369_step_440000/scheduler.bin
2025-09-30 17:03:51,535 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_369_step_440000/sampler.bin
2025-09-30 17:03:51,536 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_369_step_440000/random_states_0.pkl
2025-09-30 17:08:27,938 Stage: Train 0.5 | Epoch: 368 | Iter: 440200 | Total Loss: 0.002370 | Recon Loss: 0.001986 | Commit Loss: 0.000768 | Perplexity: 2501.206964
2025-09-30 17:13:02,836 Stage: Train 0.5 | Epoch: 368 | Iter: 440400 | Total Loss: 0.002396 | Recon Loss: 0.002012 | Commit Loss: 0.000767 | Perplexity: 2506.137717
Trainning Epoch:  88%|████████▊ | 580/658 [100:00:45<22:17:45, 1029.05s/it]Trainning Epoch:  88%|████████▊ | 580/658 [100:00:45<22:17:45, 1029.05s/it]2025-09-30 17:17:34,783 Stage: Train 0.5 | Epoch: 369 | Iter: 440600 | Total Loss: 0.002395 | Recon Loss: 0.002015 | Commit Loss: 0.000760 | Perplexity: 2496.038655
2025-09-30 17:22:02,759 Stage: Train 0.5 | Epoch: 369 | Iter: 440800 | Total Loss: 0.002395 | Recon Loss: 0.002016 | Commit Loss: 0.000758 | Perplexity: 2499.594132
2025-09-30 17:26:32,315 Stage: Train 0.5 | Epoch: 369 | Iter: 441000 | Total Loss: 0.002375 | Recon Loss: 0.001993 | Commit Loss: 0.000763 | Perplexity: 2503.378824
2025-09-30 17:31:03,295 Stage: Train 0.5 | Epoch: 369 | Iter: 441200 | Total Loss: 0.002365 | Recon Loss: 0.001982 | Commit Loss: 0.000768 | Perplexity: 2502.557438
Trainning Epoch:  88%|████████▊ | 581/658 [100:17:51<21:59:19, 1028.05s/it]Trainning Epoch:  88%|████████▊ | 581/658 [100:17:51<21:59:19, 1028.05s/it]2025-09-30 17:35:39,454 Stage: Train 0.5 | Epoch: 370 | Iter: 441400 | Total Loss: 0.002381 | Recon Loss: 0.002004 | Commit Loss: 0.000755 | Perplexity: 2508.742114
2025-09-30 17:40:09,157 Stage: Train 0.5 | Epoch: 370 | Iter: 441600 | Total Loss: 0.002391 | Recon Loss: 0.002014 | Commit Loss: 0.000753 | Perplexity: 2501.177275
2025-09-30 17:44:41,060 Stage: Train 0.5 | Epoch: 370 | Iter: 441800 | Total Loss: 0.002380 | Recon Loss: 0.001994 | Commit Loss: 0.000771 | Perplexity: 2511.356965
Trainning Epoch:  88%|████████▊ | 582/658 [100:35:04<21:44:23, 1029.78s/it]Trainning Epoch:  88%|████████▊ | 582/658 [100:35:04<21:44:23, 1029.79s/it]2025-09-30 17:49:15,023 Stage: Train 0.5 | Epoch: 371 | Iter: 442000 | Total Loss: 0.002390 | Recon Loss: 0.002009 | Commit Loss: 0.000761 | Perplexity: 2499.774744
2025-09-30 17:53:37,089 Stage: Train 0.5 | Epoch: 371 | Iter: 442200 | Total Loss: 0.002368 | Recon Loss: 0.001984 | Commit Loss: 0.000767 | Perplexity: 2508.213268
2025-09-30 17:58:00,333 Stage: Train 0.5 | Epoch: 371 | Iter: 442400 | Total Loss: 0.002382 | Recon Loss: 0.001999 | Commit Loss: 0.000764 | Perplexity: 2507.385625
2025-09-30 18:02:26,463 Stage: Train 0.5 | Epoch: 371 | Iter: 442600 | Total Loss: 0.002371 | Recon Loss: 0.001986 | Commit Loss: 0.000770 | Perplexity: 2502.747689
Trainning Epoch:  89%|████████▊ | 583/658 [100:51:54<21:19:45, 1023.80s/it]Trainning Epoch:  89%|████████▊ | 583/658 [100:51:54<21:19:45, 1023.80s/it]2025-09-30 18:06:58,437 Stage: Train 0.5 | Epoch: 372 | Iter: 442800 | Total Loss: 0.002386 | Recon Loss: 0.002002 | Commit Loss: 0.000769 | Perplexity: 2507.104988
2025-09-30 18:11:25,265 Stage: Train 0.5 | Epoch: 372 | Iter: 443000 | Total Loss: 0.002355 | Recon Loss: 0.001974 | Commit Loss: 0.000761 | Perplexity: 2502.891332
2025-09-30 18:15:52,954 Stage: Train 0.5 | Epoch: 372 | Iter: 443200 | Total Loss: 0.002381 | Recon Loss: 0.001994 | Commit Loss: 0.000775 | Perplexity: 2506.970145
2025-09-30 18:20:22,265 Stage: Train 0.5 | Epoch: 372 | Iter: 443400 | Total Loss: 0.002369 | Recon Loss: 0.001987 | Commit Loss: 0.000764 | Perplexity: 2499.421182
Trainning Epoch:  89%|████████▉ | 584/658 [101:08:57<21:02:16, 1023.46s/it]Trainning Epoch:  89%|████████▉ | 584/658 [101:08:57<21:02:16, 1023.47s/it]2025-09-30 18:24:53,956 Stage: Train 0.5 | Epoch: 373 | Iter: 443600 | Total Loss: 0.002355 | Recon Loss: 0.001974 | Commit Loss: 0.000761 | Perplexity: 2502.745767
2025-09-30 18:29:19,914 Stage: Train 0.5 | Epoch: 373 | Iter: 443800 | Total Loss: 0.002384 | Recon Loss: 0.002007 | Commit Loss: 0.000754 | Perplexity: 2496.357009
2025-09-30 18:33:47,060 Stage: Train 0.5 | Epoch: 373 | Iter: 444000 | Total Loss: 0.002393 | Recon Loss: 0.002008 | Commit Loss: 0.000770 | Perplexity: 2507.153191
2025-09-30 18:38:16,198 Stage: Train 0.5 | Epoch: 373 | Iter: 444200 | Total Loss: 0.002362 | Recon Loss: 0.001983 | Commit Loss: 0.000758 | Perplexity: 2504.579146
Trainning Epoch:  89%|████████▉ | 585/658 [101:25:57<20:43:52, 1022.36s/it]Trainning Epoch:  89%|████████▉ | 585/658 [101:25:57<20:43:52, 1022.36s/it]2025-09-30 18:42:49,177 Stage: Train 0.5 | Epoch: 374 | Iter: 444400 | Total Loss: 0.002378 | Recon Loss: 0.001998 | Commit Loss: 0.000761 | Perplexity: 2500.676202
2025-09-30 18:47:18,342 Stage: Train 0.5 | Epoch: 374 | Iter: 444600 | Total Loss: 0.002369 | Recon Loss: 0.001991 | Commit Loss: 0.000757 | Perplexity: 2501.940251
2025-09-30 18:51:47,236 Stage: Train 0.5 | Epoch: 374 | Iter: 444800 | Total Loss: 0.002416 | Recon Loss: 0.002035 | Commit Loss: 0.000763 | Perplexity: 2508.234493
2025-09-30 18:56:15,498 Stage: Train 0.5 | Epoch: 374 | Iter: 445000 | Total Loss: 0.002363 | Recon Loss: 0.001980 | Commit Loss: 0.000767 | Perplexity: 2500.644564
Trainning Epoch:  89%|████████▉ | 586/658 [101:43:03<20:28:09, 1023.46s/it]Trainning Epoch:  89%|████████▉ | 586/658 [101:43:03<20:28:09, 1023.47s/it]2025-09-30 19:00:47,385 Stage: Train 0.5 | Epoch: 375 | Iter: 445200 | Total Loss: 0.002367 | Recon Loss: 0.001988 | Commit Loss: 0.000757 | Perplexity: 2503.890294
2025-09-30 19:05:14,302 Stage: Train 0.5 | Epoch: 375 | Iter: 445400 | Total Loss: 0.002377 | Recon Loss: 0.001994 | Commit Loss: 0.000767 | Perplexity: 2503.971902
2025-09-30 19:09:41,900 Stage: Train 0.5 | Epoch: 375 | Iter: 445600 | Total Loss: 0.002398 | Recon Loss: 0.002017 | Commit Loss: 0.000761 | Perplexity: 2508.921302
Trainning Epoch:  89%|████████▉ | 587/658 [102:00:03<20:09:50, 1022.40s/it]Trainning Epoch:  89%|████████▉ | 587/658 [102:00:03<20:09:51, 1022.42s/it]2025-09-30 19:14:14,377 Stage: Train 0.5 | Epoch: 376 | Iter: 445800 | Total Loss: 0.002349 | Recon Loss: 0.001971 | Commit Loss: 0.000757 | Perplexity: 2503.125051
2025-09-30 19:18:41,477 Stage: Train 0.5 | Epoch: 376 | Iter: 446000 | Total Loss: 0.002371 | Recon Loss: 0.001989 | Commit Loss: 0.000764 | Perplexity: 2497.795137
2025-09-30 19:23:10,281 Stage: Train 0.5 | Epoch: 376 | Iter: 446200 | Total Loss: 0.002361 | Recon Loss: 0.001980 | Commit Loss: 0.000762 | Perplexity: 2502.572468
2025-09-30 19:27:39,170 Stage: Train 0.5 | Epoch: 376 | Iter: 446400 | Total Loss: 0.002397 | Recon Loss: 0.002014 | Commit Loss: 0.000766 | Perplexity: 2506.708251
Trainning Epoch:  89%|████████▉ | 588/658 [102:17:07<19:53:21, 1022.88s/it]Trainning Epoch:  89%|████████▉ | 588/658 [102:17:07<19:53:21, 1022.88s/it]2025-09-30 19:32:11,163 Stage: Train 0.5 | Epoch: 377 | Iter: 446600 | Total Loss: 0.002372 | Recon Loss: 0.001988 | Commit Loss: 0.000767 | Perplexity: 2505.582992
2025-09-30 19:36:38,017 Stage: Train 0.5 | Epoch: 377 | Iter: 446800 | Total Loss: 0.002362 | Recon Loss: 0.001983 | Commit Loss: 0.000758 | Perplexity: 2502.293177
2025-09-30 19:41:06,492 Stage: Train 0.5 | Epoch: 377 | Iter: 447000 | Total Loss: 0.002369 | Recon Loss: 0.001983 | Commit Loss: 0.000771 | Perplexity: 2507.505189
2025-09-30 19:45:35,176 Stage: Train 0.5 | Epoch: 377 | Iter: 447200 | Total Loss: 0.002389 | Recon Loss: 0.002008 | Commit Loss: 0.000762 | Perplexity: 2506.291740
Trainning Epoch:  90%|████████▉ | 589/658 [102:34:09<19:36:15, 1022.83s/it]Trainning Epoch:  90%|████████▉ | 589/658 [102:34:09<19:36:15, 1022.84s/it]2025-09-30 19:50:07,240 Stage: Train 0.5 | Epoch: 378 | Iter: 447400 | Total Loss: 0.002331 | Recon Loss: 0.001948 | Commit Loss: 0.000765 | Perplexity: 2501.460043
2025-09-30 19:54:34,117 Stage: Train 0.5 | Epoch: 378 | Iter: 447600 | Total Loss: 0.002374 | Recon Loss: 0.001989 | Commit Loss: 0.000770 | Perplexity: 2506.899127
2025-09-30 19:58:59,876 Stage: Train 0.5 | Epoch: 378 | Iter: 447800 | Total Loss: 0.002372 | Recon Loss: 0.001988 | Commit Loss: 0.000769 | Perplexity: 2499.636576
2025-09-30 20:03:26,350 Stage: Train 0.5 | Epoch: 378 | Iter: 448000 | Total Loss: 0.002360 | Recon Loss: 0.001980 | Commit Loss: 0.000761 | Perplexity: 2501.762990
Trainning Epoch:  90%|████████▉ | 590/658 [102:51:06<19:17:15, 1021.10s/it]Trainning Epoch:  90%|████████▉ | 590/658 [102:51:06<19:17:14, 1021.10s/it]2025-09-30 20:07:56,410 Stage: Train 0.5 | Epoch: 379 | Iter: 448200 | Total Loss: 0.002349 | Recon Loss: 0.001969 | Commit Loss: 0.000760 | Perplexity: 2507.547388
2025-09-30 20:12:23,448 Stage: Train 0.5 | Epoch: 379 | Iter: 448400 | Total Loss: 0.002345 | Recon Loss: 0.001967 | Commit Loss: 0.000758 | Perplexity: 2498.866425
2025-09-30 20:16:51,239 Stage: Train 0.5 | Epoch: 379 | Iter: 448600 | Total Loss: 0.002395 | Recon Loss: 0.002012 | Commit Loss: 0.000765 | Perplexity: 2504.757965
2025-09-30 20:21:17,397 Stage: Train 0.5 | Epoch: 379 | Iter: 448800 | Total Loss: 0.002391 | Recon Loss: 0.002001 | Commit Loss: 0.000780 | Perplexity: 2512.259893
Trainning Epoch:  90%|████████▉ | 591/658 [103:08:05<18:59:15, 1020.23s/it]Trainning Epoch:  90%|████████▉ | 591/658 [103:08:05<18:59:15, 1020.24s/it]2025-09-30 20:25:43,979 Stage: Train 0.5 | Epoch: 380 | Iter: 449000 | Total Loss: 0.002390 | Recon Loss: 0.002010 | Commit Loss: 0.000760 | Perplexity: 2501.363441
2025-09-30 20:30:08,150 Stage: Train 0.5 | Epoch: 380 | Iter: 449200 | Total Loss: 0.002364 | Recon Loss: 0.001980 | Commit Loss: 0.000767 | Perplexity: 2503.729559
2025-09-30 20:34:33,846 Stage: Train 0.5 | Epoch: 380 | Iter: 449400 | Total Loss: 0.002392 | Recon Loss: 0.002009 | Commit Loss: 0.000766 | Perplexity: 2500.725345
Trainning Epoch:  90%|████████▉ | 592/658 [103:24:53<18:38:15, 1016.60s/it]Trainning Epoch:  90%|████████▉ | 592/658 [103:24:53<18:38:15, 1016.60s/it]2025-09-30 20:39:02,777 Stage: Train 0.5 | Epoch: 381 | Iter: 449600 | Total Loss: 0.002356 | Recon Loss: 0.001973 | Commit Loss: 0.000766 | Perplexity: 2498.846056
2025-09-30 20:43:28,527 Stage: Train 0.5 | Epoch: 381 | Iter: 449800 | Total Loss: 0.002369 | Recon Loss: 0.001979 | Commit Loss: 0.000779 | Perplexity: 2504.805751
2025-09-30 20:47:55,848 Stage: Train 0.5 | Epoch: 381 | Iter: 450000 | Total Loss: 0.002350 | Recon Loss: 0.001964 | Commit Loss: 0.000771 | Perplexity: 2503.783921
2025-09-30 20:52:23,989 Stage: Train 0.5 | Epoch: 381 | Iter: 450200 | Total Loss: 0.002371 | Recon Loss: 0.001986 | Commit Loss: 0.000768 | Perplexity: 2501.772557
Trainning Epoch:  90%|█████████ | 593/658 [103:41:52<18:22:08, 1017.35s/it]Trainning Epoch:  90%|█████████ | 593/658 [103:41:52<18:22:08, 1017.36s/it]2025-09-30 20:56:56,955 Stage: Train 0.5 | Epoch: 382 | Iter: 450400 | Total Loss: 0.002391 | Recon Loss: 0.002011 | Commit Loss: 0.000760 | Perplexity: 2506.119915
2025-09-30 21:01:25,948 Stage: Train 0.5 | Epoch: 382 | Iter: 450600 | Total Loss: 0.002367 | Recon Loss: 0.001984 | Commit Loss: 0.000766 | Perplexity: 2497.231368
2025-09-30 21:05:56,001 Stage: Train 0.5 | Epoch: 382 | Iter: 450800 | Total Loss: 0.002374 | Recon Loss: 0.001989 | Commit Loss: 0.000772 | Perplexity: 2507.296932
2025-09-30 21:10:26,182 Stage: Train 0.5 | Epoch: 382 | Iter: 451000 | Total Loss: 0.002362 | Recon Loss: 0.001975 | Commit Loss: 0.000774 | Perplexity: 2499.691359
Trainning Epoch:  90%|█████████ | 594/658 [103:59:01<18:08:57, 1020.89s/it]Trainning Epoch:  90%|█████████ | 594/658 [103:59:01<18:08:57, 1020.90s/it]2025-09-30 21:14:57,625 Stage: Train 0.5 | Epoch: 383 | Iter: 451200 | Total Loss: 0.002348 | Recon Loss: 0.001969 | Commit Loss: 0.000759 | Perplexity: 2503.095649
2025-09-30 21:19:26,782 Stage: Train 0.5 | Epoch: 383 | Iter: 451400 | Total Loss: 0.002366 | Recon Loss: 0.001984 | Commit Loss: 0.000764 | Perplexity: 2507.692992
2025-09-30 21:23:56,168 Stage: Train 0.5 | Epoch: 383 | Iter: 451600 | Total Loss: 0.002376 | Recon Loss: 0.001996 | Commit Loss: 0.000760 | Perplexity: 2502.268566
2025-09-30 21:28:25,336 Stage: Train 0.5 | Epoch: 383 | Iter: 451800 | Total Loss: 0.002374 | Recon Loss: 0.001990 | Commit Loss: 0.000768 | Perplexity: 2502.080284
Trainning Epoch:  90%|█████████ | 595/658 [104:16:06<17:53:09, 1022.05s/it]Trainning Epoch:  90%|█████████ | 595/658 [104:16:06<17:53:10, 1022.07s/it]2025-09-30 21:32:58,304 Stage: Train 0.5 | Epoch: 384 | Iter: 452000 | Total Loss: 0.002363 | Recon Loss: 0.001980 | Commit Loss: 0.000765 | Perplexity: 2499.682445
2025-09-30 21:37:28,730 Stage: Train 0.5 | Epoch: 384 | Iter: 452200 | Total Loss: 0.002378 | Recon Loss: 0.001996 | Commit Loss: 0.000764 | Perplexity: 2502.291166
2025-09-30 21:41:58,929 Stage: Train 0.5 | Epoch: 384 | Iter: 452400 | Total Loss: 0.002395 | Recon Loss: 0.002007 | Commit Loss: 0.000775 | Perplexity: 2507.859064
2025-09-30 21:46:29,125 Stage: Train 0.5 | Epoch: 384 | Iter: 452600 | Total Loss: 0.002363 | Recon Loss: 0.001977 | Commit Loss: 0.000772 | Perplexity: 2504.097156
Trainning Epoch:  91%|█████████ | 596/658 [104:33:16<17:38:45, 1024.60s/it]Trainning Epoch:  91%|█████████ | 596/658 [104:33:16<17:38:44, 1024.60s/it]2025-09-30 21:51:00,249 Stage: Train 0.5 | Epoch: 385 | Iter: 452800 | Total Loss: 0.002361 | Recon Loss: 0.001980 | Commit Loss: 0.000762 | Perplexity: 2508.224873
2025-09-30 21:55:27,688 Stage: Train 0.5 | Epoch: 385 | Iter: 453000 | Total Loss: 0.002356 | Recon Loss: 0.001976 | Commit Loss: 0.000761 | Perplexity: 2504.538672
2025-09-30 21:59:56,977 Stage: Train 0.5 | Epoch: 385 | Iter: 453200 | Total Loss: 0.002356 | Recon Loss: 0.001972 | Commit Loss: 0.000769 | Perplexity: 2501.855597
Trainning Epoch:  91%|█████████ | 597/658 [104:50:18<17:20:47, 1023.73s/it]Trainning Epoch:  91%|█████████ | 597/658 [104:50:18<17:20:48, 1023.74s/it]2025-09-30 22:04:27,324 Stage: Train 0.5 | Epoch: 386 | Iter: 453400 | Total Loss: 0.002370 | Recon Loss: 0.001984 | Commit Loss: 0.000773 | Perplexity: 2503.257963
2025-09-30 22:08:49,898 Stage: Train 0.5 | Epoch: 386 | Iter: 453600 | Total Loss: 0.002339 | Recon Loss: 0.001959 | Commit Loss: 0.000759 | Perplexity: 2502.246799
2025-09-30 22:13:11,612 Stage: Train 0.5 | Epoch: 386 | Iter: 453800 | Total Loss: 0.002397 | Recon Loss: 0.002016 | Commit Loss: 0.000760 | Perplexity: 2508.782693
2025-09-30 22:17:33,076 Stage: Train 0.5 | Epoch: 386 | Iter: 454000 | Total Loss: 0.002363 | Recon Loss: 0.001978 | Commit Loss: 0.000770 | Perplexity: 2504.523127
Trainning Epoch:  91%|█████████ | 598/658 [105:06:58<16:56:29, 1016.49s/it]Trainning Epoch:  91%|█████████ | 598/658 [105:06:58<16:56:30, 1016.50s/it]2025-09-30 22:21:59,330 Stage: Train 0.5 | Epoch: 387 | Iter: 454200 | Total Loss: 0.002378 | Recon Loss: 0.001995 | Commit Loss: 0.000768 | Perplexity: 2507.238077
2025-09-30 22:26:23,334 Stage: Train 0.5 | Epoch: 387 | Iter: 454400 | Total Loss: 0.002352 | Recon Loss: 0.001970 | Commit Loss: 0.000765 | Perplexity: 2503.148358
2025-09-30 22:30:47,825 Stage: Train 0.5 | Epoch: 387 | Iter: 454600 | Total Loss: 0.002391 | Recon Loss: 0.002006 | Commit Loss: 0.000770 | Perplexity: 2508.894883
2025-09-30 22:35:13,677 Stage: Train 0.5 | Epoch: 387 | Iter: 454800 | Total Loss: 0.002362 | Recon Loss: 0.001975 | Commit Loss: 0.000775 | Perplexity: 2505.654871
Trainning Epoch:  91%|█████████ | 599/658 [105:23:47<16:37:32, 1014.45s/it]Trainning Epoch:  91%|█████████ | 599/658 [105:23:47<16:37:33, 1014.47s/it]2025-09-30 22:39:46,263 Stage: Train 0.5 | Epoch: 388 | Iter: 455000 | Total Loss: 0.002352 | Recon Loss: 0.001973 | Commit Loss: 0.000758 | Perplexity: 2503.603097
2025-09-30 22:44:17,505 Stage: Train 0.5 | Epoch: 388 | Iter: 455200 | Total Loss: 0.002349 | Recon Loss: 0.001962 | Commit Loss: 0.000774 | Perplexity: 2502.121506
2025-09-30 22:48:48,729 Stage: Train 0.5 | Epoch: 388 | Iter: 455400 | Total Loss: 0.002364 | Recon Loss: 0.001982 | Commit Loss: 0.000763 | Perplexity: 2503.618480
2025-09-30 22:53:19,243 Stage: Train 0.5 | Epoch: 388 | Iter: 455600 | Total Loss: 0.002367 | Recon Loss: 0.001983 | Commit Loss: 0.000768 | Perplexity: 2500.107439
Trainning Epoch:  91%|█████████ | 600/658 [105:41:00<16:25:55, 1019.92s/it]Trainning Epoch:  91%|█████████ | 600/658 [105:41:00<16:25:55, 1019.92s/it]2025-09-30 22:57:52,720 Stage: Train 0.5 | Epoch: 389 | Iter: 455800 | Total Loss: 0.002379 | Recon Loss: 0.001999 | Commit Loss: 0.000760 | Perplexity: 2505.675406
2025-09-30 23:02:21,175 Stage: Train 0.5 | Epoch: 389 | Iter: 456000 | Total Loss: 0.002340 | Recon Loss: 0.001958 | Commit Loss: 0.000764 | Perplexity: 2505.760242
2025-09-30 23:06:50,376 Stage: Train 0.5 | Epoch: 389 | Iter: 456200 | Total Loss: 0.002372 | Recon Loss: 0.001985 | Commit Loss: 0.000773 | Perplexity: 2504.633202
2025-09-30 23:11:20,218 Stage: Train 0.5 | Epoch: 389 | Iter: 456400 | Total Loss: 0.002377 | Recon Loss: 0.001990 | Commit Loss: 0.000772 | Perplexity: 2501.920396
Trainning Epoch:  91%|█████████▏| 601/658 [105:58:07<16:11:02, 1022.14s/it]Trainning Epoch:  91%|█████████▏| 601/658 [105:58:07<16:11:03, 1022.17s/it]2025-09-30 23:15:54,484 Stage: Train 0.5 | Epoch: 390 | Iter: 456600 | Total Loss: 0.002362 | Recon Loss: 0.001980 | Commit Loss: 0.000763 | Perplexity: 2496.677802
2025-09-30 23:20:24,675 Stage: Train 0.5 | Epoch: 390 | Iter: 456800 | Total Loss: 0.002346 | Recon Loss: 0.001965 | Commit Loss: 0.000763 | Perplexity: 2498.734417
2025-09-30 23:24:55,337 Stage: Train 0.5 | Epoch: 390 | Iter: 457000 | Total Loss: 0.002375 | Recon Loss: 0.001989 | Commit Loss: 0.000772 | Perplexity: 2502.827953
Trainning Epoch:  91%|█████████▏| 602/658 [106:15:19<15:56:32, 1024.86s/it]Trainning Epoch:  91%|█████████▏| 602/658 [106:15:19<15:56:32, 1024.87s/it]2025-09-30 23:29:29,956 Stage: Train 0.5 | Epoch: 391 | Iter: 457200 | Total Loss: 0.002373 | Recon Loss: 0.001989 | Commit Loss: 0.000768 | Perplexity: 2509.953987
2025-09-30 23:33:59,593 Stage: Train 0.5 | Epoch: 391 | Iter: 457400 | Total Loss: 0.002359 | Recon Loss: 0.001972 | Commit Loss: 0.000774 | Perplexity: 2506.147798
2025-09-30 23:38:30,445 Stage: Train 0.5 | Epoch: 391 | Iter: 457600 | Total Loss: 0.002371 | Recon Loss: 0.001988 | Commit Loss: 0.000767 | Perplexity: 2503.361135
2025-09-30 23:43:00,954 Stage: Train 0.5 | Epoch: 391 | Iter: 457800 | Total Loss: 0.002382 | Recon Loss: 0.002000 | Commit Loss: 0.000763 | Perplexity: 2501.495393
Trainning Epoch:  92%|█████████▏| 603/658 [106:32:29<15:41:05, 1026.64s/it]Trainning Epoch:  92%|█████████▏| 603/658 [106:32:29<15:41:05, 1026.64s/it]2025-09-30 23:47:33,267 Stage: Train 0.5 | Epoch: 392 | Iter: 458000 | Total Loss: 0.002366 | Recon Loss: 0.001983 | Commit Loss: 0.000766 | Perplexity: 2504.278253
2025-09-30 23:51:59,094 Stage: Train 0.5 | Epoch: 392 | Iter: 458200 | Total Loss: 0.002364 | Recon Loss: 0.001982 | Commit Loss: 0.000764 | Perplexity: 2502.058638
2025-09-30 23:56:27,037 Stage: Train 0.5 | Epoch: 392 | Iter: 458400 | Total Loss: 0.002363 | Recon Loss: 0.001977 | Commit Loss: 0.000772 | Perplexity: 2506.720007
2025-10-01 00:00:54,911 Stage: Train 0.5 | Epoch: 392 | Iter: 458600 | Total Loss: 0.002367 | Recon Loss: 0.001987 | Commit Loss: 0.000761 | Perplexity: 2496.252677
Trainning Epoch:  92%|█████████▏| 604/658 [106:49:30<15:22:14, 1024.71s/it]Trainning Epoch:  92%|█████████▏| 604/658 [106:49:30<15:22:14, 1024.72s/it]2025-10-01 00:05:29,509 Stage: Train 0.5 | Epoch: 393 | Iter: 458800 | Total Loss: 0.002367 | Recon Loss: 0.001988 | Commit Loss: 0.000758 | Perplexity: 2497.426923
2025-10-01 00:09:57,929 Stage: Train 0.5 | Epoch: 393 | Iter: 459000 | Total Loss: 0.002351 | Recon Loss: 0.001968 | Commit Loss: 0.000767 | Perplexity: 2509.084355
2025-10-01 00:14:26,185 Stage: Train 0.5 | Epoch: 393 | Iter: 459200 | Total Loss: 0.002341 | Recon Loss: 0.001955 | Commit Loss: 0.000771 | Perplexity: 2502.732015
2025-10-01 00:18:56,527 Stage: Train 0.5 | Epoch: 393 | Iter: 459400 | Total Loss: 0.002379 | Recon Loss: 0.001990 | Commit Loss: 0.000778 | Perplexity: 2504.731656
Trainning Epoch:  92%|█████████▏| 605/658 [107:06:37<15:05:50, 1025.49s/it]Trainning Epoch:  92%|█████████▏| 605/658 [107:06:37<15:05:51, 1025.49s/it]2025-10-01 00:23:28,101 Stage: Train 0.5 | Epoch: 394 | Iter: 459600 | Total Loss: 0.002365 | Recon Loss: 0.001983 | Commit Loss: 0.000765 | Perplexity: 2504.500745
2025-10-01 00:27:55,867 Stage: Train 0.5 | Epoch: 394 | Iter: 459800 | Total Loss: 0.002364 | Recon Loss: 0.001984 | Commit Loss: 0.000760 | Perplexity: 2502.632865
2025-10-01 00:32:23,332 Stage: Train 0.5 | Epoch: 394 | Iter: 460000 | Total Loss: 0.002388 | Recon Loss: 0.001998 | Commit Loss: 0.000778 | Perplexity: 2504.404371
2025-10-01 00:32:23,333 Saving model at iteration 460000
2025-10-01 00:32:23,629 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_395_step_460000
2025-10-01 00:32:24,187 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_395_step_460000/model.safetensors
2025-10-01 00:32:24,634 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_395_step_460000/optimizer.bin
2025-10-01 00:32:24,634 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_395_step_460000/scheduler.bin
2025-10-01 00:32:24,635 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_395_step_460000/sampler.bin
2025-10-01 00:32:24,636 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_395_step_460000/random_states_0.pkl
2025-10-01 00:36:53,162 Stage: Train 0.5 | Epoch: 394 | Iter: 460200 | Total Loss: 0.002357 | Recon Loss: 0.001972 | Commit Loss: 0.000769 | Perplexity: 2509.656689
Trainning Epoch:  92%|█████████▏| 606/658 [107:23:40<14:48:14, 1024.89s/it]Trainning Epoch:  92%|█████████▏| 606/658 [107:23:40<14:48:13, 1024.88s/it]2025-10-01 00:41:19,279 Stage: Train 0.5 | Epoch: 395 | Iter: 460400 | Total Loss: 0.002349 | Recon Loss: 0.001969 | Commit Loss: 0.000760 | Perplexity: 2502.311558
2025-10-01 00:45:41,284 Stage: Train 0.5 | Epoch: 395 | Iter: 460600 | Total Loss: 0.002342 | Recon Loss: 0.001957 | Commit Loss: 0.000770 | Perplexity: 2505.342826
2025-10-01 00:50:03,198 Stage: Train 0.5 | Epoch: 395 | Iter: 460800 | Total Loss: 0.002372 | Recon Loss: 0.001990 | Commit Loss: 0.000764 | Perplexity: 2503.131782
Trainning Epoch:  92%|█████████▏| 607/658 [107:40:20<14:24:43, 1017.32s/it]Trainning Epoch:  92%|█████████▏| 607/658 [107:40:20<14:24:43, 1017.33s/it]2025-10-01 00:54:31,360 Stage: Train 0.5 | Epoch: 396 | Iter: 461000 | Total Loss: 0.002353 | Recon Loss: 0.001966 | Commit Loss: 0.000775 | Perplexity: 2499.166576
2025-10-01 00:58:59,978 Stage: Train 0.5 | Epoch: 396 | Iter: 461200 | Total Loss: 0.002364 | Recon Loss: 0.001980 | Commit Loss: 0.000768 | Perplexity: 2502.073433
2025-10-01 01:03:28,477 Stage: Train 0.5 | Epoch: 396 | Iter: 461400 | Total Loss: 0.002360 | Recon Loss: 0.001975 | Commit Loss: 0.000770 | Perplexity: 2503.917295
2025-10-01 01:07:58,212 Stage: Train 0.5 | Epoch: 396 | Iter: 461600 | Total Loss: 0.002360 | Recon Loss: 0.001979 | Commit Loss: 0.000761 | Perplexity: 2497.137523
Trainning Epoch:  92%|█████████▏| 608/658 [107:57:26<14:10:02, 1020.06s/it]Trainning Epoch:  92%|█████████▏| 608/658 [107:57:26<14:10:02, 1020.05s/it]2025-10-01 01:12:32,000 Stage: Train 0.5 | Epoch: 397 | Iter: 461800 | Total Loss: 0.002366 | Recon Loss: 0.001982 | Commit Loss: 0.000767 | Perplexity: 2500.811704
2025-10-01 01:17:01,683 Stage: Train 0.5 | Epoch: 397 | Iter: 462000 | Total Loss: 0.002327 | Recon Loss: 0.001945 | Commit Loss: 0.000764 | Perplexity: 2500.894517
2025-10-01 01:21:32,118 Stage: Train 0.5 | Epoch: 397 | Iter: 462200 | Total Loss: 0.002372 | Recon Loss: 0.001981 | Commit Loss: 0.000782 | Perplexity: 2511.761863
2025-10-01 01:26:01,480 Stage: Train 0.5 | Epoch: 397 | Iter: 462400 | Total Loss: 0.002357 | Recon Loss: 0.001973 | Commit Loss: 0.000767 | Perplexity: 2501.891300
Trainning Epoch:  93%|█████████▎| 609/658 [108:14:36<13:55:20, 1022.86s/it]Trainning Epoch:  93%|█████████▎| 609/658 [108:14:36<13:55:20, 1022.86s/it]2025-10-01 01:30:34,074 Stage: Train 0.5 | Epoch: 398 | Iter: 462600 | Total Loss: 0.002340 | Recon Loss: 0.001962 | Commit Loss: 0.000756 | Perplexity: 2499.298303
2025-10-01 01:35:03,333 Stage: Train 0.5 | Epoch: 398 | Iter: 462800 | Total Loss: 0.002374 | Recon Loss: 0.001992 | Commit Loss: 0.000763 | Perplexity: 2502.070316
2025-10-01 01:39:33,086 Stage: Train 0.5 | Epoch: 398 | Iter: 463000 | Total Loss: 0.002366 | Recon Loss: 0.001977 | Commit Loss: 0.000777 | Perplexity: 2504.649617
2025-10-01 01:44:02,081 Stage: Train 0.5 | Epoch: 398 | Iter: 463200 | Total Loss: 0.002354 | Recon Loss: 0.001971 | Commit Loss: 0.000764 | Perplexity: 2508.347098
Trainning Epoch:  93%|█████████▎| 610/658 [108:31:43<13:39:15, 1024.06s/it]Trainning Epoch:  93%|█████████▎| 610/658 [108:31:43<13:39:15, 1024.07s/it]2025-10-01 01:48:34,826 Stage: Train 0.5 | Epoch: 399 | Iter: 463400 | Total Loss: 0.002348 | Recon Loss: 0.001966 | Commit Loss: 0.000764 | Perplexity: 2506.627395
2025-10-01 01:53:02,875 Stage: Train 0.5 | Epoch: 399 | Iter: 463600 | Total Loss: 0.002363 | Recon Loss: 0.001976 | Commit Loss: 0.000774 | Perplexity: 2505.823055
2025-10-01 01:57:31,573 Stage: Train 0.5 | Epoch: 399 | Iter: 463800 | Total Loss: 0.002385 | Recon Loss: 0.002004 | Commit Loss: 0.000763 | Perplexity: 2503.180980
2025-10-01 02:02:00,802 Stage: Train 0.5 | Epoch: 399 | Iter: 464000 | Total Loss: 0.002347 | Recon Loss: 0.001955 | Commit Loss: 0.000785 | Perplexity: 2503.020072
Trainning Epoch:  93%|█████████▎| 611/658 [108:48:48<13:22:27, 1024.42s/it]Trainning Epoch:  93%|█████████▎| 611/658 [108:48:48<13:22:27, 1024.42s/it]2025-10-01 02:06:33,273 Stage: Train 0.5 | Epoch: 400 | Iter: 464200 | Total Loss: 0.002381 | Recon Loss: 0.001994 | Commit Loss: 0.000774 | Perplexity: 2506.191232
2025-10-01 02:11:02,272 Stage: Train 0.5 | Epoch: 400 | Iter: 464400 | Total Loss: 0.002356 | Recon Loss: 0.001974 | Commit Loss: 0.000764 | Perplexity: 2500.310225
2025-10-01 02:15:32,762 Stage: Train 0.5 | Epoch: 400 | Iter: 464600 | Total Loss: 0.002384 | Recon Loss: 0.001996 | Commit Loss: 0.000777 | Perplexity: 2499.380668
Trainning Epoch:  93%|█████████▎| 612/658 [109:05:55<13:05:52, 1025.05s/it]Trainning Epoch:  93%|█████████▎| 612/658 [109:05:55<13:05:52, 1025.05s/it]2025-10-01 02:20:05,935 Stage: Train 0.5 | Epoch: 401 | Iter: 464800 | Total Loss: 0.002344 | Recon Loss: 0.001963 | Commit Loss: 0.000763 | Perplexity: 2500.661814
2025-10-01 02:24:31,830 Stage: Train 0.5 | Epoch: 401 | Iter: 465000 | Total Loss: 0.002359 | Recon Loss: 0.001977 | Commit Loss: 0.000763 | Perplexity: 2507.724410
2025-10-01 02:29:01,034 Stage: Train 0.5 | Epoch: 401 | Iter: 465200 | Total Loss: 0.002349 | Recon Loss: 0.001966 | Commit Loss: 0.000767 | Perplexity: 2497.311433
2025-10-01 02:33:31,419 Stage: Train 0.5 | Epoch: 401 | Iter: 465400 | Total Loss: 0.002365 | Recon Loss: 0.001982 | Commit Loss: 0.000765 | Perplexity: 2505.803813
Trainning Epoch:  93%|█████████▎| 613/658 [109:22:59<12:48:45, 1025.02s/it]Trainning Epoch:  93%|█████████▎| 613/658 [109:22:59<12:48:46, 1025.02s/it]2025-10-01 02:38:06,752 Stage: Train 0.5 | Epoch: 402 | Iter: 465600 | Total Loss: 0.002350 | Recon Loss: 0.001957 | Commit Loss: 0.000786 | Perplexity: 2507.790618
2025-10-01 02:42:39,079 Stage: Train 0.5 | Epoch: 402 | Iter: 465800 | Total Loss: 0.002361 | Recon Loss: 0.001977 | Commit Loss: 0.000767 | Perplexity: 2502.385753
2025-10-01 02:47:09,701 Stage: Train 0.5 | Epoch: 402 | Iter: 466000 | Total Loss: 0.002355 | Recon Loss: 0.001969 | Commit Loss: 0.000772 | Perplexity: 2504.393058
2025-10-01 02:51:40,801 Stage: Train 0.5 | Epoch: 402 | Iter: 466200 | Total Loss: 0.002353 | Recon Loss: 0.001970 | Commit Loss: 0.000766 | Perplexity: 2494.969515
Trainning Epoch:  93%|█████████▎| 614/658 [109:40:16<12:34:16, 1028.55s/it]Trainning Epoch:  93%|█████████▎| 614/658 [109:40:16<12:34:16, 1028.55s/it]2025-10-01 02:56:13,119 Stage: Train 0.5 | Epoch: 403 | Iter: 466400 | Total Loss: 0.002341 | Recon Loss: 0.001960 | Commit Loss: 0.000761 | Perplexity: 2499.608528
2025-10-01 03:00:39,493 Stage: Train 0.5 | Epoch: 403 | Iter: 466600 | Total Loss: 0.002340 | Recon Loss: 0.001951 | Commit Loss: 0.000779 | Perplexity: 2506.025150
2025-10-01 03:05:08,031 Stage: Train 0.5 | Epoch: 403 | Iter: 466800 | Total Loss: 0.002353 | Recon Loss: 0.001963 | Commit Loss: 0.000779 | Perplexity: 2507.272246
2025-10-01 03:09:36,348 Stage: Train 0.5 | Epoch: 403 | Iter: 467000 | Total Loss: 0.002403 | Recon Loss: 0.002016 | Commit Loss: 0.000775 | Perplexity: 2497.908236
Trainning Epoch:  93%|█████████▎| 615/658 [109:57:17<12:15:25, 1026.18s/it]Trainning Epoch:  93%|█████████▎| 615/658 [109:57:17<12:15:25, 1026.18s/it]2025-10-01 03:14:08,120 Stage: Train 0.5 | Epoch: 404 | Iter: 467200 | Total Loss: 0.002350 | Recon Loss: 0.001971 | Commit Loss: 0.000758 | Perplexity: 2501.356471
2025-10-01 03:18:37,304 Stage: Train 0.5 | Epoch: 404 | Iter: 467400 | Total Loss: 0.002372 | Recon Loss: 0.001985 | Commit Loss: 0.000774 | Perplexity: 2506.061282
2025-10-01 03:23:06,738 Stage: Train 0.5 | Epoch: 404 | Iter: 467600 | Total Loss: 0.002377 | Recon Loss: 0.001992 | Commit Loss: 0.000769 | Perplexity: 2502.806747
2025-10-01 03:27:35,403 Stage: Train 0.5 | Epoch: 404 | Iter: 467800 | Total Loss: 0.002342 | Recon Loss: 0.001956 | Commit Loss: 0.000772 | Perplexity: 2500.437321
Trainning Epoch:  94%|█████████▎| 616/658 [110:14:23<11:58:13, 1026.04s/it]Trainning Epoch:  94%|█████████▎| 616/658 [110:14:23<11:58:13, 1026.04s/it]2025-10-01 03:32:02,330 Stage: Train 0.5 | Epoch: 405 | Iter: 468000 | Total Loss: 0.002362 | Recon Loss: 0.001973 | Commit Loss: 0.000777 | Perplexity: 2502.765554
2025-10-01 03:36:25,098 Stage: Train 0.5 | Epoch: 405 | Iter: 468200 | Total Loss: 0.002339 | Recon Loss: 0.001961 | Commit Loss: 0.000757 | Perplexity: 2503.007042
2025-10-01 03:40:48,259 Stage: Train 0.5 | Epoch: 405 | Iter: 468400 | Total Loss: 0.002367 | Recon Loss: 0.001988 | Commit Loss: 0.000759 | Perplexity: 2511.140192
Trainning Epoch:  94%|█████████▍| 617/658 [110:31:06<11:36:29, 1019.27s/it]Trainning Epoch:  94%|█████████▍| 617/658 [110:31:06<11:36:30, 1019.28s/it]2025-10-01 03:45:15,787 Stage: Train 0.5 | Epoch: 406 | Iter: 468600 | Total Loss: 0.002379 | Recon Loss: 0.001995 | Commit Loss: 0.000768 | Perplexity: 2504.151261
2025-10-01 03:49:36,501 Stage: Train 0.5 | Epoch: 406 | Iter: 468800 | Total Loss: 0.002356 | Recon Loss: 0.001978 | Commit Loss: 0.000757 | Perplexity: 2498.926671
2025-10-01 03:53:55,966 Stage: Train 0.5 | Epoch: 406 | Iter: 469000 | Total Loss: 0.002364 | Recon Loss: 0.001974 | Commit Loss: 0.000779 | Perplexity: 2499.456171
2025-10-01 03:58:16,429 Stage: Train 0.5 | Epoch: 406 | Iter: 469200 | Total Loss: 0.002368 | Recon Loss: 0.001981 | Commit Loss: 0.000773 | Perplexity: 2506.429532
Trainning Epoch:  94%|█████████▍| 618/658 [110:47:40<11:14:20, 1011.52s/it]Trainning Epoch:  94%|█████████▍| 618/658 [110:47:40<11:14:21, 1011.53s/it]2025-10-01 04:02:46,048 Stage: Train 0.5 | Epoch: 407 | Iter: 469400 | Total Loss: 0.002336 | Recon Loss: 0.001949 | Commit Loss: 0.000775 | Perplexity: 2501.302238
2025-10-01 04:07:15,897 Stage: Train 0.5 | Epoch: 407 | Iter: 469600 | Total Loss: 0.002340 | Recon Loss: 0.001958 | Commit Loss: 0.000763 | Perplexity: 2502.286295
2025-10-01 04:11:45,531 Stage: Train 0.5 | Epoch: 407 | Iter: 469800 | Total Loss: 0.002341 | Recon Loss: 0.001957 | Commit Loss: 0.000768 | Perplexity: 2503.728445
2025-10-01 04:16:16,246 Stage: Train 0.5 | Epoch: 407 | Iter: 470000 | Total Loss: 0.002342 | Recon Loss: 0.001955 | Commit Loss: 0.000775 | Perplexity: 2501.136361
Trainning Epoch:  94%|█████████▍| 619/658 [111:04:51<11:01:22, 1017.49s/it]Trainning Epoch:  94%|█████████▍| 619/658 [111:04:51<11:01:21, 1017.49s/it]2025-10-01 04:20:50,721 Stage: Train 0.5 | Epoch: 408 | Iter: 470200 | Total Loss: 0.002355 | Recon Loss: 0.001972 | Commit Loss: 0.000766 | Perplexity: 2504.194363
2025-10-01 04:25:19,789 Stage: Train 0.5 | Epoch: 408 | Iter: 470400 | Total Loss: 0.002344 | Recon Loss: 0.001962 | Commit Loss: 0.000764 | Perplexity: 2503.655593
2025-10-01 04:29:50,236 Stage: Train 0.5 | Epoch: 408 | Iter: 470600 | Total Loss: 0.002363 | Recon Loss: 0.001978 | Commit Loss: 0.000770 | Perplexity: 2500.365571
2025-10-01 04:34:20,611 Stage: Train 0.5 | Epoch: 408 | Iter: 470800 | Total Loss: 0.002357 | Recon Loss: 0.001970 | Commit Loss: 0.000775 | Perplexity: 2501.915479
Trainning Epoch:  94%|█████████▍| 620/658 [111:22:02<10:46:54, 1021.44s/it]Trainning Epoch:  94%|█████████▍| 620/658 [111:22:02<10:46:54, 1021.44s/it]2025-10-01 04:38:52,151 Stage: Train 0.5 | Epoch: 409 | Iter: 471000 | Total Loss: 0.002354 | Recon Loss: 0.001970 | Commit Loss: 0.000767 | Perplexity: 2504.019945
2025-10-01 04:43:17,310 Stage: Train 0.5 | Epoch: 409 | Iter: 471200 | Total Loss: 0.002350 | Recon Loss: 0.001964 | Commit Loss: 0.000770 | Perplexity: 2499.318492
2025-10-01 04:47:41,897 Stage: Train 0.5 | Epoch: 409 | Iter: 471400 | Total Loss: 0.002380 | Recon Loss: 0.001994 | Commit Loss: 0.000771 | Perplexity: 2502.453962
2025-10-01 04:52:08,121 Stage: Train 0.5 | Epoch: 409 | Iter: 471600 | Total Loss: 0.002345 | Recon Loss: 0.001959 | Commit Loss: 0.000773 | Perplexity: 2502.925411
Trainning Epoch:  94%|█████████▍| 621/658 [111:38:55<10:28:27, 1019.12s/it]Trainning Epoch:  94%|█████████▍| 621/658 [111:38:55<10:28:27, 1019.12s/it]2025-10-01 04:56:38,048 Stage: Train 0.5 | Epoch: 410 | Iter: 471800 | Total Loss: 0.002351 | Recon Loss: 0.001969 | Commit Loss: 0.000766 | Perplexity: 2503.006877
2025-10-01 05:01:05,157 Stage: Train 0.5 | Epoch: 410 | Iter: 472000 | Total Loss: 0.002348 | Recon Loss: 0.001960 | Commit Loss: 0.000777 | Perplexity: 2508.218188
2025-10-01 05:05:31,921 Stage: Train 0.5 | Epoch: 410 | Iter: 472200 | Total Loss: 0.002343 | Recon Loss: 0.001953 | Commit Loss: 0.000779 | Perplexity: 2504.852798
Trainning Epoch:  95%|█████████▍| 622/658 [111:55:53<10:11:09, 1018.61s/it]Trainning Epoch:  95%|█████████▍| 622/658 [111:55:53<10:11:10, 1018.62s/it]2025-10-01 05:10:02,626 Stage: Train 0.5 | Epoch: 411 | Iter: 472400 | Total Loss: 0.002356 | Recon Loss: 0.001968 | Commit Loss: 0.000776 | Perplexity: 2508.979442
2025-10-01 05:14:25,211 Stage: Train 0.5 | Epoch: 411 | Iter: 472600 | Total Loss: 0.002360 | Recon Loss: 0.001979 | Commit Loss: 0.000762 | Perplexity: 2498.456174
2025-10-01 05:18:47,070 Stage: Train 0.5 | Epoch: 411 | Iter: 472800 | Total Loss: 0.002334 | Recon Loss: 0.001949 | Commit Loss: 0.000770 | Perplexity: 2503.194905
2025-10-01 05:23:11,865 Stage: Train 0.5 | Epoch: 411 | Iter: 473000 | Total Loss: 0.002359 | Recon Loss: 0.001976 | Commit Loss: 0.000766 | Perplexity: 2497.570947
Trainning Epoch:  95%|█████████▍| 623/658 [112:12:37<9:51:38, 1014.24s/it] Trainning Epoch:  95%|█████████▍| 623/658 [112:12:37<9:51:38, 1014.26s/it] 2025-10-01 05:27:41,124 Stage: Train 0.5 | Epoch: 412 | Iter: 473200 | Total Loss: 0.002358 | Recon Loss: 0.001970 | Commit Loss: 0.000776 | Perplexity: 2499.129535
2025-10-01 05:32:10,082 Stage: Train 0.5 | Epoch: 412 | Iter: 473400 | Total Loss: 0.002337 | Recon Loss: 0.001959 | Commit Loss: 0.000755 | Perplexity: 2501.213224
2025-10-01 05:36:38,565 Stage: Train 0.5 | Epoch: 412 | Iter: 473600 | Total Loss: 0.002334 | Recon Loss: 0.001953 | Commit Loss: 0.000762 | Perplexity: 2499.386345
2025-10-01 05:41:06,752 Stage: Train 0.5 | Epoch: 412 | Iter: 473800 | Total Loss: 0.002359 | Recon Loss: 0.001973 | Commit Loss: 0.000771 | Perplexity: 2503.082014
Trainning Epoch:  95%|█████████▍| 624/658 [112:29:41<9:36:29, 1017.34s/it]Trainning Epoch:  95%|█████████▍| 624/658 [112:29:41<9:36:30, 1017.36s/it]2025-10-01 05:45:40,289 Stage: Train 0.5 | Epoch: 413 | Iter: 474000 | Total Loss: 0.002349 | Recon Loss: 0.001959 | Commit Loss: 0.000781 | Perplexity: 2505.878132
2025-10-01 05:50:09,214 Stage: Train 0.5 | Epoch: 413 | Iter: 474200 | Total Loss: 0.002355 | Recon Loss: 0.001974 | Commit Loss: 0.000762 | Perplexity: 2502.533132
2025-10-01 05:54:39,507 Stage: Train 0.5 | Epoch: 413 | Iter: 474400 | Total Loss: 0.002334 | Recon Loss: 0.001953 | Commit Loss: 0.000761 | Perplexity: 2496.114132
2025-10-01 05:59:08,572 Stage: Train 0.5 | Epoch: 413 | Iter: 474600 | Total Loss: 0.002358 | Recon Loss: 0.001968 | Commit Loss: 0.000780 | Perplexity: 2503.586761
Trainning Epoch:  95%|█████████▍| 625/658 [112:46:49<9:21:13, 1020.41s/it]Trainning Epoch:  95%|█████████▍| 625/658 [112:46:49<9:21:13, 1020.41s/it]2025-10-01 06:03:38,536 Stage: Train 0.5 | Epoch: 414 | Iter: 474800 | Total Loss: 0.002336 | Recon Loss: 0.001953 | Commit Loss: 0.000767 | Perplexity: 2501.097040
2025-10-01 06:08:02,278 Stage: Train 0.5 | Epoch: 414 | Iter: 475000 | Total Loss: 0.002356 | Recon Loss: 0.001965 | Commit Loss: 0.000782 | Perplexity: 2505.869027
2025-10-01 06:12:27,343 Stage: Train 0.5 | Epoch: 414 | Iter: 475200 | Total Loss: 0.002351 | Recon Loss: 0.001968 | Commit Loss: 0.000765 | Perplexity: 2504.393584
2025-10-01 06:16:52,969 Stage: Train 0.5 | Epoch: 414 | Iter: 475400 | Total Loss: 0.002362 | Recon Loss: 0.001976 | Commit Loss: 0.000773 | Perplexity: 2496.868518
Trainning Epoch:  95%|█████████▌| 626/658 [113:03:40<9:02:44, 1017.64s/it]Trainning Epoch:  95%|█████████▌| 626/658 [113:03:40<9:02:44, 1017.64s/it]2025-10-01 06:21:17,819 Stage: Train 0.5 | Epoch: 415 | Iter: 475600 | Total Loss: 0.002314 | Recon Loss: 0.001930 | Commit Loss: 0.000767 | Perplexity: 2504.489712
2025-10-01 06:25:42,062 Stage: Train 0.5 | Epoch: 415 | Iter: 475800 | Total Loss: 0.002371 | Recon Loss: 0.001985 | Commit Loss: 0.000770 | Perplexity: 2506.255161
2025-10-01 06:30:05,898 Stage: Train 0.5 | Epoch: 415 | Iter: 476000 | Total Loss: 0.002348 | Recon Loss: 0.001963 | Commit Loss: 0.000771 | Perplexity: 2500.997490
Trainning Epoch:  95%|█████████▌| 627/658 [113:20:24<8:43:39, 1013.54s/it]Trainning Epoch:  95%|█████████▌| 627/658 [113:20:24<8:43:39, 1013.53s/it]2025-10-01 06:34:35,576 Stage: Train 0.5 | Epoch: 416 | Iter: 476200 | Total Loss: 0.002370 | Recon Loss: 0.001980 | Commit Loss: 0.000780 | Perplexity: 2502.919979
2025-10-01 06:39:02,378 Stage: Train 0.5 | Epoch: 416 | Iter: 476400 | Total Loss: 0.002348 | Recon Loss: 0.001959 | Commit Loss: 0.000780 | Perplexity: 2508.116184
2025-10-01 06:43:28,468 Stage: Train 0.5 | Epoch: 416 | Iter: 476600 | Total Loss: 0.002333 | Recon Loss: 0.001943 | Commit Loss: 0.000779 | Perplexity: 2502.347919
2025-10-01 06:47:56,631 Stage: Train 0.5 | Epoch: 416 | Iter: 476800 | Total Loss: 0.002354 | Recon Loss: 0.001970 | Commit Loss: 0.000767 | Perplexity: 2505.733533
Trainning Epoch:  95%|█████████▌| 628/658 [113:37:24<8:27:40, 1015.34s/it]Trainning Epoch:  95%|█████████▌| 628/658 [113:37:24<8:27:40, 1015.34s/it]2025-10-01 06:52:26,222 Stage: Train 0.5 | Epoch: 417 | Iter: 477000 | Total Loss: 0.002346 | Recon Loss: 0.001964 | Commit Loss: 0.000764 | Perplexity: 2498.752531
2025-10-01 06:56:51,037 Stage: Train 0.5 | Epoch: 417 | Iter: 477200 | Total Loss: 0.002341 | Recon Loss: 0.001958 | Commit Loss: 0.000766 | Perplexity: 2504.098584
2025-10-01 07:01:15,787 Stage: Train 0.5 | Epoch: 417 | Iter: 477400 | Total Loss: 0.002346 | Recon Loss: 0.001963 | Commit Loss: 0.000767 | Perplexity: 2503.930450
2025-10-01 07:05:40,113 Stage: Train 0.5 | Epoch: 417 | Iter: 477600 | Total Loss: 0.002348 | Recon Loss: 0.001965 | Commit Loss: 0.000767 | Perplexity: 2501.919447
Trainning Epoch:  96%|█████████▌| 629/658 [113:54:14<8:09:57, 1013.72s/it]Trainning Epoch:  96%|█████████▌| 629/658 [113:54:14<8:09:58, 1013.73s/it]2025-10-01 07:10:09,291 Stage: Train 0.5 | Epoch: 418 | Iter: 477800 | Total Loss: 0.002372 | Recon Loss: 0.001987 | Commit Loss: 0.000771 | Perplexity: 2503.016495
2025-10-01 07:14:34,918 Stage: Train 0.5 | Epoch: 418 | Iter: 478000 | Total Loss: 0.002304 | Recon Loss: 0.001918 | Commit Loss: 0.000773 | Perplexity: 2500.216420
2025-10-01 07:19:01,021 Stage: Train 0.5 | Epoch: 418 | Iter: 478200 | Total Loss: 0.002359 | Recon Loss: 0.001972 | Commit Loss: 0.000773 | Perplexity: 2501.670779
2025-10-01 07:23:28,257 Stage: Train 0.5 | Epoch: 418 | Iter: 478400 | Total Loss: 0.002360 | Recon Loss: 0.001980 | Commit Loss: 0.000760 | Perplexity: 2503.725416
Trainning Epoch:  96%|█████████▌| 630/658 [114:11:08<7:53:13, 1014.06s/it]Trainning Epoch:  96%|█████████▌| 630/658 [114:11:08<7:53:14, 1014.07s/it]2025-10-01 07:27:59,066 Stage: Train 0.5 | Epoch: 419 | Iter: 478600 | Total Loss: 0.002323 | Recon Loss: 0.001937 | Commit Loss: 0.000772 | Perplexity: 2501.681952
2025-10-01 07:32:27,817 Stage: Train 0.5 | Epoch: 419 | Iter: 478800 | Total Loss: 0.002361 | Recon Loss: 0.001982 | Commit Loss: 0.000759 | Perplexity: 2507.052952
2025-10-01 07:36:57,637 Stage: Train 0.5 | Epoch: 419 | Iter: 479000 | Total Loss: 0.002335 | Recon Loss: 0.001951 | Commit Loss: 0.000769 | Perplexity: 2506.636260
2025-10-01 07:41:27,286 Stage: Train 0.5 | Epoch: 419 | Iter: 479200 | Total Loss: 0.002337 | Recon Loss: 0.001947 | Commit Loss: 0.000779 | Perplexity: 2499.650396
Trainning Epoch:  96%|█████████▌| 631/658 [114:28:14<7:37:56, 1017.65s/it]Trainning Epoch:  96%|█████████▌| 631/658 [114:28:14<7:37:56, 1017.65s/it]2025-10-01 07:46:00,583 Stage: Train 0.5 | Epoch: 420 | Iter: 479400 | Total Loss: 0.002339 | Recon Loss: 0.001956 | Commit Loss: 0.000765 | Perplexity: 2502.817137
2025-10-01 07:50:29,182 Stage: Train 0.5 | Epoch: 420 | Iter: 479600 | Total Loss: 0.002328 | Recon Loss: 0.001942 | Commit Loss: 0.000773 | Perplexity: 2504.051898
2025-10-01 07:54:59,118 Stage: Train 0.5 | Epoch: 420 | Iter: 479800 | Total Loss: 0.002348 | Recon Loss: 0.001964 | Commit Loss: 0.000768 | Perplexity: 2502.291050
Trainning Epoch:  96%|█████████▌| 632/658 [114:45:22<7:22:16, 1020.62s/it]Trainning Epoch:  96%|█████████▌| 632/658 [114:45:22<7:22:16, 1020.63s/it]2025-10-01 07:59:32,695 Stage: Train 0.5 | Epoch: 421 | Iter: 480000 | Total Loss: 0.002325 | Recon Loss: 0.001938 | Commit Loss: 0.000774 | Perplexity: 2504.665725
2025-10-01 07:59:32,696 Saving model at iteration 480000
2025-10-01 07:59:32,907 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_422_step_480000
2025-10-01 07:59:33,447 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_422_step_480000/model.safetensors
2025-10-01 07:59:33,918 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_422_step_480000/optimizer.bin
2025-10-01 07:59:33,918 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_422_step_480000/scheduler.bin
2025-10-01 07:59:33,918 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_422_step_480000/sampler.bin
2025-10-01 07:59:33,919 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_422_step_480000/random_states_0.pkl
2025-10-01 08:04:02,548 Stage: Train 0.5 | Epoch: 421 | Iter: 480200 | Total Loss: 0.002343 | Recon Loss: 0.001957 | Commit Loss: 0.000772 | Perplexity: 2506.001013
2025-10-01 08:08:30,706 Stage: Train 0.5 | Epoch: 421 | Iter: 480400 | Total Loss: 0.002338 | Recon Loss: 0.001950 | Commit Loss: 0.000777 | Perplexity: 2499.432296
2025-10-01 08:12:59,710 Stage: Train 0.5 | Epoch: 421 | Iter: 480600 | Total Loss: 0.002334 | Recon Loss: 0.001947 | Commit Loss: 0.000775 | Perplexity: 2501.102183
Trainning Epoch:  96%|█████████▌| 633/658 [115:02:28<7:05:53, 1022.14s/it]Trainning Epoch:  96%|█████████▌| 633/658 [115:02:28<7:05:53, 1022.15s/it]2025-10-01 08:17:30,163 Stage: Train 0.5 | Epoch: 422 | Iter: 480800 | Total Loss: 0.002328 | Recon Loss: 0.001943 | Commit Loss: 0.000770 | Perplexity: 2507.652970
2025-10-01 08:21:54,303 Stage: Train 0.5 | Epoch: 422 | Iter: 481000 | Total Loss: 0.002363 | Recon Loss: 0.001980 | Commit Loss: 0.000765 | Perplexity: 2501.716063
2025-10-01 08:26:17,790 Stage: Train 0.5 | Epoch: 422 | Iter: 481200 | Total Loss: 0.002347 | Recon Loss: 0.001959 | Commit Loss: 0.000776 | Perplexity: 2505.049722
2025-10-01 08:30:40,347 Stage: Train 0.5 | Epoch: 422 | Iter: 481400 | Total Loss: 0.002357 | Recon Loss: 0.001971 | Commit Loss: 0.000772 | Perplexity: 2503.133331
Trainning Epoch:  96%|█████████▋| 634/658 [115:19:14<6:47:00, 1017.52s/it]Trainning Epoch:  96%|█████████▋| 634/658 [115:19:14<6:47:00, 1017.53s/it]2025-10-01 08:35:10,097 Stage: Train 0.5 | Epoch: 423 | Iter: 481600 | Total Loss: 0.002318 | Recon Loss: 0.001936 | Commit Loss: 0.000763 | Perplexity: 2497.583856
2025-10-01 08:39:37,394 Stage: Train 0.5 | Epoch: 423 | Iter: 481800 | Total Loss: 0.002371 | Recon Loss: 0.001983 | Commit Loss: 0.000778 | Perplexity: 2508.704999
2025-10-01 08:44:06,845 Stage: Train 0.5 | Epoch: 423 | Iter: 482000 | Total Loss: 0.002322 | Recon Loss: 0.001935 | Commit Loss: 0.000774 | Perplexity: 2502.899703
2025-10-01 08:48:36,093 Stage: Train 0.5 | Epoch: 423 | Iter: 482200 | Total Loss: 0.002342 | Recon Loss: 0.001955 | Commit Loss: 0.000773 | Perplexity: 2499.908251
Trainning Epoch:  97%|█████████▋| 635/658 [115:36:17<6:30:36, 1018.98s/it]Trainning Epoch:  97%|█████████▋| 635/658 [115:36:17<6:30:36, 1019.00s/it]2025-10-01 08:53:09,066 Stage: Train 0.5 | Epoch: 424 | Iter: 482400 | Total Loss: 0.002343 | Recon Loss: 0.001963 | Commit Loss: 0.000760 | Perplexity: 2502.043203
2025-10-01 08:57:36,929 Stage: Train 0.5 | Epoch: 424 | Iter: 482600 | Total Loss: 0.002344 | Recon Loss: 0.001959 | Commit Loss: 0.000770 | Perplexity: 2506.606692
2025-10-01 09:02:06,226 Stage: Train 0.5 | Epoch: 424 | Iter: 482800 | Total Loss: 0.002334 | Recon Loss: 0.001950 | Commit Loss: 0.000769 | Perplexity: 2496.959448
2025-10-01 09:06:34,045 Stage: Train 0.5 | Epoch: 424 | Iter: 483000 | Total Loss: 0.002341 | Recon Loss: 0.001952 | Commit Loss: 0.000778 | Perplexity: 2503.133026
Trainning Epoch:  97%|█████████▋| 636/658 [115:53:21<6:14:13, 1020.59s/it]Trainning Epoch:  97%|█████████▋| 636/658 [115:53:21<6:14:13, 1020.60s/it]2025-10-01 09:11:07,805 Stage: Train 0.5 | Epoch: 425 | Iter: 483200 | Total Loss: 0.002334 | Recon Loss: 0.001949 | Commit Loss: 0.000771 | Perplexity: 2505.155559
2025-10-01 09:15:37,205 Stage: Train 0.5 | Epoch: 425 | Iter: 483400 | Total Loss: 0.002311 | Recon Loss: 0.001923 | Commit Loss: 0.000777 | Perplexity: 2504.423427
2025-10-01 09:20:06,341 Stage: Train 0.5 | Epoch: 425 | Iter: 483600 | Total Loss: 0.002340 | Recon Loss: 0.001954 | Commit Loss: 0.000773 | Perplexity: 2503.761191
Trainning Epoch:  97%|█████████▋| 637/658 [116:10:29<5:57:56, 1022.69s/it]Trainning Epoch:  97%|█████████▋| 637/658 [116:10:29<5:57:56, 1022.69s/it]2025-10-01 09:24:39,403 Stage: Train 0.5 | Epoch: 426 | Iter: 483800 | Total Loss: 0.002352 | Recon Loss: 0.001962 | Commit Loss: 0.000780 | Perplexity: 2503.142454
2025-10-01 09:29:07,120 Stage: Train 0.5 | Epoch: 426 | Iter: 484000 | Total Loss: 0.002327 | Recon Loss: 0.001939 | Commit Loss: 0.000776 | Perplexity: 2501.842244
2025-10-01 09:33:34,817 Stage: Train 0.5 | Epoch: 426 | Iter: 484200 | Total Loss: 0.002341 | Recon Loss: 0.001957 | Commit Loss: 0.000767 | Perplexity: 2497.289847
2025-10-01 09:38:04,123 Stage: Train 0.5 | Epoch: 426 | Iter: 484400 | Total Loss: 0.002339 | Recon Loss: 0.001955 | Commit Loss: 0.000768 | Perplexity: 2505.355334
Trainning Epoch:  97%|█████████▋| 638/658 [116:27:32<5:40:57, 1022.88s/it]Trainning Epoch:  97%|█████████▋| 638/658 [116:27:32<5:40:57, 1022.89s/it]2025-10-01 09:42:37,062 Stage: Train 0.5 | Epoch: 427 | Iter: 484600 | Total Loss: 0.002328 | Recon Loss: 0.001943 | Commit Loss: 0.000770 | Perplexity: 2503.935631
2025-10-01 09:47:04,753 Stage: Train 0.5 | Epoch: 427 | Iter: 484800 | Total Loss: 0.002340 | Recon Loss: 0.001952 | Commit Loss: 0.000775 | Perplexity: 2505.385879
2025-10-01 09:51:32,397 Stage: Train 0.5 | Epoch: 427 | Iter: 485000 | Total Loss: 0.002360 | Recon Loss: 0.001976 | Commit Loss: 0.000769 | Perplexity: 2504.568365
2025-10-01 09:55:59,687 Stage: Train 0.5 | Epoch: 427 | Iter: 485200 | Total Loss: 0.002324 | Recon Loss: 0.001939 | Commit Loss: 0.000771 | Perplexity: 2501.869424
Trainning Epoch:  97%|█████████▋| 639/658 [116:44:34<5:23:49, 1022.63s/it]Trainning Epoch:  97%|█████████▋| 639/658 [116:44:34<5:23:50, 1022.64s/it]2025-10-01 10:00:32,761 Stage: Train 0.5 | Epoch: 428 | Iter: 485400 | Total Loss: 0.002323 | Recon Loss: 0.001934 | Commit Loss: 0.000780 | Perplexity: 2502.188988
2025-10-01 10:05:00,875 Stage: Train 0.5 | Epoch: 428 | Iter: 485600 | Total Loss: 0.002331 | Recon Loss: 0.001948 | Commit Loss: 0.000767 | Perplexity: 2507.064330
2025-10-01 10:09:29,666 Stage: Train 0.5 | Epoch: 428 | Iter: 485800 | Total Loss: 0.002360 | Recon Loss: 0.001974 | Commit Loss: 0.000773 | Perplexity: 2506.047554
2025-10-01 10:13:56,819 Stage: Train 0.5 | Epoch: 428 | Iter: 486000 | Total Loss: 0.002328 | Recon Loss: 0.001939 | Commit Loss: 0.000778 | Perplexity: 2499.153560
Trainning Epoch:  97%|█████████▋| 640/658 [117:01:37<5:06:48, 1022.72s/it]Trainning Epoch:  97%|█████████▋| 640/658 [117:01:37<5:06:48, 1022.72s/it]2025-10-01 10:18:23,942 Stage: Train 0.5 | Epoch: 429 | Iter: 486200 | Total Loss: 0.002343 | Recon Loss: 0.001955 | Commit Loss: 0.000775 | Perplexity: 2505.249458
2025-10-01 10:22:49,174 Stage: Train 0.5 | Epoch: 429 | Iter: 486400 | Total Loss: 0.002344 | Recon Loss: 0.001954 | Commit Loss: 0.000780 | Perplexity: 2504.132825
2025-10-01 10:27:14,683 Stage: Train 0.5 | Epoch: 429 | Iter: 486600 | Total Loss: 0.002315 | Recon Loss: 0.001924 | Commit Loss: 0.000783 | Perplexity: 2505.763251
2025-10-01 10:31:41,146 Stage: Train 0.5 | Epoch: 429 | Iter: 486800 | Total Loss: 0.002324 | Recon Loss: 0.001937 | Commit Loss: 0.000774 | Perplexity: 2504.182708
Trainning Epoch:  97%|█████████▋| 641/658 [117:18:28<4:48:47, 1019.27s/it]Trainning Epoch:  97%|█████████▋| 641/658 [117:18:28<4:48:47, 1019.27s/it]2025-10-01 10:36:15,026 Stage: Train 0.5 | Epoch: 430 | Iter: 487000 | Total Loss: 0.002322 | Recon Loss: 0.001931 | Commit Loss: 0.000783 | Perplexity: 2505.757474
2025-10-01 10:40:46,945 Stage: Train 0.5 | Epoch: 430 | Iter: 487200 | Total Loss: 0.002357 | Recon Loss: 0.001973 | Commit Loss: 0.000767 | Perplexity: 2496.174274
2025-10-01 10:45:17,822 Stage: Train 0.5 | Epoch: 430 | Iter: 487400 | Total Loss: 0.002342 | Recon Loss: 0.001950 | Commit Loss: 0.000784 | Perplexity: 2501.503267
Trainning Epoch:  98%|█████████▊| 642/658 [117:35:41<4:32:52, 1023.30s/it]Trainning Epoch:  98%|█████████▊| 642/658 [117:35:41<4:32:52, 1023.30s/it]2025-10-01 10:49:53,128 Stage: Train 0.5 | Epoch: 431 | Iter: 487600 | Total Loss: 0.002311 | Recon Loss: 0.001923 | Commit Loss: 0.000777 | Perplexity: 2496.587004
2025-10-01 10:54:25,251 Stage: Train 0.5 | Epoch: 431 | Iter: 487800 | Total Loss: 0.002333 | Recon Loss: 0.001952 | Commit Loss: 0.000763 | Perplexity: 2496.140815
2025-10-01 10:58:57,416 Stage: Train 0.5 | Epoch: 431 | Iter: 488000 | Total Loss: 0.002345 | Recon Loss: 0.001956 | Commit Loss: 0.000779 | Perplexity: 2504.231101
2025-10-01 11:03:30,677 Stage: Train 0.5 | Epoch: 431 | Iter: 488200 | Total Loss: 0.002337 | Recon Loss: 0.001946 | Commit Loss: 0.000782 | Perplexity: 2505.751085
Trainning Epoch:  98%|█████████▊| 643/658 [117:53:01<4:17:05, 1028.35s/it]Trainning Epoch:  98%|█████████▊| 643/658 [117:53:01<4:17:05, 1028.37s/it]2025-10-01 11:08:06,863 Stage: Train 0.5 | Epoch: 432 | Iter: 488400 | Total Loss: 0.002338 | Recon Loss: 0.001953 | Commit Loss: 0.000770 | Perplexity: 2504.640283
2025-10-01 11:12:35,929 Stage: Train 0.5 | Epoch: 432 | Iter: 488600 | Total Loss: 0.002340 | Recon Loss: 0.001949 | Commit Loss: 0.000782 | Perplexity: 2508.272479
2025-10-01 11:17:04,759 Stage: Train 0.5 | Epoch: 432 | Iter: 488800 | Total Loss: 0.002349 | Recon Loss: 0.001965 | Commit Loss: 0.000769 | Perplexity: 2499.854423
2025-10-01 11:21:34,455 Stage: Train 0.5 | Epoch: 432 | Iter: 489000 | Total Loss: 0.002344 | Recon Loss: 0.001958 | Commit Loss: 0.000772 | Perplexity: 2499.055781
Trainning Epoch:  98%|█████████▊| 644/658 [118:10:10<3:59:57, 1028.37s/it]Trainning Epoch:  98%|█████████▊| 644/658 [118:10:10<3:59:57, 1028.36s/it]2025-10-01 11:26:07,639 Stage: Train 0.5 | Epoch: 433 | Iter: 489200 | Total Loss: 0.002329 | Recon Loss: 0.001949 | Commit Loss: 0.000761 | Perplexity: 2500.580043
2025-10-01 11:30:38,614 Stage: Train 0.5 | Epoch: 433 | Iter: 489400 | Total Loss: 0.002356 | Recon Loss: 0.001969 | Commit Loss: 0.000773 | Perplexity: 2503.411183
2025-10-01 11:35:10,110 Stage: Train 0.5 | Epoch: 433 | Iter: 489600 | Total Loss: 0.002341 | Recon Loss: 0.001947 | Commit Loss: 0.000788 | Perplexity: 2505.749808
2025-10-01 11:39:40,378 Stage: Train 0.5 | Epoch: 433 | Iter: 489800 | Total Loss: 0.002350 | Recon Loss: 0.001957 | Commit Loss: 0.000785 | Perplexity: 2503.546520
Trainning Epoch:  98%|█████████▊| 645/658 [118:27:22<3:43:02, 1029.45s/it]Trainning Epoch:  98%|█████████▊| 645/658 [118:27:22<3:43:02, 1029.45s/it]2025-10-01 11:44:15,477 Stage: Train 0.5 | Epoch: 434 | Iter: 490000 | Total Loss: 0.002344 | Recon Loss: 0.001955 | Commit Loss: 0.000778 | Perplexity: 2509.396171
2025-10-01 11:48:46,966 Stage: Train 0.5 | Epoch: 434 | Iter: 490200 | Total Loss: 0.002327 | Recon Loss: 0.001937 | Commit Loss: 0.000780 | Perplexity: 2502.159240
2025-10-01 11:53:19,879 Stage: Train 0.5 | Epoch: 434 | Iter: 490400 | Total Loss: 0.002341 | Recon Loss: 0.001950 | Commit Loss: 0.000782 | Perplexity: 2502.958363
2025-10-01 11:57:51,186 Stage: Train 0.5 | Epoch: 434 | Iter: 490600 | Total Loss: 0.002367 | Recon Loss: 0.001983 | Commit Loss: 0.000769 | Perplexity: 2503.524600
Trainning Epoch:  98%|█████████▊| 646/658 [118:44:38<3:26:20, 1031.68s/it]Trainning Epoch:  98%|█████████▊| 646/658 [118:44:38<3:26:20, 1031.68s/it]2025-10-01 12:02:26,220 Stage: Train 0.5 | Epoch: 435 | Iter: 490800 | Total Loss: 0.002309 | Recon Loss: 0.001925 | Commit Loss: 0.000769 | Perplexity: 2498.342478
2025-10-01 12:06:57,935 Stage: Train 0.5 | Epoch: 435 | Iter: 491000 | Total Loss: 0.002352 | Recon Loss: 0.001964 | Commit Loss: 0.000777 | Perplexity: 2500.192140
2025-10-01 12:11:28,739 Stage: Train 0.5 | Epoch: 435 | Iter: 491200 | Total Loss: 0.002332 | Recon Loss: 0.001948 | Commit Loss: 0.000769 | Perplexity: 2505.884581
Trainning Epoch:  98%|█████████▊| 647/658 [119:01:53<3:09:19, 1032.67s/it]Trainning Epoch:  98%|█████████▊| 647/658 [119:01:53<3:09:19, 1032.67s/it]2025-10-01 12:16:02,646 Stage: Train 0.5 | Epoch: 436 | Iter: 491400 | Total Loss: 0.002355 | Recon Loss: 0.001961 | Commit Loss: 0.000787 | Perplexity: 2504.511477
2025-10-01 12:20:17,914 Stage: Train 0.5 | Epoch: 436 | Iter: 491600 | Total Loss: 0.002322 | Recon Loss: 0.001936 | Commit Loss: 0.000772 | Perplexity: 2500.705254
2025-10-01 12:24:37,466 Stage: Train 0.5 | Epoch: 436 | Iter: 491800 | Total Loss: 0.002341 | Recon Loss: 0.001955 | Commit Loss: 0.000771 | Perplexity: 2505.164209
2025-10-01 12:29:00,249 Stage: Train 0.5 | Epoch: 436 | Iter: 492000 | Total Loss: 0.002311 | Recon Loss: 0.001927 | Commit Loss: 0.000768 | Perplexity: 2502.631143
Trainning Epoch:  98%|█████████▊| 648/658 [119:18:27<2:50:10, 1021.03s/it]Trainning Epoch:  98%|█████████▊| 648/658 [119:18:27<2:50:10, 1021.04s/it]2025-10-01 12:33:32,679 Stage: Train 0.5 | Epoch: 437 | Iter: 492200 | Total Loss: 0.002308 | Recon Loss: 0.001919 | Commit Loss: 0.000778 | Perplexity: 2502.753932
2025-10-01 12:38:00,716 Stage: Train 0.5 | Epoch: 437 | Iter: 492400 | Total Loss: 0.002327 | Recon Loss: 0.001941 | Commit Loss: 0.000772 | Perplexity: 2502.348875
2025-10-01 12:42:28,233 Stage: Train 0.5 | Epoch: 437 | Iter: 492600 | Total Loss: 0.002324 | Recon Loss: 0.001931 | Commit Loss: 0.000785 | Perplexity: 2506.165192
2025-10-01 12:46:57,237 Stage: Train 0.5 | Epoch: 437 | Iter: 492800 | Total Loss: 0.002332 | Recon Loss: 0.001941 | Commit Loss: 0.000782 | Perplexity: 2502.533717
Trainning Epoch:  99%|█████████▊| 649/658 [119:35:31<2:33:16, 1021.87s/it]Trainning Epoch:  99%|█████████▊| 649/658 [119:35:31<2:33:16, 1021.88s/it]2025-10-01 12:51:30,284 Stage: Train 0.5 | Epoch: 438 | Iter: 493000 | Total Loss: 0.002349 | Recon Loss: 0.001961 | Commit Loss: 0.000776 | Perplexity: 2503.378538
2025-10-01 12:56:00,694 Stage: Train 0.5 | Epoch: 438 | Iter: 493200 | Total Loss: 0.002322 | Recon Loss: 0.001934 | Commit Loss: 0.000776 | Perplexity: 2500.746195
2025-10-01 13:00:30,290 Stage: Train 0.5 | Epoch: 438 | Iter: 493400 | Total Loss: 0.002345 | Recon Loss: 0.001956 | Commit Loss: 0.000777 | Perplexity: 2499.701516
2025-10-01 13:04:59,654 Stage: Train 0.5 | Epoch: 438 | Iter: 493600 | Total Loss: 0.002325 | Recon Loss: 0.001938 | Commit Loss: 0.000773 | Perplexity: 2507.033534
Trainning Epoch:  99%|█████████▉| 650/658 [119:52:40<2:16:32, 1024.04s/it]Trainning Epoch:  99%|█████████▉| 650/658 [119:52:40<2:16:32, 1024.04s/it]2025-10-01 13:09:32,947 Stage: Train 0.5 | Epoch: 439 | Iter: 493800 | Total Loss: 0.002344 | Recon Loss: 0.001953 | Commit Loss: 0.000782 | Perplexity: 2507.643733
2025-10-01 13:14:00,410 Stage: Train 0.5 | Epoch: 439 | Iter: 494000 | Total Loss: 0.002329 | Recon Loss: 0.001938 | Commit Loss: 0.000782 | Perplexity: 2500.163048
2025-10-01 13:18:30,427 Stage: Train 0.5 | Epoch: 439 | Iter: 494200 | Total Loss: 0.002319 | Recon Loss: 0.001932 | Commit Loss: 0.000775 | Perplexity: 2499.358616
2025-10-01 13:23:00,268 Stage: Train 0.5 | Epoch: 439 | Iter: 494400 | Total Loss: 0.002335 | Recon Loss: 0.001948 | Commit Loss: 0.000774 | Perplexity: 2497.073522
Trainning Epoch:  99%|█████████▉| 651/658 [120:09:47<1:59:35, 1025.01s/it]Trainning Epoch:  99%|█████████▉| 651/658 [120:09:47<1:59:35, 1025.00s/it]2025-10-01 13:27:35,398 Stage: Train 0.5 | Epoch: 440 | Iter: 494600 | Total Loss: 0.002307 | Recon Loss: 0.001921 | Commit Loss: 0.000771 | Perplexity: 2504.186136
2025-10-01 13:32:06,759 Stage: Train 0.5 | Epoch: 440 | Iter: 494800 | Total Loss: 0.002346 | Recon Loss: 0.001958 | Commit Loss: 0.000776 | Perplexity: 2500.774337
2025-10-01 13:36:36,364 Stage: Train 0.5 | Epoch: 440 | Iter: 495000 | Total Loss: 0.002339 | Recon Loss: 0.001950 | Commit Loss: 0.000778 | Perplexity: 2499.438770
Trainning Epoch:  99%|█████████▉| 652/658 [120:26:59<1:42:41, 1026.96s/it]Trainning Epoch:  99%|█████████▉| 652/658 [120:26:59<1:42:41, 1026.98s/it]2025-10-01 13:41:09,739 Stage: Train 0.5 | Epoch: 441 | Iter: 495200 | Total Loss: 0.002339 | Recon Loss: 0.001951 | Commit Loss: 0.000777 | Perplexity: 2503.852325
2025-10-01 13:45:36,645 Stage: Train 0.5 | Epoch: 441 | Iter: 495400 | Total Loss: 0.002311 | Recon Loss: 0.001925 | Commit Loss: 0.000772 | Perplexity: 2499.936154
2025-10-01 13:50:06,352 Stage: Train 0.5 | Epoch: 441 | Iter: 495600 | Total Loss: 0.002331 | Recon Loss: 0.001946 | Commit Loss: 0.000770 | Perplexity: 2502.103557
2025-10-01 13:54:37,217 Stage: Train 0.5 | Epoch: 441 | Iter: 495800 | Total Loss: 0.002321 | Recon Loss: 0.001933 | Commit Loss: 0.000776 | Perplexity: 2503.253140
Trainning Epoch:  99%|█████████▉| 653/658 [120:44:08<1:25:38, 1027.61s/it]Trainning Epoch:  99%|█████████▉| 653/658 [120:44:08<1:25:38, 1027.60s/it]2025-10-01 13:59:13,337 Stage: Train 0.5 | Epoch: 442 | Iter: 496000 | Total Loss: 0.002325 | Recon Loss: 0.001936 | Commit Loss: 0.000777 | Perplexity: 2506.991710
2025-10-01 14:03:40,293 Stage: Train 0.5 | Epoch: 442 | Iter: 496200 | Total Loss: 0.002325 | Recon Loss: 0.001936 | Commit Loss: 0.000779 | Perplexity: 2508.004967
2025-10-01 14:08:07,174 Stage: Train 0.5 | Epoch: 442 | Iter: 496400 | Total Loss: 0.002331 | Recon Loss: 0.001947 | Commit Loss: 0.000770 | Perplexity: 2500.856469
2025-10-01 14:12:39,160 Stage: Train 0.5 | Epoch: 442 | Iter: 496600 | Total Loss: 0.002341 | Recon Loss: 0.001954 | Commit Loss: 0.000775 | Perplexity: 2501.181761
Trainning Epoch:  99%|█████████▉| 654/658 [121:01:12<1:08:25, 1026.48s/it]Trainning Epoch:  99%|█████████▉| 654/658 [121:01:12<1:08:25, 1026.50s/it]2025-10-01 14:17:11,014 Stage: Train 0.5 | Epoch: 443 | Iter: 496800 | Total Loss: 0.002321 | Recon Loss: 0.001931 | Commit Loss: 0.000779 | Perplexity: 2504.623450
2025-10-01 14:21:41,688 Stage: Train 0.5 | Epoch: 443 | Iter: 497000 | Total Loss: 0.002332 | Recon Loss: 0.001943 | Commit Loss: 0.000778 | Perplexity: 2505.178372
2025-10-01 14:26:13,292 Stage: Train 0.5 | Epoch: 443 | Iter: 497200 | Total Loss: 0.002341 | Recon Loss: 0.001952 | Commit Loss: 0.000777 | Perplexity: 2498.152650
2025-10-01 14:30:42,481 Stage: Train 0.5 | Epoch: 443 | Iter: 497400 | Total Loss: 0.002326 | Recon Loss: 0.001934 | Commit Loss: 0.000783 | Perplexity: 2506.187052
Trainning Epoch: 100%|█████████▉| 655/658 [121:18:23<51:23, 1027.92s/it]  Trainning Epoch: 100%|█████████▉| 655/658 [121:18:23<51:23, 1027.92s/it]  2025-10-01 14:35:14,152 Stage: Train 0.5 | Epoch: 444 | Iter: 497600 | Total Loss: 0.002301 | Recon Loss: 0.001917 | Commit Loss: 0.000768 | Perplexity: 2500.454503
2025-10-01 14:39:42,984 Stage: Train 0.5 | Epoch: 444 | Iter: 497800 | Total Loss: 0.002340 | Recon Loss: 0.001949 | Commit Loss: 0.000781 | Perplexity: 2501.932769
2025-10-01 14:44:11,231 Stage: Train 0.5 | Epoch: 444 | Iter: 498000 | Total Loss: 0.002336 | Recon Loss: 0.001944 | Commit Loss: 0.000783 | Perplexity: 2502.770551
2025-10-01 14:48:39,511 Stage: Train 0.5 | Epoch: 444 | Iter: 498200 | Total Loss: 0.002328 | Recon Loss: 0.001940 | Commit Loss: 0.000776 | Perplexity: 2499.851316
Trainning Epoch: 100%|█████████▉| 656/658 [121:35:27<34:13, 1026.58s/it]Trainning Epoch: 100%|█████████▉| 656/658 [121:35:27<34:13, 1026.58s/it]2025-10-01 14:53:10,086 Stage: Train 0.5 | Epoch: 445 | Iter: 498400 | Total Loss: 0.002316 | Recon Loss: 0.001926 | Commit Loss: 0.000779 | Perplexity: 2501.785345
2025-10-01 14:57:35,651 Stage: Train 0.5 | Epoch: 445 | Iter: 498600 | Total Loss: 0.002327 | Recon Loss: 0.001939 | Commit Loss: 0.000775 | Perplexity: 2501.827146
2025-10-01 15:02:01,246 Stage: Train 0.5 | Epoch: 445 | Iter: 498800 | Total Loss: 0.002331 | Recon Loss: 0.001941 | Commit Loss: 0.000780 | Perplexity: 2504.637239
Trainning Epoch: 100%|█████████▉| 657/658 [121:52:23<17:03, 1023.45s/it]Trainning Epoch: 100%|█████████▉| 657/658 [121:52:23<17:03, 1023.45s/it]2025-10-01 15:06:34,444 Stage: Train 0.5 | Epoch: 446 | Iter: 499000 | Total Loss: 0.002322 | Recon Loss: 0.001933 | Commit Loss: 0.000779 | Perplexity: 2507.470242
2025-10-01 15:11:02,290 Stage: Train 0.5 | Epoch: 446 | Iter: 499200 | Total Loss: 0.002338 | Recon Loss: 0.001954 | Commit Loss: 0.000767 | Perplexity: 2498.534355
2025-10-01 15:15:31,894 Stage: Train 0.5 | Epoch: 446 | Iter: 499400 | Total Loss: 0.002312 | Recon Loss: 0.001927 | Commit Loss: 0.000771 | Perplexity: 2507.699858
2025-10-01 15:20:02,441 Stage: Train 0.5 | Epoch: 446 | Iter: 499600 | Total Loss: 0.002344 | Recon Loss: 0.001951 | Commit Loss: 0.000786 | Perplexity: 2509.252369
Trainning Epoch: 100%|██████████| 658/658 [122:09:32<00:00, 1025.26s/it]Trainning Epoch: 100%|██████████| 658/658 [122:09:32<00:00, 1025.27s/it]2025-10-01 15:24:35,046 Stage: Train 0.5 | Epoch: 447 | Iter: 499800 | Total Loss: 0.002339 | Recon Loss: 0.001945 | Commit Loss: 0.000789 | Perplexity: 2501.130457
2025-10-01 15:28:58,546 Stage: Train 0.5 | Epoch: 447 | Iter: 500000 | Total Loss: 0.002319 | Recon Loss: 0.001933 | Commit Loss: 0.000771 | Perplexity: 2502.612740
2025-10-01 15:28:58,546 Saving model at iteration 500000
2025-10-01 15:28:58,768 Saving current state to vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_448_step_500000
2025-10-01 15:28:59,341 Model weights saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_448_step_500000/model.safetensors
2025-10-01 15:28:59,816 Optimizer state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_448_step_500000/optimizer.bin
2025-10-01 15:28:59,816 Scheduler state saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_448_step_500000/scheduler.bin
2025-10-01 15:28:59,816 Sampler state for dataloader 0 saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_448_step_500000/sampler.bin
2025-10-01 15:28:59,817 Random states saved in vqvae_experiment/joint_and_image/joint3d_image_affined_192x256/f16s1d16_cb4096x2048_mpjpe_Tdown1-2/hrFix_lvl3_ratio0.5/models/checkpoint_epoch_448_step_500000/random_states_0.pkl
Trainning Epoch: 100%|██████████| 658/658 [122:15:48<00:00, 984.67s/it] 
Trainning Epoch: 100%|██████████| 658/658 [122:15:48<00:00, 984.67s/it] 
2025-10-01 15:29:00,933 Training finished
[rank0]:[W1001 15:29:01.194326399 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
